[
  {
    "id": "page_0",
    "url": "https://en.wikipedia.org/wiki/Artificial_intelligence",
    "domain": "en.wikipedia.org",
    "title": "Artificial intelligence - Wikipedia",
    "text": "Artificial intelligence | Part of a series on | | Artificial intelligence (AI) | |---| Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[2][3] Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.[a] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[4] Some companies, such as OpenAI, Google DeepMind and Meta,[5] aim to create artificial general intelligence (AGI) – AI that can complete virtually any cognitive task at least as well as a human. Artificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture.[12] In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms. Ethical concerns have been raised about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology. Goals The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a] Reasoning and problem-solving Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14] Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem. Knowledge representation Knowledge representation and knowledge engineering[17] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[18] scene interpretation,[19] clinical decision support,[20] knowledge discovery (mining \"interesting\" and actionable inferences from large databases),[21] and other areas.[22] A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[23] Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;[24] situations, events, states, and time;[25] causes and effects;[26] knowledge about knowledge (what we know about what other people know);[27] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[28] and many other aspects and domains of knowledge. Among the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[29] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).[16] There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.[c] Planning and decision-making An \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][32] In automated planning, the agent has a specific goal.[33] In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[34] In classical planning, the agent knows exactly what the effect of any action will be.[35] In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[36] In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences.[37] Information value theory can be used to weigh the value of exploratory or experimental actions.[38] The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be. A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.[39] Game theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.[40] Learning Machine learning is the study of programs that can improve their performance on a given task automatically.[41] It has been a part of AI from the beginning.[e] There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[44] Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[45] In reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".[46] Transfer learning is when the knowledge gained from one problem is applied to a new problem.[47] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[48] Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[49] Natural language processing Natural language processing (NLP) allows programs to read, write and communicate in human languages.[50] Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[51] Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f] unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem[29]). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure. Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[52] transformers (a deep learning architecture using an attention mechanism),[53] and others.[54] In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text,[55][56] and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[57] Perception Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[58] The field includes speech recognition,[59] image classification,[60] facial recognition, object recognition,[61] object tracking,[62] and robotic perception.[63] Social intelligence Affective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood.[65] For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction. However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.[66] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject.[67] General intelligence A machine with artificial general intelligence would be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[68] Techniques AI research uses a wide variety of techniques to accomplish the goals above.[b] Search and optimization AI can solve many problems by intelligently searching through many possible solutions.[69] There are two very different kinds of search used in AI: state space search and local search. State space search State space search searches through a tree of possible states to try to find a goal state.[70] For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[71] Simple exhaustive searches[72] are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.[15] \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.[73] Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.[74] Local search Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.[75] Gradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks,[76] through the backpropagation algorithm. Another type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.[77] Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[78] Logic Formal logic is used for reasoning and knowledge representation.[79] Formal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")[80] and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").[81] Deductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises).[82] Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules. Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem.[83] In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.[84] Inference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.[85] Fuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.[86] Non-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning.[28] Other specialized versions of logic have been developed to describe many complex domains. Probabilistic methods for uncertain reasoning Many problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[87] Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[88] and information value theory.[89] These tools include models such as Markov decision processes,[90] dynamic decision networks,[91] game theory and mechanism design.[92] Bayesian networks[93] are a tool that can be used for reasoning (using the Bayesian inference algorithm),[g][95] learning (using the expectation–maximization algorithm),[h][97] planning (using decision networks)[98] and perception (using dynamic Bayesian networks).[91] Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[91] Classifiers and statistical learning methods The simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers[99] are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[45] There are many kinds of classifiers in use.[100] The decision tree is the simplest and most widely used symbolic machine learning algorithm.[101] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[102] The naive Bayes classifier is reportedly the \"most widely used learner\"[103] at Google, due in part to its scalability.[104] Neural networks are also used as classifiers.[105] Artificial neural networks An artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.[105] Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[106] Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[107] In feedforward neural networks the signal passes in only one direction.[108] The term perceptron typically refers to a single-layer neural network.[109] In contrast, deep learning uses many layers.[110] Recurrent neural networks (RNNs) feed the output signal back into the input, which allows short-term memories of previous input events. Long short-term memory networks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to the vanishing gradient problem.[111] Convolutional neural networks (CNNs) use layers of kernels to more efficiently process local patterns. This local processing is especially important in image processing, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects.[112] Deep learning Deep learning uses several layers of neurons between the network's inputs and outputs.[110] The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.[114] Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification,[115] and others. The reason that deep learning performs so well in so many applications is not known as of 2021.[116] The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[i] but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[j] GPT Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.[124] Such systems are used in chatbots, which allow people to ask a question or request a task in simple text.[125][126] Current models and services include ChatGPT, Claude, Gemini, Copilot, and Meta AI.[127] Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.[128] Hardware and software In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[129] Specialized programming languages such as Prolog were used in early AI research,[130] but general-purpose programming languages like Python have become predominant.[131] The transistor density in integrated circuits has been observed to roughly double every 18 months—a trend known as Moore's law, named after the Intel co-founder Gordon Moore, who first identified it. Improvements in GPUs have been even faster,[132] a trend sometimes called Huang's law,[133] named after Nvidia co-founder and CEO Jensen Huang. Applications AI and machine learning technology is used in most of the essential applications of the 2020s, including: - search engines (such as Google Search) - targeting online advertisements - recommendation systems (offered by Netflix, YouTube or Amazon) driving internet traffic - targeted advertising (AdSense, Facebook) - virtual assistants (such as Siri or Alexa) - autonomous vehicles (including drones, ADAS and self-driving cars) - automatic language translation (Microsoft Translator, Google Translate) - facial recognition (Apple's FaceID or Microsoft's DeepFace and Google's FaceNet) - image labeling (used by Facebook, Apple's Photos and TikTok). The deployment of AI may be overseen by a chief automation officer (CAO). Health and medicine It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.[134] AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[135] In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.[136] In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.[137][138] Games Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques.[139] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[140] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[141] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world.[142] Other programs handle imperfect-information games, such as the poker-playing program Pluribus.[143] DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games.[144] In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.[145] In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.[146] In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.[147] Mathematics Large language models, such as GPT-4, Gemini, Claude, Llama or Mistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning[148] or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections.[149] A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.[150] One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result.[151] The Alibaba Group developed a version of its Qwen models called Qwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems.[152] In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53% of the AIME 2024 and 90% of the MATH benchmark problems.[153] Alternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor, AlphaGeometry, AlphaProof and AlphaEvolve[154] all from Google DeepMind,[155] Llemma from EleutherAI[156] or Julius.[157] When natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks. The experimental model Gemini Deep Think accepts natural language prompts directly and achieved gold medal results in the International Math Olympiad of 2025.[158] Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.[159] Topological deep learning integrates various topological approaches. Finance Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.[160] According to Nicolas Firzli, director of the World Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"[161] Military Various countries are deploying AI military applications.[162] The main applications enhance command and control, communications, sensors, integration and interoperability.[163] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[162] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous.[163] AI has been used in military operations in Iraq, Syria, Israel and Ukraine.[162][164][165][166] Generative AI Generative artificial intelligence (Generative AI or GenAI) is a subfield of artificial intelligence that uses generative models to generate text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data[167] in response to input, which often comes in the form of natural language prompts.[168][169] The prevalence of generative AI tools has increased significantly since the AI boom in the 2020s. This boom was made possible by improvements in deep neural networks, particularly large language models (LLMs), which are based on the transformer architecture. Major tools include LLM-based chatbots such as ChatGPT, Claude, Copilot, DeepSeek, Google Gemini and Grok; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo, LTX and Sora.[170][171][172] Technology companies developing generative AI include Alibaba, Anthropic, Baidu, DeepSeek, Google, Lightricks,[173] Meta AI, Microsoft, Mistral AI, OpenAI, Perplexity AI, xAI,[174] and Yandex.[175] Generative AI has been adopted in a variety of sectors, including software development, healthcare,[176] finance,[177] entertainment,[178] customer service,[179] sales and marketing,[180] art, writing,[181] and product design.[182] Agents AI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.[183][184][185] Web search Microsoft introduced Copilot Search in February 2023 under the name Bing Chat, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summaries[186] and step-by-step reasoning based of information from web publishers, ranked in Bing Search.[187] For safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content.[188] Google officially pushed its AI Search at its Google I/O event on 20 May 2025.[189] It keeps people looking at Google instead of clicking on a search result. AI Overviews uses Gemini 2.5 to provide contextual answers to user queries based on web content.[190] Sexuality Applications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,[191] AI-integrated sex toys (e.g., teledildonics),[192] AI-generated sexual education content,[193] and AI agents that simulate sexual and romantic partners (e.g., Replika).[194] AI is also used for the production of non-consensual deepfake pornography, raising significant ethical and legal concerns.[195] AI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.[196][197] Other industry-specific tasks There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.[198] A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management. AI applications for evacuation and disaster management are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions.[199][200][201] In agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water. Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation. During the 2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.[202] Ethics AI has potential benefits and potential risks.[205] AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\".[206] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[207][208] In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.[209] Risks and harm Privacy and copyright Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright. AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency. Sensitive user data collected may include online activity records, geolocation data, video, or audio.[210] For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them.[211] Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[212] AI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[213] Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\"[214] Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".[215][216] Website owners can indicate that they do not want their content scraped via a \"robots.txt\" file.[217] However, some companies will scrape content regardless[218][219] because the robots.txt file has no real authority. In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[220][221] Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.[222] Dominance by tech giants The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft.[223][224][225] Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.[226][227] Power needs and environmental impacts In January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use.[229] This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.[230] Prodigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.[231] A 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.[232] Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.[233] In 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million.[234] Nvidia CEO Jensen Huang said nuclear power is a good option for the data centers.[235] In September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act.[236] The US government and the state of Michigan are investing almost US$2 billion to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon's spinoff of Constellation.[237] After the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages.[238] Taiwan aims to phase out nuclear power by 2025.[238] On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.[238] Although most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.[239] Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.[239] On 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center.[240] According to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.[240] In 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it.[241] Misinformation YouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[242] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[243] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.[244] In the early 2020s, generative AI began to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,[245] while realistic AI-generated videos became feasible in the mid-2020s.[246][247][248] It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;[249] one such potential malicious use is deepfakes for computational propaganda.[250] AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.[251] The ability to influence electorates has been proved in at least one study. This same study shows more inaccurate statements from the models when they advocate for candidates of the political right.[252] AI researchers at Microsoft, OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models.[253] Algorithmic bias and fairness Machine learning applications can be biased[k] if they learn from biased data.[255] The developers may not be aware that the bias exists.[256] Discriminatory behavior by some LLMs can be observed in their output.[257] Bias can be introduced by the way training data is selected and by the way a model is deployed.[258][255] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[259] The field of fairness studies how to prevent harms from algorithmic biases. On 28 June 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,[260] a problem called \"sample size disparity\".[261] Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[262] COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[263] In 2017, several researchers[l] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[265] A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".[266] Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"[267] Criticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist.[268] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.[m] Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[261] There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.[254] At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.[dubious – discuss][270] Lack of transparency Many AI systems are so complex that their designers cannot explain how they reach their decisions.[271] Particularly with deep neural networks, in which there are many non-linear relationships between inputs and outputs. But some popular explainability techniques exist.[272] It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.[273] Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.[274] People who have been harmed by an algorithm's decision have a right to an explanation.[275] Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.[n] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[276] DARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.[277] Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.[278] LIME can locally approximate a model's outputs with a simpler, interpretable model.[279] Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[280] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.[281] For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.[282] Bad actors and weaponized AI Artificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states. A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[o] Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction.[284] Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person.[284] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.[285] By 2015, over fifty countries were reported to be researching battlefield robots.[286] AI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision-making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware.[287] All these technologies have been available since 2020 or earlier—AI facial recognition systems are already being used for mass surveillance in China.[288][289] There are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.[290] Technological unemployment Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[291] In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI.[292] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[293] Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".[p][295] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.[291] In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.[296][297] Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[298] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[299] In July 2025, Ford CEO Jim Farley predicted that \"artificial intelligence is going to replace literally half of all white-collar workers in the U.S.\"[300] From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[301] Existential risk It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\".[302] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.[q] These sci-fi scenarios are misleading in several ways. First, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of an automated paperclip factory that destroys the world to get more iron for paperclips).[304] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\"[305] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".[306] Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are built on language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[307] Geoffrey Hinton said in 2025 that modern AI is particularly \"good at persuasion\" and getting better all the time. He asks \"Suppose you wanted to invade the capital of the US. Do you have to go there and do it yourself? No. You just have to be good at persuasion.\"[308] The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[309] Personalities such as Stephen Hawking, Bill Gates, and Elon Musk,[310] as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI. In May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\".[311] He notably mentioned risks of an AI takeover,[312] and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.[313] In 2023, many leading AI experts endorsed the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".[314] Some other researchers were more optimistic. AI pioneer Jürgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"[315] While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"[316][317] Andrew Ng also argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\"[318] Yann LeCun \"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"[319] In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[320] However, after 2016, the study of current and future risks and possible solutions became a serious area of research.[321] Ethical machines and alignment Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[322] Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[323] The field of machine ethics is also called computational morality,[323] and was founded at an AAAI symposium in 2005.[324] Other approaches include Wendell Wallach's \"artificial moral agents\"[325] and Stuart J. Russell's three principles for developing provably beneficial machines.[326] Open source Active organizations in the AI open-source community include Hugging Face,[327] Google,[328] EleutherAI and Meta.[329] Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight,[330][331] meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case.[332] Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.[333] Frameworks Artificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows:[334][335] - Respect the dignity of individual people - Connect with other people sincerely, openly, and inclusively - Care for the wellbeing of everyone - Protect social values, justice, and the public interest Other developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;[336] however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks.[337] Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.[338] The UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.[339] Regulation The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.[340] The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[341] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[342][343] Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[344] Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[344] The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[344] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[345] In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[346] In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.[347] On 1 August 2024, the EU Artificial Intelligence Act entered into force, establishing the first comprehensive EU-wide AI regulation.[348] In 2024, the Council of Europe created the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.[349] In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".[342] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[350] In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".[351][352] In November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[353] 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.[354][355] In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.[356][357] History The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.[359][360] This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\".[r] They developed several areas of research that would become part of AI,[362] such as McCulloch and Pitts design for \"artificial neurons\" in 1943,[117] and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that \"machine intelligence\" was plausible.[363][360] The field of AI research was founded at a workshop at Dartmouth College in 1956.[s][6] The attendees became the leaders of AI research in the 1960s.[t] They and their students produced programs that the press described as \"astonishing\":[u] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[v][7] Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.[360] Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.[367] In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".[368] In 1967 Marvin Minsky agreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".[369] They had, however, underestimated the difficulty of the problem.[w] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[371] and ongoing pressure from the U.S. Congress to fund more productive projects.[372] Minsky and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.[373] The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.[9] In the early 1980s, AI research was revived by the commercial success of expert systems,[374] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[8] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[10] Up to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition,[375] and began to look into \"sub-symbolic\" approaches.[376] Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive.[x] Judea Pearl, Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[87][381] But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others.[382] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[383] AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[384] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the AI effect).[385] However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.[68] Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[11] For many specific tasks, other methods were abandoned.[y] Deep learning's success was based on both hardware improvements (faster computers,[387] graphics processing units, cloud computing[388]) and access to large amounts of data[389] (including curated datasets,[388] such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.[z] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.[344] In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[321] In the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text.[390] ChatGPT, launched on 30 November 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.[391] It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.[392] These programs, and others, inspired an aggressive AI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".[393] About 800,000 \"AI\"-related U.S. job openings existed in 2022.[394] According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies.[395] Philosophy Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.[396] Another major focus has been whether machines can be conscious, and the associated ethical implications.[397] Many other topics in philosophy are relevant to AI, such as epistemology and free will.[398] Rapid advancements have intensified public discussions on the philosophy and ethics of AI.[397] Defining artificial intelligence Alan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\"[399] He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".[399] He devised the Turing test, which measures the ability of a machine to simulate human conversation.[363] Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"[400] Russell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.[1] However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\"[402] AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".[403] McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".[404] Another AI founder, Marvin Minsky, similarly describes it as \"the ability to solve hard problems\".[405] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.[1] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine – and no other philosophical discussion is required, or may not even be possible. Another definition has been adopted by Google,[406] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence. As a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itself[407] including discussing the many AI narratives and myths to be found within societal, political and academic discourses.[408] Similarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,[409] with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".[410] There has been debate over whether large language models exhibit genuine intelligence or merely simulate it by imitating human text.[411] Evaluating approaches to AI No established unifying theory or paradigm has guided AI research for most of its history.[aa] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers. Symbolic AI and its limits Symbolic AI (or \"GOFAI\")[413] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"[414] However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.[415] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.[416] Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.[ab][16] The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[418][419] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches. Neat vs. scruffy \"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,[420] but eventually was seen as irrelevant. Modern AI has elements of both. Soft vs. hard computing Finding a provably correct or optimal solution is intractable for many important problems.[15] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks. Narrow vs. general AI AI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.[421][422] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively. Machine consciousness, sentience, and mind There is no settled consensus in philosophy of mind on whether a machine can have a mind, consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"[423] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction. Consciousness David Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[424] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[425] Computationalism and functionalism Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[426] Philosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[ac] Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.[430] AI welfare and rights It is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree.[431] But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.[432][433] Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights.[432] Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.[434] In 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.[435] Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own.[436][437] Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.[433][432] Future Superintelligence and the singularity A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[422] If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".[438] However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[439] Transhumanism Robot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger.[440] Edward Fredkin argues that \"artificial intelligence is the next step in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.[441] In fiction Thought-capable artificial beings have appeared as storytelling devices since antiquity,[442] and have been a persistent theme in science fiction.[443] A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[444] Isaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;[445] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[446] Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[447] See also - Artificial consciousness – Field in cognitive science - Artificial intelligence and elections – Impact of AI on political elections - Artificial intelligence content detection – Software to detect AI-generated content - Artificial intelligence in Wikimedia projects – Use of artificial intelligence to develop Wikipedia and other Wikimedia projects - Association for the Advancement of Artificial Intelligence (AAAI) - Behavior selection algorithm – Algorithm that selects actions for intelligent agents - Business process automation – Automation of business processes - Case-based reasoning – Process of solving new problems based on the solutions of similar past problems - Computational intelligence – Ability of a computer to learn a specific task from data or experimental observation - DARWIN EU – A European Union initiative coordinated by the European Medicines Agency (EMA) to generate and utilize real world evidence (RWE) to support the evaluation and supervision of medicines across the EU - Digital immortality – Hypothetical concept of storing a personality in digital form - Emergent algorithm – Algorithm exhibiting emergent behavior - Female gendering of AI technologies – Gender biases in digital technology - Glossary of artificial intelligence – List of concepts in artificial intelligence - Intelligence amplification – Use of information technology to augment human intelligence - Intelligent agent – Software agent which acts autonomously - Intelligent automation – Software process that combines robotic process automation and artificial intelligence - List of artificial intelligence books - List of artificial intelligence journals - List of artificial intelligence projects - Mind uploading – Hypothetical process of digitally emulating a brain - Organoid intelligence – Use of brain cells and brain organoids for intelligent computing - Pseudorandomness – Appearing random but actually being generated by a deterministic, causal process - Robotic process automation – Form of business process automation technology - The Last Day – 1967 Welsh science fiction novel - Wetware computer – Computer composed of organic material Explanatory notes - ^ a b This list of intelligent traits is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998) - ^ a b This list of tools is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998) - ^ It is among the reasons that expert systems proved to be inefficient for capturing knowledge.[30][31] - ^ \"Rational agent\" is general term used in economics, philosophy and theoretical artificial intelligence. It can refer to anything that directs its behavior to accomplish goals, such as a person, an animal, a corporation, a nation, or in the case of AI, a computer program. - ^ Alan Turing discussed the centrality of learning as early as 1950, in his classic paper \"Computing Machinery and Intelligence\".[42] In 1956, at the original Dartmouth AI summer conference, Ray Solomonoff wrote a report on unsupervised probabilistic machine learning: \"An Inductive Inference Machine\".[43] - ^ See AI winter § Machine translation and the ALPAC report of 1966. - ^ Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. AdSense uses a Bayesian network with over 300 million edges to learn which ads to serve.[94] - ^ Expectation–maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown latent variables.[96] - ^ Some form of deep neural networks (without a specific learning algorithm) were described by: Warren S. McCulloch and Walter Pitts (1943)[117] Alan Turing (1948);[118] Karl Steinbuch and Roger David Joseph (1961).[119] Deep or recurrent networks that learned (or used gradient descent) were developed by: Frank Rosenblatt(1957);[118] Oliver Selfridge (1959);[119] Alexey Ivakhnenko and Valentin Lapa (1965);[120] Kaoru Nakano (1971);[121] Shun-Ichi Amari (1972);[121] John Joseph Hopfield (1982).[121] Precursors to backpropagation were developed by: Henry J. Kelley (1960);[118] Arthur E. Bryson (1962);[118] Stuart Dreyfus (1962);[118] Arthur E. Bryson and Yu-Chi Ho (1969);[118] Backpropagation was independently developed by: Seppo Linnainmaa (1970);[122] Paul Werbos (1974).[118] - ^ Geoffrey Hinton said, of his work on neural networks in the 1990s, \"our labeled datasets were thousands of times too small. [And] our computers were millions of times too slow.\"[123] - ^ In statistics, a bias is a systematic error or deviation from the correct value. But in the context of fairness, it refers to a tendency in favor or against a certain group or individual characteristic, usually in a way that is considered unfair or harmful. A statistically unbiased AI system that produces disparate outcomes for different demographic groups may thus be viewed as biased in the ethical sense.[254] - ^ Including Jon Kleinberg (Cornell University), Sendhil Mullainathan (University of Chicago), Cynthia Chouldechova (Carnegie Mellon) and Sam Corbett-Davis (Stanford)[264] - ^ Moritz Hardt (a director at the Max Planck Institute for Intelligent Systems) argues that machine learning \"is fundamentally the wrong tool for a lot of domains, where you're trying to design interventions and mechanisms that change the world.\"[269] - ^ When the law was passed in 2018, it still contained a form of this provision. - ^ This is the United Nations' definition, and includes things like land mines as well.[283] - ^ See table 4; 9% is both the OECD average and the U.S. average.[294] - ^ Sometimes called a \"robopocalypse\"[303] - ^ \"Electronic brain\" was the term used by the press around this time.[359][361] - ^ Daniel Crevier wrote, \"the conference is generally recognized as the official birthdate of the new science.\"[364] Russell and Norvig called the conference \"the inception of artificial intelligence.\"[117] - ^ Russell and Norvig wrote \"for the next 20 years the field would be dominated by these people and their students.\"[365] - ^ Russell and Norvig wrote, \"it was astonishing whenever a computer did anything kind of smartish\".[366] - ^ The programs described are Arthur Samuel's checkers program for the IBM 701, Daniel Bobrow's STUDENT, Newell and Simon's Logic Theorist and Terry Winograd's SHRDLU. - ^ Russell and Norvig write: \"in almost all cases, these early systems failed on more difficult problems\"[370] - ^ Embodied approaches to AI[377] were championed by Hans Moravec[378] and Rodney Brooks[379] and went by many names: Nouvelle AI.[379] Developmental robotics.[380] - ^ Matteo Wong wrote in The Atlantic: \"Whereas for decades, computer-science fields such as natural-language processing, computer vision, and robotics used extremely different methods, now they all use a programming method called \"deep learning\". As a result, their code and approaches have become more similar, and their models are easier to integrate into one another.\"[386] - ^ Jack Clark wrote in Bloomberg: \"After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever\", and noted that the number of software projects that use machine learning at Google increased from a \"sporadic usage\" in 2012 to more than 2,700 projects in 2015.[388] - ^ Nils Nilsson wrote in 1983: \"Simply put, there is wide disagreement in the field about what AI is all about.\"[412] - ^ Daniel Crevier wrote that \"time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier.\"[417] - ^ Searle presented this definition of \"Strong AI\" in 1999.[427] Searle's original formulation was \"The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states.\"[428] Strong AI is defined similarly by Russell and Norvig: \"Stong AI – the assertion that machines that do so are actually thinking (as opposed to simulating thinking).\"[429] References - ^ a b c Russell & Norvig (2021), pp. 1–4. - ^ AI set to exceed human brain power Archived 19 February 2008 at the Wayback Machine CNN.com (26 July 2006) - ^ Kaplan, Andreas; Haenlein, Michael (2019). \"Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence\". Business Horizons. 62: 15–25. doi:10.1016/j.bushor.2018.08.004. [the question of the source is a pastiche of: Snow White] - ^ Russell & Norvig (2021, §1.2). - ^ \"Tech companies want to build artificial general intelligence. But who decides when AGI is attained?\". AP News. 4 April 2024. Retrieved 20 May 2025. - ^ a b Dartmouth workshop: Russell & Norvig (2021, p. 18), McCorduck (2004, pp. 111–136), NRC (1999, pp. 200–201) The proposal: McCarthy et al. (1955) - ^ a b Successful programs of the 1960s: McCorduck (2004, pp. 243–252), Crevier (1993, pp. 52–107), Moravec (1988, p. 9), Russell & Norvig (2021, pp. 19–21) - ^ a b Funding initiatives in the early 1980s: Fifth Generation Project (Japan), Alvey (UK), Microelectronics and Computer Technology Corporation (US), Strategic Computing Initiative (US): McCorduck (2004, pp. 426–441), Crevier (1993, pp. 161–162, 197–203, 211, 240), Russell & Norvig (2021, p. 23), NRC (1999, pp. 210–211), Newquist (1994, pp. 235–248) - ^ a b First AI Winter, Lighthill report, Mansfield Amendment: Crevier (1993, pp. 115–117), Russell & Norvig (2021, pp. 21–22), NRC (1999, pp. 212–213), Howe (1994), Newquist (1994, pp. 189–201) - ^ a b Second AI Winter: Russell & Norvig (2021, p. 24), McCorduck (2004, pp. 430–435), Crevier (1993, pp. 209–210), NRC (1999, pp. 214–216), Newquist (1994, pp. 301–318) - ^ a b Deep learning revolution, AlexNet: Goldman (2022), Russell & Norvig (2021, p. 26), McKinsey (2018) - ^ Toews (2023). - ^ Problem-solving, puzzle solving, game playing, and deduction: Russell & Norvig (2021, chpt. 3–5), Russell & Norvig (2021, chpt. 6) (constraint satisfaction), Poole, Mackworth & Goebel (1998, chpt. 2, 3, 7, 9), Luger & Stubblefield (2004, chpt. 3, 4, 6, 8), Nilsson (1998, chpt. 7–12) - ^ Uncertain reasoning: Russell & Norvig (2021, chpt. 12–18), Poole, Mackworth & Goebel (1998, pp. 345–395), Luger & Stubblefield (2004, pp. 333–381), Nilsson (1998, chpt. 7–12) - ^ a b c Intractability and efficiency and the combinatorial explosion: Russell & Norvig (2021, p. 21) - ^ a b c Psychological evidence of the prevalence of sub-symbolic reasoning and knowledge: Kahneman (2011), Dreyfus & Dreyfus (1986), Wason & Shapiro (1966), Kahneman, Slovic & Tversky (1982) - ^ Knowledge representation and knowledge engineering: Russell & Norvig (2021, chpt. 10), Poole, Mackworth & Goebel (1998, pp. 23–46, 69–81, 169–233, 235–277, 281–298, 319–345), Luger & Stubblefield (2004, pp. 227–243), Nilsson (1998, chpt. 17.1–17.4, 18) - ^ Smoliar & Zhang (1994). - ^ Neumann & Möller (2008). - ^ Kuperman, Reichley & Bailey (2006). - ^ McGarry (2005). - ^ Bertini, Del Bimbo & Torniai (2006). - ^ Russell & Norvig (2021), pp. 272. - ^ Representing categories and relations: Semantic networks, description logics, inheritance (including frames, and scripts): Russell & Norvig (2021, §10.2 & 10.5), Poole, Mackworth & Goebel (1998, pp. 174–177), Luger & Stubblefield (2004, pp. 248–258), Nilsson (1998, chpt. 18.3) - ^ Representing events and time:Situation calculus, event calculus, fluent calculus (including solving the frame problem): Russell & Norvig (2021, §10.3), Poole, Mackworth & Goebel (1998, pp. 281–298), Nilsson (1998, chpt. 18.2) - ^ Causal calculus: Poole, Mackworth & Goebel (1998, pp. 335–337) - ^ Representing knowledge about knowledge: Belief calculus, modal logics: Russell & Norvig (2021, §10.4), Poole, Mackworth & Goebel (1998, pp. 275–277) - ^ a b Default reasoning, Frame problem, default logic, non-monotonic logics, circumscription, closed world assumption, abduction: Russell & Norvig (2021, §10.6), Poole, Mackworth & Goebel (1998, pp. 248–256, 323–335), Luger & Stubblefield (2004, pp. 335–363), Nilsson (1998, ~18.3.3) (Poole et al. places abduction under \"default reasoning\". Luger et al. places this under \"uncertain reasoning\"). - ^ a b Breadth of commonsense knowledge: Lenat & Guha (1989, Introduction), Crevier (1993, pp. 113–114), Moravec (1988, p. 13), Russell & Norvig (2021, pp. 241, 385, 982) (qualification problem) - ^ Newquist (1994), p. 296. - ^ Crevier (1993), pp. 204–208. - ^ Russell & Norvig (2021), p. 528. - ^ Automated planning: Russell & Norvig (2021, chpt. 11). - ^ Automated decision making, Decision theory: Russell & Norvig (2021, chpt. 16–18). - ^ Classical planning: Russell & Norvig (2021, Section 11.2). - ^ Sensorless or \"conformant\" planning, contingent planning, replanning (a.k.a. online planning): Russell & Norvig (2021, Section 11.5). - ^ Uncertain preferences: Russell & Norvig (2021, Section 16.7) Inverse reinforcement learning: Russell & Norvig (2021, Section 22.6) - ^ Information value theory: Russell & Norvig (2021, Section 16.6). - ^ Markov decision process: Russell & Norvig (2021, chpt. 17). - ^ Game theory and multi-agent decision theory: Russell & Norvig (2021, chpt. 18). - ^ Learning: Russell & Norvig (2021, chpt. 19–22), Poole, Mackworth & Goebel (1998, pp. 397–438), Luger & Stubblefield (2004, pp. 385–542), Nilsson (1998, chpt. 3.3, 10.3, 17.5, 20) - ^ Turing (1950). - ^ Solomonoff (1956). - ^ Unsupervised learning: Russell & Norvig (2021, pp. 653) (definition), Russell & Norvig (2021, pp. 738–740) (cluster analysis), Russell & Norvig (2021, pp. 846–860) (word embedding) - ^ a b Supervised learning: Russell & Norvig (2021, §19.2) (Definition), Russell & Norvig (2021, Chpt. 19–20) (Techniques) - ^ Reinforcement learning: Russell & Norvig (2021, chpt. 22), Luger & Stubblefield (2004, pp. 442–449) - ^ Transfer learning: Russell & Norvig (2021, pp. 281), The Economist (2016) - ^ \"Artificial Intelligence (AI): What Is AI and How Does It Work? | Built In\". builtin.com. Retrieved 30 October 2023. - ^ Computational learning theory: Russell & Norvig (2021, pp. 672–674), Jordan & Mitchell (2015) - ^ Natural language processing (NLP): Russell & Norvig (2021, chpt. 23–24), Poole, Mackworth & Goebel (1998, pp. 91–104), Luger & Stubblefield (2004, pp. 591–632) - ^ Subproblems of NLP: Russell & Norvig (2021, pp. 849–850) - ^ Russell & Norvig (2021), pp. 856–858. - ^ Dickson (2022). - ^ Modern statistical and deep learning approaches to NLP: Russell & Norvig (2021, chpt. 24), Cambria & White (2014) - ^ Vincent (2019). - ^ Russell & Norvig (2021), pp. 875–878. - ^ Bushwick (2023). - ^ Computer vision: Russell & Norvig (2021, chpt. 25), Nilsson (1998, chpt. 6) - ^ Russell & Norvig (2021), pp. 849–850. - ^ Russell & Norvig (2021), pp. 895–899. - ^ Russell & Norvig (2021), pp. 899–901. - ^ Challa et al. (2011). - ^ Russell & Norvig (2021), pp. 931–938. - ^ MIT AIL (2014). - ^ Affective computing: Thro (1993), Edelson (1991), Tao & Tan (2005), Scassellati (2002) - ^ Waddell (2018). - ^ Poria et al. (2017). - ^ a b Artificial general intelligence: Russell & Norvig (2021, pp. 32–33, 1020–1021) Proposal for the modern version: Pennachin & Goertzel (2007) Warnings of overspecialization in AI from leading researchers: Nilsson (1995), McCarthy (2007), Beal & Winston (2009) - ^ Search algorithms: Russell & Norvig (2021, chpts. 3–5), Poole, Mackworth & Goebel (1998, pp. 113–163), Luger & Stubblefield (2004, pp. 79–164, 193–219), Nilsson (1998, chpts. 7–12) - ^ State space search: Russell & Norvig (2021, chpt. 3) - ^ Russell & Norvig (2021), sect. 11.2. - ^ Uninformed searches (breadth first search, depth-first search and general state space search): Russell & Norvig (2021, sect. 3.4), Poole, Mackworth & Goebel (1998, pp. 113–132), Luger & Stubblefield (2004, pp. 79–121), Nilsson (1998, chpt. 8) - ^ Heuristic or informed searches (e.g., greedy best first and A*): Russell & Norvig (2021, sect. 3.5), Poole, Mackworth & Goebel (1998, pp. 132–147), Poole & Mackworth (2017, sect. 3.6), Luger & Stubblefield (2004, pp. 133–150) - ^ Adversarial search: Russell & Norvig (2021, chpt. 5) - ^ Local or \"optimization\" search: Russell & Norvig (2021, chpt. 4) - ^ Singh Chauhan, Nagesh (18 December 2020). \"Optimization Algorithms in Neural Networks\". KDnuggets. Retrieved 13 January 2024. - ^ Evolutionary computation: Russell & Norvig (2021, sect. 4.1.2) - ^ Merkle & Middendorf (2013). - ^ Logic: Russell & Norvig (2021, chpts. 6–9), Luger & Stubblefield (2004, pp. 35–77), Nilsson (1998, chpt. 13–16) - ^ Propositional logic: Russell & Norvig (2021, chpt. 6), Luger & Stubblefield (2004, pp. 45–50), Nilsson (1998, chpt. 13) - ^ First-order logic and features such as equality: Russell & Norvig (2021, chpt. 7), Poole, Mackworth & Goebel (1998, pp. 268–275), Luger & Stubblefield (2004, pp. 50–62), Nilsson (1998, chpt. 15) - ^ Logical inference: Russell & Norvig (2021, chpt. 10) - ^ logical deduction as search: Russell & Norvig (2021, sects. 9.3, 9.4), Poole, Mackworth & Goebel (1998, pp. ~46–52), Luger & Stubblefield (2004, pp. 62–73), Nilsson (1998, chpt. 4.2, 7.2) - ^ Resolution and unification: Russell & Norvig (2021, sections 7.5.2, 9.2, 9.5) - ^ Warren, D.H.; Pereira, L.M.; Pereira, F. (1977). \"Prolog-the language and its implementation compared with Lisp\". ACM SIGPLAN Notices. 12 (8): 109–115. doi:10.1145/872734.806939. - ^ Fuzzy logic: Russell & Norvig (2021, pp. 214, 255, 459), Scientific American (1999) - ^ a b Stochastic methods for uncertain reasoning: Russell & Norvig (2021, chpt. 12–18, 20), Poole, Mackworth & Goebel (1998, pp. 345–395), Luger & Stubblefield (2004, pp. 165–191, 333–381), Nilsson (1998, chpt. 19) - ^ decision theory and decision analysis: Russell & Norvig (2021, chpt. 16–18), Poole, Mackworth & Goebel (1998, pp. 381–394) - ^ Information value theory: Russell & Norvig (2021, sect. 16.6) - ^ Markov decision processes and dynamic decision networks: Russell & Norvig (2021, chpt. 17) - ^ a b c Stochastic temporal models: Russell & Norvig (2021, chpt. 14) Hidden Markov model: Russell & Norvig (2021, sect. 14.3) Kalman filters: Russell & Norvig (2021, sect. 14.4) Dynamic Bayesian networks: Russell & Norvig (2021, sect. 14.5) - ^ Game theory and mechanism design: Russell & Norvig (2021, chpt. 18) - ^ Bayesian networks: Russell & Norvig (2021, sects. 12.5–12.6, 13.4–13.5, 14.3–14.5, 16.5, 20.2–20.3), Poole, Mackworth & Goebel (1998, pp. 361–381), Luger & Stubblefield (2004, pp. ~182–190, ≈363–379), Nilsson (1998, chpt. 19.3–19.4) - ^ Domingos (2015), chpt. 6. - ^ Bayesian inference algorithm: Russell & Norvig (2021, sect. 13.3–13.5), Poole, Mackworth & Goebel (1998, pp. 361–381), Luger & Stubblefield (2004, pp. ~363–379), Nilsson (1998, chpt. 19.4 & 7) - ^ Domingos (2015), p. 210. - ^ Bayesian learning and the expectation–maximization algorithm: Russell & Norvig (2021, chpt. 20), Poole, Mackworth & Goebel (1998, pp. 424–433), Nilsson (1998, chpt. 20), Domingos (2015, p. 210) - ^ Bayesian decision theory and Bayesian decision networks: Russell & Norvig (2021, sect. 16.5) - ^ Statistical learning methods and classifiers: Russell & Norvig (2021, chpt. 20), - ^ Ciaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI. Intellisemantic Editions. ISBN 978-8-8947-8760-3. - ^ Decision trees: Russell & Norvig (2021, sect. 19.3), Domingos (2015, p. 88) - ^ Non-parameteric learning models such as K-nearest neighbor and support vector machines: Russell & Norvig (2021, sect. 19.7), Domingos (2015, p. 187) (k-nearest neighbor) - Domingos (2015, p. 88) (kernel methods) - ^ Domingos (2015), p. 152. - ^ Naive Bayes classifier: Russell & Norvig (2021, sect. 12.6), Domingos (2015, p. 152) - ^ a b Neural networks: Russell & Norvig (2021, chpt. 21), Domingos (2015, Chapter 4) - ^ Gradient calculation in computational graphs, backpropagation, automatic differentiation: Russell & Norvig (2021, sect. 21.2), Luger & Stubblefield (2004, pp. 467–474), Nilsson (1998, chpt. 3.3) - ^ Universal approximation theorem: Russell & Norvig (2021, p. 752) The theorem: Cybenko (1988), Hornik, Stinchcombe & White (1989) - ^ Feedforward neural networks: Russell & Norvig (2021, sect. 21.1) - ^ Perceptrons: Russell & Norvig (2021, pp. 21, 22, 683, 22) - ^ a b Deep learning: Russell & Norvig (2021, chpt. 21), Goodfellow, Bengio & Courville (2016), Hinton et al. (2016), Schmidhuber (2015) - ^ Recurrent neural networks: Russell & Norvig (2021, sect. 21.6) - ^ Convolutional neural networks: Russell & Norvig (2021, sect. 21.3) - ^ Sindhu V, Nivedha S, Prakash M (February 2020). \"An Empirical Science Research on Bioinformatics in Machine Learning\". Journal of Mechanics of Continua and Mathematical Sciences (7). doi:10.26782/jmcms.spl.7/2020.02.00006. - ^ Deng & Yu (2014), pp. 199–200. - ^ Ciresan, Meier & Schmidhuber (2012). - ^ Russell & Norvig (2021), p. 750. - ^ a b c Russell & Norvig (2021), p. 17. - ^ a b c d e f g Russell & Norvig (2021), p. 785. - ^ a b Schmidhuber (2022), sect. 5. - ^ Schmidhuber (2022), sect. 6. - ^ a b c Schmidhuber (2022), sect. 7. - ^ Schmidhuber (2022), sect. 8. - ^ Quoted in Christian (2020, p. 22) - ^ Metz, Cade; Weise, Karen (5 May 2025). \"A.I. Hallucinations Are Getting Worse, Even as New Systems Become More Powerful\". The New York Times. ISSN 0362-4331. Retrieved 6 May 2025. - ^ Smith (2023). - ^ \"Explained: Generative AI\". MIT News | Massachusetts Institute of Technology. 9 November 2023. - ^ \"AI Writing and Content Creation Tools\". MIT Sloan Teaching & Learning Technologies. Archived from the original on 25 December 2023. Retrieved 25 December 2023. - ^ Marmouyet (2023). - ^ Kobielus (2019). - ^ Thomason, James (21 May 2024). \"Mojo Rising: The resurgence of AI-first programming languages\". VentureBeat. Archived from the original on 27 June 2024. Retrieved 26 May 2024. - ^ Wodecki, Ben (5 May 2023). \"7 AI Programming Languages You Need to Know\". AI Business. Archived from the original on 25 July 2024. Retrieved 5 October 2024. - ^ Plumb, Taryn (18 September 2024). \"Why Jensen Huang and Marc Benioff see 'gigantic' opportunity for agentic AI\". VentureBeat. Archived from the original on 5 October 2024. Retrieved 4 October 2024. - ^ Mims, Christopher (19 September 2020). \"Huang's Law Is the New Moore's Law, and Explains Why Nvidia Wants Arm\". Wall Street Journal. ISSN 0099-9660. Archived from the original on 2 October 2023. Retrieved 19 January 2025. - ^ Dankwa-Mullan, Irene (2024). \"Health Equity and Ethical Considerations in Using Artificial Intelligence in Public Health and Medicine\". Preventing Chronic Disease. 21 240245: E64. doi:10.5888/pcd21.240245. ISSN 1545-1151. PMC 11364282. PMID 39173183. - ^ Jumper, J; Evans, R; Pritzel, A (2021). \"Highly accurate protein structure prediction with AlphaFold\". Nature. 596 (7873): 583–589. Bibcode:2021Natur.596..583J. doi:10.1038/s41586-021-03819-2. PMC 8371605. PMID 34265844. - ^ Fullname}, #Author (20 December 2023). \"AI discovers new class of antibiotics to kill drug-resistant bacteria\". New Scientist. Archived from the original on 16 September 2024. Retrieved 5 October 2024. {{cite web}} :|first1= has generic name (help)CS1 maint: numeric names: authors list (link) - ^ \"AI speeds up drug design for Parkinson's ten-fold\". University of Cambridge. Cambridge University. 17 April 2024. Archived from the original on 5 October 2024. Retrieved 5 October 2024. - ^ Horne, Robert I.; Andrzejewska, Ewa A.; Alam, Parvez; Brotzakis, Z. Faidon; Srivastava, Ankit; Aubert, Alice; Nowinska, Magdalena; Gregory, Rebecca C.; Staats, Roxine; Possenti, Andrea; Chia, Sean; Sormanni, Pietro; Ghetti, Bernardino; Caughey, Byron; Knowles, Tuomas P. J.; Vendruscolo, Michele (17 April 2024). \"Discovery of potent inhibitors of α-synuclein aggregation using structure-based iterative learning\". Nature Chemical Biology. 20 (5). Nature: 634–645. doi:10.1038/s41589-024-01580-x. PMC 11062903. PMID 38632492. - ^ Grant, Eugene F.; Lardner, Rex (25 July 1952). \"The Talk of the Town – It\". The New Yorker. ISSN 0028-792X. Archived from the original on 16 February 2020. Retrieved 28 January 2024. - ^ Anderson, Mark Robert (11 May 2017). \"Twenty years on from Deep Blue vs Kasparov: how a chess match started the big data revolution\". The Conversation. Archived from the original on 17 September 2024. Retrieved 28 January 2024. - ^ Markoff, John (16 February 2011). \"Computer Wins on 'Jeopardy!': Trivial, It's Not\". The New York Times. ISSN 0362-4331. Archived from the original on 22 October 2014. Retrieved 28 January 2024. - ^ Byford, Sam (27 May 2017). \"AlphaGo retires from competitive Go after defeating world number one 3–0\". The Verge. Archived from the original on 7 June 2017. Retrieved 28 January 2024. - ^ Brown, Noam; Sandholm, Tuomas (30 August 2019). \"Superhuman AI for multiplayer poker\". Science. 365 (6456): 885–890. Bibcode:2019Sci...365..885B. doi:10.1126/science.aay2400. PMID 31296650. - ^ \"MuZero: Mastering Go, chess, shogi and Atari without rules\". Google DeepMind. 23 December 2020. Retrieved 28 January 2024. - ^ Sample, Ian (30 October 2019). \"AI becomes grandmaster in 'fiendishly complex' StarCraft II\". The Guardian. ISSN 0261-3077. Archived from the original on 29 December 2020. Retrieved 28 January 2024. - ^ Wurman, P. R.; Barrett, S.; Kawamoto, K. (2022). \"Outracing champion Gran Turismo drivers with deep reinforcement learning\" (PDF). Nature. 602 (7896): 223–228. Bibcode:2022Natur.602..223W. doi:10.1038/s41586-021-04357-7. PMID 35140384. - ^ Wilkins, Alex (13 March 2024). \"Google AI learns to play open-world video games by watching them\". New Scientist. Archived from the original on 26 July 2024. Retrieved 21 July 2024. - ^ Wu, Zhengxuan; Arora, Aryaman; Wang, Zheng; Geiger, Atticus; Jurafsky, Dan; Manning, Christopher D.; Potts, Christopher (2024). \"ReFT: Representation Finetuning for Language Models\". NeurIPS. arXiv:2404.03592. - ^ \"Improving mathematical reasoning with process supervision\". OpenAI. 31 May 2023. Retrieved 26 January 2025. - ^ Srivastava, Saurabh (29 February 2024). \"Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap\". arXiv:2402.19450 [cs.AI]. - ^ Lightman, Hunter; Kosaraju, Vineet; Burda, Yura; Edwards, Harri; Baker, Bowen; Lee, Teddy; Leike, Jan; Schulman, John; Sutskever, Ilya; Cobbe, Karl (2023). \"Let's Verify Step by Step\". arXiv:2305.20050v1 [cs.LG]. - ^ Franzen, Carl (8 August 2024). \"Alibaba claims no. 1 spot in AI math models with Qwen2-Math\". VentureBeat. Retrieved 16 February 2025. - ^ Franzen, Carl (9 January 2025). \"Microsoft's new rStar-Math technique upgrades small models to outperform OpenAI's o1-preview at math problems\". VentureBeat. Retrieved 26 January 2025. - ^ Gina Genkina: New AI Model Advances the \"Kissing Problem\" and More. AlphaEvolve made several mathematical discoveries and practical optimizations IEEE Spectrum 14 May 2025. Retrieved 7 June 2025 - ^ Roberts, Siobhan (25 July 2024). \"AI achieves silver-medal standard solving International Mathematical Olympiad problems\". The New York Times. Archived from the original on 26 September 2024. Retrieved 7 August 2024. - ^ Azerbayev, Zhangir; Schoelkopf, Hailey; Paster, Keiran; Santos, Marco Dos; McAleer', Stephen; Jiang, Albert Q.; Deng, Jia; Biderman, Stella; Welleck, Sean (16 October 2023). \"Llemma: An Open Language Model For Mathematics\". EleutherAI Blog. Retrieved 26 January 2025. - ^ \"Julius AI\". julius.ai. - ^ Metz, Cade (21 July 2025). \"Google A.I. System Wins Gold Medal in International Math Olympiad\". The New York Times. ISSN 0362-4331. Retrieved 24 July 2025. - ^ McFarland, Alex (12 July 2024). \"8 Best AI for Math Tools (January 2025)\". Unite.AI. Retrieved 26 January 2025. - ^ Matthew Finio & Amanda Downie: IBM Think 2024 Primer, \"What is Artificial Intelligence (AI) in Finance?\" 8 December 2023 - ^ M. Nicolas, J. Firzli: Pensions Age / European Pensions magazine, \"Artificial Intelligence: Ask the Industry\", May–June 2024. https://videovoice.org/ai-in-finance-innovation-entrepreneurship-vs-over-regulation-with-the-eus-artificial-intelligence-act-wont-work-as-intended/ Archived 11 September 2024 at the Wayback Machine. - ^ a b c Congressional Research Service (2019). Artificial Intelligence and National Security (PDF). Washington, DC: Congressional Research Service. Archived (PDF) from the original on 8 May 2020. Retrieved 25 February 2024.PD-notice - ^ a b Slyusar, Vadym (2019). Artificial intelligence as the basis of future control networks (Preprint). doi:10.13140/RG.2.2.30247.50087. - ^ Iraqi, Amjad (3 April 2024). \"'Lavender': The AI machine directing Israel's bombing spree in Gaza\". +972 Magazine. Archived from the original on 10 October 2024. Retrieved 6 April 2024. - ^ Davies, Harry; McKernan, Bethan; Sabbagh, Dan (1 December 2023). \"'The Gospel': how Israel uses AI to select bombing targets in Gaza\". The Guardian. Archived from the original on 6 December 2023. Retrieved 4 December 2023. - ^ Marti, J Werner (10 August 2024). \"Drohnen haben den Krieg in der Ukraine revolutioniert, doch sie sind empfindlich auf Störsender – deshalb sollen sie jetzt autonom operieren\". Neue Zürcher Zeitung (in German). Archived from the original on 10 August 2024. Retrieved 10 August 2024. - ^ Pasick, Adam (27 March 2023). \"Artificial Intelligence Glossary: Neural Networks and Other Terms Explained\". The New York Times. ISSN 0362-4331. Archived from the original on 1 September 2023. Retrieved 22 April 2023. - ^ Griffith, Erin; Metz, Cade (27 January 2023). \"Anthropic Said to Be Closing In on $300 Million in New A.I. Funding\". The New York Times. Archived from the original on 9 December 2023. Retrieved 14 March 2023. - ^ Lanxon, Nate; Bass, Dina; Davalos, Jackie (10 March 2023). \"A Cheat Sheet to AI Buzzwords and Their Meanings\". Bloomberg News. Archived from the original ",
    "text_length": 120000,
    "depth": 0,
    "crawled_at": "2026-01-11T13:21:46.998953"
  },
  {
    "id": "page_1",
    "url": "https://en.wikipedia.org/w/index.php",
    "domain": "en.wikipedia.org",
    "title": "Wikipedia, the free encyclopedia",
    "text": "Main Page From today's featured article The northern gannet (Morus bassanus) is a seabird, the largest species of the gannet family, Sulidae. It is native to the coasts of the Atlantic Ocean, breeding in Western Europe and northeastern North America. It is the largest seabird in the northern Atlantic. The sexes are similar in appearance. Nesting takes place in colonies on both sides of the North Atlantic. Its breeding range has extended northward and eastward, with colonies being established on Russia's Kola Peninsula in 1995 and Bear Island (the southernmost island of Svalbard) in 2011. Colonies are mostly located on offshore islands with cliffs, from which birds can more easily launch into the air. The northern gannet undertakes seasonal migrations and catches fish (which are the mainstay of its diet) by making high-speed dives into the sea. It faces few other natural or man-made threats. Because the northern gannet is both a conspicuous and a common bird, it is referred to in several ancient myths and legends. (Full article...) Did you know ... - ... that some Lake Superior agates have circular, concentric rings on their surfaces, called \"eyes\" (examples pictured)? - ... that Cūḷāmaṇi Cetiya is believed in Buddhist cosmology to enshrine both the Buddha's topknot and his right canine tooth? - ... that Joscelin I of Edessa won his final battle while carried in a litter and died of his wounds shortly thereafter? - ... that Helmut Lachenmann's composition ... zwei Gefühle ... was based on a text about fear and desire by Leonardo da Vinci? - ... that Framoi Bérété founded a political party with Ahmed Sékou Touré, but later lost his seat in parliament to another party founded by Sékou Touré? - ... that a Genshin Impact character was inspired by the Queen song \"Bohemian Rhapsody\"? - ... that the documentary ...So Goes the Nation is named after the US state of Ohio's history of voting for the winning presidential candidate? - ... that the artist Atang Tshikare sculpted an animal with the body of a lion and the head of South Africa's national flower? - ... that Surreal launched a line of cereal that came with a free vibrator in every pack? In the news - The Southern Transitional Council's secretary-general announces its dissolution after Yemeni government forces capture Aden. - Faustin-Archange Touadéra (pictured) is re-elected as president of the Central African Republic. - Delcy Rodríguez is sworn in as interim president of Venezuela following the capture of Nicolás Maduro during United States strikes on the capital. - Luke Littler wins the PDC World Darts Championship. On this day January 11: Prithvi Jayanti in Nepal - 1055 – Theodora Porphyrogenita became the sole ruler of the Byzantine Empire after the death of her brother-in-law Constantine IX Monomachos. - 1946 – The People's Republic of Albania was proclaimed, with Enver Hoxha as the country's de facto head of state. - 1961 – Students at the University of Georgia rioted in an attempt to prevent the attendance of two African-American students. - 1986 – The Gateway Bridge (pictured) in Brisbane, Australia, opened as the largest prestressed-concrete, single-box bridge in the world. - 2024 – Several thousand North Korean migrant workers in Helong engaged in civil unrest, including a factory occupation and the taking of managers as hostages, due to unpaid wages. - Alice Paul (b. 1885) - Roberta Fulbright (d. 1953) - Emile Heskey (b. 1978) - Tom Parry Jones (d. 2013) Today's featured video | An effusive eruption is a type of volcanic eruption in which lava steadily flows out of a volcano onto the ground. It is one of two major groupings of eruptions, the other being explosive. Effusive eruptions form lava flows and lava domes, each of which vary in shape, length, and width. Deep in the crust, gases are dissolved into the magma because of high pressures but, upon ascent and eruption, pressure drops rapidly, and these gases begin to exsolve out of the melt. A volcanic eruption is effusive when the erupting magma is volatile-poor, which suppresses fragmentation, creating oozing magma that spills out of the volcanic vent and out into the surrounding area. Effusive eruptions are most common in basaltic magma, but they also occur in intermediate and felsic magma, and occasionally in silicic magma as well. This video shows lava agitating and bubbling in an effusive eruption of Litli-Hrútur, near the volcano Fagradalsfjall in Iceland, in 2023. Video credit: Giles Laurent Recently featured: | Other areas of Wikipedia - Community portal – The central hub for editors, with resources, links, tasks, and announcements. - Village pump – Forum for discussions about Wikipedia itself, including policies and technical issues. - Site news – Sources of news about Wikipedia and the broader Wikimedia movement. - Teahouse – Ask basic questions about using or editing Wikipedia. - Help desk – Ask questions about using or editing Wikipedia. - Reference desk – Ask research questions about encyclopedic topics. - Content portals – A unique way to navigate the encyclopedia. Wikipedia's sister projects Wikipedia is written by volunteer editors and hosted by the Wikimedia Foundation, a non-profit organization that also hosts a range of other volunteer projects: - Commons Free media repository - MediaWiki Wiki software development - Meta-Wiki Wikimedia project coordination - Wikibooks Free textbooks and manuals - Wikidata Free knowledge base - Wikinews Free-content news - Wikiquote Collection of quotations - Wikisource Free-content library - Wikispecies Directory of species - Wikiversity Free learning tools - Wikivoyage Free travel guide - Wiktionary Dictionary and thesaurus Wikipedia languages This Wikipedia is written in English. Many other Wikipedias are available; some of the largest are listed below. - 1,000,000+ articles - 250,000+ articles - 50,000+ articles",
    "text_length": 5888,
    "depth": 1,
    "crawled_at": "2026-01-11T13:21:50.731550"
  },
  {
    "id": "page_2",
    "url": "https://en.wikipedia.org/wiki/Intelligent_agent",
    "domain": "en.wikipedia.org",
    "title": "Intelligent agent - Wikipedia",
    "text": "Intelligent agent In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. AI textbooks[which?] define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence. A specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods. Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[1] Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[2] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[3] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[4] Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations. Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[1] Intelligent agents as the foundation of AI [edit]This section possibly contains original research. (February 2023) | The concept of intelligent agents provides a foundational lens through which to define and understand artificial intelligence. For instance, the influential textbook Artificial Intelligence: A Modern Approach (Russell & Norvig) describes: - Agent: Anything that perceives its environment (using sensors) and acts upon it (using actuators). E.g., a robot with cameras and wheels, or a software program that reads data and makes recommendations. - Rational Agent: An agent that strives to achieve the *best possible outcome* based on its knowledge and past experiences. \"Best\" is defined by a performance measure – a way of evaluating how well the agent is doing. - Artificial Intelligence (as a field): The study and creation of these rational agents. Other researchers and definitions build upon this foundation. Padgham & Winikoff emphasize that intelligent agents should react to changes in their environment in a timely way, proactively pursue goals, and be flexible and robust (able to handle unexpected situations). Some also suggest that ideal agents should be \"rational\" in the economic sense (making optimal choices) and capable of complex reasoning, like having beliefs, desires, and intentions (BDI model). Kaplan and Haenlein offer a similar definition, focusing on a system's ability to understand external data, learn from that data, and use what is learned to achieve goals through flexible adaptation. Defining AI in terms of intelligent agents offers several key advantages: - Avoids Philosophical Debates: It sidesteps arguments about whether AI is \"truly\" intelligent or conscious, like those raised by the Turing test or Searle's Chinese Room. It focuses on behavior and goal achievement, not on replicating human thought. - Objective Testing: It provides a clear, scientific way to evaluate AI systems. Researchers can compare different approaches by measuring how well they maximize a specific \"goal function\" (or objective function). This allows for direct comparison and combination of techniques. - Interdisciplinary Communication: It creates a common language for AI researchers to collaborate with other fields like mathematical optimization and economics, which also use concepts like \"goals\" and \"rational agents.\" Objective function [edit]An objective function (or goal function) specifies the goals of an intelligent agent. An agent is deemed more intelligent if it consistently selects actions that yield outcomes better aligned with its objective function. In effect, the objective function serves as a measure of success. The objective function may be: - Simple: For example, in a game of Go, the objective function might assign a value of 1 for a win and 0 for a loss. - Complex: It might require the agent to evaluate and learn from past actions, adapting its behavior based on patterns that have proven effective. The objective function encapsulates all of the goals the agent is designed to achieve. For rational agents, it also incorporates the trade-offs between potentially conflicting goals. For instance, a self-driving car's objective function might balance factors such as safety, speed, and passenger comfort. Different terms are used to describe this concept, depending on the context. These include: - Utility function: Often used in economics and decision theory, representing the desirability of a state. - Objective function: A general term used in optimization. - Loss function: Typically used in machine learning, where the goal is to minimize the loss (error). - Reward Function: Used in reinforcement learning. - Fitness Function: Used in evolutionary systems. Goals, and therefore the objective function, can be: - Explicitly defined: Programmed directly into the agent. - Induced: Learned or evolved over time. - In reinforcement learning, a \"reward function\" provides feedback, encouraging desired behaviors and discouraging undesirable ones. The agent learns to maximize its cumulative reward. - In evolutionary systems, a \"fitness function\" determines which agents are more likely to reproduce. This is analogous to natural selection, where organisms evolve to maximize their chances of survival and reproduction.[5] Some AI systems, such as nearest-neighbor, reason by analogy rather than being explicitly goal-driven. However, even these systems can have goals implicitly defined within their training data.[6] Such systems can still be benchmarked by framing the non-goal system as one whose \"goal\" is to accomplish its narrow classification task.[7] Systems not traditionally considered agents, like knowledge-representation systems, are sometimes included in the paradigm by framing them as agents with a goal of, for example, answering questions accurately. Here, the concept of an \"action\" is extended to encompass the \"act\" of providing an answer. As a further extension, mimicry-driven systems can be framed as agents optimizing a \"goal function\" based on how closely the IA mimics the desired behavior.[2] In generative adversarial networks (GANs) of the 2010s, an \"encoder\"/\"generator\" component attempts to mimic and improvise human text composition. The generator tries to maximize a function representing how well it can fool an antagonistic \"predictor\"/\"discriminator\" component.[8] While symbolic AI systems often use an explicit goal function, the paradigm also applies to neural networks and evolutionary computing. Reinforcement learning can generate intelligent agents that appear to act in ways intended to maximize a \"reward function\".[9] Sometimes, instead of setting the reward function directly equal to the desired benchmark evaluation function, machine learning programmers use reward shaping to initially give the machine rewards for incremental progress.[10] Yann LeCun stated in 2018, \"Most of the learning algorithms that people have come up with essentially consist of minimizing some objective function.\"[11] AlphaZero chess had a simple objective function: +1 point for each win, and -1 point for each loss. A self-driving car's objective function would be more complex.[12] Evolutionary computing can evolve intelligent agents that appear to act in ways intended to maximize a \"fitness function\" influencing how many descendants each agent is allowed to leave.[4] The mathematical formalism of AIXI was proposed as a maximally intelligent agent in this paradigm.[13] However, AIXI is uncomputable. In the real world, an IA is constrained by finite time and hardware resources, and scientists compete to produce algorithms that achieve progressively higher scores on benchmark tests with existing hardware.[14] Agent function [edit]An intelligent agent's behavior can be described mathematically by an agent function. This function determines what the agent does based on what it has seen. A percept refers to the agent's sensory inputs at a single point in time. For example, a self-driving car's percepts might include camera images, lidar data, GPS coordinates, and speed readings at a specific instant. The agent uses these percepts, and potentially its history of percepts, to decide on its next action (e.g., accelerate, brake, turn). The agent function, often denoted as f, maps the agent's entire history of percepts to an action.[15] Mathematically, this can be represented as where: - represents the set of all possible percept sequences (the agent's entire perceptual history). The asterisk (*) indicates a sequence of zero or more percepts. - represents the set of all possible actions the agent can take. - is the agent function that maps a percept sequence to an action. It's crucial to distinguish between the agent function (an abstract mathematical concept) and the agent program (the concrete implementation of that function). - The agent function is a theoretical description. - The agent program is the actual code that runs on the agent. The agent program takes the current percept as input and produces an action as output. The agent function can incorporate a wide range of decision-making approaches, including:[16] - Calculating the utility (desirability) of different actions. - Using logical rules and deduction. - Employing fuzzy logic. - Other methods. Classes of intelligent agents [edit]Russell and Norvig's classification [edit]Russell & Norvig (2003) group agents into five classes based on their degree of perceived intelligence and capability:[17] Simple reflex agents [edit]Simple reflex agents act only on the basis of the current percept, ignoring the rest of the percept history. The agent function is based on the condition-action rule: \"if condition, then action\". This agent function only succeeds when the environment is fully observable. Some reflex agents can also contain information on their current state which allows them to disregard conditions whose actuators are already triggered. Infinite loops are often unavoidable for simple reflex agents operating in partially observable environments. If the agent can randomize its actions, it may be possible to escape from infinite loops. A home thermostat, which turns on or off when the temperature drops below a certain point, is an example of a simple reflex agent.[18][19] Model-based reflex agents [edit]A model-based agent can handle partially observable environments. Its current state is stored inside the agent, maintaining a structure that describes the part of the world which cannot be seen. This knowledge about \"how the world works\" is referred to as a model of the world, hence the name \"model-based agent\". A model-based reflex agent should maintain some sort of internal model that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. Percept history and impact of action on the environment can be determined by using the internal model. It then chooses an action in the same way as reflex agent. An agent may also use models to describe and predict the behaviors of other agents in the environment.[20] Goal-based agents [edit]Goal-based agents further expand on the capabilities of the model-based agents, by using \"goal\" information. Goal information describes situations that are desirable. This provides the agent a way to choose among multiple possibilities, selecting the one which reaches a goal state. Search and planning are the subfields of artificial intelligence devoted to finding action sequences that achieve the agent's goals. ChatGPT and the Roomba vacuum are examples of goal-based agents.[21] Utility-based agents [edit]Goal-based agents only distinguish between goal states and non-goal states. It is also possible to define a measure of how desirable a particular state is. This measure can be obtained through the use of a utility function which maps a state to a measure of the utility of the state. A more general performance measure should allow a comparison of different world states according to how well they satisfied the agent's goals. The term utility can be used to describe how \"happy\" the agent is. A rational utility-based agent chooses the action that maximizes the expected utility of the action outcomes - that is, what the agent expects to derive, on average, given the probabilities and utilities of each outcome. A utility-based agent has to model and keep track of its environment, tasks that have involved a great deal of research on perception, representation, reasoning, and learning. Learning agents [edit]Learning lets agents begin in unknown environments and gradually surpass the bounds of their initial knowledge. A key distinction in such agents is the separation between a \"learning element,\" responsible for improving performance, and a \"performance element,\" responsible for choosing external actions. The learning element gathers feedback from a \"critic\" to assess the agent's performance and decides how the performance element—also called the \"actor\"—can be adjusted to yield better outcomes. The performance element, once considered the entire agent, interprets percepts and takes actions. The final component, the \"problem generator,\" suggests new and informative experiences that encourage exploration and further improvement. Weiss's classification [edit]According to Weiss (2013), agents can be categorized into four classes: - Logic-based agents, where decisions about actions are derived through logical deduction. - Reactive agents, where decisions occur through a direct mapping from situation to action. - Belief–desire–intention agents, where decisions depend on manipulating data structures that represent the agent's beliefs, desires, and intentions. - Layered architectures, where decision-making takes place across multiple software layers, each of which reasons about the environment at a different level of abstraction. Other [edit]In 2013, Alexander Wissner-Gross published a theory exploring the relationship between Freedom and Intelligence in intelligent agents.[22][23] Hierarchies of agents [edit]Intelligent agents can be organized hierarchically into multiple \"sub-agents.\" These sub-agents handle lower-level functions, and together with the main agent, they form a complete system capable of executing complex tasks and achieving challenging goals. Typically, an agent is structured by dividing it into sensors and actuators. The perception system gathers input from the environment via the sensors and feeds this information to a central controller, which then issues commands to the actuators. Often, a multilayered hierarchy of controllers is necessary to balance the rapid responses required for low-level tasks with the more deliberative reasoning needed for high-level objectives.[24] Alternative definitions and uses [edit]\"Intelligent agent\" is also often used as a vague term, sometimes synonymous with \"virtual personal assistant\".[25] Some 20th-century definitions characterize an agent as a program that aids a user or that acts on behalf of a user.[26] These examples are known as software agents, and sometimes an \"intelligent software agent\" (that is, a software agent with intelligence) is referred to as an \"intelligent agent\". According to Nikola Kasabov in 1998, IA systems should exhibit the following characteristics:[27] - Accommodate new problem solving rules incrementally. - Adapt online and in real time. - Are able to analyze themselves in terms of behavior, error and success. - Learn and improve through interaction with the environment (embodiment). - Learn quickly from large amounts of data. - Have memory-based exemplar storage and retrieval capacities. - Have parameters to represent short- and long-term memory, age, forgetting, etc. Agentic AI [edit]In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight.[28] They possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user supervision, and the integration of software tools or planning systems. Their control flow is frequently driven by large language models (LLMs).[29] Agents also include memory systems for remembering previous user-agent interactions and orchestration software for organizing agent components.[30] Researchers and commentators have noted that AI agents do not have a standard definition.[29][31][32][33] The concept of agentic AI has been compared to the fictional character J.A.R.V.I.S..[34] A common application of AI agents is the automation of tasks—for example, booking travel plans based on a user's prompted request.[35][36] Prominent examples include Devin AI, AutoGPT, and SIMA.[37] Further examples of agents released since 2025 include OpenAI Operator,[38] ChatGPT Deep Research,[39] Manus,[40] Quark (based on Qwen),[41] AutoGLM Rumination,[41] and Coze (by ByteDance).[41] Frameworks for building AI agents include LangChain,[42] as well as tools such as CAMEL,[43][44] Microsoft AutoGen,[45] and OpenAI Swarm.[46] Applications [edit]This section may lend undue weight to certain ideas, incidents, or controversies. (September 2023) | The concept of agent-based modeling for self-driving cars was discussed as early as 2003.[47] Hallerbach et al. explored the use of agent-based approaches for developing and validating automated driving systems. Their method involved a digital twin of the vehicle under test and microscopic traffic simulations using independent agents.[48] Waymo developed a multi-agent simulation environment called Carcraft, to test algorithms for self-driving cars.[49][50] This system simulates interactions between human drivers, pedestrians, and automated vehicles. Artificial agents replicate human behavior using real-world data. Salesforce's Agentforce is an agentic AI platform that allows for the building of autonomous agents to perform tasks.[51][52] The Transport Security Administration is integrating agentic AI into new technologies, including machines to authenticate passenger identities using biometrics and photos, and also for incident response.[53] See also [edit]- Ambient intelligence - Artificial conversational entity - Artificial intelligence systems integration - Autonomous agent - Cognitive architectures - Cognitive radio – a practical field for implementation - Cybernetics - DAYDREAMER - Embodied agent - Federated search – the ability for agents to search heterogeneous data sources using a single vocabulary - Friendly artificial intelligence - Fuzzy agents – IA implemented with adaptive fuzzy logic - GOAL agent programming language - Hybrid intelligent system - Intelligent control - Intelligent system - JACK Intelligent Agents - Multi-agent system and multiple-agent system – multiple interactive agents - Reinforcement learning - Semantic Web – making data on the Web available for automated processing by agents - Social simulation - Software agent - Software bot References [edit]- ^ a b Russell & Norvig 2003, chpt. 2. - ^ a b Bringsjord, Selmer; Govindarajulu, Naveen Sundar (12 July 2018). \"Artificial Intelligence\". In Edward N. Zalta (ed.). The Stanford Encyclopedia of Philosophy (Summer 2020 Edition). - ^ Wolchover, Natalie (30 January 2020). \"Artificial Intelligence Will Do What We Ask. That's a Problem\". Quanta Magazine. Retrieved 21 June 2020. - ^ a b Bull, Larry (1999). \"On model-based evolutionary computation\". Soft Computing. 3 (2): 76–82. doi:10.1007/s005000050055. S2CID 9699920. - ^ Domingos 2015, Chapter 5. - ^ Domingos 2015, Chapter 7. - ^ Lindenbaum, M., Markovitch, S., & Rusakov, D. (2004). Selective sampling for nearest neighbor classifiers. Machine learning, 54(2), 125–152. - ^ \"Generative adversarial networks: What GANs are and how they've evolved\". VentureBeat. 26 December 2019. Retrieved 18 June 2020. - ^ Wolchover, Natalie (January 2020). \"Artificial Intelligence Will Do What We Ask. That's a Problem\". Quanta Magazine. Retrieved 18 June 2020. - ^ Andrew Y. Ng, Daishi Harada, and Stuart Russell. \"Policy invariance under reward transformations: Theory and application to reward shaping.\" In ICML, vol. 99, pp. 278-287. 1999. - ^ Martin Ford. Architects of Intelligence: The truth about AI from the people building it. Packt Publishing Ltd, 2018. - ^ \"Why AlphaZero's Artificial Intelligence Has Trouble With the Real World\". Quanta Magazine. 2018. Retrieved 18 June 2020. - ^ Adams, Sam; Arel, Itmar; Bach, Joscha; Coop, Robert; Furlan, Rod; Goertzel, Ben; Hall, J. Storrs; Samsonovich, Alexei; Scheutz, Matthias; Schlesinger, Matthew; Shapiro, Stuart C.; Sowa, John (15 March 2012). \"Mapping the Landscape of Human-Level Artificial General Intelligence\". AI Magazine. 33 (1): 25. doi:10.1609/aimag.v33i1.2322. - ^ Hutson, Matthew (27 May 2020). \"Eye-catching advances in some AI fields are not real\". Science | AAAS. Retrieved 18 June 2020. - ^ Russell & Norvig 2003, p. 33 - ^ Salamon, Tomas (2011). Design of Agent-Based Models. Repin: Bruckner Publishing. pp. 42–59. ISBN 978-80-904661-1-1. - ^ Russell & Norvig 2003, pp. 46–54 - ^ Thakur, Shreeya. \"AI Agents: 5 Key Types Explained With Examples // Unstop\". unstop.com. Retrieved 2025-04-24. - ^ \"Types of AI Agents | IBM\". www.ibm.com. 2025-03-17. Retrieved 2025-04-24. - ^ Stefano Albrecht and Peter Stone (2018). Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems. Artificial Intelligence, Vol. 258, pp. 66-95. https://doi.org/10.1016/j.artint.2018.01.002 - ^ \"What is an AI agent? A computer scientist explains the next wave of artificial intelligence tools\". Inverse. 2024-12-24. Retrieved 2025-04-24. - ^ Box, Geeks out of the (2019-12-04). \"A Universal Formula for Intelligence\". Geeks out of the box. Retrieved 2022-10-11. - ^ Wissner-Gross, A. D.; Freer, C. E. (2013-04-19). \"Causal Entropic Forces\". Physical Review Letters. 110 (16) 168702. Bibcode:2013PhRvL.110p8702W. doi:10.1103/PhysRevLett.110.168702. hdl:1721.1/79750. PMID 23679649. - ^ Poole, David; Mackworth, Alan. \"1.3 Agents Situated in Environments‣ Chapter 2 Agent Architectures and Hierarchical Control‣ Artificial Intelligence: Foundations of Computational Agents, 2nd Edition\". artint.info. Retrieved 28 November 2018. - ^ Fingar, Peter (2018). \"Competing For The Future With Intelligent Agents... And A Confession\". Forbes Sites. Retrieved 18 June 2020. - ^ Burgin, Mark; Dodig-Crnkovic, Gordana (2009). \"A Systematic Approach to Artificial Agents\". arXiv:0902.3513 [cs.AI]. - ^ Kasabov 1998. - ^ Purdy, Mark (2024-12-12). \"What Is Agentic AI, and How Will It Change Work?\". Harvard Business Review. ISSN 0017-8012. Retrieved 2025-04-24. - ^ a b Kapoor, Sayash; Stroebl, Benedikt; Siegel, Zachary S.; Nadgir, Nitya; Narayanan, Arvind (2024). \"AI Agents That Matter\". arXiv:2407.01502 [cs.LG]. - ^ Holmes, Aaron (2025-07-07). \"The Seven Kinds of AI Agents\". The Information. Archived from the original on 2025-07-20. Retrieved 2025-11-09. - ^ Zeff, Maxwell; Wiggers, Kyle (2025-03-14). \"No one knows what the hell an AI agent is\". TechCrunch. Archived from the original on 2025-03-18. Retrieved 2025-05-15. - ^ Varanasi, Lakshmi. \"AI agents are all the rage. But no one can agree on what they do\". Business Insider. Archived from the original on 2025-04-11. Retrieved 2025-05-15. - ^ Bort, Julie (2025-05-12). \"Even a16z VCs say no one really knows what an AI agent is\". TechCrunch. Archived from the original on 2025-05-12. Retrieved 2025-05-15. - ^ Field, Hayden (2025-08-31). \"AI agents are science fiction not yet ready for primetime\". The Verge. Archived from the original on 2025-09-15. Retrieved 2025-11-09. - ^ \"AI Agents: The Next Generation of Artificial Intelligence\". The National Law Review. 2024-12-30. Archived from the original on 2025-01-11. Retrieved 2025-01-14. - ^ \"What are the risks and benefits of 'AI agents'?\". World Economic Forum. 2024-12-16. Archived from the original on 2024-12-28. Retrieved 2025-01-14. - ^ Knight, Will (2024-03-14). \"Forget Chatbots. AI Agents Are the Future\". Wired. ISSN 1059-1028. Archived from the original on 2025-01-05. Retrieved 2025-01-14. - ^ Marshall, Matt (2025-02-22). \"The rise of browser-use agents: Why Convergence's Proxy is beating OpenAI's Operator\". VentureBeat. Archived from the original on 2025-02-22. Retrieved 2025-04-02. - ^ Milmo, Dan (2025-02-03). \"OpenAI launches 'deep research' tool that it says can match research analyst\". The Guardian. ISSN 0261-3077. Archived from the original on 2025-02-03. Retrieved 2025-04-02. - ^ Chen, Caiwei (2025-03-11). \"Everyone in AI is talking about Manus. We put it to the test\". MIT Technology Review. Archived from the original on 2025-03-12. Retrieved 2025-04-02. - ^ a b c \"China is gaining ground in the global race to develop AI agents\". Rest of World. 2025-06-02. Archived from the original on 2025-06-02. Retrieved 2025-06-12. - ^ David, Emilia (2024-12-30). \"Why 2025 will be the year of AI orchestration\". VentureBeat. Archived from the original on 2024-12-30. Retrieved 2025-01-14. - ^ \"CAMEL: Finding the Scaling Law of Agents. The first and the best multi-agent framework\". GitHub. - ^ Li, Guohao (2023). \"Camel: Communicative agents for \"mind\" exploration of large language model society\" (PDF). Advances in Neural Information Processing Systems. 36: 51991–52008. arXiv:2303.17760. S2CID 257900712. - ^ Dickson, Ben (2023-10-03). \"Microsoft's AutoGen framework allows multiple AI agents to talk to each other and complete your tasks\". VentureBeat. Archived from the original on 2024-12-27. Retrieved 2025-01-14. - ^ \"The next AI wave — agents — should come with warning labels\". Computerworld. 2025-01-13. Archived from the original on 2025-01-14. Retrieved 2025-01-14. - ^ Yang, Guoqing; Wu, Zhaohui; Li, Xiumei; Chen, Wei (2003). \"SVE: embedded agent-based smart vehicle environment\". Proceedings of the 2003 IEEE International Conference on Intelligent Transportation Systems. Vol. 2. pp. 1745–1749. doi:10.1109/ITSC.2003.1252782. ISBN 0-7803-8125-4. S2CID 110177067. - ^ Hallerbach, S.; Xia, Y.; Eberle, U.; Koester, F. (2018). \"Simulation-Based Identification of Critical Scenarios for Cooperative and Automated Vehicles\". SAE International Journal of Connected and Automated Vehicles. 1 (2). SAE International: 93. doi:10.4271/2018-01-1066. - ^ Madrigal, Story by Alexis C. \"Inside Waymo's Secret World for Training Self-Driving Cars\". The Atlantic. Retrieved 14 August 2020. - ^ Connors, J.; Graham, S.; Mailloux, L. (2018). \"Cyber Synthetic Modeling for Vehicle-to-Vehicle Applications\". In International Conference on Cyber Warfare and Security. Academic Conferences International Limited: 594-XI. - ^ Nuñez, Michael (2025-03-05). \"Salesforce launches Agentforce 2dx, letting AI run autonomously across enterprise systems\". VentureBeat. Retrieved 2025-04-24. - ^ \"Salesforce unveils Agentforce to help create autonomous AI bots\". CIO. Retrieved 2025-04-24. - ^ \"TSA Showcase Biometric AI-powered Airport Immigration Security\". techinformed.com. 2025-01-23. Retrieved 2025-04-24. Sources [edit]- Domingos, Pedro (September 22, 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0-465-06570-7. - Russell, Stuart J.; Norvig, Peter (2003). Artificial Intelligence: A Modern Approach (2nd ed.). Upper Saddle River, New Jersey: Prentice Hall. Chapter 2. ISBN 0-13-790395-2. - Kasabov, N. (1998). \"Introduction: Hybrid intelligent adaptive systems\". International Journal of Intelligent Systems. 13 (6): 453–454. doi:10.1002/(SICI)1098-111X(199806)13:6<453::AID-INT1>3.0.CO;2-K. S2CID 120318478. - Weiss, G. (2013). Multiagent systems (2nd ed.). Cambridge, MA: MIT Press. ISBN 978-0-262-01889-0.",
    "text_length": 29001,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:02.768622"
  },
  {
    "id": "page_3",
    "url": "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling",
    "domain": "en.wikipedia.org",
    "title": "Automated planning and scheduling - Wikipedia",
    "text": "Automated planning and scheduling This article includes a list of general references, but it lacks sufficient corresponding inline citations. (January 2012) | | Part of a series on | | Artificial intelligence (AI) | |---| Automated planning and scheduling, sometimes denoted as simply AI planning,[1] is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control and classification problems, the solutions are complex and must be discovered and optimized in multidimensional space. Planning is also related to decision theory. In known environments with available models, planning can be done offline. Solutions can be found and evaluated prior to execution. In dynamically unknown environments, the strategy often needs to be revised online. Models and policies must be adapted. Solutions usually resort to iterative trial and error processes commonly seen in artificial intelligence. These include dynamic programming, reinforcement learning and combinatorial optimization. Languages used to describe planning and scheduling are often called action languages. Overview [edit]This section needs additional citations for verification. (February 2021) | Given a description of the possible initial states of the world, a description of the desired goals, and a description of a set of possible actions, the planning problem is to synthesize a plan that is guaranteed (when applied to any of the initial states) to generate a state which contains the desired goals (such a state is called a goal state). The difficulty of planning is dependent on the simplifying assumptions employed. Several classes of planning problems can be identified depending on the properties the problems have in several dimensions. - Are the actions deterministic or non-deterministic? For nondeterministic actions, are the associated probabilities available? - Are the state variables discrete or continuous? If they are discrete, do they have only a finite number of possible values? - Can the current state be observed unambiguously? There can be full observability and partial observability. - How many initial states are there, finite or arbitrarily many? - Do actions have a duration? - Can several actions be taken concurrently, or is only one action possible at a time? - Is the objective of a plan to reach a designated goal state, or to maximize a reward function? - Is there only one agent or are there several agents? Are the agents cooperative or selfish? Do all of the agents construct their own plans separately, or are the plans constructed centrally for all agents? The simplest possible planning problem, known as the Classical Planning Problem, is determined by: - a unique known initial state, - durationless actions, - deterministic actions, - which can be taken only one at a time, - and a single agent. Since the initial state is known unambiguously, and all actions are deterministic, the state of the world after any sequence of actions can be accurately predicted, and the question of observability is irrelevant for classical planning. Further, plans can be defined as sequences of actions, because it is always known in advance which actions will be needed. With nondeterministic actions or other events outside the control of the agent, the possible executions form a tree, and plans have to determine the appropriate actions for every node of the tree. Discrete-time Markov decision processes (MDP) are planning problems with: - durationless actions, - nondeterministic actions with probabilities, - full observability, - maximization of a reward function, - and a single agent. When full observability is replaced by partial observability, planning corresponds to a partially observable Markov decision process (POMDP). If there are more than one agent, we have multi-agent planning, which is closely related to game theory. Domain independent planning [edit]This section needs additional citations for verification. (February 2021) | In AI planning, planners typically input a domain model (a description of a set of possible actions which model the domain) as well as the specific problem to be solved specified by the initial state and goal, in contrast to those in which there is no input domain specified. Such planners are called \"domain independent\" to emphasize the fact that they can solve planning problems from a wide range of domains. Typical examples of domains are block-stacking, logistics, workflow management, and robot task planning. Hence a single domain-independent planner can be used to solve planning problems in all these various domains. On the other hand, a route planner is typical of a domain-specific planner. Planning domain modelling languages [edit]This section needs additional citations for verification. (February 2021) | The most commonly used languages for representing planning domains and specific planning problems, such as STRIPS and PDDL for Classical Planning, are based on state variables. Each possible state of the world is an assignment of values to the state variables, and actions determine how the values of the state variables change when that action is taken. Since a set of state variables induce a state space that has a size that is exponential in the set, planning, similarly to many other computational problems, suffers from the curse of dimensionality and the combinatorial explosion. An alternative language for describing planning problems is that of hierarchical task networks, in which a set of tasks is given, and each task can be either realized by a primitive action or decomposed into a set of other tasks. This does not necessarily involve state variables, although in more realistic applications state variables simplify the description of task networks. Algorithms for planning [edit]Classical planning [edit]- forward chaining state space search, possibly enhanced with heuristics - backward chaining search, possibly enhanced by the use of state constraints (see STRIPS, graphplan) - partial-order planning Action model learning [edit]Creating domain models is difficult, takes a lot of time, and can easily lead to mistakes. To help with this, several methods have been developed to automatically learn full or partial domain models from given observations. [2] [3] [4] - Read more: Action model learning Reduction to other problems [edit]- reduction to the propositional satisfiability problem (satplan). - reduction to model checking - both are essentially problems of traversing state spaces, and the classical planning problem corresponds to a subclass of model checking problems. Temporal planning [edit]Temporal planning can be solved with methods similar to classical planning. The main difference is, because of the possibility of several, temporally overlapping actions with a duration being taken concurrently, that the definition of a state has to include information about the current absolute time and how far the execution of each active action has proceeded. Further, in planning with rational or real time, the state space may be infinite, unlike in classical planning or planning with integer time. Temporal planning is closely related to scheduling problems when uncertainty is involved and can also be understood in terms of timed automata. The Simple Temporal Network with Uncertainty (STNU) is a scheduling problem which involves controllable actions, uncertain events and temporal constraints. Dynamic Controllability for such problems is a type of scheduling which requires a temporal planning strategy to activate controllable actions reactively as uncertain events are observed so that all constraints are guaranteed to be satisfied.[5] Probabilistic planning [edit]Probabilistic planning can be solved with iterative methods such as value iteration and policy iteration, when the state space is sufficiently small. With partial observability, probabilistic planning is similarly solved with iterative methods, but using a representation of the value functions defined for the space of beliefs instead of states. Preference-based planning [edit]In preference-based planning, the objective is not only to produce a plan but also to satisfy user-specified preferences. A difference to the more common reward-based planning, for example corresponding to MDPs, preferences don't necessarily have a precise numerical value. Conditional planning [edit]Deterministic planning was introduced with the STRIPS planning system, which is a hierarchical planner. Action names are ordered in a sequence and this is a plan for the robot. Hierarchical planning can be compared with an automatic generated behavior tree.[6] The disadvantage is, that a normal behavior tree is not so expressive like a computer program. That means, the notation of a behavior graph contains action commands, but no loops or if-then-statements. Conditional planning overcomes the bottleneck and introduces an elaborated notation which is similar to a control flow, known from other programming languages like Pascal. It is very similar to program synthesis, which means a planner generates sourcecode which can be executed by an interpreter.[7] An early example of a conditional planner is “Warplan-C” which was introduced in the mid 1970s.[8] What is the difference between a normal sequence and a complicated plan, which contains if-then-statements? It has to do with uncertainty at runtime of a plan. The idea is that a plan can react to sensor signals which are unknown for the planner. The planner generates two choices in advance. For example, if an object was detected, then action A is executed, if an object is missing, then action B is executed.[9] A major advantage of conditional planning is the ability to handle partial plans.[10] An agent is not forced to plan everything from start to finish but can divide the problem into chunks. This helps to reduce the state space and solves much more complex problems. Contingency planning [edit]We speak of \"contingent planning\" when the environment is observable through sensors, which can be faulty. It is thus a situation where the planning agent acts under incomplete information. For a contingent planning problem, a plan is no longer a sequence of actions but a decision tree because each step of the plan is represented by a set of states rather than a single perfectly observable state, as in the case of classical planning.[11] The selected actions depend on the state of the system. For example, if it rains, the agent chooses to take the umbrella, and if it doesn't, they may choose not to take it. Michael L. Littman showed in 1998 that with branching actions, the planning problem becomes EXPTIME-complete.[12][13] A particular case of contiguous planning is represented by FOND problems - for \"fully-observable and non-deterministic\". If the goal is specified in LTLf (linear time logic on finite trace) then the problem is always EXPTIME-complete[14] and 2EXPTIME-complete if the goal is specified with LDLf. Conformant planning [edit]Conformant planning is when the agent is uncertain about the state of the system, and it cannot make any observations. The agent then has beliefs about the real world, but cannot verify them with sensing actions, for instance. These problems are solved by techniques similar to those of classical planning,[15][16] but where the state space is exponential in the size of the problem, because of the uncertainty about the current state. A solution for a conformant planning problem is a sequence of actions. Haslum and Jonsson have demonstrated that the problem of conformant planning is EXPSPACE-complete,[17] and 2EXPTIME-complete when the initial situation is uncertain, and there is non-determinism in the actions outcomes.[13] Deployment of planning systems [edit]- The Hubble Space Telescope uses a short-term system called SPSS and a long-term planning system called Spike [citation needed]. See also [edit]- Action description language - Action model learning - Actor model - Applications of artificial intelligence - Constraint satisfaction problem - International Conference on Automated Planning and Scheduling - Reactive planning - Scheduling (computing) - Strategy (game theory) - Lists - List of constraint programming languages - List of emerging technologies - List of SMT solvers - Outline of artificial intelligence References [edit]- ^ Ghallab, Malik; Nau, Dana S.; Traverso, Paolo (2004), Automated Planning: Theory and Practice, Morgan Kaufmann, ISBN 1-55860-856-7, archived from the original on 2009-08-24, retrieved 2008-08-20 - ^ Callanan, Ethan and De Venezia, Rebecca and Armstrong, Victoria and Paredes, Alison and Chakraborti, Tathagata and Muise, Christian (2022). MACQ: A Holistic View of Model Acquisition Techniques (PDF). ICAPS Workshop on Knowledge Engineering for Planning and Scheduling (KEPS). {{cite conference}} : CS1 maint: multiple names: authors list (link) - ^ Aineto, Diego and Jiménez Celorrio, Sergio and Onaindia, Eva (2019). \"Learning action models with minimal observability\". Artificial Intelligence. 275: 104–137. doi:10.1016/j.artint.2019.05.003. hdl:10251/144560. {{cite journal}} : CS1 maint: multiple names: authors list (link) - ^ Jiménez, Sergio and de la Rosa, Tomás and Fernández, Susana and Fernández, Fernando and Borrajo, Daniel (2012). \"A review of machine learning for automated planning\". The Knowledge Engineering Review. 27 (4): 433–467. doi:10.1017/S026988891200001X. {{cite journal}} : CS1 maint: multiple names: authors list (link) - ^ Vidal, Thierry (January 1999). \"Handling contingency in temporal constraint networks: from consistency to controllabilities\". Journal of Experimental & Theoretical Artificial Intelligence. 11 (1): 23--45. CiteSeerX 10.1.1.107.1065. doi:10.1080/095281399146607. - ^ Neufeld, Xenija and Mostaghim, Sanaz and Sancho-Pradel, Dario and Brand, Sandy (2017). \"Building a Planner: A Survey of Planning Systems Used in Commercial Video Games\". IEEE Transactions on Games. IEEE. {{cite journal}} : CS1 maint: multiple names: authors list (link) - ^ Sanelli, Valerio and Cashmore, Michael and Magazzeni, Daniele and Iocchi, Luca (2017). Short-term human robot interaction through conditional planning and execution. Proc. of International Conference on Automated Planning and Scheduling (ICAPS). Archived from the original on 2019-08-16. Retrieved 2019-08-16. {{cite conference}} : CS1 maint: multiple names: authors list (link) - ^ Peot, Mark A and Smith, David E (1992). Conditional nonlinear planning (PDF). Artificial Intelligence Planning Systems. Elsevier. pp. 189–197. {{cite conference}} : CS1 maint: multiple names: authors list (link) - ^ Karlsson, Lars (2001). Conditional progressive planning under uncertainty. IJCAI. pp. 431–438. - ^ Liu, Daphne Hao (2008). A survey of planning in intelligent agents: from externally motivated to internally motivated systems (Technical report). Technical Report TR-2008-936, Department of Computer Science, University of Rochester. Archived from the original on 2023-03-15. Retrieved 2019-08-16. - ^ Alexandre Albore; Hector Palacios; Hector Geffner (2009). A Translation-Based Approach to Contingent Planning. International Joint Conference of Artificial Intelligence (IJCAI). Pasadena, CA: AAAI. Archived from the original on 2019-07-03. Retrieved 2019-07-03. - ^ Littman, Michael L. (1997). Probabilistic Propositional Planning: Representations and Complexity. Fourteenth National Conference on Artificial Intelligence. MIT Press. pp. 748–754. Archived from the original on 2019-02-12. Retrieved 2019-02-10. - ^ a b Jussi Rintanen (2004). Complexity of Planning with Partial Observability (PDF). Int. Conf. Automated Planning and Scheduling. AAAI. Archived (PDF) from the original on 2020-10-31. Retrieved 2019-07-03. - ^ De Giacomo, Giuseppe; Rubin, Sasha (2018). Automata-Theoretic Foundations of FOND Planning for LTLf and LDLf Goals. IJCAI. Archived from the original on 2018-07-17. Retrieved 2018-07-17. - ^ Palacios, Hector; Geffner, Hector (2009). \"Compiling uncertainty away in conformant planning problems with bounded width\". Journal of Artificial Intelligence Research. 35: 623–675. arXiv:1401.3468. doi:10.1613/jair.2708. Archived from the original on 2020-04-27. Retrieved 2019-08-16. - ^ Albore, Alexandre; Ramírez, Miquel; Geffner, Hector (2011). Effective heuristics and belief tracking for planning with incomplete information. Twenty-First International Conference on Automated Planning and Scheduling (ICAPS). Archived from the original on 2017-07-06. Retrieved 2019-08-16. - ^ Haslum, Patrik; Jonsson, Peter (2000). Some Results on the Complexity of Planning with Incomplete Information. Lecture Notes in Computer Science. Vol. 1809. Springer Berlin Heidelberg. pp. 308–318. doi:10.1007/10720246_24. ISBN 9783540446576. conference: Recent Advances in AI Planning Further reading [edit]- Vlahavas, I. \"Planning and Scheduling\". EETN. Archived from the original on 2013-12-22.",
    "text_length": 17069,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:14.862926"
  },
  {
    "id": "page_4",
    "url": "https://en.wikipedia.org/wiki/Computer_vision",
    "domain": "en.wikipedia.org",
    "title": "Computer vision - Wikipedia",
    "text": "Computer vision | Part of a series on | | Artificial intelligence (AI) | |---| Computer vision tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the form of decisions.[1][2][3][4] \"Understanding\" in this context signifies the transformation of visual images (the input to the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory. The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. Image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, 3D point clouds from LiDaR sensors, or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems. Subdisciplines of computer vision include scene reconstruction, object detection, event detection, activity recognition, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration. Definition [edit]Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.[5][6][7] \"Computer vision is concerned with the automatic extraction, analysis, and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding.\"[8] As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner.[9] As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems. Machine vision refers to a systems engineering discipline, especially in the context of factory automation. In more recent times, the terms computer vision and machine vision have converged to a greater degree.[10]: 13 History [edit]In the late 1960s, computer vision began at universities that were pioneering artificial intelligence. It was meant to mimic the human visual system as a stepping stone to endowing robots with intelligent behavior.[11] In 1966, it was believed that this could be achieved through an undergraduate summer project,[12] by attaching a camera to a computer and having it \"describe what it saw\".[13][14] What distinguished computer vision from the prevalent field of digital image processing at that time was a desire to extract three-dimensional structure from images with the goal of achieving full scene understanding. Studies in the 1970s formed the early foundations for many of the computer vision algorithms that exist today, including extraction of edges from images, labeling of lines, non-polyhedral and polyhedral modeling, representation of objects as interconnections of smaller structures, optical flow, and motion estimation.[11] The next decade saw studies based on more rigorous mathematical analysis and quantitative aspects of computer vision. These include the concept of scale-space, the inference of shape from various cues such as shading, texture and focus, and contour models known as snakes. Researchers also realized that many of these mathematical concepts could be treated within the same optimization framework as regularization and Markov random fields.[15] By the 1990s, some of the previous research topics became more active than others. Research in projective 3-D reconstructions led to better understanding of camera calibration. With the advent of optimization methods for camera calibration, it was realized that a lot of the ideas were already explored in bundle adjustment theory from the field of photogrammetry. This led to methods for sparse 3-D reconstructions of scenes from multiple images. Progress was made on the dense stereo correspondence problem and further multi-view stereo techniques. At the same time, variations of graph cut were used to solve image segmentation. This decade also marked the first time statistical learning techniques were used in practice to recognize faces in images (see Eigenface). Toward the end of the 1990s, a significant change came about with the increased interaction between the fields of computer graphics and computer vision. This included image-based rendering, image morphing, view interpolation, panoramic image stitching and early light-field rendering.[11] Recent work has seen the resurgence of feature-based methods used in conjunction with machine learning techniques and complex optimization frameworks.[16][17] The advancement of Deep Learning techniques has brought further life to the field of computer vision. The accuracy of deep learning algorithms on several benchmark computer vision data sets for tasks ranging from classification,[18] segmentation and optical flow has surpassed prior methods.[19][20] Related fields [edit]Solid-state physics [edit]Solid-state physics is another field that is closely related to computer vision. Most computer vision systems rely on image sensors, which detect electromagnetic radiation, which is typically in the form of either visible, infrared or ultraviolet light. The sensors are designed using quantum physics. The process by which light interacts with surfaces is explained using physics. Physics explains the behavior of optics which are a core part of most imaging systems. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process.[11] Also, various measurement problems in physics can be addressed using computer vision, for example, motion in fluids. Neurobiology [edit]Neurobiology has greatly influenced the development of computer vision algorithms. Over the last century, there has been an extensive study of eyes, neurons, and brain structures devoted to the processing of visual stimuli in both humans and various animals. This has led to a coarse yet convoluted description of how natural vision systems operate in order to solve certain vision-related tasks. These results have led to a sub-field within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems at different levels of complexity. Also, some of the learning-based methods developed within computer vision (e.g. neural net and deep learning based image and feature analysis and classification) have their background in neurobiology. The Neocognitron, a neural network developed in the 1970s by Kunihiko Fukushima, is an early example of computer vision taking direct inspiration from neurobiology, specifically the primary visual cortex. Some strands of computer vision research are closely related to the study of biological vision—indeed, just as many strands of AI research are closely tied with research into human intelligence and the use of stored knowledge to interpret, integrate, and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. Computer vision, on the other hand, develops and describes the algorithms implemented in software and hardware behind artificial vision systems. An interdisciplinary exchange between biological and computer vision has proven fruitful for both fields.[22] Signal processing [edit]Yet another field related to computer vision is signal processing. Many methods for processing one-variable signals, typically temporal signals, can be extended in a natural way to the processing of two-variable signals or multi-variable signals in computer vision. However, because of the specific nature of images, there are many methods developed within computer vision that have no counterpart in the processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing as a part of computer vision. Robotic navigation [edit]Robot navigation sometimes deals with autonomous path planning or deliberation for robotic systems to navigate through an environment.[23] A detailed understanding of these environments is required to navigate through them. Information about the environment could be provided by a computer vision system, acting as a vision sensor and providing high-level information about the environment and the robot Visual computing [edit]Visual computing is a generic term for all computer science disciplines dealing with images and 3D models, such as computer graphics, image processing, visualization, computer vision, virtual and augmented reality, video processing, and computational visualistics. Visual computing also includes aspects of pattern recognition, human computer interaction, machine learning and digital libraries. The core challenges are the acquisition, processing, analysis and rendering of visual information (mainly images and video). Application areas include industrial quality control, medical image processing and visualization, surveying, robotics, multimedia systems, virtual heritage, special effects in movies and television, and ludology. Visual computing also includes digital art and digital media studies. Other fields [edit]Besides the above-mentioned views on computer vision, many of the related research topics can also be studied from a purely mathematical point of view. For example, many methods in computer vision are based on statistics, optimization or geometry. Finally, a significant part of the field is devoted to the implementation aspect of computer vision; how existing methods can be realized in various combinations of software and hardware, or how these methods can be modified in order to gain processing speed without losing too much performance. Computer vision is also used in fashion eCommerce, inventory management, patent search, furniture, and the beauty industry.[24] Distinctions [edit]The fields most closely related to computer vision are image processing, image analysis and machine vision. There is a significant overlap in the range of techniques and applications that these cover. This implies that the basic techniques that are used and developed in these fields are similar, something which can be interpreted as there is only one field with different names. On the other hand, it appears to be necessary for research groups, scientific journals, conferences, and companies to present or market themselves as belonging specifically to one of these fields and, hence, various characterizations which distinguish each of the fields from the others have been presented. In image processing, the input and output are both images, whereas in computer vision, the input is an image or video, and the output could be an enhanced image, an analysis of the image's content, or even a system's behavior based on that analysis. Computer graphics produces image data from 3D models, and computer vision often produces 3D models from image data.[25] There is also a trend towards a combination of the two disciplines, e.g., as explored in augmented reality. The following characterizations appear relevant but should not be taken as universally accepted: - Image processing and image analysis tend to focus on 2D images, how to transform one image to another, e.g., by pixel-wise operations such as contrast enhancement, local operations such as edge extraction or noise removal, or geometrical transformations such as rotating the image. This characterization implies that image processing/analysis neither requires assumptions nor produces interpretations about the image content. - Computer vision includes 3D analysis from 2D images. This analyzes the 3D scene projected onto one or several images, e.g., how to reconstruct structure or other information about the 3D scene from one or several images. Computer vision often relies on more or less complex assumptions about the scene depicted in an image. - Machine vision is the process of applying a range of technologies and methods to provide imaging-based automatic inspection, process control, and robot guidance[26] in industrial applications.[22] Machine vision tends to focus on applications, mainly in manufacturing, e.g., vision-based robots and systems for vision-based inspection, measurement, or picking (such as bin picking[27]). This implies that image sensor technologies and control theory often are integrated with the processing of image data to control a robot and that real-time processing is emphasized by means of efficient implementations in hardware and software. It also implies that external conditions such as lighting can be and are often more controlled in machine vision than they are in general computer vision, which can enable the use of different algorithms. - There is also a field called imaging which primarily focuses on the process of producing images, but sometimes also deals with the processing and analysis of images. For example, medical imaging includes substantial work on the analysis of image data in medical applications. Progress in convolutional neural networks (CNNs) has improved the accurate detection of disease in medical images, particularly in cardiology, pathology, dermatology, and radiology.[28] - Finally, pattern recognition is a field that uses various methods to extract information from signals in general, mainly based on statistical approaches and artificial neural networks.[29] A significant part of this field is devoted to applying these methods to image data. Photogrammetry also overlaps with computer vision, e.g., stereophotogrammetry vs. computer stereo vision. Applications [edit]Applications range from tasks such as industrial machine vision systems which, say, inspect bottles speeding by on a production line, to research into artificial intelligence and computers or robots that can comprehend the world around them. The computer vision and machine vision fields have significant overlap. Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining automated image analysis with other methods and technologies to provide automated inspection and robot guidance in industrial applications. In many computer-vision applications, computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common. Examples of applications of computer vision include systems for: - Automatic inspection, e.g., in manufacturing applications; - Assisting humans in identification tasks, e.g., a species identification system;[30] - Controlling processes, e.g., an industrial robot; - Detecting events, e.g., for visual surveillance or people counting, e.g., in the restaurant industry; - Interaction, e.g., as the input to a device for computer-human interaction; - MediaPipe, an open-source framework from Google for AI edge device computing, e.g., face detection, image classification, object detection; - monitoring agricultural crops, e.g. an open-source vision transformers model[31] has been developed to help farmers automatically detect strawberry diseases with 98.4% accuracy.[32] - Modeling objects or environments, e.g., medical image analysis or topographical modeling; - Navigation, e.g., by an autonomous vehicle or mobile robot; - Organizing information, e.g., for indexing databases of images and image sequences. - Tracking surfaces or planes in 3D coordinates for allowing Augmented Reality experiences. - Analyzing the condition of facilities in industry or construction. - Automatic real-time lip-reading for devices and apps to assist people with disabilities.[33] For 2024, the leading areas of computer vision were industry (market size US$5.22 billion),[34] medicine (market size US$2.6 billion),[35] military (market size US$996.2 million).[36] Medicine [edit]One of the most prominent application fields is medical computer vision, or medical image processing, characterized by the extraction of information from image data to diagnose a patient.[37] An example of this is the detection of tumours, arteriosclerosis or other malign changes, and a variety of dental pathologies; measurements of organ dimensions, blood flow, etc. are another example. It also supports medical research by providing new information: e.g., about the structure of the brain or the quality of medical treatments. Applications of computer vision in the medical area also include enhancement of images interpreted by humans—ultrasonic images or X-ray images, for example—to reduce the influence of noise. Machine vision [edit]A second application area in computer vision is in industry, sometimes called machine vision, where information is extracted for the purpose of supporting a production process. One example is quality control where details or final products are being automatically inspected in order to find defects. One of the most prevalent fields for such inspection is the Wafer industry in which every single Wafer is being measured and inspected for inaccuracies or defects to prevent a computer chip from coming to market in an unusable manner. Another example is a measurement of the position and orientation of details to be picked up by a robot arm. Machine vision is also heavily used in the agricultural processes to remove undesirable foodstuff from bulk material, a process called optical sorting.[38] Military [edit]The obvious examples are the detection of enemy soldiers or vehicles and missile guidance. More advanced systems for missile guidance send the missile to an area rather than a specific target, and target selection is made when the missile reaches the area based on locally acquired image data. Modern military concepts, such as \"battlefield awareness\", imply that various sensors, including image sensors, provide a rich set of information about a combat scene that can be used to support strategic decisions. In this case, automatic processing of the data is used to reduce complexity and to fuse information from multiple sensors to increase reliability. Autonomous vehicles [edit]One of the newer application areas is autonomous vehicles, which include submersibles, land-based vehicles (small robots with wheels, cars, or trucks), aerial vehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully autonomous (unmanned) vehicles to vehicles where computer-vision-based systems support a driver or a pilot in various situations. Fully autonomous vehicles typically use computer vision for navigation, e.g., for knowing where they are or mapping their environment (SLAM), for detecting obstacles. It can also be used for detecting certain task-specific events, e.g., a UAV looking for forest fires. Examples of supporting systems are obstacle warning systems in cars, cameras and LiDAR sensors in vehicles, and systems for autonomous landing of aircraft. Several car manufacturers have demonstrated systems for autonomous driving of cars. There are ample examples of military autonomous vehicles ranging from advanced missiles to UAVs for recon missions or missile guidance. Space exploration is already being made with autonomous vehicles using computer vision, e.g., NASA's Curiosity and CNSA's Yutu-2 rover. Tactile feedback [edit]Materials such as rubber and silicon are being used to create sensors that allow for applications such as detecting microundulations and calibrating robotic hands. Rubber can be used in order to create a mold that can be placed over a finger, inside of this mold would be multiple strain gauges. The finger mold and sensors could then be placed on top of a small sheet of rubber containing an array of rubber pins. A user can then wear the finger mold and trace a surface. A computer can then read the data from the strain gauges and measure if one or more of the pins are being pushed upward. If a pin is being pushed upward then the computer can recognize this as an imperfection in the surface. This sort of technology is useful in order to receive accurate data on imperfections on a very large surface.[39] Another variation of this finger mold sensor are sensors that contain a camera suspended in silicon. The silicon forms a dome around the outside of the camera and embedded in the silicon are point markers that are equally spaced. These cameras can then be placed on devices such as robotic hands in order to allow the computer to receive highly accurate tactile data.[40] Other application areas include: - Support of visual effects creation for cinema and broadcast, e.g., camera tracking (match moving). - Surveillance. - Driver drowsiness detection[41][42][43] - Tracking and counting organisms in the biological sciences[44] Typical tasks [edit]Each of the application areas described above employ a range of computer vision tasks; more or less well-defined measurement problems or processing problems, which can be solved using a variety of methods. Some examples of typical computer vision tasks are presented below. Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g., in the forms of decisions.[1][2][3][4] Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.[45] Recognition [edit]The classical problem in computer vision, image processing, and machine vision is that of determining whether or not the image data contains some specific object, feature, or activity. Different varieties of recognition problem are described in the literature.[46] - Object recognition (also called object classification) – one or several pre-specified or learned objects or object classes can be recognized, usually together with their 2D positions in the image or 3D poses in the scene. Blippar, Google Goggles, and LikeThat provide stand-alone programs that illustrate this functionality. - Identification – an individual instance of an object is recognized. Examples include identification of a specific person's face or fingerprint, identification of handwritten digits, or the identification of a specific vehicle. - Detection – the image data are scanned for specific objects along with their locations. Examples include the detection of an obstacle in the car's field of view and possible abnormal cells or tissues in medical images or the detection of a vehicle in an automatic road toll system. Detection based on relatively simple and fast computations is sometimes used for finding smaller regions of interesting image data which can be further analyzed by more computationally demanding techniques to produce a correct interpretation. Currently, the best algorithms for such tasks are based on convolutional neural networks. An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and 1000 object classes used in the competition.[47] Performance of convolutional neural networks on the ImageNet tests is now close to that of humans.[47] The best algorithms still struggle with objects that are small or thin, such as a small ant on the stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters (an increasingly common phenomenon with modern digital cameras). By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained classes, such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this with ease.[citation needed] Several specialized tasks based on recognition exist, such as: - Content-based image retrieval – finding all images in a larger set of images which have a specific content. The content can be specified in different ways, for example in terms of similarity relative to a target image (give me all images similar to image X) by utilizing reverse image search techniques, or in terms of high-level search criteria given as text input (give me all images which contain many houses, are taken during winter and have no cars in them). - Pose estimation – estimating the position or orientation of a specific object relative to the camera. An example application for this technique would be assisting a robot arm in retrieving objects from a conveyor belt in an assembly line situation or picking parts from a bin. - Optical character recognition (OCR) – identifying characters in images of printed or handwritten text, usually with a view to encoding the text in a format more amenable to editing or indexing (e.g. ASCII). A related task is reading of 2D codes such as data matrix and QR codes. - Facial recognition – a technology that enables the matching of faces in digital images or video frames to a face database, which is now widely used for mobile phone facelock, smart door locking, etc.[48] - Emotion recognition – a subset of facial recognition, emotion recognition refers to the process of classifying human emotions. Psychologists caution, however, that internal emotions cannot be reliably detected from faces.[49] - Shape Recognition Technology (SRT) in people counter systems differentiating human beings (head and shoulder patterns) from objects. - Human activity recognition - deals with recognizing the activity from a series of video frames, such as, if the person is picking up an object or walking. Motion analysis [edit]Several tasks relate to motion estimation, where an image sequence is processed to produce an estimate of the velocity either at each points in the image or in the 3D scene or even of the camera that produces the images. Examples of such tasks are: - Egomotion – determining the 3D rigid motion (rotation and translation) of the camera from an image sequence produced by the camera. - Tracking – following the movements of a (usually) smaller set of interest points or objects (e.g., vehicles, objects, humans or other organisms[44]) in the image sequence. This has vast industry applications as most high-running machinery can be monitored in this way. - Optical flow – to determine, for each point in the image, how that point is moving relative to the image plane, i.e., its apparent motion. This motion is a result of both how the corresponding 3D point is moving in the scene and how the camera is moving relative to the scene. Scene reconstruction [edit]Given one or (typically) more images of a scene, or a video, scene reconstruction aims at computing a 3D model of the scene. In the simplest case, the model can be a set of 3D points. More sophisticated methods produce a complete 3D surface model. The advent of 3D imaging not requiring motion or scanning, and related processing algorithms is enabling rapid advances in this field. Grid-based 3D sensing can be used to acquire 3D images from multiple angles. Algorithms are now available to stitch multiple 3D images together into point clouds and 3D models.[25] Image restoration [edit]Image restoration comes into the picture when the original image is degraded or damaged due to some external factors like lens wrong positioning, transmission interference, low lighting or motion blurs, etc., which is referred to as noise. When the images are degraded or damaged, the information to be extracted from them also gets damaged. Therefore, we need to recover or restore the image as it was intended to be. The aim of image restoration is the removal of noise (sensor noise, motion blur, etc.) from images. The simplest possible approach for noise removal is various types of filters, such as low-pass filters or median filters. More sophisticated methods assume a model of how the local image structures look to distinguish them from noise. By first analyzing the image data in terms of the local image structures, such as lines or edges, and then controlling the filtering based on local information from the analysis step, a better level of noise removal is usually obtained compared to the simpler approaches. An example in this field is inpainting. System methods [edit]The organization of a computer vision system is highly application-dependent. Some systems are stand-alone applications that solve a specific measurement or detection problem, while others constitute a sub-system of a larger design which, for example, also contains sub-systems for control of mechanical actuators, planning, information databases, man-machine interfaces, etc. The specific implementation of a computer vision system also depends on whether its functionality is pre-specified or if some part of it can be learned or modified during operation. Many functions are unique to the application. There are, however, typical functions that are found in many computer vision systems. - Image acquisition – A digital image is produced by one or several image sensors, which, besides various types of light-sensitive cameras, include range sensors, tomography devices, radar, ultra-sonic cameras, etc. Depending on the type of sensor, the resulting image data is an ordinary 2D image, a 3D volume, or an image sequence. The pixel values typically correspond to light intensity in one or several spectral bands (gray images or colour images) but can also be related to various physical measures, such as depth, absorption or reflectance of sonic or electromagnetic waves, or magnetic resonance imaging.[38] - Pre-processing – Before a computer vision method can be applied to image data in order to extract some specific piece of information, it is usually necessary to process the data in order to ensure that it satisfies certain assumptions implied by the method. Examples are: - Re-sampling to ensure that the image coordinate system is correct. - Noise reduction to ensure that sensor noise does not introduce false information. - Contrast enhancement to ensure that relevant information can be detected. - Scale space representation to enhance image structures at locally appropriate scales. - Feature extraction – Image features at various levels of complexity are extracted from the image data.[38] Typical examples of such features are: - Lines, edges and ridges. - Localized interest points such as corners, blobs or points. - More complex features may be related to texture, shape, or motion. - Detection/segmentation – At some point in the processing, a decision is made about which image points or regions of the image are relevant for further processing.[38] Examples are: - Selection of a specific set of interest points. - Segmentation of one or multiple image regions that contain a specific object of interest. - Segmentation of image into nested scene architecture comprising foreground, object groups, single objects or salient object[50] parts (also referred to as spatial-taxon scene hierarchy),[51] while the visual salience is often implemented as spatial and temporal attention. - Segmentation or co-segmentation of one or multiple videos into a series of per-frame foreground masks while maintaining its temporal semantic continuity.[52][53] - High-level processing – At this step, the input is typically a small set of data, for example, a set of points or an image region, which is assumed to contain a specific object.[38] The remaining processing deals with, for example: - Verification that the data satisfies model-based and application-specific assumptions. - Estimation of application-specific parameters, such as object pose or object size. - Image recognition – classifying a detected object into different categories. - Image registration – comparing and combining two different views of the same object. - Decision making Making the final decision required for the application,[38] for example: - Pass/fail on automatic inspection applications. - Match/no-match in recognition applications. - Flag for further human review in medical, military, security and recognition applications. Image-understanding systems [edit]Image-understanding systems (IUS) include three levels of abstraction as follows: low level includes image primitives such as edges, texture elements, or regions; intermediate level includes boundaries, surfaces and volumes; and high level includes objects, scenes, or events. Many of these requirements are entirely topics for further research. The representational requirements in the designing of IUS for these levels are: representation of prototypical concepts, concept organization, spatial knowledge, temporal knowledge, scaling, and description by comparison and differentiation. While inference refers to the process of deriving new, not explicitly represented facts from currently known facts, control refers to the process that selects which of the many inference, search, and matching techniques should be applied at a particular stage of processing. Inference and control requirements for IUS are: search and hypothesis activation, matching and hypothesis testing, generation and use of expectations, change and focus of attention, certainty and strength of belief, inference and goal satisfaction.[54] Hardware [edit]There are many kinds of computer vision systems; however, all of them contain these basic elements: a power source, at least one image acquisition device (camera, ccd, etc.), a processor, and control and communication cables or some kind of wireless interconnection mechanism. In addition, a practical vision system contains software, as well as a display in order to monitor the system. Vision systems for inner spaces, as most industrial ones, contain an illumination system and may be placed in a controlled environment. Furthermore, a completed system includes many accessories, such as camera supports, cables, and connectors. Most computer vision systems use visible-light cameras passively viewing a scene at frame rates of at most 60 frames per second (usually far slower). A few computer vision systems use image-acquisition hardware with active illumination or something other than visible light or both, such as structured-light 3D scanners, thermographic cameras, hyperspectral imagers, radar imaging, lidar scanners, magnetic resonance images, side-scan sonar, synthetic aperture sonar, etc. Such hardware captures \"images\" that are then processed often using the same computer vision algorithms used to process visible-light images. While traditional broadcast and consumer video systems operate at a rate of 30 frames per second, advances in digital signal processing and consumer graphics hardware has made high-speed image acquisition, processing, and display possible for real-time systems on the order of hundreds to thousands of frames per second. For applications in robotics, fast, real-time video systems are critically important and often can simplify the processing needed for certain algorithms. When combined with a high-speed projector, fast image acquisition allows 3D measurement and feature tracking to be realized.[55] Egocentric vision systems are composed of a wearable camera that automatically take pictures from a first-person perspective. As of 2016, vision processing units are emerging as a new class of processors to complement CPUs and graphics processing units (GPUs) in this role.[56] See also [edit]Lists [edit]References [edit]- ^ a b Reinhard Klette (2014). Concise Computer Vision. Springer. ISBN 978-1-4471-6320-6. - ^ a b Linda G. Shapiro; George C. Stockman (2001). Computer Vision. Prentice Hall. ISBN 978-0-13-030796-5. - ^ a b Tim Morris (2004). Computer Vision and Image Processing. Palgrave Macmillan. ISBN 978-0-333-99451-1. - ^ a b Bernd Jähne; Horst Haußecker (2000). Computer Vision and Applications, A Guide for Students and Practitioners. Academic Press. ISBN 978-0-13-085198-7. - ^ Dana H. Ballard; Christopher M. Brown (1982). Computer Vision. Prentice Hall. ISBN 978-0-13-165316-0. - ^ Huang, T. (1996-11-19). Vandoni, Carlo E (ed.). Computer Vision: Evolution And Promise (PDF). 19th CERN School of Computing. Geneva: CERN. pp. 21–25. doi:10.5170/CERN-1996-008.21. ISBN 978-92-9083-095-5. Archived (PDF) from the original on 2018-02-07. - ^ Milan Sonka; Vaclav Hlavac; Roger Boyle (2008). Image Processing, Analysis, and Machine Vision. Thomson. ISBN 978-0-495-08252-1. - ^ http://www.bmva.org/visionoverview Archived 2017-02-16 at the Wayback Machine The British Machine Vision Association and Society for Pattern Recognition Retrieved February 20, 2017 - ^ Murphy, Mike (13 April 2017). \"Star Trek's \"tricorder\" medical scanner just got closer to becoming a reality\". Archived from the original on 2 July 2017. Retrieved 18 July 2017. - ^ Computer Vision Principles, algorithms, Applications, Learning 5th Edition by E.R. Davies Academic Press, Elsevier 2018 ISBN 978-0-12-809284-2 - ^ a b c d Richard Szeliski (30 September 2010). Computer Vision: Algorithms and Applications. Springer Science & Business Media. pp. 10–16. ISBN 978-1-84882-935-0. - ^ Sejnowski, Terrence J. (2018). The deep learning revolution. Cambridge, Massachusetts London, England: The MIT Press. p. 28. ISBN 978-0-262-03803-4. - ^ Papert, Seymour (1966-07-01). \"The Summer Vision Project\". MIT AI Memos (1959 - 2004). hdl:1721.1/6125. - ^ Margaret Ann Boden (2006). Mind as Machine: A History of Cognitive Science. Clarendon Press. p. 781. ISBN 978-0-19-954316-8. - ^ Takeo Kanade (6 December 2012). Three-Dimensional Machine Vision. Springer Science & Business Media. ISBN 978-1-4613-1981-8. - ^ Nicu Sebe; Ira Cohen; Ashutosh Garg; Thomas S. Huang (3 June 2005). Machine Learning in Computer Vision. Springer Science & Business Media. ISBN 978-1-4020-3274-5. - ^ William Freeman; Pietro Perona; Bernhard Scholkopf (2008). \"Guest Editorial: Machine Learning for Computer Vision\". International Journal of Computer Vision. 77 (1): 1. doi:10.1007/s11263-008-0127-7. hdl:21.11116/0000-0003-30FB-C. ISSN 1573-1405. - ^ LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (2015). \"Deep Learning\" (PDF). Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID 26017442. S2CID 3074096. - ^ Ilg, Eddy; Mayer, Nikolaus; Saikia, Tonmoy; Keuper, Margret; Dosovitskiy, Alexey; Brox, Thomas (2016). \"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\". arXiv:1612.01925 [cs.CV]. - ^ Jiao, Licheng; Zhang, Fan; Liu, Fang; Yang, Shuyuan; Li, Lingling; Feng, Zhixi; Qu, Rong (2019). \"A Survey of Deep Learning-Based Object Detection\". IEEE Access. 7: 128837–128868. arXiv:1907.09408. Bibcode:2019IEEEA...7l8837J. doi:10.1109/ACCESS.2019.2939201. S2CID 198147317. - ^ Ferrie, C.; Kaiser, S. (2019). Neural Networks for Babies. Sourcebooks. ISBN 978-1-4926-7120-6. - ^ a b Steger, Carsten; Markus Ulrich; Christian Wiedemann (2018). Machine Vision Algorithms and Applications (2nd ed.). Weinheim: Wiley-VCH. p. 1. ISBN 978-3-527-41365-2. Archived from the original on 2023-03-15. Retrieved 2018-01-30. - ^ Murray, Don, and Cullen Jennings. \"Stereo vision-based mapping and navigation for mobile robots Archived 2020-10-31 at the Wayback Machine.\" Proceedings of International Conference on Robotics and Automation. Vol. 2. IEEE, 1997. - ^ Andrade, Norberto Almeida. \"Computational Vision and Business Intelligence in the Beauty Segment - An Analysis through Instagram\" (PDF). Journal of Marketing Management. American Research Institute for Policy Development. Archived from the original on March 11, 2024. Retrieved 11 March 2024. - ^ a b c Soltani, A. A.; Huang, H.; Wu, J.; Kulkarni, T. D.; Tenenbaum, J. B. (2017). \"Synthesizing 3D Shapes via Modeling Multi-view Depth Maps and Silhouettes with Deep Generative Networks\". 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 1511–1519. doi:10.1109/CVPR.2017.269. hdl:1721.1/126644. ISBN 978-1-5386-0457-1. S2CID 31373273. - ^ Turek, Fred (June 2011). \"Machine Vision Fundamentals, How to Make Robots See\". NASA Tech Briefs Magazine. 35 (6). pages 60–62 - ^ \"The Future of Automated Random Bin Picking\". Archived from the original on 2018-01-11. Retrieved 2018-01-10. - ^ Esteva, Andre; Chou, Katherine; Yeung, Serena; Naik, Nikhil; Madani, Ali; Mottaghi, Ali; Liu, Yun; Topol, Eric; Dean, Jeff; Socher, Richard (2021-01-08). \"Deep learning-enabled medical computer vision\". npj Digital Medicine. 4 (1): 5. doi:10.1038/s41746-020-00376-2. ISSN 2398-6352. PMC 7794558. PMID 33420381. - ^ Chervyakov, N. I.; Lyakhov, P. A.; Deryabin, M. A.; Nagornov, N. N.; Valueva, M. V.; Valuev, G. V. (2020). \"Residue Number System-Based Solution for Reducing the Hardware Cost of a Convolutional Neural Network\". Neurocomputing. 407: 439–453. doi:10.1016/j.neucom.2020.04.018. S2CID 219470398. Convolutional neural networks (CNNs) represent deep learning architectures that are currently used in a wide range of applications, including computer vision, speech recognition, identification of albuminous sequences in bioinformatics, production control, time series analysis in finance, and many others. - ^ Wäldchen, Jana; Mäder, Patrick (2017-01-07). \"Plant Species Identification Using Computer Vision Techniques: A Systematic Literature Review\". Archives of Computational Methods in Engineering. 25 (2): 507–543. doi:10.1007/s11831-016-9206-z. ISSN 1134-3060. PMC 6003396. PMID 29962832. - ^ Aghamohammadesmaeilketabforoosh, Kimia; Nikan, Soodeh; Antonini, Giorgio; Pearce, Joshua M. (January 2024). \"Optimizing Strawberry Disease and Quality Detection with Vision Transformers and Attention-Based Convolutional Neural Networks\". Foods. 13 (12): 1869. doi:10.3390/foods13121869. ISSN 2304-8158. PMC 11202458. PMID 38928810. - ^ \"New AI model developed at Western detects strawberry diseases, takes aim at waste\". London. 2024-09-13. Retrieved 2024-09-19. - ^ \"Applications of Computer Vision\". GeeksforGeeks. 2020-06-30. Retrieved 2025-04-27. - ^ \"Global Industrial Machine Vision Market Growth Analysis - Size and Forecast 2024 - 2028\". www.technavio.com. Retrieved 2025-05-14. - ^ Laviola, Erin. \"What Is Computer Vision and How Is It Being Used in Healthcare?\". HealthTech. Retrieved 2025-05-14. - ^ \"Computer Vision - Artificial intelligence in military market outlook\". www.grandviewresearch.com. Retrieved 2025-05-14. - ^ Li, Mengfang; Jiang, Yuanyuan; Zhang, Yanzhou; Zhu, Haisheng (2023). \"Medical image analysis using deep learning algorithms\". Frontiers in Public Health. 11 1273253. Bibcode:2023FrPH...1173253L. doi:10.3389/fpubh.2023.1273253. ISSN 2296-2565. PMC 10662291. PMID 38026291. - ^ a b c d e f E. Roy Davies (2005). Machine Vision: Theory, Algorithms, Practicalities. Morgan Kaufmann. ISBN 978-0-12-206093-9. - ^ Ando, Mitsuhito; Takei, Toshinobu; Mochiyama, Hiromi (2020-03-03). \"Rubber artificial skin layer with flexible structure for shape estimation of micro-undulation surfaces\". ROBOMECH Journal. 7 (1): 11. doi:10.1186/s40648-020-00159-0. ISSN 2197-4225. - ^ Choi, Seung-hyun; Tahara, Kenji (2020-03-12). \"Dexterous object manipulation by a multi-fingered robotic hand with visual-tactile fingertip sensors\". ROBOMECH Journal. 7 (1): 14. doi:10.1186/s40648-020-00162-5. ISSN 2197-4225. - ^ Garg, Hitendra (2020-02-29). \"Drowsiness Detection of a Driver using Conventional Computer Vision Application\". 2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC). pp. 50–53. doi:10.1109/PARC49193.2020.236556. ISBN 978-1-7281-6575-2. S2CID 218564267. - ^ Hasan, Fudail; Kashevnik, Alexey (2021-05-14). \"State-of-the-Art Analysis of Modern Drowsiness Detection Algorithms Based on Computer Vision\". 2021 29th Conference of Open Innovations Association (FRUCT). pp. 141–149. doi:10.23919/FRUCT52173.2021.9435480. ISBN 978-952-69244-5-8. S2CID 235207036. Archived from the original on 2022-06-27. Retrieved 2022-11-06. - ^ Balasundaram, A; Ashokkumar, S; Kothandaraman, D; kora, SeenaNaik; Sudarshan, E; Harshaverdhan, A (2020-12-01). \"Computer vision based fatigue detection using facial parameters\". IOP Conference Series: Materials Science and Engineering. 981 (2) 022005. Bibcode:2020MS&E..981b2005B. doi:10.1088/1757-899x/981/2/022005. ISSN 1757-899X. S2CID 230639179. - ^ a b Bruijning, Marjolein; Visser, Marco D.; Hallmann, Caspar A.; Jongejans, Eelke; Golding, Nick (2018). \"trackdem: Automated particle tracking to obtain population counts and size distributions from videos in r\". Methods in Ecology and Evolution. 9 (4): 965–973. Bibcode:2018MEcEv...9..965B. doi:10.1111/2041-210X.12975. hdl:2066/184075. ISSN 2041-210X. - ^ David A. Forsyth; Jean Ponce (2003). Computer Vision, A Modern Approach. Prentice Hall. ISBN 978-0-13-085198-7. - ^ Forsyth, David; Ponce, Jean (2012). Computer vision: a modern approach. Pearson. - ^ a b Russakovsky, Olga; Deng, Jia; Su, Hao; Krause, Jonathan; Satheesh, Sanjeev; Ma, Sean; Huang, Zhiheng; Karpathy, Andrej; Khosla, Aditya; Bernstein, Michael; Berg, Alexander C. (December 2015). \"ImageNet Large Scale Visual Recognition Challenge\". International Journal of Computer Vision. 115 (3): 211–252. arXiv:1409.0575. doi:10.1007/s11263-015-0816-y. hdl:1721.1/104944. ISSN 0920-5691. S2CID 2930547. Archived from the original on 2023-03-15. Retrieved 2020-11-20. - ^ Quinn, Arthur (2022-10-09). \"AI Image Recognition: Inevitable Trending of Modern Lifestyle\". TopTen.ai. Archived from the original on 2022-12-02. Retrieved 2022-12-23. - ^ Barrett, Lisa Feldman; Adolphs, Ralph; Marsella, Stacy; Martinez, Aleix M.; Pollak, Seth D. (July 2019). \"Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements\". Psychological Science in the Public Interest. 20 (1): 1–68. doi:10.1177/1529100619832930. ISSN 1529-1006. PMC 6640856. PMID 31313636. - ^ A. Maity (2015). \"Improvised Salient Object Detection and Manipulation\". arXiv:1511.02999 [cs.CV]. - ^ Barghout, Lauren. \"Visual Taxometric Approach to Image Segmentation Using Fuzzy-Spatial Taxon Cut Yields Contextually Relevant Regions Archived 2018-11-14 at the Wayback Machine.\" Information Processing and Management of Uncertainty in Knowledge-Based Systems. Springer International Publishing, 2014. - ^ Liu, Ziyi; Wang, Le; Hua, Gang; Zhang, Qilin; Niu, Zhenxing; Wu, Ying; Zheng, Nanning (2018). \"Joint Video Object Discovery and Segmentation by Coupled Dynamic Markov Networks\" (PDF). IEEE Transactions on Image Processing. 27 (12): 5840–5853. Bibcode:2018ITIP...27.5840L. doi:10.1109/tip.2018.2859622. ISSN 1057-7149. PMID 30059300. S2CID 51867241. Archived from the original (PDF) on 2018-09-07. Retrieved 2018-09-14. - ^ Wang, Le; Duan, Xuhuan; Zhang, Qilin; Niu, Zhenxing; Hua, Gang; Zheng, Nanning (2018-05-22). \"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\" (PDF). Sensors. 18 (5): 1657. Bibcode:2018Senso..18.1657W. doi:10.3390/s18051657. ISSN 1424-8220. PMC 5982167. PMID 29789447. Archived (PDF) from the original on 2018-09-07. - ^ Shapiro, Stuart C. (1992). Encyclopedia of Artificial Intelligence, Volume 1. New York: John Wiley & Sons, Inc. pp. 643–646. ISBN 978-0-471-50306-4. - ^ Kagami, Shingo (2010). \"High-speed vision systems and projectors for real-time perception of the world\". 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops. Vol. 2010. pp. 100–107. doi:10.1109/CVPRW.2010.5543776. ISBN 978-1-4244-7029-7. S2CID 14111100. - ^ Seth Colaner (January 3, 2016). \"A Third Type Of Processor For VR/AR: Movidius' Myriad 2 VPU\". www.tomshardware.com. Archived from the original on March 15, 2023. Retrieved May 3, 2016. Further reading [edit]- James E. Dobson (2023). The Birth of Computer Vision. University of Minnesota Press. ISBN 978-1-5179-1421-9. - David Marr (1982). Vision. W. H. Freeman and Company. ISBN 978-0-7167-1284-8. - Azriel Rosenfeld; Avinash Kak (1982). Digital Picture Processing. Academic Press. ISBN 978-0-12-597301-4. - Barghout, Lauren; Lawrence W. Lee (2003). Perceptual information processing system. U.S. Patent Application 10/618,543. ISBN 978-0-262-08159-7. - Berthold K.P. Horn (1986). Robot Vision. MIT Press. ISBN 978-0-262-08159-7. - Michael C. Fairhurst (1988). Computer Vision for robotic systems. Prentice Hall. ISBN 978-0-13-166919-2. - Olivier Faugeras (1993). Three-Dimensional Computer Vision, A Geometric Viewpoint. MIT Press. ISBN 978-0-262-06158-2. - Tony Lindeberg (1994). Scale-Space Theory in Computer Vision. Springer. ISBN 978-0-7923-9418-1. - James L. Crowley; Henrik I. Christensen, eds. (1995). Vision as Process. Springer-Verlag. ISBN 978-3-540-58143-7. - Gösta H. Granlund; Hans Knutsson (1995). Signal Processing for Computer Vision. Kluwer Academic Publisher. ISBN 978-0-7923-9530-0. - Reinhard Klette; Karsten Schluens; Andreas Koschan (1998). Computer Vision – Three-Dimensional Data from Images. Springer, Singapore. ISBN 978-981-3083-71-4. - Emanuele Trucco; Alessandro Verri (1998). Introductory Techniques for 3-D Computer Vision. Prentice Hall. ISBN 978-0-13-261108-4. - Bernd Jähne (2002). Digital Image Processing. Springer. ISBN 978-3-540-67754-3. - Richard Hartley and Andrew Zisserman (2003). Multiple View Geometry in Computer Vision. Cambridge University Press. ISBN 978-0-521-54051-3. - Gérard Medioni; Sing Bing Kang (2004). Emerging Topics in Computer Vision. Prentice Hall. ISBN 978-0-13-101366-7. - R. Fisher; K Dawson-Howe; A. Fitzgibbon; C. Robertson; E. Trucco (2005). Dictionary of Computer Vision and Image Processing. John Wiley. ISBN 978-0-470-01526-1. - Nikos Paragios and Yunmei Chen and Olivier Faugeras (2005). Handbook of Mathematical Models in Computer Vision. Springer. ISBN 978-0-387-26371-7. - Wilhelm Burger; Mark J. Burge (2007). Digital Image Processing: An Algorithmic Approach Using Java. Springer. ISBN 978-1-84628-379-6. Archived from the original on 2014-05-17. Retrieved 2007-06-13. - Pedram Azad; Tilo Gockel; Rüdiger Dillmann (2008). Computer Vision – Principles and Practice. Elektor International Media BV. ISBN 978-0-905705-71-2. - Richard Szeliski (2010). Computer Vision: Algorithms and Applications. Springer-Verlag. ISBN 978-1-84882-934-3. - J. R. Parker (2011). Algorithms for Image Processing and Computer Vision (2nd ed.). Wiley. ISBN 978-0-470-64385-3. - Richard J. Radke (2013). Computer Vision for Visual Effects. Cambridge University Press. ISBN 978-0-521-76687-6. - Nixon, Mark; Aguado, Alberto (2019). Feature Extraction and Image Processing for Computer Vision (4th ed.). Academic Press. ISBN 978-0-12-814976-8. External links [edit]- USC Iris computer vision conference list - Computer vision papers on the web – a complete list of papers of the most relevant computer vision conferences. - Computer Vision Online Archived 2011-11-30 at the Wayback Machine – news, source code, datasets and job offers related to computer vision - CVonline – Bob Fisher's Compendium of Computer Vision. - British Machine Vision Association – supporting computer vision research within the UK via the BMVC and MIUA conferences, Annals of the BMVA (open-source journal), BMVA Summer School and one-day meetings - Computer Vision Container, Joe Hoeller GitHub: Widely adopted open-source container for GPU accelerated computer vision applications. Used by researchers, universities, private companies, as well as the U.S. Gov't.",
    "text_length": 52361,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:16.931493"
  },
  {
    "id": "page_5",
    "url": "https://en.wikipedia.org/wiki/General_game_playing",
    "domain": "en.wikipedia.org",
    "title": "General game playing - Wikipedia",
    "text": "General game playing It has been suggested that this article be split out into a new article titled General video game playing. (Discuss) (June 2023) | | Part of a series on | | Artificial intelligence (AI) | |---| General game playing (GGP) is the design of artificial intelligence programs to be able to play more than one game successfully.[1][2][3] For many games like chess, computers are programmed to play these games using a specially designed algorithm, which cannot be transferred to another context. For instance, a chess-playing computer program cannot play checkers. General game playing is considered as a necessary milestone on the way to artificial general intelligence.[4] General video game playing (GVGP) is the concept of GGP adjusted to the purpose of playing video games. For video games, game rules have to be either learnt over multiple iterations by artificial players like TD-Gammon,[5] or are predefined manually in a domain-specific language and sent in advance to artificial players[6][7] like in traditional GGP. Starting in 2013, significant progress was made following the deep reinforcement learning approach, including the development of programs that can learn to play Atari 2600 games[8][5][9][10][11] as well as a program that can learn to play Nintendo Entertainment System games.[12][13][14] The first commercial usage of general game playing technology was Zillions of Games in 1998. General game playing was also proposed for trading agents in supply chain management there under price negotiation in online auctions from 2003 onwards.[15][16][17][18] History [edit]This section needs to be updated.(October 2021) | In 1992, Barney Pell defined the concept of Meta-Game Playing and developed the \"MetaGame\" system. This was the first program to automatically generate chess-like game rules, and one of the earliest programs to use automated game generation. Pell then developed the system Metagamer.[19] This system was able to play a number of chess-like games, given game rules definition in a special language called Game Description Language (GDL), without any human interaction once the games were generated.[20] In 1998, the commercial system Zillions of Games was developed by Jeff Mallett and Mark Lefler. The system used a LISP-like language to define the game rules. Zillions of Games derived the evaluation function automatically from the game rules based on piece mobility, board structure and game goals. It also employed usual algorithms as found in computer chess systems: alpha–beta pruning with move ordering, transposition tables, etc.[21] The package was extended in 2007 by the addition of the Axiom plug-in, an alternate metagame engine that incorporates a complete Forth-based programming language. In 1998, z-Tree was developed by Urs Fischbacher.[22] z-Tree is the first and the most cited software tool for experimental economics. z-Tree allows the definition of game rules in z-Tree-language for game-theoretic experiments with human subjects. It also allows definition of computer players, which participate in a play with human subjects.[23] In 2005, the Stanford Project General Game Playing was established.[3] In 2012, the development of PyVGDL started.[24] GGP implementations [edit]Stanford project [edit]General Game Playing is a project of the Stanford Logic Group of Stanford University, California, which aims to create a platform for general game playing. It is the most well-known effort at standardizing GGP AI, and generally seen as the standard for GGP systems. The games are defined by sets of rules represented in the Game Description Language. In order to play the games, players interact with a game hosting server[25][26] that monitors moves for legality and keeps players informed of state changes. Since 2005, there have been annual General Game Playing competitions at the AAAI Conference. The competition judges competitor AI's abilities to play a variety of different games, by recording their performance on each individual game. In the first stage of the competition, entrants are judged on their ability to perform legal moves, gain the upper hand, and complete games faster. In the following runoff round, the AIs face off against each other in increasingly complex games. The AI that wins the most games at this stage wins the competition, and until 2013 its creator used to win a $10,000 prize.[19] So far, the following programs were victorious:[27] | Year | Name | Developer | Institution | Ref | |---|---|---|---|---| | 2005 | Cluneplayer | Jim Clune | UCLA | | | 2006 | Fluxplayer | Stephan Schiffel and Michael Thielscher | Dresden University of Technology | [28] | | 2007 | Cadiaplayer | Yngvi Björnsson and Hilmar Finnsson | Reykjavik University | [29] | | 2008 | Cadiaplayer | Yngvi Björnsson, Hilmar Finnsson and Gylfi Þór Guðmundsson | Reykjavik University | | | 2009 | Ary | Jean Méhat | Paris 8 University | | | 2010 | Ary | Jean Méhat | Paris 8 University | | | 2011 | TurboTurtle | Sam Schreiber | || | 2012 | Cadiaplayer | Hilmar Finnsson and Yngvi Björnsson | Reykjavik University | | | 2013 | TurboTurtle | Sam Schreiber | || | 2014 | Sancho | Steve Draper and Andrew Rose | [30] | | | 2015 | Galvanise | Richard Emslie | || | 2016 | WoodStock | Eric Piette | Artois University | Other approaches [edit]Other general game playing software that use their own languages for defining game rules include: | System | Year | Description | |---|---|---| | FRAMASI | 2009 | Developed for general game playing and economic experiments by Rustam Tagiew.[31][32] | | AiAi | 2015-2017 | Developed by Stephen Tavener (previous Zillions developer).[33][34][35] | | PolyGamo Player | 2017 | Released by David M. Bennett in September 2017 based on the Unity game engine.[36] | | Regular Boardgames | 2019 | Developed by Jakub Kowalski, Marek Szykuła, and their team at University of Wrocław.[37][38] | | Ludii | 2020 | Released by Cameron Browne and his team at Maastricht University as part of the ERC-funded Digital Ludeme Project.[39][40][41] | GVGP implementations [edit]Reinforcement learning [edit]GVGP could potentially be used to create real video game AI automatically, as well as \"to test game environments, including those created automatically using procedural content generation and to find potential loopholes in the gameplay that a human player could exploit\".[7] GVGP has also been used to generate game rules, and estimate a game's quality based on Relative Algorithm Performance Profiles (RAPP), which compare the skill differentiation that a game allows between good AI and bad AI.[42] Video Game Description Language [edit]The General Video Game AI Competition (GVGAI) has been running since 2014. In this competition, two-dimensional video games similar to (and sometimes based on) 1980s-era arcade and console games are used instead of the board games used in the GGP competition. It has offered a way for researchers and practitioners to test and compare their best general video game playing algorithms. The competition has an associated software framework including a large number of games written in the Video Game Description Language (VGDL), which should not be confused with GDL and is a coding language using simple semantics and commands that can easily be parsed. One example for VGDL is PyVGDL developed in 2013.[6][24] The games used in GVGP are, for now, often 2-dimensional arcade games, as they are the simplest and easiest to quantify.[43] To simplify the process of creating an AI that can interpret video games, games for this purpose are written in VGDL manually.[clarification needed] VGDL can be used to describe a game specifically for procedural generation of levels, using Answer Set Programming (ASP) and an Evolutionary Algorithm (EA). GVGP can then be used to test the validity of procedural levels, as well as the difficulty or quality of levels based on how an agent performed.[44] Algorithms [edit]Since GGP AI must be designed to play multiple games, its design cannot rely on algorithms created specifically for certain games. Instead, the AI must be designed using algorithms whose methods can be applied to a wide range of games. Recent GGP systems such as Regular Boardgames (RBG) and Ludii have explored alternative rule representations to optimize reasoning efficiency and support a broader variety of games. The AI must also be an ongoing process, that can adapt to its current state rather than the output of previous states. For this reason, open loop techniques are often most effective.[45] A popular method for developing GGP AI is the Monte Carlo tree search (MCTS) algorithm.[46] Often used together with the UCT method (Upper Confidence Bound applied to Trees), variations of MCTS have been proposed to better play certain games, as well as to make it compatible with video game playing.[47][48][49] Another variation of tree-search algorithms used is the Directed Breadth-first Search (DBS),[50] in which a child node to the current state is created for each available action, and visits each child ordered by highest average reward, until either the game ends or runs out of time.[51] In each tree-search method, the AI simulates potential actions and ranks each based on the average highest reward of each path, in terms of points earned.[46][51] Assumptions [edit]In order to interact with games, algorithms must operate under the assumption that games all share common characteristics. In the book Half-Real: Video Games Between Real Worlds and Fictional Worlds, Jesper Juul gives the following definition of games: Games are based on rules, they have variable outcomes, different outcomes give different values, player effort influences outcomes, the player is attached to the outcomes, and the game has negotiable consequences.[52] Using these assumptions, game playing AI can be created by quantifying the player input, the game outcomes, and how the various rules apply, and using algorithms to compute the most favorable path.[43] See also [edit]- AlphaZero - Artificial general intelligence - Artificial intelligence in video games - Game Description Language - Multi-task learning - Outline of artificial intelligence - Transfer learning References [edit]- ^ Pell, Barney (1992). H. van den Herik; L. Allis (eds.). \"Metagame: a new challenge for games and learning\" [Heuristic programming in artificial intelligence 3–the third computerolympiad] (PDF). Ellis-Horwood. Archived (PDF) from the original on 2020-02-17. Retrieved 2020-02-17. - ^ Pell, Barney (1996). \"A Strategic Metagame Player for General Chess-Like Games\". Computational Intelligence. 12 (1): 177–198. doi:10.1111/j.1467-8640.1996.tb00258.x. ISSN 1467-8640. S2CID 996006. - ^ a b Genesereth, Michael; Love, Nathaniel; Pell, Barney (15 June 2005). \"General Game Playing: Overview of the AAAI Competition\". AI Magazine. 26 (2): 62. doi:10.1609/aimag.v26i2.1813. ISSN 2371-9621. - ^ Canaan, Rodrigo; Salge, Christoph; Togelius, Julian; Nealen, Andy (2019). Proceedings of the 14th International Conference on the Foundations of Digital Games [Proceedings of the 14th International Conference on the Leveling the playing field: fairness in AI versus human game benchmarks]. pp. 1–8. doi:10.1145/3337722. ISBN 9781450372176. S2CID 58599284. - ^ a b Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Graves, Alex; Antonoglou, Ioannis; Wierstra, Daan; Riedmiller, Martin (2013). \"Playing Atari with Deep Reinforcement Learning\" (PDF). Neural Information Processing Systems Workshop 2013. Archived (PDF) from the original on 12 September 2014. Retrieved 25 April 2015. - ^ a b Schaul, Tom (August 2013). \"A video game description language for model-based or interactive learning\". 2013 IEEE Conference on Computational Inteligence in Games (CIG). pp. 1–8. CiteSeerX 10.1.1.360.2263. doi:10.1109/CIG.2013.6633610. ISBN 978-1-4673-5311-3. S2CID 812565. - ^ a b Levine, John; Congdon, Clare Bates; Ebner, Marc; Kendall, Graham; Lucas, Simon M.; Miikkulainen, Risto; Schaul, Tom; Thompson, Tommy (2013). \"General Video Game Playing\". Artificial and Computational Intelligence in Games. 6. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik: 77–83. Archived from the original on 9 April 2016. Retrieved 25 April 2015. - ^ Bowling, M.; Veness, J.; Naddaf, Y.; Bellemare, M. G. (2013-06-14). \"The Arcade Learning Environment: An Evaluation Platform for General Agents\". Journal of Artificial Intelligence Research. 47: 253–279. arXiv:1207.4708. doi:10.1613/jair.3912. ISSN 1076-9757. S2CID 1552061. - ^ Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu, Andrei A.; Veness, Joel; Hassabis, Demis; Bellemare, Marc G.; Graves, Alex; Riedmiller, Martin; Fidjeland, Andreas K.; Stig Petersen, Georg Ostrovski; Beattie, Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan; Wierstra, Daan; Legg, Shane (26 February 2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529–533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID 25719670. S2CID 205242740. - ^ Korjus, Kristjan; Kuzovkin, Ilya; Tampuu, Ardi; Pungas, Taivo (2014). \"Replicating the Paper \"Playing Atari with Deep Reinforcement Learning\"\" (PDF). University of Tartu. Archived (PDF) from the original on 18 December 2014. Retrieved 25 April 2015. - ^ Guo, Xiaoxiao; Singh, Satinder; Lee, Honglak; Lewis, Richard L.; Wang, Xiaoshi (2014). \"Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning\" (PDF). NIPS Proceedingsβ. Conference on Neural Information Processing Systems. Archived (PDF) from the original on 17 November 2015. Retrieved 25 April 2015. - ^ Murphy, Tom (2013). \"The First Level of Super Mario Bros. is Easy with Lexicographic Orderings and Time Travel ... after that it gets a little tricky.\" (PDF). SIGBOVIK. Archived (PDF) from the original on 26 April 2013. Retrieved 25 April 2015. - ^ Murphy, Tom. \"learnfun & playfun: A general technique for automating NES games\". Archived from the original on 19 April 2015. Retrieved 25 April 2015. - ^ Teller, Swizec (October 28, 2013). \"Week 2: Level 1 of Super Mario Bros. is easy with lexicographic orderings and\". A geek with a hat. Archived from the original on 30 April 2015. Retrieved 25 April 2015. - ^ McMillen, Colin (2003). Toward the Development of an Intelligent Agent for the Supply Chain Management Game of the 2003 Trading Agent Competition [2003 Trading Agent Competition] (Thesis). Master's Thesis. Minneapolis, MN: University of Minnesota. S2CID 167336006. - ^ Zhang, Dongmo (2009). From general game descriptions to a market specification language for general trading agents [Agent-mediated electronic commerce. Designing trading strategies and mechanisms for electronic markets.]. Berlin, Heidelberg: Springer. pp. 259–274. Bibcode:2010aecd.book..259T. CiteSeerX 10.1.1.467.4629. - ^ \"AGAPE - An Auction LanGuage for GenerAl Auction PlayErs\". AGAPE (in French). 8 March 2019. Archived from the original on 2 August 2021. Retrieved 5 March 2020. - ^ Michael, Friedrich; Ignatov, Dmitry (2019). \"General Game Playing B-to-B Price Negotiations\" (PDF). CEUR Workshop Proceedings. -2479: 89–99. Archived (PDF) from the original on 6 December 2019. Retrieved 5 March 2020. - ^ a b Barney Pell's research on computer game playing Archived 2007-08-12 at the Wayback Machine. - ^ \"Metagame and General Game Playing\". Metagame and General Game Playing. Archived from the original on 3 March 2001. Retrieved 27 March 2016. - ^ Available: Universal Game Engine Archived 2012-11-03 at the Wayback Machine email to comp.ai.games by Jeff Mallett, 10-Dec-1998. - ^ \"UZH - z-Tree - Zurich Toolbox for Readymade Economic Experiments\". www.ztree.uzh.ch. Archived from the original on 21 February 2016. Retrieved 17 February 2020. - ^ Beckenkamp, Martin; Hennig-Schmidt, Heike; Maier-Rigaud, Frank P. (1 March 2007). \"Cooperation in Symmetric and Asymmetric Prisoner's Dilemma Games\". Social Science Research Network. SSRN 968942. - ^ a b Schaul, Tom (7 February 2020). \"schaul/py-vgdl\". GitHub. Archived from the original on 11 June 2018. Retrieved 9 February 2020. - ^ GGP Server Archived 2014-02-21 at the Wayback Machine, platform for competition of general game playing systems. - ^ Dresden GGP Server Archived 2013-04-07 at the Wayback Machine, platform for competition of general game playing systems with automatic scheduling of matches. - ^ \"General Game Playing\". www.general-game-playing.de. Archived from the original on 2008-12-26. Retrieved 2008-08-21. - ^ Information about Fluxplayer Archived 2011-07-19 at the Wayback Machine, the winner of the 2nd International General Game Playing competition. - ^ Information about CADIAPlayer Archived 2011-07-22 at the Wayback Machine, more information about the winner of the 3rd, 4th, and 8th International General Game Playing competitions. - ^ Sancho is GGP Champion 2014! Archived 2015-12-22 at the Wayback Machine, winner of the 2014 International General Game Playing competition. - ^ Tagiew, Rustam (2009). Filipe, Joaquim; Fred, Ana; Sharp, Bernadette (eds.). Towards a framework for management of strategic interaction [Proceedings of the International Conference on Agents and Artificial Intelligence] (PDF). Porto, Portugal. pp. 587–590. ISBN 978-989-8111-66-1. Archived (PDF) from the original on 2021-03-09. Retrieved 2021-06-02. {{cite book}} : CS1 maint: location missing publisher (link) - ^ Tagiew, Rustam (2011). Strategische Interaktion realer Agenten Ganzheitliche Konzeptualisierung und Softwarekomponenten einer interdisziplinären Forschungsinfrastruktur (neue Ausg ed.). Saarbrücken. ISBN 9783838125121. {{cite book}} : CS1 maint: location missing publisher (link) - ^ \"Zillions of Games - Who Are We?\". www.zillions-of-games.com. Archived from the original on 2017-11-15. Retrieved 2017-11-16. - ^ \"AiAi Home Page – Stephen Tavener\". mrraow.com. Archived from the original on 2015-09-06. Retrieved 2017-11-16. - ^ \"Ai Ai announcement thread\". BoardGameGeek. Archived from the original on 2017-11-16. Retrieved 2017-11-16. - ^ \"The PolyGamo Player Project | Programming Languages and General Players for Abstract Games and Puzzles\". www.polyomino.com. Archived from the original on 2002-09-23. Retrieved 2017-11-16. - ^ Kowalski, Jakub; Mika, Maksymilian; Sutowicz, Jakub; Szykuła, Marek (2019-07-17). \"Regular Boardgames\". Proceedings of the AAAI Conference on Artificial Intelligence. 33 (1): 1699–1706. doi:10.1609/aaai.v33i01.33011699. ISSN 2374-3468. S2CID 20296467. - ^ Kowalski, Jakub; Miernik, Radoslaw; Mika, Maksymilian; Pawlik, Wojciech; Sutowicz, Jakub; Szykula, Marek; Tkaczyk, Andrzej (2020). \"Efficient Reasoning in Regular Boardgames\". 2020 IEEE Conference on Games (CoG). pp. 455–462. arXiv:2006.08295. doi:10.1109/cog47356.2020.9231668. ISBN 978-1-7281-4533-4. S2CID 219687404. - ^ \"Ludii Portal | Home of the Ludii General Game System\". www.ludii.games. Archived from the original on 2021-10-27. Retrieved 2021-10-27. - ^ \"Digital Ludeme Project | Modelling the Evolution of Traditional Games\". www.ludeme.eu. Archived from the original on 2021-10-02. Retrieved 2021-10-27. - ^ Piette, E.; Soemers, D. J. N. J.; Stephenson, M.; Sironi, C.; Stephenson, M.; Winands M. H. M.; Browne, C. (2020). \"Ludii – The Ludemic General Game System\" (PDF). European Conference on Artificial Intelligence (ECAI 2020), Santiago de Compestela. Archived (PDF) from the original on 2022-01-21. Retrieved 2021-10-27. - ^ Nielsen, Thorbjørn S.; Barros, Gabriella A. B.; Togelius, Julian; Nelson, Mark J. \"Towards generating arcade game rules with VGDL\" (PDF). Archived (PDF) from the original on 2015-09-12. Retrieved 2018-02-24. - ^ a b Levine, John; Congdon, Clare Bates; Ebner, Marc; Kendall, Graham; Lucas, Simon M.; Miikkulainen Risto, Schaul; Tom, Thompson; Tommy. \"General Video Game Playing\" (PDF). Archived (PDF) from the original on 2016-04-18. Retrieved 2016-04-09. - ^ Neufeld, Xenija; Mostaghim, Sanaz; Perez-Liebana, Diego. \"Procedural Level Generation with Answer Set Programming for General Video Game Playing\" (PDF). Archived (PDF) from the original on 2016-03-28. Retrieved 2018-02-24. - ^ Świechowski, Maciej; Park, Hyunsoo; Mańdziuk, Jacek; Kim, Kyung-Joong (2015). \"Recent Advances in General Game Playing\". The Scientific World Journal. 2015 986262. Hindawi Publishing Corporation. doi:10.1155/2015/986262. PMC 4561326. PMID 26380375. - ^ a b \"Monte-Carlo Tree Search for General Game Playing\". ResearchGate. Retrieved 2016-04-01. - ^ Finnsson, Hilmar (2012). \"Generalized Monte-Carlo Tree Search Extensions for General Game Playing\". Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence. Archived from the original on 2013-10-15. Retrieved 2016-04-09. - ^ Frydenberg, Frederik; Anderson, Kasper R.; Risi, Sebastian; Togelius, Julian. \"Investigating MCTS Modifications in General Video Game Playing\" (PDF). Archived (PDF) from the original on 2016-04-12. Retrieved 2016-04-09. - ^ M. Swiechowski; J. Mandziuk; Y. S. Ong, \"Specialization of a UCT-based General Game Playing Program to Single-Player Games,\" in IEEE Transactions on Computational Intelligence and AI in Games, vol.PP, no.99, pp.1-1 doi:10.1109/TCIAIG.2015.2391232 - ^ \"Changing the root node from a previous game step\". Archived from the original on 2021-01-17. DBS: A Directed Breadth First Search (DBS) algorithm - ^ a b Perez, Diego; Dieskau, Jens; Hünermund, Martin. \"Open Loop Search for General Video Game Playing\" (PDF). Archived (PDF) from the original on 2016-03-28. Retrieved 2016-04-09. - ^ Jesper Juul. Half-Real: Video Games Between Real Rules and Fictional Worlds. MIT Press, 2005. External links [edit]- General Game Playing Home Page at Stanford University - See also the GGP.org, GGP.org GitHub page, and games.stanford.edu. - General Game Playing Resources provided by Dresden University of Technology. - AiAi by Stephen Tavener - PolyGamo Player Project by David M. Bennett - Axiom Development kit a meta-game development system compatible with Zillions of Games, by Greg Schmidt. - Palamedes - A General Game Playing IDE - ConvNetJS Deep Q Learning Demo",
    "text_length": 22110,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:19.143542"
  },
  {
    "id": "page_6",
    "url": "https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning",
    "domain": "en.wikipedia.org",
    "title": "Knowledge representation and reasoning - Wikipedia",
    "text": "Knowledge representation and reasoning Knowledge representation (KR) aims to model information in a structured manner to formally represent it as knowledge in knowledge-based systems whereas knowledge representation and reasoning (KRR, KR&R, or KR²) also aims to understand, reason, and interpret knowledge. KRR is widely used in the field of artificial intelligence (AI) with the goal to represent information about the world in a form that a computer system can use to solve complex tasks, such as diagnosing a medical condition or having a natural-language dialog. KR incorporates findings from psychology[1] about how humans solve problems and represent knowledge, in order to design formalisms that make complex systems easier to design and build. KRR also incorporates findings from logic to automate various kinds of reasoning. Traditional KRR focuses more on the declarative representation of knowledge. Related knowledge representation formalisms mainly include vocabularies, thesaurus, semantic networks, axiom systems, frames, rules, logic programs, and ontologies. Examples of automated reasoning engines include inference engines, theorem provers, model generators, and classifiers. In a broader sense, parameterized models in machine learning — including neural network architectures such as convolutional neural networks and transformers — can also be regarded as a family of knowledge representation formalisms. The question of which formalism is most appropriate for knowledge-based systems has long been a subject of extensive debate. For instance, Frank van Harmelen et al. discussed the suitability of logic as a knowledge representation formalism and reviewed arguments presented by anti-logicists.[2] Paul Smolensky criticized the limitations of symbolic formalisms and explored the possibilities of integrating it with connectionist approaches.[3] History [edit]| Part of a series on | | Artificial intelligence (AI) | |---| The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959 and the Advice Taker proposed by John McCarthy also in 1959. GPS featured data structures for planning and decomposition. The system would begin with a goal. It would then decompose that goal into sub-goals and then set out to construct strategies that could accomplish each subgoal. The Advisor Taker, on the other hand, proposed the use of the predicate calculus to implement common sense reasoning. Many of the early approaches to knowledge representation in Artificial Intelligence (AI) used graph representations and semantic networks, similar to knowledge graphs today. In such approaches, problem solving was a form of graph traversal[4] or path-finding, as in the A* search algorithm. Typical applications included robot plan-formation and game-playing. Other researchers focused on developing automated theorem-provers for first-order logic, motivated by the use of mathematical logic to formalise mathematics and to automate the proof of mathematical theorems. A major step in this direction was the development of the resolution method by John Alan Robinson. In the meanwhile, John McCarthy and Pat Hayes developed the situation calculus as a logical representation of common sense knowledge about the laws of cause and effect. Cordell Green, in turn, showed how to do robot plan-formation by applying resolution to the situation calculus. He also showed how to use resolution for question-answering and automatic programming.[5] In contrast, researchers at Massachusetts Institute of Technology (MIT) rejected the resolution uniform proof procedure paradigm and advocated the procedural embedding of knowledge instead.[6] The resulting conflict between the use of logical representations and the use of procedural representations was resolved in the early 1970s with the development of logic programming and Prolog, using SLD resolution to treat Horn clauses as goal-reduction procedures. The early development of logic programming was largely a European phenomenon. In North America, AI researchers such as Ed Feigenbaum and Frederick Hayes-Roth advocated the representation of domain-specific knowledge rather than general-purpose reasoning.[7] These efforts led to the cognitive revolution in psychology and to the phase of AI focused on knowledge representation that resulted in expert systems in the 1970s and 80s, production systems, frame languages, etc. Rather than general problem solvers, AI changed its focus to expert systems that could match human competence on a specific task, such as medical diagnosis.[8] Expert systems gave us the terminology still in use today where AI systems are divided into a knowledge base, which includes facts and rules about a problem domain, and an inference engine, which applies the knowledge in the knowledge base to answer questions and solve problems in the domain. In these early systems the facts in the knowledge base tended to be a fairly flat structure, essentially assertions about the values of variables used by the rules.[9] Meanwhile, Marvin Minsky developed the concept of frame in the mid-1970s.[10] A frame is similar to an object class: It is an abstract description of a category describing things in the world, problems, and potential solutions. Frames were originally used on systems geared toward human interaction, e.g. understanding natural language and the social settings in which various default expectations such as ordering food in a restaurant narrow the search space and allow the system to choose appropriate responses to dynamic situations. It was not long before the frame communities and the rule-based researchers realized that there was a synergy between their approaches. Frames were good for representing the real world, described as classes, subclasses, slots (data values) with various constraints on possible values. Rules were good for representing and utilizing complex logic such as the process to make a medical diagnosis. Integrated systems were developed that combined frames and rules. One of the most powerful and well known was the 1983 Knowledge Engineering Environment (KEE) from Intellicorp. KEE had a complete rule engine with forward and backward chaining. It also had a complete frame-based knowledge base with triggers, slots (data values), inheritance, and message passing. Although message passing originated in the object-oriented community rather than AI it was quickly embraced by AI researchers as well in environments such as KEE and in the operating systems for Lisp machines from Symbolics, Xerox, and Texas Instruments.[11] The integration of frames, rules, and object-oriented programming was significantly driven by commercial ventures such as KEE and Symbolics spun off from various research projects. At the same time, there was another strain of research that was less commercially focused and was driven by mathematical logic and automated theorem proving.[citation needed] One of the most influential languages in this research was the KL-ONE language of the mid-'80s. KL-ONE was a frame language that had a rigorous semantics, formal definitions for concepts such as an Is-A relation.[12] KL-ONE and languages that were influenced by it such as Loom had an automated reasoning engine that was based on formal logic rather than on IF-THEN rules. This reasoner is called the classifier. A classifier can analyze a set of declarations and infer new assertions, for example, redefine a class to be a subclass or superclass of some other class that wasn't formally specified. In this way the classifier can function as an inference engine, deducing new facts from an existing knowledge base. The classifier can also provide consistency checking on a knowledge base (which in the case of KL-ONE languages is also referred to as an Ontology).[13] Another area of knowledge representation research was the problem of common-sense reasoning. One of the first realizations learned from trying to make software that can function with human natural language was that humans regularly draw on an extensive foundation of knowledge about the real world that we simply take for granted but that is not at all obvious to an artificial agent, such as basic principles of common-sense physics, causality, intentions, etc. An example is the frame problem, that in an event driven logic there need to be axioms that state things maintain position from one moment to the next unless they are moved by some external force. In order to make a true artificial intelligence agent that can converse with humans using natural language and can process basic statements and questions about the world, it is essential to represent this kind of knowledge.[14] In addition to McCarthy and Hayes' situation calculus, one of the most ambitious programs to tackle this problem was Doug Lenat's Cyc project. Cyc established its own Frame language and had large numbers of analysts document various areas of common-sense reasoning in that language. The knowledge recorded in Cyc included common-sense models of time, causality, physics, intentions, and many others.[15] The starting point for knowledge representation is the knowledge representation hypothesis first formalized by Brian C. Smith in 1985:[16] Any mechanically embodied intelligent process will be comprised of structural ingredients that a) we as external observers naturally take to represent a propositional account of the knowledge that the overall process exhibits, and b) independent of such external semantic attribution, play a formal but causal and essential role in engendering the behavior that manifests that knowledge. One of the most active areas of knowledge representation research is the Semantic Web.[citation needed] The Semantic Web seeks to add a layer of semantics (meaning) on top of the current Internet. Rather than indexing web sites and pages via keywords, the Semantic Web creates large ontologies of concepts. Searching for a concept will be more effective than traditional text only searches. Frame languages and automatic classification play a big part in the vision for the future Semantic Web. The automatic classification gives developers technology to provide order on a constantly evolving network of knowledge. Defining ontologies that are static and incapable of evolving on the fly would be very limiting for Internet-based systems. The classifier technology provides the ability to deal with the dynamic environment of the Internet. Recent projects funded primarily by the Defense Advanced Research Projects Agency (DARPA) have integrated frame languages and classifiers with markup languages based on XML. The Resource Description Framework (RDF) provides the basic capability to define classes, subclasses, and properties of objects. The Web Ontology Language (OWL) provides additional levels of semantics and enables integration with classification engines.[17][18] Overview [edit]Knowledge-representation is a field of artificial intelligence that focuses on designing computer representations that capture information about the world that can be used for solving complex problems. The justification for knowledge representation is that conventional procedural code is not the best formalism to use to solve complex problems. Knowledge representation makes complex software easier to define and maintain than procedural code and can be used in expert systems. For example, talking to experts in terms of business rules rather than code lessens the semantic gap between users and developers and makes development of complex systems more practical. Knowledge representation goes hand in hand with automated reasoning because one of the main purposes of explicitly representing knowledge is to be able to reason about that knowledge, to make inferences, assert new knowledge, etc. Virtually all knowledge representation languages have a reasoning or inference engine as part of the system.[19] A key trade-off in the design of knowledge representation formalisms is that between expressivity and tractability.[20] First Order Logic (FOL), with its high expressive power and ability to formalise much of mathematics, is a standard for comparing the expressibility of knowledge representation languages. Arguably, FOL has two drawbacks as a knowledge representation formalism in its own right, namely ease of use and efficiency of implementation. Firstly, because of its high expressive power, FOL allows many ways of expressing the same information, and this can make it hard for users to formalise or even to understand knowledge expressed in complex, mathematically-oriented ways. Secondly, because of its complex proof procedures, it can be difficult for users to understand complex proofs and explanations, and it can be hard for implementations to be efficient. As a consequence, unrestricted FOL can be intimidating for many software developers. One of the key discoveries of AI research in the 1970s was that languages that do not have the full expressive power of FOL can still provide close to the same expressive power of FOL, but can be easier for both the average developer and for the computer to understand. Many of the early AI knowledge representation formalisms, from databases to semantic nets to production systems, can be viewed as making various design decisions about how to balance expressive power with naturalness of expression and efficiency.[21] In particular, this balancing act was a driving motivation for the development of IF-THEN rules in rule-based expert systems. A similar balancing act was also a motivation for the development of logic programming (LP) and the logic programming language Prolog. Logic programs have a rule-based syntax, which is easily confused with the IF-THEN syntax of production rules. But logic programs have a well-defined logical semantics, whereas production systems do not. The earliest form of logic programming was based on the Horn clause subset of FOL. But later extensions of LP included the negation as failure inference rule, which turns LP into a non-monotonic logic for default reasoning. The resulting extended semantics of LP is a variation of the standard semantics of Horn clauses and FOL, and is a form of database semantics,[22] which includes the unique name assumption and a form of closed world assumption. These assumptions are much harder to state and reason with explicitly using the standard semantics of FOL. In a key 1993 paper on the topic, Randall Davis of MIT outlined five distinct roles to analyze a knowledge representation framework:[23] - \"A knowledge representation (KR) is most fundamentally a surrogate, a substitute for the thing itself, used to enable an entity to determine consequences by thinking rather than acting,\" [23] i.e., \"by reasoning about the world rather than taking action in it.\"[23] - \"It is a set of ontological commitments\",[23] i.e., \"an answer to the question: In what terms should I think about the world?\" [23] - \"It is a fragmentary theory of intelligent reasoning, expressed in terms of three components: (i) the representation's fundamental conception of intelligent reasoning; (ii) the set of inferences the representation sanctions; and (iii) the set of inferences it recommends.\"[23] - \"It is a medium for pragmatically efficient computation\",[23] i.e., \"the computational environment in which thinking is accomplished. One contribution to this pragmatic efficiency is supplied by the guidance a representation provides for organizing information\" [23] so as \"to facilitate making the recommended inferences.\"[23] - \"It is a medium of human expression\",[23] i.e., \"a language in which we say things about the world.\"[23] Knowledge representation and reasoning are a key enabling technology for the Semantic Web. Languages based on the Frame model with automatic classification provide a layer of semantics on top of the existing Internet. Rather than searching via text strings as is typical today, it will be possible to define logical queries and find pages that map to those queries.[17] The automated reasoning component in these systems is an engine known as the classifier. Classifiers focus on the subsumption relations in a knowledge base rather than rules. A classifier can infer new classes and dynamically change the ontology as new information becomes available. This capability is ideal for the ever-changing and evolving information space of the Internet.[24] The Semantic Web integrates concepts from knowledge representation and reasoning with markup languages based on XML. The Resource Description Framework (RDF) provides the basic capabilities to define knowledge-based objects on the Internet with basic features such as Is-A relations and object properties. The Web Ontology Language (OWL) adds additional semantics and integrates with automatic classification reasoners.[18] Characteristics [edit]In 1985, Ron Brachman categorized the core issues for knowledge representation as follows:[25] - Primitives. What is the underlying framework used to represent knowledge? Semantic networks were one of the first knowledge representation primitives. Also, data structures and algorithms for general fast search. In this area, there is a strong overlap with research in data structures and algorithms in computer science. In early systems, the Lisp programming language, which was modeled after the lambda calculus, was often used as a form of functional knowledge representation. Frames and Rules were the next kind of primitive. Frame languages had various mechanisms for expressing and enforcing constraints on frame data. All data in frames are stored in slots. Slots are analogous to relations in entity-relation modeling and to object properties in object-oriented modeling. Another technique for primitives is to define languages that are modeled after First Order Logic (FOL). The most well known example is Prolog, but there are also many special-purpose theorem-proving environments. These environments can validate logical models and can deduce new theories from existing models. Essentially they automate the process a logician would go through in analyzing a model. Theorem-proving technology had some specific practical applications in the areas of software engineering. For example, it is possible to prove that a software program rigidly adheres to a formal logical specification. - Meta-representation. This is also known as the issue of reflection in computer science. It refers to the ability of a formalism to have access to information about its own state. An example is the meta-object protocol in Smalltalk and CLOS that gives developers runtime access to the class objects and enables them to dynamically redefine the structure of the knowledge base even at runtime. Meta-representation means the knowledge representation language is itself expressed in that language. For example, in most Frame based environments all frames would be instances of a frame class. That class object can be inspected at runtime, so that the object can understand and even change its internal structure or the structure of other parts of the model. In rule-based environments, the rules were also usually instances of rule classes. Part of the meta protocol for rules were the meta rules that prioritized rule firing. - Incompleteness. Traditional logic requires additional axioms and constraints to deal with the real world as opposed to the world of mathematics. Also, it is often useful to associate degrees of confidence with a statement, i.e., not simply say \"Socrates is Human\" but rather \"Socrates is Human with confidence 50%\". This was one of the early innovations from expert systems research which migrated to some commercial tools, the ability to associate certainty factors with rules and conclusions. Later research in this area is known as fuzzy logic.[26] - Definitions and universals vs. facts and defaults. Universals are general statements about the world such as \"All humans are mortal\". Facts are specific examples of universals such as \"Socrates is a human and therefore mortal\". In logical terms definitions and universals are about universal quantification while facts and defaults are about existential quantifications. All forms of knowledge representation must deal with this aspect and most do so with some variant of set theory, modeling universals as sets and subsets and definitions as elements in those sets. - Non-monotonic reasoning. Non-monotonic reasoning allows various kinds of hypothetical reasoning. The system associates facts asserted with the rules and facts used to justify them and as those facts change updates the dependent knowledge as well. In rule based systems this capability is known as a truth maintenance system.[27] - Expressive adequacy. The standard that Brachman and most AI researchers use to measure expressive adequacy is usually First Order Logic (FOL). Theoretical limitations mean that a full implementation of FOL is not practical. Researchers should be clear about how expressive (how much of full FOL expressive power) they intend their representation to be.[28] - Reasoning efficiency. This refers to the runtime efficiency of a system: The ability of the knowledge base to be updated and the reasoner to develop new inferences in a reasonable time. In some ways, this is the flip side of expressive adequacy. In general, the more powerful a representation, the more it has expressive adequacy, the less efficient its automated reasoning engine will be. Efficiency was often an issue, especially for early applications of knowledge representation technology. They were usually implemented in interpreted environments such as Lisp, which were slow compared to more traditional platforms of the time. Ontology engineering [edit]In the early years of knowledge-based systems the knowledge-bases were fairly small. The knowledge-bases that were meant to actually solve real problems rather than do proof of concept demonstrations needed to focus on well defined problems. So for example, not just medical diagnosis as a whole topic, but medical diagnosis of certain kinds of diseases. As knowledge-based technology scaled up, the need for larger knowledge bases and for modular knowledge bases that could communicate and integrate with each other became apparent. This gave rise to the discipline of ontology engineering, designing and building large knowledge bases that could be used by multiple projects. One of the leading research projects in this area was the Cyc project. Cyc was an attempt to build a huge encyclopedic knowledge base that would contain not just expert knowledge but common-sense knowledge. In designing an artificial intelligence agent, it was soon realized that representing common-sense knowledge, knowledge that humans simply take for granted, was essential to make an AI that could interact with humans using natural language. Cyc was meant to address this problem. The language they defined was known as CycL. After CycL, a number of ontology languages have been developed. Most are declarative languages, and are either frame languages, or are based on first-order logic. Modularity—the ability to define boundaries around specific domains and problem spaces—is essential for these languages because as stated by Tom Gruber, \"Every ontology is a treaty–a social agreement among people with common motive in sharing.\" There are always many competing and differing views that make any general-purpose ontology impossible. A general-purpose ontology would have to be applicable in any domain and different areas of knowledge need to be unified.[29] There is a long history of work attempting to build ontologies for a variety of task domains, e.g., an ontology for liquids,[30] the lumped element model widely used in representing electronic circuits (e.g.[31]), as well as ontologies for time, belief, and even programming itself. Each of these offers a way to see some part of the world. The lumped element model, for instance, suggests that we think of circuits in terms of components with connections between them, with signals flowing instantaneously along the connections. This is a useful view, but not the only possible one. A different ontology arises if we need to attend to the electrodynamics in the device: Here signals propagate at finite speed and an object (like a resistor) that was previously viewed as a single component with an I/O behavior may now have to be thought of as an extended medium through which an electromagnetic wave flows. Ontologies can of course be written down in a wide variety of languages and notations (e.g., logic, LISP, etc.); the essential information is not the form of that language but the content, i.e., the set of concepts offered as a way of thinking about the world. Simply put, the important part is notions like connections and components, not the choice between writing them as predicates or LISP constructs. The commitment made selecting one or another ontology can produce a sharply different view of the task at hand. Consider the difference that arises in selecting the lumped element view of a circuit rather than the electrodynamic view of the same device. As a second example, medical diagnosis viewed in terms of rules (e.g., MYCIN) looks substantially different from the same task viewed in terms of frames (e.g., INTERNIST). Where MYCIN sees the medical world as made up of empirical associations connecting symptom to disease, INTERNIST sees a set of prototypes, in particular prototypical diseases, to be matched against the case at hand. See also [edit]- Alphabet of human thought – Hypothetical language created by Gottfried Wilhelm Leibniz - Belief revision – Process of changing beliefs to take into account a new piece of information - Chunking (psychology) – Cognitive psychology process - Commonsense knowledge base – Facts assumed to be known to all humans - Conceptual graph – Formalism for knowledge representation - DIKW pyramid – Data, information, knowledge, wisdom hierarchy - DATR, a language for lexical knowledge representation - FO(.), a KR language based on first-order logic - Knowledge graph – Type of knowledge base - Knowledge management – Processing of knowledge to accomplish organizational goals - Logic programming – Programming paradigm based on formal logic - Logico-linguistic modeling - Mind map – Diagram to visually organize information - Semantic technology – Technology to help machines understand data - Valuation-based system References [edit]- ^ Schank, Roger; Abelson, Robert (1977). Scripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures. Lawrence Erlbaum Associates, Inc. - ^ Porter, Bruce; Lifschitz, Vladimir; Van Harmelen, Frank (2008). Handbook of knowledge representation. Foundations of artificial intelligence (1st ed.). Amsterdam Boston: Elsevier. ISBN 978-0-444-52211-5. - ^ Smolensky, Paul (March 1988). \"On the proper treatment of connectionism\". Behavioral and Brain Sciences. 11 (1): 1–23. doi:10.1017/S0140525X00052432. ISSN 0140-525X. - ^ Doran, J. E.; Michie, D. (1966-09-20). \"Experiments with the Graph Traverser program\". Proc. R. Soc. Lond. A. 294 (1437): 235–259. Bibcode:1966RSPSA.294..235D. doi:10.1098/rspa.1966.0205. S2CID 21698093. - ^ Green, Cordell. Application of Theorem Proving to Problem Solving (PDF). IJCAI 1969. - ^ Hewitt, C., 2009. Inconsistency robustness in logic programs. arXiv preprint arXiv:0904.3036. - ^ Kowalski, Robert (1986). \"The limitation of logic\". Proceedings of the 1986 ACM fourteenth annual conference on Computer science - CSC '86. pp. 7–13. doi:10.1145/324634.325168. ISBN 0-89791-177-6. S2CID 17211581. - ^ Nilsson, Nils (1995). \"Eye on the Prize\". AI Magazine. 16: 2. - ^ Hayes-Roth, Frederick; Waterman, Donald; Lenat, Douglas (1983). Building Expert Systems. Addison-Wesley. ISBN 978-0-201-10686-2. - ^ Marvin Minsky, A Framework for Representing Knowledge Archived 2021-01-07 at the Wayback Machine, MIT-AI Laboratory Memo 306, June, 1974 - ^ Mettrey, William (1987). \"An Assessment of Tools for Building Large Knowledge-Based Systems\". AI Magazine. 8 (4). Archived from the original on 2013-11-10. Retrieved 2013-12-24. - ^ Brachman, Ron (1978). \"A Structural Paradigm for Representing Knowledge\" (PDF). Bolt, Beranek, and Neumann Technical Report (3605). Archived (PDF) from the original on April 30, 2020. - ^ MacGregor, Robert (June 1991). \"Using a description classifier to enhance knowledge representation\". IEEE Expert. 6 (3): 41–46. Bibcode:1991IExp....6...41M. doi:10.1109/64.87683. S2CID 29575443. - ^ McCarthy, J., and Hayes, P. J. 1969. \"Some philosophical problems from the standpoint of artificial intelligence\" (PDF). Archived from the original on August 25, 2013. Retrieved January 18, 2024. {{cite web}} : CS1 maint: bot: original URL status unknown (link). In Meltzer, B., and Michie, D., eds., Machine Intelligence 4. Edinburgh: Edinburgh University Press. 463–502. - ^ Lenat, Doug; R. V. Guha (January 1990). Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project. Addison-Wesley. ISBN 978-0201517521. - ^ Smith, Brian C. (1985). \"Prologue to Reflections and Semantics in a Procedural Language\". In Ronald Brachman and Hector J. Levesque (ed.). Readings in Knowledge Representation. Morgan Kaufmann. pp. 31–40. ISBN 978-0-934613-01-9. - ^ a b Berners-Lee, Tim; Hendler, James; Lassila, Ora (May 17, 2001). \"The Semantic Web – A new form of Web content that is meaningful to computers will unleash a revolution of new possibilities\". Scientific American. 284 (5): 34–43. doi:10.1038/scientificamerican0501-34. Archived from the original on April 24, 2013. - ^ a b Knublauch, Holger; Oberle, Daniel; Tetlow, Phil; Wallace, Evan (2006-03-09). \"A Semantic Web Primer for Object-Oriented Software Developers\". W3C. Archived from the original on 2018-01-06. Retrieved 2008-07-30. - ^ Hayes-Roth, Frederick; Waterman, Donald; Lenat, Douglas (1983). Building Expert Systems. Addison-Wesley. pp. 6–7. ISBN 978-0-201-10686-2. - ^ Levesque, H.J. and Brachman, R.J., 1987. Expressiveness and tractability in knowledge representation and reasoning 1. Computational intelligence, 3(1), pp.78-93. - ^ Levesque, Hector; Brachman, Ronald (1985). \"A Fundamental Tradeoff in Knowledge Representation and Reasoning\". In Ronald Brachman and Hector J. Levesque (ed.). Readings in Knowledge Representation. Morgan Kaufmann. p. 49. ISBN 978-0-934613-01-9. The good news in reducing KR service to theorem proving is that we now have a very clear, very specific notion of what the KR system should do; the bad new is that it is also clear that the services can not be provided... deciding whether or not a sentence in FOL is a theorem... is unsolvable. - ^ Russell, Stuart J.; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. p. 282. ISBN 978-0134610993. LCCN 20190474. - ^ a b c d e f g h i j k Davis, Randall; Shrobe, Howard; Szolovits, Peter (Spring 1993). \"What Is a Knowledge Representation?\". AI Magazine. 14 (1): 17–33. Archived from the original on 2012-04-06. Retrieved 2011-03-23. - ^ Macgregor, Robert (August 13, 1999). \"Retrospective on Loom\". isi.edu. Information Sciences Institute. Archived from the original on 25 October 2013. Retrieved 10 December 2013. - ^ Brachman, Ron (1985). \"Introduction\". In Brachman, Ronald; Levesque, Hector J. (eds.). Readings in Knowledge Representation. Morgan Kaufmann. pp. XVI–XVII. ISBN 978-0-934613-01-9. - ^ Bih, Joseph (2006). \"Paradigm Shift: An Introduction to Fuzzy Logic\" (PDF). IEEE Potentials. 25 (1): 6–21. Bibcode:2006IPot...25a...6B. doi:10.1109/MP.2006.1635021. S2CID 15451765. Archived (PDF) from the original on 12 June 2014. Retrieved 24 December 2013. - ^ Zlatarva, Nellie (1992). \"Truth Maintenance Systems and their Application for Verifying Expert System Knowledge Bases\". Artificial Intelligence Review. 6: 67–110. doi:10.1007/bf00155580. S2CID 24696160. - ^ Levesque, Hector; Brachman, Ronald (1985). \"A Fundamental Tradeoff in Knowledge Representation and Reasoning\". In Ronald Brachman and Hector J. Levesque (ed.). Readings in Knowledge Representation. Morgan Kaufmann. pp. 41–70. ISBN 978-0-934613-01-9. - ^ Russell, Stuart J.; Norvig, Peter (2010), Artificial Intelligence: A Modern Approach (3rd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-604259-7, p. 437-439 - ^ Hayes P, Naive physics I: Ontology for liquids. University of Essex report, 1978, Essex, UK. - ^ Davis R, Shrobe H E, Representing Structure and Behavior of Digital Hardware, IEEE Computer, Special Issue on Knowledge Representation, 16(10):75-82. Further reading [edit]- Ronald J. Brachman; What IS-A is and isn't. An Analysis of Taxonomic Links in Semantic Networks; IEEE Computer, 16 (10); October 1983 - Ronald J. Brachman, Hector J. Levesque Knowledge Representation and Reasoning, Morgan Kaufmann, 2004 ISBN 978-1-55860-932-7 - Ronald J. Brachman, Hector J. Levesque (eds) Readings in Knowledge Representation, Morgan Kaufmann, 1985, ISBN 0-934613-01-X - Chein, M., Mugnier, M.-L. (2009),Graph-based Knowledge Representation: Computational Foundations of Conceptual Graphs, Springer, 2009,ISBN 978-1-84800-285-2. - Randall Davis, Howard Shrobe, and Peter Szolovits; What Is a Knowledge Representation? AI Magazine, 14(1):17-33,1993 - Ronald Fagin, Joseph Y. Halpern, Yoram Moses, Moshe Y. Vardi Reasoning About Knowledge, MIT Press, 1995, ISBN 0-262-06162-7 - Jean-Luc Hainaut, Jean-Marc Hick, Vincent Englebert, Jean Henrard, Didier Roland: Understanding Implementations of IS-A Relations. ER 1996: 42-57 - Hermann Helbig: Knowledge Representation and the Semantics of Natural Language, Springer, Berlin, Heidelberg, New York 2006 - Frank van Harmelen, Vladimir Lifschitz and Bruce Porter: Handbook of Knowledge Representation 2007. - Arthur B. Markman: Knowledge Representation Lawrence Erlbaum Associates, 1998 - John F. Sowa: Knowledge Representation: Logical, Philosophical, and Computational Foundations. Brooks/Cole: New York, 2000 - Adrian Walker, Michael McCord, John F. Sowa, and Walter G. Wilson: Knowledge Systems and Prolog, Second Edition, Addison-Wesley, 1990 - Mary-Anne Williams and Hans Rott: \"Frontiers in Belief Revision, Kluwer\", 2001. External links [edit]- What is a Knowledge Representation? by Randall Davis and others - Introduction to Knowledge Modeling by Pejman Makhfi - Introduction to Description Logics course by Enrico Franconi, Faculty of Computer Science, Free University of Bolzano, Italy - DATR Lexical knowledge representation language - Loom Project Home Page - Principles of Knowledge Representation and Reasoning Incorporated - Description Logic in Practice: A CLASSIC Application - The Rule Markup Initiative - Nelements KOS - a non-free 3d knowledge representation system",
    "text_length": 34950,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:23.131760"
  },
  {
    "id": "page_7",
    "url": "https://en.wikipedia.org/wiki/Robotics",
    "domain": "en.wikipedia.org",
    "title": "Robotics - Wikipedia",
    "text": "Robotics This article may relate to a different subject or has undue weight on an aspect of the subject. Specifically, the article goes in too much detail on specific types of robot and includes product placement. (August 2024) | Robotics is the interdisciplinary study and practice of the design, construction, operation, and use of robots.[1] Within mechanical engineering, robotics is the design and construction of the physical structures of robots, while in computer science, robotics focuses on robotic automation algorithms. Other disciplines contributing to robotics include electrical, control, software, information, electronic, telecommunication, computer, mechatronic, and materials engineering. The goal of most robotics is to design machines that can help and assist humans. Many robots are built to do jobs that are hazardous to people, such as finding survivors in unstable ruins, and exploring space, mines and shipwrecks. Others replace people in jobs that are boring, repetitive, or unpleasant, such as cleaning, monitoring, transporting, and assembling. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes. A roboticist is someone who specializes in robotics. Robotics aspects [edit]Robotics usually combines three aspects of design work to create robot systems: - Mechanical construction: a frame, form or shape designed to achieve a particular task. For example, a robot designed to travel across heavy dirt or mud might use caterpillar tracks. Origami inspired robots can sense and analyze in extreme environments.[2] The mechanical aspect of the robot is mostly the creator's solution to completing the assigned task and dealing with the physics of the environment around it. Form follows function. - Electrical components that power and control the machinery. For example, the robot with caterpillar tracks would need some kind of power to move the tracker treads. That power comes in the form of electricity, which will have to travel through a wire and originate from a battery, a basic electrical circuit. Even petrol-powered machines that get their power mainly from petrol still require an electric current to start the combustion process which is why most petrol-powered machines like cars, have batteries. The electrical aspect of robots is used for movement (through motors), sensing (where electrical signals are used to measure things like heat, sound, position, and energy status), and operation (robots need some level of electrical energy supplied to their motors and sensors in order to activate and perform basic operations) - Software. A program is how a robot decides when or how to do something. In the caterpillar track example, a robot that needs to move across a muddy road may have the correct mechanical construction and receive the correct amount of power from its battery, but would not be able to go anywhere without a program telling it to move. Programs are the core essence of a robot, it could have excellent mechanical and electrical construction, but if its program is poorly structured, its performance will be very poor (or it may not perform at all). There are three different types of robotic programs: remote control, artificial intelligence, and hybrid. A robot with remote control programming has a preexisting set of commands that it will only perform if and when it receives a signal from a control source, typically a human being with remote control. It is perhaps more appropriate to view devices controlled primarily by human commands as falling in the discipline of automation rather than robotics. Robots that use artificial intelligence interact with their environment on their own without a control source, and can determine reactions to objects and problems they encounter using their preexisting programming. A hybrid is a form of programming that incorporates both AI and RC functions in them.[3] Applied robotics [edit]As many robots are designed for specific tasks, this method of classification becomes more relevant. For example, many robots are designed for assembly work, which may not be readily adaptable for other applications. They are termed \"assembly robots\". For seam welding, some suppliers provide complete welding systems with the robot i.e. the welding equipment along with other material handling facilities like turntables, etc. as an integrated unit. Such an integrated robotic system is called a \"welding robot\" even though its discrete manipulator unit could be adapted to a variety of tasks. Some robots are specifically designed for heavy load manipulation, and are labeled as \"heavy-duty robots\".[4] Current and potential applications include: - Manufacturing. Robots have been increasingly used in manufacturing since the 1960s. According to the Robotic Industries Association US data, in 2016 the automotive industry was the main customer of industrial robots with 52% of total sales.[5] In the auto industry, they can amount for more than half of the \"labor\". There are even \"lights off\" factories such as an IBM keyboard manufacturing factory in Texas that was fully automated as early as 2003.[6] - Autonomous transport including airplane autopilot and self-driving cars - Domestic robots including robotic vacuum cleaners, robotic lawn mowers, dishwasher loading[7] and flatbread baking.[8] - Construction robots. Construction robots can be separated into three types: traditional robots, robotic arm, and robotic exoskeleton.[9] - Automated mining. - Space exploration, including Mars rovers. - Energy applications including cleanup of nuclear contaminated areas;[a] and cleaning solar panel arrays. - Medical robots and Robot-assisted surgery designed and used in clinics.[11] - Agricultural robots.[12] The use of robots in agriculture is closely linked to the concept of AI-assisted precision agriculture and drone usage.[13] - Food processing. Commercial examples of kitchen automation are Flippy (burgers), Zume Pizza (pizza), Cafe X (coffee), Makr Shakr (cocktails), Frobot (frozen yogurts), Sally (salads),[14] salad or food bowl robots manufactured by Dexai (a Draper Laboratory spinoff, operating on military bases), and integrated food bowl assembly systems manufactured by Spyce Kitchen (acquired by Sweetgreen) and Silicon Valley startup Hyphen.[15] Other examples may include manufacturing technologies based on 3D Food Printing. - Military robots. - Robot sports for entertainment and education, including Robot combat, Autonomous racing, drone racing, and FIRST Robotics. Mechanical robotics areas [edit]Power source [edit]At present, mostly (lead–acid) batteries are used as a power source. Many different types of batteries can be used as a power source for robots. They range from lead–acid batteries, which are safe and have relatively long shelf lives but are rather heavy compared to silver–cadmium batteries which are much smaller in volume and are currently much more expensive. Designing a battery-powered robot needs to take into account factors such as safety, cycle lifetime, and weight. Generators, often some type of internal combustion engine, can also be used. However, such designs are often mechanically complex and need fuel, require heat dissipation, and are relatively heavy. A tether connecting the robot to a power supply would remove the power supply from the robot entirely. This has the advantage of saving weight and space by moving all power generation and storage components elsewhere. However, this design does come with the drawback of constantly having a cable connected to the robot, which can be difficult to manage.[16] Potential power sources could be: - pneumatic (compressed gases) - Solar power (using the sun's energy and converting it into electrical power) - hydraulics (liquids) - flywheel energy storage - organic garbage (through anaerobic digestion) - nuclear Actuation [edit]Actuators are the \"muscles\" of a robot, the parts which convert stored energy into movement.[17] By far the most popular actuators are electric motors that rotate a wheel or gear, and linear actuators that control industrial robots in factories. There are some recent advances in alternative types of actuators, powered by electricity, chemicals, or compressed air. Electric motors [edit]The vast majority of robots use electric motors, often brushed and brushless DC motors in portable robots or AC motors in industrial robots and CNC machines. These motors are often preferred in systems with lighter loads, and where the predominant form of motion is rotational. Linear actuators [edit]Various types of linear actuators move in and out instead of by spinning, and often have quicker direction changes, particularly when very large forces are needed such as with industrial robotics. They are typically powered by compressed air (pneumatic actuator) or an oil (hydraulic actuator) Linear actuators can also be powered by electricity which usually consists of a motor and a leadscrew. Another common type is a mechanical linear actuator such as a rack and pinion on a car. Series elastic actuators [edit]Series elastic actuation (SEA) relies on the idea of introducing intentional elasticity between the motor actuator and the load for robust force control. Due to the resultant lower reflected inertia, series elastic actuation improves safety when a robot interacts with the environment (e.g., humans or workpieces) or during collisions.[18] Furthermore, it also provides energy efficiency and shock absorption (mechanical filtering) while reducing excessive wear on the transmission and other mechanical components. This approach has successfully been employed in various robots, particularly advanced manufacturing robots[19] and walking humanoid robots.[20][21] The controller design of a series elastic actuator is most often performed within the passivity framework as it ensures the safety of interaction with unstructured environments.[22] Despite its remarkable stability and robustness, this framework suffers from the stringent limitations imposed on the controller which may trade-off performance. The reader is referred to the following survey which summarizes the common controller architectures for SEA along with the corresponding sufficient passivity conditions.[23] One recent study has derived the necessary and sufficient passivity conditions for one of the most common impedance control architectures, namely velocity-sourced SEA.[24] This work is of particular importance as it drives the non-conservative passivity bounds in an SEA scheme for the first time which allows a larger selection of control gains. Air muscles [edit]Pneumatic artificial muscles also known as air muscles, are special tubes that expand (typically up to 42%) when air is forced inside them. They are used in some robot applications.[25][26][27] Wire muscles [edit]Muscle wire, also known as shape memory alloy, is a material that contracts (under 5%) when electricity is applied. They have been used for some small robot applications.[28][29] Electroactive polymers [edit]EAPs or EPAMs are a plastic material that can contract substantially (up to 380% activation strain) from electricity, and have been used in facial muscles and arms of humanoid robots,[30] and to enable new robots to float,[31] fly, swim or walk.[32] Piezo motors [edit]Recent alternatives to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to step the motor in a circle or a straight line.[33] Another type uses the piezo elements to cause a nut to vibrate or to drive a screw. The advantages of these motors are nanometer resolution, speed, and available force for their size.[34] These motors are already available commercially and being used on some robots.[35][36] Elastic nanotubes [edit]Elastic nanotubes are a promising artificial muscle technology in early-stage experimental development. The absence of defects in carbon nanotubes enables these filaments to deform elastically by several percent, with energy storage levels of perhaps 10 J/cm3 for metal nanotubes. Human biceps could be replaced with an 8 mm diameter wire of this material. Such compact \"muscle\" might allow future robots to outrun and outjump humans.[37] Sensing [edit]Sensors allow robots to receive information about a certain measurement of the environment, or internal components. This is essential for robots to perform their tasks, and act upon any changes in the environment to calculate the appropriate response. They are used for various forms of measurements, to give the robots warnings about safety or malfunctions, and to provide real-time information about the task it is performing. Touch [edit]Current robotic and prosthetic hands receive far less tactile information than the human hand. Recent research has developed a tactile sensor array that mimics the mechanical properties and touch receptors of human fingertips.[38][39] The sensor array is constructed as a rigid core surrounded by conductive fluid contained by an elastomeric skin. Electrodes are mounted on the surface of the rigid core and are connected to an impedance-measuring device within the core. When the artificial skin touches an object the fluid path around the electrodes is deformed, producing impedance changes that map the forces received from the object. The researchers expect that an important function of such artificial fingertips will be adjusting the robotic grip on held objects. Scientists from several European countries and Israel developed a prosthetic hand in 2009, called SmartHand, which functions like a real one —allowing patients to write with it, type on a keyboard, play piano, and perform other fine movements. The prosthesis has sensors which enable the patient to sense real feelings in its fingertips.[40] Other [edit]Other common forms of sensing in robotics use lidar, radar, and sonar.[41] Lidar measures the distance to a target by illuminating the target with laser light and measuring the reflected light with a sensor. Radar uses radio waves to determine the range, angle, or velocity of objects. Sonar uses sound propagation to navigate, communicate with or detect objects on or under the surface of the water. Mechanical grippers [edit]One of the most common types of end-effectors are \"grippers\". In its simplest manifestation, it consists of just two fingers that can open and close to pick up and let go of a range of small objects. Fingers can, for example, be made of a chain with a metal wire running through it.[42] Hands that resemble and work more like a human hand include the Shadow Hand and the Robonaut hand.[43] Hands that are of a mid-level complexity include the Delft hand.[44][45] Mechanical grippers can come in various types, including friction and encompassing jaws. Friction jaws use all the force of the gripper to hold the object in place using friction. Encompassing jaws cradle the object in place, using less friction. Suction end-effectors [edit]Suction end-effectors, powered by vacuum generators, are very simple astrictive[46] devices that can hold very large loads provided the prehension surface is smooth enough to ensure suction. Pick and place robots for electronic components and for large objects like car windscreens, often use very simple vacuum end-effectors. Suction is a highly used type of end-effector in industry, in part because the natural compliance of soft suction end-effectors can enable a robot to be more robust in the presence of imperfect robotic perception. As an example: consider the case of a robot vision system that estimates the position of a water bottle but has 1 centimeter of error. While this may cause a rigid mechanical gripper to puncture the water bottle, the soft suction end-effector may just bend slightly and conform to the shape of the water bottle surface. General purpose effectors [edit]Some advanced robots are beginning to use fully humanoid hands, like the Shadow Hand, MANUS,[47] and the Schunk hand.[48] They have powerful Robot Dexterity Intelligence (RDI), with as many as 20 degrees of freedom and hundreds of tactile sensors.[49] Control robotics areas [edit]The mechanical structure of a robot must be controlled to perform tasks.[50] The control of a robot involves three distinct phases – perception, processing, and action (robotic paradigms).[51] Sensors give information about the environment or the robot itself (e.g. the position of its joints or its end effector). This information is then processed to be stored or transmitted and to calculate the appropriate signals to the actuators (motors), which move the mechanical structure to achieve the required co-ordinated motion or force actions. The processing phase can range in complexity. At a reactive level, it may translate raw sensor information directly into actuator commands (e.g. firing motor power electronic gates based directly upon encoder feedback signals to achieve the required torque/velocity of the shaft). Sensor fusion and internal models may first be used to estimate parameters of interest (e.g. the position of the robot's gripper) from noisy sensor data. An immediate task (such as moving the gripper in a certain direction until an object is detected with a proximity sensor) is sometimes inferred from these estimates. Techniques from control theory are generally used to convert the higher-level tasks into individual commands that drive the actuators, most often using kinematic and dynamic models of the mechanical structure.[50][51][52] At longer time scales or with more sophisticated tasks, the robot may need to build and reason with a \"cognitive\" model. Cognitive models try to represent the robot, the world, and how the two interact. Pattern recognition and computer vision can be used to track objects.[50] Mapping techniques can be used to build maps of the world. Finally, motion planning and other artificial intelligence techniques may be used to figure out how to act. For example, a planner may figure out how to achieve a task without hitting obstacles, falling over, etc. Modern commercial robotic control systems are highly complex, integrate multiple sensors and effectors, have many interacting degrees-of-freedom (DOF) and require operator interfaces, programming tools and real-time capabilities.[51] They are oftentimes interconnected to wider communication networks and in many cases are now both IoT-enabled and mobile.[53] Progress towards open architecture, layered, user-friendly and 'intelligent' sensor-based interconnected robots has emerged from earlier concepts related to Flexible Manufacturing Systems (FMS), and several 'open or 'hybrid' reference architectures exist which assist developers of robot control software and hardware to move beyond traditional, earlier notions of 'closed' robot control systems have been proposed.[52] Open architecture controllers are said to be better able to meet the growing requirements of a wide range of robot users, including system developers, end users and research scientists, and are better positioned to deliver the advanced robotic concepts related to Industry 4.0.[52] In addition to utilizing many established features of robot controllers, such as position, velocity and force control of end effectors, they also enable IoT interconnection and the implementation of more advanced sensor fusion and control techniques, including adaptive control, Fuzzy control and Artificial Neural Network (ANN)-based control.[52] When implemented in real-time, such techniques can potentially improve the stability and performance of robots operating in unknown or uncertain environments by enabling the control systems to learn and adapt to environmental changes.[54] There are several examples of reference architectures for robot controllers, and also examples of successful implementations of actual robot controllers developed from them. One example of a generic reference architecture and associated interconnected, open-architecture robot and controller implementation was used in a number of research and development studies, including prototype implementation of novel advanced and intelligent control and environment mapping methods in real-time.[54][55] Manipulation [edit]A definition of robotic manipulation has been provided by Matt Mason as: \"manipulation refers to an agent's control of its environment through selective contact\".[56] Robots need to manipulate objects; pick up, modify, destroy, move or otherwise have an effect. Thus the functional end of a robot arm intended to make the effect (whether a hand, or tool) are often referred to as end effectors,[57] while the \"arm\" is referred to as a manipulator.[58] Most robot arms have replaceable end-effectors, each allowing them to perform some small range of tasks. Some have a fixed manipulator that cannot be replaced, while a few have one very general-purpose manipulator, for example, a humanoid hand.[59] Locomotion [edit]Rolling robots [edit]For simplicity, most mobile robots have four wheels or a number of continuous tracks. Some researchers have tried to create more complex wheeled robots with only one or two wheels. These can have certain advantages such as greater efficiency and reduced parts, as well as allowing a robot to navigate in confined places that a four-wheeled robot would not be able to. Two-wheeled balancing robots [edit]Balancing robots generally use a gyroscope to detect how much a robot is falling and then drive the wheels proportionally in the same direction, to counterbalance the fall at hundreds of times per second, based on the dynamics of an inverted pendulum.[60] Many different balancing robots have been designed.[61] While the Segway is not commonly thought of as a robot, it can be thought of as a component of a robot, when used as such Segway refer to them as RMP (Robotic Mobility Platform). An example of this use has been as NASA's Robonaut that has been mounted on a Segway.[62] One-wheeled balancing robots [edit]A one-wheeled balancing robot is an extension of a two-wheeled balancing robot so that it can move in any 2D direction using a round ball as its only wheel. Several one-wheeled balancing robots have been designed recently, such as Carnegie Mellon University's \"Ballbot\" which is the approximate height and width of a person, and Tohoku Gakuin University's \"BallIP\".[63] Because of the long, thin shape and ability to maneuver in tight spaces, they have the potential to function better than other robots in environments with people.[64] Spherical orb robots [edit]Several attempts have been made in robots that are completely inside a spherical ball, either by spinning a weight inside the ball,[65][66] or by rotating the outer shells of the sphere.[67][68] These have also been referred to as an orb bot[69] or a ball bot.[70][71] Six-wheeled robots [edit]Using six wheels instead of four wheels can give better traction or grip in outdoor terrain such as on rocky dirt or grass. Tracked robots [edit]Tracks provide even more traction than a six-wheeled robot. Tracked wheels behave as if they were made of hundreds of wheels, therefore are very common for outdoor off-road robots, where the robot must drive on very rough terrain. However, they are difficult to use indoors such as on carpets and smooth floors. Examples include NASA's Urban Robot \"Urbie\".[72] Walking robots [edit]Walking is a difficult and dynamic problem to solve. Several robots have been made which can walk reliably on two legs, however, none have yet been made which are as robust as a human. There has been much study on human-inspired walking, such as AMBER lab which was established in 2008 by the Mechanical Engineering Department at Texas A&M University.[73] Many other robots have been built that walk on more than two legs, due to these robots being significantly easier to construct.[74][75] Walking robots can be used for uneven terrains, which would provide better mobility and energy efficiency than other locomotion methods. Typically, robots on two legs can walk well on flat floors and can occasionally walk up stairs. None can walk over rocky, uneven terrain. Some of the methods which have been tried are: ZMP technique [edit]The zero moment point (ZMP) is the algorithm used by robots such as Honda's ASIMO. The robot's onboard computer tries to keep the total inertial forces (the combination of Earth's gravity and the acceleration and deceleration of walking), exactly opposed by the floor reaction force (the force of the floor pushing back on the robot's foot). In this way, the two forces cancel out, leaving no moment (force causing the robot to rotate and fall over).[76] However, this is not exactly how a human walks, and the difference is obvious to human observers, some of whom have pointed out that ASIMO walks as if it needs the lavatory.[77][78][79] ASIMO's walking algorithm is not static, and some dynamic balancing is used (see below). However, it still requires a smooth surface to walk on. Hopping [edit]Several robots, built in the 1980s by Marc Raibert at the MIT Leg Laboratory, successfully demonstrated very dynamic walking. Initially, a robot with only one leg, and a very small foot could stay upright simply by hopping. The movement is the same as that of a person on a pogo stick. As the robot falls to one side, it would jump slightly in that direction, in order to catch itself.[80] Soon, the algorithm was generalized to two and four legs. A bipedal robot was demonstrated running and even performing somersaults.[81] A quadruped was also demonstrated which could trot, run, pace, and bound.[82] For a full list of these robots, see the MIT Leg Lab Robots page.[83] Dynamic balancing (controlled falling) [edit]A more advanced way for a robot to walk is by using a dynamic balancing algorithm, which is potentially more robust than the Zero Moment Point technique, as it constantly monitors the robot's motion, and places the feet in order to maintain stability.[84] This technique was recently demonstrated by Anybots' Dexter Robot,[85] which is so stable, it can even jump.[86] Another example is the TU Delft Flame. Passive dynamics [edit]Perhaps the most promising approach uses passive dynamics where the momentum of swinging limbs is used for greater efficiency. It has been shown that totally unpowered humanoid mechanisms can walk down a gentle slope, using only gravity to propel themselves. Using this technique, a robot need only supply a small amount of motor power to walk along a flat surface or a little more to walk up a hill. This technique promises to make walking robots at least ten times more efficient than ZMP walkers, like ASIMO.[87][88] Flying [edit]A modern passenger airliner is essentially a flying robot, with two humans to manage it. The autopilot can control the plane for each stage of the journey, including takeoff, normal flight, and even landing.[89] Other flying robots are uninhabited and are known as unmanned aerial vehicles (UAVs). They can be smaller and lighter without a human pilot on board, and fly into dangerous territory for military surveillance missions. Some can even fire on targets under command. UAVs are also being developed which can fire on targets automatically, without the need for a command from a human. Other flying robots include cruise missiles, the Entomopter, and the Epson micro helicopter robot. Robots such as the Air Penguin, Air Ray, and Air Jelly have lighter-than-air bodies, are propelled by paddles, and are guided by sonar. Biomimetic flying robots (BFRs) [edit]BFRs take inspiration from flying mammals, birds, or insects. BFRs can have flapping wings, which generate the lift and thrust, or they can be propeller-actuated. BFRs with flapping wings have increased stroke efficiencies, increased maneuverability, and reduced energy consumption in comparison to propeller-actuated BFRs.[90] Mammal and bird inspired BFRs share similar flight characteristics and design considerations. For instance, both mammal and bird inspired BFRs minimize edge fluttering and pressure-induced wingtip curl by increasing the rigidity of the wing edge and wingtips. Mammal and insect inspired BFRs can be impact resistant, making them useful in cluttered environments. Mammal inspired BFRs typically take inspiration from bats, but the flying squirrel has also inspired a prototype.[91] Examples of bat inspired BFRs include Bat Bot[92] and the DALER.[93] Mammal inspired BFRs can be designed to be multi-modal; therefore, they're capable of both flight and terrestrial movement. To reduce the impact of landing, shock absorbers can be implemented along the wings.[93] Alternatively, the BFR can pitch up and increase the amount of drag it experiences.[91] By increasing the drag force, the BFR will decelerate and minimize the impact upon grounding. Different land gait patterns can also be implemented.[91] Bird inspired BFRs can take inspiration from raptors, gulls, and everything in-between. Bird inspired BFRs can be feathered to increase the angle of attack range over which the prototype can operate before stalling.[94] The wings of bird inspired BFRs allow for in-plane deformation, and the in-plane wing deformation can be adjusted to maximize flight efficiency depending on the flight gait.[94] An example of a raptor inspired BFR is the prototype by Savastano et al.[95] The prototype has fully deformable flapping wings and is capable of carrying a payload of up to 0.8 kg while performing a parabolic climb, steep descent, and rapid recovery. The gull inspired prototype by Grant et al. accurately mimics the elbow and wrist rotation of gulls, and they find that lift generation is maximized when the elbow and wrist deformations are opposite but equal.[96] Insect inspired BFRs typically take inspiration from beetles or dragonflies. An example of a beetle inspired BFR is the prototype by Phan and Park,[97] and a dragonfly inspired BFR is the prototype by Hu et al.[98] The flapping frequency of insect inspired BFRs are much higher than those of other BFRs; this is because of the aerodynamics of insect flight.[99] Insect inspired BFRs are much smaller than those inspired by mammals or birds, so they are more suitable for dense environments. Biologically-inspired flying robots [edit]A class of robots that are biologically inspired, but which do not attempt to mimic biology, are creations such as the Entomopter. Funded by DARPA, NASA, the United States Air Force, and the Georgia Tech Research Institute and patented by Prof. Robert C. Michelson for covert terrestrial missions as well as flight in the lower Mars atmosphere, the Entomopter flight propulsion system uses low Reynolds number wings similar to those of the hawk moth (Manduca sexta), but flaps them in a non-traditional \"opposed x-wing fashion\" while \"blowing\" the surface to enhance lift based on the Coandă effect as well as to control vehicle attitude and direction. Waste gas from the propulsion system not only facilitates the blown wing aerodynamics, but also serves to create ultrasonic emissions like that of a Bat for obstacle avoidance. The Entomopter and other biologically-inspired robots leverage features of biological systems, but do not attempt to create mechanical analogs. Snaking [edit]Several snake robots have been successfully developed. Mimicking the way real snakes move, these robots can navigate very confined spaces, meaning they may one day be used to search for people trapped in collapsed buildings.[100] The Japanese ACM-R5 snake robot[101] can even navigate both on land and in water.[102] Skating [edit]A small number of skating robots have been developed, one of which is a multi-mode walking and skating device. It has four legs, with unpowered wheels, which can either step or roll.[103] Another robot, Plen, can use a miniature skateboard or roller-skates, and skate across a desktop.[104] Climbing [edit]Several different approaches have been used to develop robots that have the ability to climb vertical surfaces. One approach mimics the movements of a human climber on a wall with protrusions; adjusting the center of mass and moving each limb in turn to gain leverage. An example of this is Capuchin,[105] built by Ruixiang Zhang at Stanford University, California. Another approach uses the specialized toe pad method of wall-climbing geckoes, which can run on smooth surfaces such as vertical glass. Examples of this approach include Wallbot[106] and Stickybot.[107] China's Technology Daily reported on 15 November 2008, that Li Hiu Yeung and his research group of New Concept Aircraft (Zhuhai) Co., Ltd. had successfully developed a bionic gecko robot named \"Speedy Freelander\". According to Yeung, the gecko robot could rapidly climb up and down a variety of building walls, navigate through ground and wall fissures, and walk upside-down on the ceiling. It was also able to adapt to the surfaces of smooth glass, rough, sticky or dusty walls as well as various types of metallic materials. It could also identify and circumvent obstacles automatically. Its flexibility and speed were comparable to a natural gecko. A third approach is to mimic the motion of a snake climbing a pole.[41] Swimming (Piscine) [edit]It is calculated that when swimming some fish can achieve a propulsive efficiency greater than 90%.[108] Furthermore, they can accelerate and maneuver far better than any man-made boat or submarine, and produce less noise and water disturbance. Therefore, many researchers studying underwater robots would like to copy this type of locomotion.[109] Notable examples are the Robotic Fish G9,[110] and Robot Tuna built to analyze and mathematically model thunniform motion.[111] The Aqua Penguin,[112] copies the streamlined shape and propulsion by front \"flippers\" of penguins. The Aqua Ray and Aqua Jelly emulate the locomotion of manta ray, and jellyfish, respectively. In 2014, iSplash-II was developed as the first robotic fish capable of outperforming real carangiform fish in terms of average maximum velocity (measured in body lengths/ second) and endurance, the duration that top speed is maintained.[113] This build attained swimming speeds of 11.6BL/s (i.e. 3.7 m/s).[114] The first build, iSplash-I (2014) was the first robotic platform to apply a full-body length carangiform swimming motion which was found to increase swimming speed by 27% over the traditional approach of a posterior confined waveform.[115] Sailing [edit]Sailboat robots have also been developed in order to make measurements at the surface of the ocean. A typical sailboat robot is Vaimos.[116] Since the propulsion of sailboat robots uses the wind, the energy of the batteries is only used for the computer, for the communication and for the actuators (to tune the rudder and the sail). If the robot is equipped with solar panels, the robot could theoretically navigate forever. The two main competitions of sailboat robots are WRSC, which takes place every year in Europe, and Sailbot. Computational robotics areas [edit]Control systems may also have varying levels of autonomy. - Direct interaction is used for haptic or teleoperated devices, and the human has nearly complete control over the robot's motion. - Operator-assist modes have the operator commanding medium-to-high-level tasks, with the robot automatically figuring out how to achieve them.[118] - An autonomous robot may go without human interaction for extended periods of time . Higher levels of autonomy do not necessarily require more complex cognitive capabilities. For example, robots in assembly plants are completely autonomous but operate in a fixed pattern. Another classification takes into account the interaction between human control and the machine motions. - Teleoperation. A human controls each movement, each machine actuator change is specified by the operator. - Supervisory. A human specifies general moves or position changes and the machine decides specific movements of its actuators. - Task-level autonomy. The operator specifies only the task and the robot manages itself to complete it. - Full autonomy. The machine will create and complete all its tasks without human interaction. Vision [edit]Computer vision is the science and technology of machines that see. As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences and views from cameras. In most practical computer vision applications, the computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common. Computer vision systems rely on image sensors that detect electromagnetic radiation which is typically in the form of either visible light or infra-red light. The sensors are designed using solid-state physics. The process by which light propagates and reflects off surfaces is explained using optics. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process. Robots can also be equipped with multiple vision sensors to be better able to compute the sense of depth in the environment. Like human eyes, robots' \"eyes\" must also be able to focus on a particular area of interest, and also adjust to variations in light intensities. There is a subfield within computer vision where artificial systems are designed to mimic the processing and behavior of biological system, at different levels of complexity. Also, some of the learning-based methods developed within computer vision have a background in biology. Environmental interaction and navigation [edit]Though a significant percentage of robots in commission today are either human controlled or operate in a static environment, there is an increasing interest in robots that can operate autonomously in a dynamic environment. These robots require some combination of navigation hardware and software in order to traverse their environment. In particular, unforeseen events (e.g. people and other obstacles that are not stationary) can cause problems or collisions. Some highly advanced robots such as ASIMO and Meinü robot have particularly good robot navigation hardware and software. Also, self-controlled cars, Ernst Dickmanns' driverless car, and the entries in the DARPA Grand Challenge, are capable of sensing the environment well and subsequently making navigational decisions based on this information, including by a swarm of autonomous robots.[119] Most of these robots employ a GPS navigation device with waypoints, along with radar, sometimes combined with other sensory data such as lidar, video cameras, and inertial guidance systems for better navigation between waypoints. Human-robot interaction [edit]The state of the art in sensory intelligence for robots will have to progress through several orders of magnitude if we want the robots working in our homes to go beyond vacuum-cleaning the floors. If robots are to work effectively in homes and other non-industrial environments, the way they are instructed to perform their jobs, and especially how they will be told to stop will be of critical importance. The people who interact with them may have little or no training in robotics, and so any interface will need to be extremely intuitive. Science fiction authors also typically assume that robots will eventually be capable of communicating with humans through speech, gestures, and facial expressions, rather than a command-line interface. Although speech would be the most natural way for the human to communicate, it is unnatural for the robot. It will probably be a long time before robots interact as naturally as the fictional C-3PO, or Data of Star Trek, Next Generation. Even though the current state of robotics cannot meet the standards of these robots from science-fiction, robotic media characters (e.g., Wall-E, R2-D2) can elicit audience sympathies that increase people's willingness to accept actual robots in the future.[120] Acceptance of social robots is also likely to increase if people can meet a social robot under appropriate conditions. Studies have shown that interacting with a robot by looking at, touching, or even imagining interacting with the robot can reduce negative feelings that some people have about robots before interacting with them.[121] However, if pre-existing negative sentiments are especially strong, interacting with a robot can increase those negative feelings towards robots.[121] Speech recognition [edit]Interpreting the continuous flow of sounds coming from a human, in real time, is a difficult task for a computer, mostly because of the great variability of speech.[122] The same word, spoken by the same person may sound different depending on local acoustics, volume, the previous word, whether or not the speaker has a cold, etc.. It becomes even harder when the speaker has a different accent.[123] Nevertheless, great strides have been made in the field since Davis, Biddulph, and Balashek designed the first \"voice input system\" which recognized \"ten digits spoken by a single user with 100% accuracy\" in 1952.[124] Currently, the best systems can recognize continuous, natural speech, up to 160 words per minute, with an accuracy of 95%.[125] With the help of artificial intelligence, machines nowadays can use people's voice to identify their emotions such as satisfied or angry.[126] Robotic voice [edit]Other hurdles exist when allowing the robot to use voice for interacting with humans. For social reasons, synthetic voice proves suboptimal as a communication medium,[127] making it necessary to develop the emotional component of robotic voice through various techniques.[128][129] An advantage of diphonic branching is the emotion that the robot is programmed to project, can be carried on the voice tape, or phoneme, already pre-programmed onto the voice media. One of the earliest examples is a teaching robot named Leachim developed in 1974 by Michael J. Freeman.[130][131] Leachim was able to convert digital memory to rudimentary verbal speech on pre-recorded computer discs.[132] It was programmed to teach students in The Bronx, New York.[132] Facial expression [edit]Facial expressions can provide rapid feedback on the progress of a dialog between two humans, and soon may be able to do the same for humans and robots. Robotic faces have been constructed by Hanson Robotics using their elastic polymer called Frubber, allowing a large number of facial expressions due to the elasticity of the rubber facial coating and embedded subsurface motors (servos).[133] The coating and servos are built on a metal skull. A robot should know how to approach a human, judging by their facial expression and body language. Whether the person is happy, frightened, or crazy-looking affects the type of interaction expected of the robot. Likewise, robots like Kismet and the more recent addition, Nexi[134] can produce a range of facial expressions, allowing it to have meaningful social exchanges with humans.[135] Gestures [edit]One can imagine, in the future, explaining to a robot chef how to make a pastry, or asking directions from a robot police officer. In both of these cases, making hand gestures would aid the verbal descriptions. In the first case, the robot would be recognizing gestures made by the human, and perhaps repeating them for confirmation. In the second case, the robot police officer would gesture to indicate \"down the road, then turn right\". It is likely that gestures will make up a part of the interaction between humans and robots.[136] A great many systems have been developed to recognize human hand gestures.[137] Proxemics [edit]Proxemics is the study of personal space, and HRI systems may try to model and work with its concepts for human interactions. Artificial emotions [edit]Artificial emotions can also be generated, composed of a sequence of facial expressions or gestures. As can be seen from the movie Final Fantasy: The Spirits Within, the programming of these artificial emotions is complex and requires a large amount of human observation. To simplify this programming in the movie, presets were created together with a special software program. This decreased the amount of time needed to make the film. These presets could possibly be transferred for use in real-life robots. An example of a robot with artificial emotions is Robin the Robot developed by an Armenian IT company Expper Technologies, which uses AI-based peer-to-peer interaction. Its main task is achieving emotional well-being, i.e. overcome stress and anxiety. Robin was trained to analyze facial expressions and use his face to display his emotions given the context. The robot has been tested by kids in US clinics, and observations show that Robin increased the appetite and cheerfulness of children after meeting and talking.[138] Personality [edit]Many of the robots of science fiction have a personality, something which may or may not be desirable in the commercial robots of the future.[139] Nevertheless, researchers are trying to create robots which appear to have a personality:[140][141] i.e. they use sounds, facial expressions, and body language to try to convey an internal state, which may be joy, sadness, or fear. One commercial example is Pleo, a toy robot dinosaur, which can exhibit several apparent emotions.[142] Research robotics [edit]Much of the research in robotics focuses not on specific industrial tasks, but on investigations into new types of robots, alternative ways to think about or design robots, and new ways to manufacture them. Other investigations, such as MIT's cyberflora project, are almost wholly academic. To describe the level of advancement of a robot, the term \"Generation Robots\" can be used. This term is coined by Professor Hans Moravec, Principal Research Scientist at the Carnegie Mellon University Robotics Institute in describing the near future evolution of robot technology. First-generation robots, Moravec predicted in 1997, should have an intellectual capacity comparable to perhaps a lizard and should become available by 2010. Because the first generation robot would be incapable of learning, however, Moravec predicts that the second generation robot would be an improvement over the first and become available by 2020, with the intelligence maybe comparable to that of a mouse. The third generation robot should have intelligence comparable to that of a monkey. Though fourth generation robots, robots with human intelligence, professor Moravec predicts, would become possible, he does not predict this happening before around 2040 or 2050.[143] Dynamics and kinematics [edit]| External videos | | |---|---| | How the BB-8 Sphero Toy Works | The study of motion can be divided into kinematics and dynamics.[144] Direct kinematics or forward kinematics refers to the calculation of end effector position, orientation, velocity, and acceleration when the corresponding joint values are known. Inverse kinematics refers to the opposite case in which required joint values are calculated for given end effector values, as done in path planning. Some special aspects of kinematics include handling of redundancy (different possibilities of performing the same movement), collision avoidance, and singularity avoidance. Once all relevant positions, velocities, and accelerations have been calculated using kinematics, methods from the field of dynamics are used to study the effect of forces upon these movements. Direct dynamics refers to the calculation of accelerations in the robot once the applied forces are known. Direct dynamics is used in computer simulations of the robot. Inverse dynamics refers to the calculation of the actuator forces necessary to create a prescribed end-effector acceleration. This information can be used to improve the control algorithms of a robot. In each area mentioned above, researchers strive to develop new concepts and strategies, improve existing ones, and improve the interaction between these areas. To do this, criteria for \"optimal\" performance and ways to optimize design, structure, and control of robots must be developed and implemented. Open source robotics [edit]Open source robotics research seeks standards for defining, and methods for designing and building, robots so that they can easily be reproduced by anyone. Research includes legal and technical definitions; seeking out alternative tools and materials to reduce costs and simplify builds; and creating interfaces and standards for designs to work together. Human usability research also investigates how to best document builds through visual, text or video instructions. Evolutionary robotics [edit]Evolutionary robots is a methodology that uses evolutionary computation to help design robots, especially the body form, or motion and behavior controllers. In a similar way to natural evolution, a large population of robots is allowed to compete in some way, or their ability to perform a task is measured using a fitness function. Those that perform worst are removed from the population and replaced by a new set, which have new behaviors based on those of the winners. Over time the population improves, and eventually a satisfactory robot may appear. This happens without any direct programming of the robots by the researchers. Researchers use this method both to create better robots,[145] and to explore the nature of evolution.[146] Because the process often requires many generations of robots to be simulated,[147] this technique may be run entirely or mostly in simulation, using a robot simulator software package, then tested on real robots once the evolved algorithms are good enough.[148] According to the International Federation of Robotics (IFR) study World Robotics 2023, there were about 4,281,585 operational industrial robots by the end of 2023[149] Bionics and biomimetics [edit]Bionics and biomimetics apply the physiology and methods of locomotion of animals to the design of robots. For example, the design of BionicKangaroo was based on the way kangaroos jump. Swarm robotics [edit]Swarm robotics is an approach to the coordination of multiple robots as a system which consist of large numbers of mostly simple physical robots. ″In a robot swarm, the collective behavior of the robots results from local interactions between the robots and between the robots and the environment in which they act.″* [119] Quantum computing [edit]There has been some research into whether robotics algorithms can be run more quickly on quantum computers than they can be run on digital computers. This area has been referred to as quantum robotics.[150] Other research areas [edit]- Nanorobots. - Cobots (collaborative robots).[151] - Autonomous drones. - High temperature crucibles allow robotic systems to automate sample analysis.[152] The main venues for robotics research are the international conferences ICRA and IROS. Human factors [edit]Education and training [edit]Robotics engineers design robots, maintain them, develop new applications for them, and conduct research to expand the potential of robotics.[153] Robots have become a popular educational tool in some middle and high schools, particularly in parts of the USA,[154] as well as in numerous youth summer camps, raising interest in programming, artificial intelligence, and robotics among students. Employment [edit]Robotics is an essential component in many modern manufacturing environments. As factories increase their use of robots, the number of robotics–related jobs grow and have been observed to be steadily rising.[155] The employment of robots in industries has increased productivity and efficiency savings and is typically seen as a long-term investment for benefactors. A study found that 47 percent of US jobs are at risk to automation \"over some unspecified number of years\".[156] These claims have been criticized on the ground that social policy, not AI, causes unemployment.[157] In a 2016 article in The Guardian, Stephen Hawking stated \"The automation of factories has already decimated jobs in traditional manufacturing, and the rise of artificial intelligence is likely to extend this job destruction deep into the middle classes, with only the most caring, creative or supervisory roles remaining\".[158] The rise of robotics is thus often used as an argument for universal basic income. According to a GlobalData September 2021 report, the robotics industry was worth $45bn in 2020, and by 2030, it will have grown at a compound annual growth rate (CAGR) of 29% to $568bn, driving jobs in robotics and related industries.[159] Occupational safety and health implications [edit]A discussion paper drawn up by EU-OSHA highlights how the spread of robotics presents both opportunities and challenges for occupational safety and health (OSH).[160] The greatest OSH benefits stemming from the wider use of robotics should be substitution for people working in unhealthy or dangerous environments. In space, defense, security, or the nuclear industry, but also in logistics, maintenance, and inspection, autonomous robots are particularly useful in replacing human workers performing dirty, dull or unsafe tasks, thus avoiding workers' exposures to hazardous agents and conditions and reducing physical, ergonomic and psychosocial risks. For example, robots are already used to perform repetitive and monotonous tasks, to handle radioactive material or to work in explosive atmospheres. In the future, many other highly repetitive, risky or unpleasant tasks will be performed by robots in a variety of sectors like agriculture, construction, transport, healthcare, firefighting or cleaning services.[161] Moreover, there are certain skills to which humans will be better suited than machines for some time to come and the question is how to achieve the best combination of human and robot skills. The advantages of robotics include heavy-duty jobs with precision and repeatability, whereas the advantages of humans include creativity, decision-making, flexibility, and adaptability. This need to combine optimal skills has resulted in collaborative robots and humans sharing a common workspace more closely and led to the development of new approaches and standards to guarantee the safety of the \"man-robot merger\". Some European countries are including robotics in their national programs and trying to promote a safe and flexible cooperation between robots and operators to achieve better productivity. For example, the German Federal Institute for Occupational Safety and Health (BAuA) organizes annual workshops on the topic \"human-robot collaboration\". In the future, cooperation between robots and humans will be diversified, with robots increasing their autonomy and human-robot collaboration reaching completely new forms. Current approaches and technical standards[162][163] aiming to protect employees from the risk of working with collaborative robots will have to be revised. User experience [edit]Great user experience predicts the needs, experiences, behaviors, language and cognitive abilities, and other factors of each user group. It then uses these insights to produce a product or solution that is ultimately useful and usable. For robots, user experience begins with an understanding of the robot's intended task and environment, while considering any possible social impact the robot may have on human operations and interactions with it.[164] It defines that communication as the transmission of information through signals, which are elements perceived through touch, sound, smell and sight.[165] The author states that the signal connects the sender to the receiver and consists of three parts: the signal itself, what it refers to, and the interpreter. Body postures and gestures, facial expressions, hand and head movements are all part of nonverbal behavior and communication. Robots are no exception when it comes to human-robot interaction. Therefore, humans use their verbal and nonverbal behaviors to communicate their defining characteristics. Similarly, social robots need this coordination to perform human-like behaviors. Careers [edit]Robotics is an interdisciplinary field, combining primarily mechanical engineering and computer science but also drawing on electronic engineering and other subjects. The usual way to build a career in robotics is to complete an undergraduate degree in one of these established subjects, followed by a graduate (masters') degree in Robotics. Graduate degrees are typically joined by students coming from all of the contributing disciplines, and include familiarization of relevant undergraduate level subject matter from each of them, followed by specialist study in pure robotics topics which build upon them. As an interdisciplinary subject, robotics graduate programmes tend to be especially reliant on students working and learning together and sharing their knowledge and skills from their home discipline first degrees. Robotics industry careers then follow the same pattern, with most roboticists working as part of interdisciplinary teams of specialists from these home disciplines followed by the robotics graduate degrees which enable them to work together. Workers typically continue to identify as members of their home disciplines who work in robotics, rather than as 'roboticists'. This structure is reinforced by the nature of some engineering professions, which grant chartered engineer status to members of home disciplines rather than to robotics as a whole. Robotics careers are widely predicted to grow in the 21st century, as robots replace more manual and intellectual human work. Some workers who lose their jobs to robotics may be well-placed to retrain to build and maintain these robots, using their domain-specific knowledge and skills. History [edit]| Date | Significance | Robot name | Inventor | |---|---|---|---| | c. 420 B.C. | A wooden, steam-propelled bird, which was able to fly | Flying pigeon | Archytas of Tarentum | | Third century B.C. and earlier | One of the earliest descriptions of automata appears in the Lie Zi text, on a much earlier encounter between King Mu of Zhou (1023–957 BC) and a mechanical engineer known as Yan Shi, an 'artificer'. The latter allegedly presented the king with a life-size, human-shaped figure of his mechanical handiwork.[166] | Yan Shi (Chinese: 偃师) | | | First century A.D. and earlier | Descriptions of more than 100 machines and automata, including a fire engine, a wind organ, a coin-operated machine, and a steam-powered engine, in Pneumatica and Automata by Heron of Alexandria | Ctesibius, Philo of Byzantium, Heron of Alexandria, and others | | | 1206 | Created early humanoid automata, programmable automaton band[167] Robot band, hand-washing automaton,[168] automated moving peacocks[169] | Al-Jazari | | | 1495 | Designs for a humanoid robot | Mechanical Knight | Leonardo da Vinci | | 1560s | Clockwork Prayer that had machinal feet built under its robes that imitated walking. The robot's eyes, lips, and head all move in lifelike gestures. | Clockwork Prayer [citation needed] | Gianello della Torre | | 1738 | Mechanical duck that was able to eat, flap its wings, and excrete | Digesting Duck | Jacques de Vaucanson | | 1898 | Nikola Tesla demonstrates the first radio-controlled vessel. | Teleautomaton | Nikola Tesla | | 1903 | Leonardo Torres Quevedo presented the Telekino at the Paris Academy of Science, a radio-based control system with different operational states, for testing airships without risking human lives.[170] He conduct the initial test controlling a tricycle almost 100 feet away, being the first example of a radio-controlled unmanned ground vehicle.[171][172] | Telekino | Leonardo Torres Quevedo | | 1912 | Leonardo Torres Quevedo builds the first truly autonomous machine capable of playing chess. As opposed to the human-operated The Turk and Ajeeb, El Ajedrecista had an integrated automaton built to play chess without human guidance. It only played an endgame with three chess pieces, automatically moving a white king and a rook to checkmate the black king moved by a human opponent.[173][174] | El Ajedrecista | Leonardo Torres Quevedo | | 1914 | In his paper Essays on Automatics published in 1914, Leonardo Torres Quevedo proposed a machine that makes \"judgments\" using sensors that capture information from the outside, parts that manipulate the outside world like arms, power sources such as batteries and air pressure, and most importantly, captured information and past information. It was defined as an organism that can control reactions in response to external information and adapt to changes in the environment to change its behavior.[175][176][177][178] | Essays on Automatics | Leonardo Torres Quevedo | | 1921 | First fictional automatons called \"robots\" appear in the play R.U.R. | Rossum's Universal Robots | Karel Čapek | | 1930s | Humanoid robot exhibited at the 1939 and 1940 World's Fairs | Elektro | Westinghouse Electric Corporation | | 1946 | First general-purpose digital computer | Whirlwind | Multiple people | | 1948 | Simple robots exhibiting biological behaviors[179] | Elsie and Elmer | William Grey Walter | | 1948 | Formulation of principles of cybernetics | cybernetics | Norbert Wiener | | 1956 | First commercial robot, from the Unimation company founded by George Devol and Joseph Engelberger, based on Devol's patents[180] | Unimate | George Devol | | 1961 | First installed industrial robot. The first digitally operated and programmable robot, Unimate, was installed in 1961 to lift hot pieces of metal from a die casting machine and stack them. | Unimate | George Devol | | 1967 to 1972 | First full-scale humanoid intelligent robot,[181][182] and first android. Its limb control system allowed it to walk with the lower limbs, and to grip and transport objects with its hands, using tactile sensors. Its vision system allowed it to measure distances and directions to objects using external receptors, artificial eyes, and ears. And its conversation system allowed it to communicate with a person in Japanese, with an artificial mouth.[183][184][185] | WABOT-1 | Waseda University | | 1973 | First industrial robot with six electromechanically driven axes[186][187] | Famulus | KUKA Robot Group | | 1974 | The world's first microcomputer controlled electric industrial robot, IRB 6 from ASEA, was delivered to a small mechanical engineering company in southern Sweden. The design of this robot had been patented in 1972. | IRB 6 | ABB Robot Group | | 1975 | Programmable universal manipulation arm, a Unimation product | PUMA | Victor Scheinman | | 1978 | The first object-level robot programming language, RAPT, allowing robots to handle variations in object position, shape, and sensor noise.[188] | Freddy I and II | Patricia Ambler and Robin Popplestone | | 1983 | First multitasking, the parallel programming language used for robot control. It was the Event Driven Language (EDL) on the IBM/Series/1 process computer, with the implementation of both inter-process communication (WAIT/POST) and mutual exclusion (ENQ/DEQ) mechanisms for robot control.[189] | ADRIEL I | Stevo Bozinovski and Mihail Sestakov | See also [edit]- Artificial intelligence - Autonomous robot - Cloud robotics - Cognitive robotics - Evolutionary robotics - Fog robotics - Glossary of robotics - Index of robotics articles - Mechatronics - Multi-agent system - Outline of robotics - Quantum robotics - Roboethics - Robot rights - Robotic art - Robotic governance - Self-reconfiguring modular robot - Soft robotics - Telerobotics Notes [edit]- ^ One database, developed by the United States Department of Energy, contains information on almost 500 existing robotic technologies.[10] References [edit]- ^ \"German National Library\". International classification system of the German National Library (GND). Archived from the original on 2020-08-19. - ^ \"Origami-Inspired Robots Can Sense, Analyze and Act in Challenging Environments\". UCLA. Retrieved 2023-04-10. - ^ Raj, Aditi (26 August 2024). \"AI & Robotics: The Role of AI in Robots\". Retrieved 2024-08-29. - ^ Hunt, V. Daniel (1985). \"Smart Robots\". Smart Robots: A Handbook of Intelligent Robotic Systems. Chapman and Hall. p. 141. ISBN 978-1-4613-2533-8. Archived from the original on 2023-03-15. Retrieved 2018-12-04. - ^ \"Robot density rises globally\". Robotic Industries Association. 8 February 2018. Archived from the original on 2020-11-23. Retrieved 2018-12-03. - ^ Pinto, Jim (1 October 2003). \"Fully automated factories approach reality\". Automation World. Archived from the original on 2011-10-01. Retrieved 2018-12-03. - ^ Eyre, Michael (12 September 2014). \"'Boris' the robot can load up dishwasher\". BBC News. Archived from the original on 2020-12-21. Retrieved 2018-12-03. - ^ Corner, Stuart (23 November 2017). \"AI-driven robot makes 'perfect' flatbread\". iothub.com.au. Archived from the original on 2020-11-24. Retrieved 2018-12-03. - ^ Pollock, Emily (7 June 2018). \"Construction Robotics Industry Set to Double by 2023\". engineering.com. Archived from the original on 2020-08-07. Retrieved 2018-12-03. - ^ \"Technology Advanced Search\". D&D Knowledge Management Information Tool. Archived from the original on 2020-08-06. - ^ Arámbula Cosío, F.; Hibberd, R. D.; Davies, B. L. (July 1997). \"Electromagnetic compatibility aspects of active robotic systems for surgery: the robotic prostatectomy experience\". Medical and Biological Engineering and Computing. 35 (4): 436–440. doi:10.1007/BF02534105. ISSN 1741-0444. PMID 9327627. S2CID 21479700. - ^ Grift, Tony E. (2004). \"Agricultural Robotics\". University of Illinois at Urbana–Champaign. Archived from the original on 2007-05-04. Retrieved 2018-12-03. - ^ Thomas, Jim (1 November 2017). \"How corporate giants are automating the farm\". New Internationalist. Archived from the original on 2021-01-10. Retrieved 2018-12-03. - ^ Kolodny, Lora (4 July 2017). \"Robots are coming to a burger joint near you\". CNBC. Archived from the original on 2020-12-05. Retrieved 2018-12-03. - ^ Kirsner, Scott (27 January 2023). \"Robots in the kitchen? Local engineers are making it a reality\". The Boston Globe. - ^ Dowling, Kevin. \"Power Sources for Small Robots\" (PDF). Carnegie Mellon University. Archived (PDF) from the original on 2020-11-25. Retrieved 2012-05-11. - ^ Roozing, Wesley; Li, Zhibin; Tsagarakis, Nikos; Caldwell, Darwin (2016). \"Design Optimisation and Control of Compliant Actuation Arrangements in Articulated Robots for Improved Energy Efficiency\". IEEE Robotics and Automation Letters. 1 (2): 1110–1117. Bibcode:2016IRAL....1.1110R. doi:10.1109/LRA.2016.2521926. S2CID 1940410. - ^ Pratt, G. A.; Williamson, M. M. (1995). \"Series elastic actuators\". Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human-Robot Interaction and Cooperative Robots. Vol. 1. pp. 399–406. doi:10.1109/IROS.1995.525827. hdl:1721.1/36966. ISBN 0-8186-7108-4. S2CID 17120394. - ^ Furnémont, Raphaël; Mathijssen, Glenn; Verstraten, Tom; Lefeber, Dirk; Vanderborght, Bram (27 January 2016). \"Bi-directional series-parallel elastic actuator and overlap of the actuation layers\" (PDF). Bioinspiration & Biomimetics. 11 (1) 016005. Bibcode:2016BiBi...11a6005F. doi:10.1088/1748-3190/11/1/016005. PMID 26813145. S2CID 37031990. Archived (PDF) from the original on 2022-10-01. Retrieved 2023-03-15. - ^ Pratt, Jerry E.; Krupp, Benjamin T. (2004). \"Series Elastic Actuators for legged robots\". In Gerhart, Grant R; Shoemaker, Chuck M; Gage, Douglas W (eds.). Unmanned Ground Vehicle Technology VI. Vol. 5422. pp. 135–144. doi:10.1117/12.548000. S2CID 16586246. - ^ Li, Zhibin; Tsagarakis, Nikos; Caldwell, Darwin (2013). \"Walking Pattern Generation for a Humanoid Robot with Compliant Joints\". Autonomous Robots. 35 (1): 1–14. doi:10.1007/s10514-013-9330-7. S2CID 624563. - ^ Colgate, J. Edward (1988). The control of dynamically interacting systems (Thesis). hdl:1721.1/14380. - ^ Calanca, Andrea; Muradore, Riccardo; Fiorini, Paolo (November 2017). \"Impedance control of series elastic actuators: Passivity and acceleration-based control\". Mechatronics. 47: 37–48. doi:10.1016/j.mechatronics.2017.08.010. - ^ Tosun, Fatih Emre; Patoglu, Volkan (June 2020). \"Necessary and Sufficient Conditions for the Passivity of Impedance Rendering With Velocity-Sourced Series Elastic Actuation\". IEEE Transactions on Robotics. 36 (3): 757–772. Bibcode:2020ITRob..36..757T. doi:10.1109/TRO.2019.2962332. S2CID 212907787. - ^ www.imagesco.com, Images SI Inc -. \"Air Muscle actuators, going further, page 6\". Archived from the original on 2020-11-14. Retrieved 2010-05-24. - ^ \"Air Muscles\". Shadow Robot. Archived from the original on 2007-09-27. - ^ Tondu, Bertrand (2012). \"Modelling of the McKibben artificial muscle: A review\". Journal of Intelligent Material Systems and Structures. 23 (3): 225–253. doi:10.1177/1045389X11435435. S2CID 136854390. - ^ \"TALKING ELECTRONICS Nitinol Page-1\". Talkingelectronics.com. Archived from the original on 2020-01-18. Retrieved 2010-11-27. - ^ \"lf205, Hardware: Building a Linux-controlled walking robot\". Ibiblio.org. 1 November 2001. Archived from the original on 2016-03-03. Retrieved 2010-11-27. - ^ \"WW-EAP and Artificial Muscles\". Eap.jpl.nasa.gov. Archived from the original on 2017-01-20. Retrieved 2010-11-27. - ^ \"Empa – a117-2-eap\". Empa.ch. Archived from the original on 2015-09-24. Retrieved 2010-11-27. - ^ \"Electroactive Polymers (EAP) as Artificial Muscles (EPAM) for Robot Applications\". Hizook. Archived from the original on 2020-08-06. Retrieved 2010-11-27. - ^ \"Piezo LEGS – -09-26\". Archived from the original on 2008-01-30. Retrieved 2007-10-28. - ^ \"Squiggle Motors: Overview\". Archived from the original on 2007-10-07. Retrieved 2007-10-08. - ^ Nishibori; et al. (2003). \"Robot Hand with Fingers Using Vibration-Type Ultrasonic Motors (Driving Characteristics)\". Journal of Robotics and Mechatronics. 15 (6): 588–595. doi:10.20965/jrm.2003.p0588. - ^ Otake, Mihoko; Kagami, Yoshiharu; Ishikawa, Kohei; Inaba, Masayuki; Inoue, Hirochika (6 April 2001). Wilson, Alan R.; Asanuma, Hiroshi (eds.). \"Shape design of gel robots made of electroactive polymer gel\". Smart Materials. 4234: 194–202. Bibcode:2001SPIE.4234..194O. doi:10.1117/12.424407. S2CID 30357330. - ^ Madden, John D. (16 November 2007). \"Mobile Robots: Motor Challenges and Materials Solutions\". Science. 318 (5853): 1094–1097. Bibcode:2007Sci...318.1094M. CiteSeerX 10.1.1.395.4635. doi:10.1126/science.1146351. PMID 18006737. S2CID 52827127. - ^ \"Syntouch LLC: BioTac(R) Biomimetic Tactile Sensor Array\". Archived from the original on 2009-10-03. Retrieved 2009-08-10. - ^ Wettels, Nicholas; Santos, Veronica J.; Johansson, Roland S.; Loeb, Gerald E. (January 2008). \"Biomimetic Tactile Sensor Array\". Advanced Robotics. 22 (8): 829–849. doi:10.1163/156855308X314533. S2CID 4594917. - ^ \"What is The SmartHand?\". SmartHand Project. Archived from the original on 2015-03-03. Retrieved 2011-02-04. - ^ a b Arreguin, Juan (2008). Automation and Robotics. Vienna, Austria: I-Tech and Publishing. - ^ \"Annotated Mythbusters: Episode 78: Ninja Myths – Walking on Water, Catching a Sword, Catching an Arrow\". Archived from the original on 2020-11-12. Retrieved 2010-02-13. (Discovery Channel's Mythbusters making mechanical gripper from the chain and metal wire) - ^ \"Robonaut hand\". Archived from the original on 2020-02-22. Retrieved 2011-11-21. - ^ \"Delft hand\". TU Delft. Archived from the original on 2012-02-03. Retrieved 2011-11-21. - ^ M & C. \"TU Delft ontwikkelt goedkope, voorzichtige robothand\". TU Delft. Archived from the original on 2017-03-13. Retrieved 2011-11-21. - ^ \"astrictive definition – English definition dictionary – Reverso\". Archived from the original on 2020-04-30. Retrieved 2008-01-06. - ^ Tijsma, H. A.; Liefhebber, F.; Herder, J. L. (2005). \"Evaluation of New User Interface Features for the MANUS Robot Arm\". 9th International Conference on Rehabilitation Robotics, 2005. ICORR 2005. pp. 258–263. doi:10.1109/ICORR.2005.1501097. ISBN 0-7803-9003-2. S2CID 36445389. - ^ Allcock, Andrew (2006). \"Anthropomorphic hand is almost human\". Machinery. Archived from the original on 2007-09-28. Retrieved 2007-10-17. - ^ \"Welcome\". Archived (PDF) from the original on 2013-05-10. Retrieved 2007-10-28. - ^ a b c Corke, Peter (2017). Robotics, Vision and Control. Springer Tracts in Advanced Robotics. Vol. 118. doi:10.1007/978-3-319-54413-7. ISBN 978-3-319-54412-0. ISSN 1610-7438. Archived from the original on 2022-10-20. Retrieved 2023-03-15. - ^ a b c Lee, C S. G.; Fu, K. S.; Gonzalez, Ralph (1987). Robotics: Control Sensing. Vis. McGraw-Hill. ISBN 978-0-07-026510-3. Archived from the original on 2023-03-15. Retrieved 2023-03-15. - ^ a b c d Short, Michael; Burn, Kevin (1 April 2011). \"A generic controller architecture for intelligent robotic systems\". Robotics and Computer-Integrated Manufacturing. 27 (2): 292–305. doi:10.1016/j.rcim.2010.07.013. ISSN 0736-5845. - ^ Ray, Partha Pratim (2016). \"Internet of Robotic Things: Concept, Technologies, and Challenges\". IEEE Access. 4: 9489–9500. Bibcode:2016IEEEA...4.9489R. doi:10.1109/ACCESS.2017.2647747. ISSN 2169-3536. S2CID 9273802. - ^ a b Burn, K.; Short, M.; Bicker, R. (July 2003). \"Adaptive and Nonlinear Fuzzy Force Control Techniques Applied to Robots Operating in Uncertain Environments\". Journal of Robotic Systems. 20 (7): 391–400. doi:10.1002/rob.10093. ISSN 0741-2223. Archived from the original on 2022-11-26. Retrieved 2023-03-15. - ^ Burn, Kevin; Home, Geoffrey (1 May 2008). \"Environment classification using Kohonen self-organizing maps\". Expert Systems. 25 (2): 98–114. doi:10.1111/j.1468-0394.2008.00441.x. ISSN 0266-4720. S2CID 33369232. - ^ Mason, Matthew T. (2001). Mechanics of Robotic Manipulation. doi:10.7551/mitpress/4527.001.0001. ISBN 978-0-262-25662-9. S2CID 5260407. - ^ \"What is a robotic end-effector?\". ATI Industrial Automation. 2007. Archived from the original on 2020-12-17. Retrieved 2007-10-16. - ^ Crane, Carl D.; Joseph Duffy (1998). Kinematic Analysis of Robot Manipulators. Cambridge University Press. ISBN 978-0-521-57063-3. Archived from the original on 2020-04-02. Retrieved 2007-10-16. - ^ G. J. Monkman, S. Hesse, R. Steinmann & H. Schunk (2007). Robot Grippers. Berlin, Germany: Wiley. - ^ \"T.O.B.B\". Mtoussaint.de. Archived from the original on 2020-07-08. Retrieved 2010-11-27. - ^ \"nBot, a two wheel balancing robot\". Geology.heroy.smu.edu. Archived from the original on 2021-01-26. Retrieved 2010-11-27. - ^ \"ROBONAUT Activity Report\". NASA. 2004. Archived from the original on 2007-08-20. Retrieved 2007-10-20. - ^ Guizzo, Erico (29 April 2010). \"A Robot That Balances on a Ball\". IEEE Spectrum. Archived from the original on 2023-02-10. Retrieved 2023-03-15. - ^ \"Carnegie Mellon Researchers Develop New Type of Mobile Robot That Balances and Moves on a Ball Instead of Legs or Wheels\" (Press release). Carnegie Mellon. 9 August 2006. Archived from the original on 2007-06-09. Retrieved 2007-10-20. - ^ \"Spherical Robot Can Climb Over Obstacles\". BotJunkie. Archived from the original on 2012-03-28. Retrieved 2010-11-27. - ^ \"Rotundus\". Rotundus.se. Archived from the original on 2011-08-26. Retrieved 2010-11-27. - ^ \"OrbSwarm Gets A Brain\". BotJunkie. 11 July 2007. Archived from the original on 2012-05-16. Retrieved 2010-11-27. - ^ \"Rolling Orbital Bluetooth Operated Thing\". BotJunkie. Archived from the original on 2012-03-28. Retrieved 2010-11-27. - ^ \"Swarm\". Orbswarm.com. Archived from the original on 2021-01-26. Retrieved 2010-11-27. - ^ \"The Ball Bot: Johnnytronic@Sun\". Blogs.sun.com. Archived from the original on 2011-08-24. Retrieved 2010-11-27. - ^ \"Senior Design Projects | College of Engineering & Applied Science| University of Colorado at Boulder\". Engineering.colorado.edu. 30 April 2008. Archived from the original on 2011-07-23. Retrieved 2010-11-27. - ^ \"JPL Robotics: System: Commercial Rovers\". Archived from the original on 2006-06-15. - ^ \"AMBER Lab\". Archived from the original on 2020-11-25. Retrieved 2012-01-23. - ^ \"Micromagic Systems Robotics Lab\". Archived from the original on 2017-06-01. Retrieved 2009-04-29. - ^ \"AMRU-5 hexapod robot\" (PDF). Archived (PDF) from the original on 2016-08-17. Retrieved 2009-04-29. - ^ \"Achieving Stable Walking\". Honda Worldwide. Archived from the original on 2011-11-08. Retrieved 2007-10-22. - ^ \"Funny Walk\". Pooter Geek. 28 December 2004. Archived from the original on 2011-09-28. Retrieved 2007-10-22. - ^ \"ASIMO's Pimp Shuffle\". Popular Science. 9 January 2007. Archived from the original on 2011-07-24. Retrieved 2007-10-22. - ^ \"Robot Shows Prime Minister How to Loosen Up > > A drunk robot?\". The Temple of VTEC – Honda and Acura Enthusiasts Online Forums. 25 August 2003. Archived from the original on 2020-04-30. - ^ \"3D One-Leg Hopper (1983–1984)\". MIT Leg Laboratory. Archived from the original on 2018-07-25. Retrieved 2007-10-22. - ^ \"3D Biped (1989–1995)\". MIT Leg Laboratory. Archived from the original on 2011-09-26. Retrieved 2007-10-28. - ^ \"Quadruped (1984–1987)\". MIT Leg Laboratory. Archived from the original on 2011-08-23. Retrieved 2007-10-28. - ^ \"MIT Leg Lab Robots – Main\". Archived from the original on 2020-08-07. Retrieved 2007-10-28. - ^ \"About the Robots\". Anybots. Archived from the original on 2007-09-09. Retrieved 2007-10-23. - ^ \"Anything, Anytime, Anywhere\". Anybots. Archived from the original on 2007-10-27. Retrieved 2007-10-23. - ^ \"Dexter Jumps video\". YouTube. 1 March 2007. Archived from the original on 2021-10-30. Retrieved 2007-10-23. - ^ Collins, Steve; Ruina, Andy; Tedrake, Russ; Wisse, Martijn (18 February 2005). \"Efficient Bipedal Robots Based on Passive-Dynamic Walkers\". Science. 307 (5712): 1082–1085. Bibcode:2005Sci...307.1082C. doi:10.1126/science.1107799. PMID 15718465. S2CID 1315227. - ^ Collins, S. H.; Ruina, A. (2005). \"A Bipedal Walking Robot with Efficient and Human-Like Gait\". Proceedings of the 2005 IEEE International Conference on Robotics and Automation. pp. 1983–1988. doi:10.1109/ROBOT.2005.1570404. ISBN 0-7803-8914-X. S2CID 15145353. - ^ \"Testing the Limits\" (PDF). Boeing. p. 29. Archived (PDF) from the original on 2018-12-15. Retrieved 2008-04-09. - ^ Zhang, Jun; Zhao, Ning; Qu, Feiyang (15 November 2022). \"Bio-inspired flapping wing robots with foldable or deformable wings: a review\". Bioinspiration & Biomimetics. 18 (1): 011002. doi:10.1088/1748-3190/ac9ef5. ISSN 1748-3182. PMID 36317380. S2CID 253246037. - ^ a b c Shin, Won Dong; Park, Jaejun; Park, Hae-Won (1 September 2019). \"Development and experiments of a bio-inspired robot with multi-mode in aerial and terrestrial locomotion\". Bioinspiration & Biomimetics. 14 (5): 056009. Bibcode:2019BiBi...14e6009S. doi:10.1088/1748-3190/ab2ab7. ISSN 1748-3182. PMID 31212268. S2CID 195066183. - ^ Ramezani, Alireza; Shi, Xichen; Chung, Soon-Jo; Hutchinson, Seth (May 2016). \"Bat Bot (B2), a biologically inspired flying machine\". 2016 IEEE International Conference on Robotics and Automation (ICRA). Stockholm, Sweden: IEEE. pp. 3219–3226. doi:10.1109/ICRA.2016.7487491. ISBN 978-1-4673-8026-3. S2CID 8581750. - ^ a b Daler, Ludovic; Mintchev, Stefano; Stefanini, Cesare; Floreano, Dario (19 January 2015). \"A bioinspired multi-modal flying and walking robot\". Bioinspiration & Biomimetics. 10 (1) 016005. Bibcode:2015BiBi...10a6005D. doi:10.1088/1748-3190/10/1/016005. ISSN 1748-3190. PMID 25599118. S2CID 11132948. - ^ a b Kilian, Lukas; Shahid, Farzeen; Zhao, Jing-Shan; Nayeri, Christian Navid (1 July 2022). \"Bioinspired morphing wings: mechanical design and wind tunnel experiments\". Bioinspiration & Biomimetics. 17 (4): 046019. Bibcode:2022BiBi...17d6019K. doi:10.1088/1748-3190/ac72e1. ISSN 1748-3182. PMID 35609562. S2CID 249045806. - ^ Savastano, E.; Perez-Sanchez, V.; Arrue, B.C.; Ollero, A. (July 2022). \"High-Performance Morphing Wing for Large-Scale Bio-Inspired Unmanned Aerial Vehicles\". IEEE Robotics and Automation Letters. 7 (3): 8076–8083. Bibcode:2022IRAL....7.8076S. doi:10.1109/LRA.2022.3185389. ISSN 2377-3766. S2CID 250008824. - ^ Grant, Daniel T.; Abdulrahim, Mujahid; Lind, Rick (June 2010). \"Flight Dynamics of a Morphing Aircraft Utilizing Independent Multiple-Joint Wing Sweep\". International Journal of Micro Air Vehicles. 2 (2): 91–106. doi:10.1260/1756-8293.2.2.91. ISSN 1756-8293. S2CID 110577545. - ^ Phan, Hoang Vu; Park, Hoon Cheol (4 December 2020). \"Mechanisms of collision recovery in flying beetles and flapping-wing robots\". Science. 370 (6521): 1214–1219. Bibcode:2020Sci...370.1214P. doi:10.1126/science.abd3285. ISSN 0036-8075. PMID 33273101. S2CID 227257247. - ^ Hu, Zheng; McCauley, Raymond; Schaeffer, Steve; Deng, Xinyan (May 2009). \"Aerodynamics of dragonfly flight and robotic design\". 2009 IEEE International Conference on Robotics and Automation. pp. 3061–3066. doi:10.1109/ROBOT.2009.5152760. ISBN 978-1-4244-2788-8. S2CID 12291429. - ^ Balta, Miquel; Deb, Dipan; Taha, Haithem E (26 October 2021). \"Flow visualization and force measurement of the clapping effect in bio-inspired flying robots\". Bioinspiration & Biomimetics. 16 (6): 066020. Bibcode:2021BiBi...16f6020B. doi:10.1088/1748-3190/ac2b00. ISSN 1748-3182. PMID 34584023. S2CID 238217893. - ^ Miller, Gavin. \"Introduction\". snakerobots.com. Archived from the original on 2011-08-17. Retrieved 2007-10-22. - ^ \"ACM-R5\". Archived from the original on 2011-10-11. - ^ \"Swimming snake robot (commentary in Japanese)\". Archived from the original on 2012-02-08. Retrieved 2007-10-28. - ^ \"Commercialized Quadruped Walking Vehicle \"TITAN VII\"\". Hirose Fukushima Robotics Lab. Archived from the original on 2007-11-06. Retrieved 2007-10-23. - ^ Pachal, Peter (23 January 2007). \"Plen, the robot that skates across your desk\". SCI FI Tech. Archived from the original on 2007-10-11. - ^ Capuchin on YouTube - ^ Wallbot on YouTube - ^ Stanford University: Stickybot on YouTube - ^ Sfakiotakis, M.; Lane, D. M.; Davies, J. B. C. (April 1999). \"Review of fish swimming modes for aquatic locomotion\". IEEE Journal of Oceanic Engineering. 24 (2): 237–252. Bibcode:1999IJOE...24..237S. CiteSeerX 10.1.1.459.8614. doi:10.1109/48.757275. S2CID 17226211. - ^ Mason, Richard. \"What is the market for robot fish?\". Archived from the original on 2009-07-04. - ^ \"Robotic fish powered by Gumstix PC and PIC\". Human Centred Robotics Group at Essex University. Archived from the original on 2011-08-14. Retrieved 2007-10-25. - ^ Juwarahawong, Witoon. \"Fish Robot\". Institute of Field Robotics. Archived from the original on 2007-11-04. Retrieved 2007-10-25. - ^ \"Festo – AquaPenguin\". 17 April 2009 – via YouTube. - ^ \"High-Speed Robotic Fish\". iSplash-Robotics. Archived from the original on 2020-03-11. Retrieved 2017-01-07. - ^ \"iSplash-II: Realizing Fast Carangiform Swimming to Outperform a Real Fish\" (PDF). Robotics Group at Essex University. Archived from the original (PDF) on 2015-09-30. Retrieved 2015-09-29. - ^ \"iSplash-I: High Performance Swimming Motion of a Carangiform Robotic Fish with Full-Body Coordination\" (PDF). Robotics Group at Essex University. Archived from the original (PDF) on 2015-09-30. Retrieved 2015-09-29. - ^ Jaulin, Luc; Le Bars, Fabrice (February 2013). \"An Interval Approach for Stability Analysis: Application to Sailboat Robotics\". IEEE Transactions on Robotics. 29 (1): 282–287. Bibcode:2013ITRob..29..282J. CiteSeerX 10.1.1.711.7180. doi:10.1109/TRO.2012.2217794. S2CID 4977937. - ^ \"A Ping-Pong-Playing Terminator\". Popular Science. Archived from the original on 2021-01-22. Retrieved 2010-12-19. - ^ \"Synthiam Exosphere combines AI, human operators to train robots\". The Robot Report. Archived from the original on 2020-10-06. Retrieved 2020-04-29. - ^ a b Kagan, Eugene; Ben-Gal, Irad (2015). Search and foraging:individual motion and swarm dynamics. Chapman and Hall/CRC. ISBN 978-1-4822-4210-2. Archived from the original on 2023-03-15. Retrieved 2020-08-26. - ^ Banks, Jaime (2020). \"Optimus Primed: Media Cultivation of Robot Mental Models and Social Judgments\". Frontiers in Robotics and AI. 7 62. doi:10.3389/frobt.2020.00062. PMC 7805817. PMID 33501230. - ^ a b Wullenkord, Ricarda; Fraune, Marlena R.; Eyssel, Friederike; Sabanovic, Selma (2016). \"Getting in Touch: How imagined, actual, and physical contact affect evaluations of robots\". 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). pp. 980–985. doi:10.1109/ROMAN.2016.7745228. ISBN 978-1-5090-3929-6. S2CID 6305599. - ^ Norberto Pires, J. (December 2005). \"Robot-by-voice: experiments on commanding an industrial robot using the human voice\". Industrial Robot. 32 (6): 505–511. doi:10.1108/01439910510629244. - ^ \"Survey of the State of the Art in Human Language Technology: 1.2: Speech Recognition\". Archived from the original on 2007-11-11. - ^ Fournier, Randolph Scott; Schmidt, B. June (1995). \"Voice input technology: Learning style and attitude toward its use\". Delta Pi Epsilon Journal. 37 (1): 1–12. ProQuest 1297783046. - ^ \"History of Speech & Voice Recognition and Transcription Software\". Dragon Naturally Speaking. Archived from the original on 2015-08-13. Retrieved 2007-10-27. - ^ Cheng Lin, Kuan; Huang, Tien-Chi; Hung, Jason C.; Yen, Neil Y.; Ju Chen, Szu (7 June 2013). \"Facial emotion recognition towards affective computing-based learning\". Library Hi Tech. 31 (2): 294–307. doi:10.1108/07378831311329068. - ^ Walters, M. L.; Syrdal, D. S.; Koay, K. L.; Dautenhahn, K.; Te Boekhorst, R. (2008). \"Human approach distances to a mechanical-looking robot with different robot voice styles\". RO-MAN 2008 – the 17th IEEE International Symposium on Robot and Human Interactive Communication. pp. 707–712. doi:10.1109/ROMAN.2008.4600750. ISBN 978-1-4244-2212-8. S2CID 8653718. - ^ Pauletto, Sandra; Bowles, Tristan (2010). \"Designing the emotional content of a robotic speech signal\". Proceedings of the 5th Audio Mostly Conference on a Conference on Interaction with Sound – AM '10. pp. 1–8. doi:10.1145/1859799.1859804. ISBN 978-1-4503-0046-9. S2CID 30423778. - ^ Bowles, Tristan; Pauletto, Sandra (2010). Emotions in the Voice: Humanising a Robotic Voice (PDF). Proceedings of the 7th Sound and Music Computing Conference. Barcelona. Archived (PDF) from the original on 2023-02-10. Retrieved 2023-03-15. - ^ \"World of 2-XL: Leachim\". www.2xlrobot.com. Archived from the original on 2020-07-05. Retrieved 2019-05-28. - ^ \"The Boston Globe from Boston, Massachusetts on June 23, 1974 · 132\". Newspapers.com. 23 June 1974. Archived from the original on 2020-01-10. Retrieved 2019-05-28. - ^ a b \"A history of cybernetic animals and early robots\". cyberneticzoo.com. p. 135. Archived from the original on 2020-08-06. Retrieved 2019-05-28. - ^ \"Frubber facial expressions\". Archived from the original on 2009-02-07. - ^ \"Best Inventions of 2008 – TIME\". Time. 29 October 2008. Archived from the original on 2008-11-02 – via www.time.com. - ^ \"Kismet: Robot at MIT's AI Lab Interacts With Humans\". Sam Ogden. Archived from the original on 2007-10-12. Retrieved 2007-10-28. - ^ Waldherr, Stefan; Romero, Roseli; Thrun, Sebastian (1 September 2000). \"A Gesture Based Interface for Human-Robot Interaction\". Autonomous Robots. 9 (2): 151–173. doi:10.1023/A:1008918401478. S2CID 1980239. - ^ Li, Ling Hua; Du, Ji Fang (December 2012). \"Visual Based Hand Gesture Recognition Systems\". Applied Mechanics and Materials. 263–266: 2422–2425. Bibcode:2012AMM...263.2422L. doi:10.4028/www.scientific.net/AMM.263-266.2422. S2CID 62744240. - ^ \"Armenian Robin the Robot to comfort kids at U.S. clinics starting July\". Public Radio of Armenia. Archived from the original on 2021-05-13. Retrieved 2021-05-13. - ^ Park, S.; Sharlin, Ehud; Kitamura, Y.; Lau, E. (29 April 2005). Synthetic Personality in Robots and its Effect on Human-Robot Relationship (Report). doi:10.11575/PRISM/31041. hdl:1880/45619. - ^ \"Robot Receptionist Dishes Directions and Attitude\". NPR.org. Archived from the original on 2020-12-01. Retrieved 2018-04-05. - ^ \"New Scientist: A good robot has personality but not looks\" (PDF). Archived from the original (PDF) on 2006-09-29. - ^ \"Playtime with Pleo, your robotic dinosaur friend\". 25 September 2008. Archived from the original on 2019-01-20. Retrieved 2014-12-14. - ^ NOVA conversation with Professor Moravec, October 1997. NOVA Online Archived 2017-08-02 at the Wayback Machine - ^ Agarwal, P. K. Elements of Physics XI. Rastogi Publications. p. 2. ISBN 978-81-7133-911-2. - ^ Sandhana, Lakshmi (5 September 2002). \"A Theory of Evolution, for Robots\". Wired. Archived from the original on 2014-03-29. Retrieved 2007-10-28. - ^ \"Experimental Evolution In Robots Probes The Emergence Of Biological Communication\". Science Daily. 24 February 2007. Archived from the original on 2018-11-16. Retrieved 2007-10-28. - ^ Žlajpah, Leon (15 December 2008). \"Simulation in robotics\". Mathematics and Computers in Simulation. 79 (4): 879–897. doi:10.1016/j.matcom.2008.02.017. - ^ \"Evolution trains robot teams TRN 051904\". Technology Research News. Archived from the original on 2016-06-23. Retrieved 2009-01-22. - ^ Müller, Christopher (2023). World Robotics 2023 – Industrial Robots. Frankfurt, Germany: IFR Statistical Department, VDMA Services GmbH. - ^ Tandon, Prateek (2017). Quantum Robotics. Morgan & Claypool Publishers. ISBN 978-1-62705-913-8. - ^ Dragani, Rachelle (8 November 2018). \"Can a robot make you a 'superworker'?\". Verizon Communications. Archived from the original on 2020-08-06. Retrieved 2018-12-03. - ^ \"Robotics\". American Elements. Retrieved 2023-04-10. - ^ \"Career: Robotics Engineer\". Princeton Review. 2012. Archived from the original on 2015-01-21. Retrieved 2012-01-27. - ^ Saad, Ashraf; Kroutil, Ryan (2012). Hands-on Learning of Programming Concepts Using Robotics for Middle and High School Students. Proceedings of the 50th Annual Southeast Regional Conference of the Association for Computing Machinery. ACM. pp. 361–362. doi:10.1145/2184512.2184605. - ^ Toy, Tommy (29 June 2011). \"Outlook for robotics and Automation for 2011 and beyond are excellent says expert\". PBT Consulting. Archived from the original on 2012-01-27. Retrieved 2012-01-27. - ^ Frey, Carl Benedikt; Osborne, Michael A. (January 2017). \"The future of employment: How susceptible are jobs to computerisation?\". Technological Forecasting and Social Change. 114: 254–280. CiteSeerX 10.1.1.395.416. doi:10.1016/j.techfore.2016.08.019. - ^ McGaughey, Ewan (16 October 2019). \"Will robots automate your job away? Full employment, basic income, and economic democracy\". LawArXiv Papers. doi:10.31228/osf.io/udbj8. S2CID 243172487. SSRN 3044448. - ^ Hawking, Stephen (1 January 2016). \"This is the most dangerous time for our planet\". The Guardian. Archived from the original on 2021-01-31. Retrieved 2019-11-22. - ^ \"Robotics – Thematic Research\". GlobalData. Archived from the original on 2021-09-28. Retrieved 2021-09-22. - ^ \"Focal Points Seminar on review articles in the future of work – Safety and health at work – EU-OSHA\". osha.europa.eu. Archived from the original on 2020-01-25. Retrieved 2016-04-19. - ^ \"Robotics: Redefining crime prevention, public safety and security\". SourceSecurity.com. Archived from the original on 2017-10-09. Retrieved 2016-09-16. - ^ \"Draft Standard for Intelligent Assist Devices — Personnel Safety Requirements\" (PDF). Archived (PDF) from the original on 2020-11-25. Retrieved 2016-06-01. - ^ \"ISO/TS 15066:2016 – Robots and robotic devices – Collaborative robots\". 8 March 2016. Archived from the original on 2016-10-10. Retrieved 2016-06-01. - ^ Brogårdh, Torgny (January 2007). \"Present and future robot control development—An industrial perspective\". Annual Reviews in Control. 31 (1): 69–79. doi:10.1016/j.arcontrol.2007.01.002. ISSN 1367-5788. - ^ Wang, Tian-Miao; Tao, Yong; Liu, Hui (17 April 2018). \"Current Researches and Future Development Trend of Intelligent Robot: A Review\". International Journal of Automation and Computing. 15 (5): 525–546. doi:10.1007/s11633-018-1115-1. ISSN 1476-8186. S2CID 126037910. - ^ Needham, Joseph (1991). Science and Civilisation in China: Volume 2, History of Scientific Thought. Cambridge University Press. ISBN 978-0-521-05800-1. - ^ Fowler, Charles B. (October 1967). \"The Museum of Music: A History of Mechanical Instruments\". Music Educators Journal. 54 (2): 45–49. doi:10.2307/3391092. JSTOR 3391092. S2CID 190524140. - ^ Rosheim, Mark E. (1994). Robot Evolution: The Development of Anthrobotics. Wiley-IEEE. pp. 9–10. ISBN 978-0-471-02622-8. - ^ al-Jazari (Islamic artist) Archived 2008-05-07 at the Wayback Machine, Encyclopædia Britannica. - ^ A. P. Yuste. Electrical Engineering Hall of Fame. Early Developments of Wireless Remote Control: The Telekino of Torres-Quevedo,(pdf) vol. 96, No. 1, January 2008, Proceedings of the IEEE. - ^ H. R. Everett (2015). Unmanned Systems of World Wars I and II. MIT Press. pp. 91–95. ISBN 978-0-262-02922-3. - ^ Randy Alfred, \"Nov. 7, 1905: Remote Control Wows Public\", Wired, 7 November 2011. - ^ Williams, Andrew (16 March 2017). History of Digital Games: Developments in Art, Design and Interaction. CRC Press. ISBN 978-1-317-50381-1. - ^ Randell, Brian (October 1982). \"From Analytical Engine to Electronic Digital Computer: The Contributions of Ludgate, Torres, and Bush\". IEEE Annals of the History of Computing. 4 (4): 327–341. Bibcode:1982IAHC....4d.327R. doi:10.1109/MAHC.1982.10042. S2CID 1737953. - ^ L. Torres Quevedo. Ensayos sobre Automática – Su definicion. Extension teórica de sus aplicaciones, Revista de la Academia de Ciencias Exacta, Revista 12, pp. 391–418, 1914. - ^ Torres Quevedo, Leonardo. Automática: Complemento de la Teoría de las Máquinas, (pdf), pp. 575–583, Revista de Obras Públicas, 19 November 1914. - ^ L. Torres Quevedo. Essais sur l'Automatique – Sa définition. Etendue théorique de ses applications. Archived 2023-02-10 at the Wayback Machine, Revue Génerale des Sciences Pures et Appliquées, vol. 2, pp. 601–611, 1915. - ^ B. Randell. Essays on Automatics, The Origins of Digital Computers, pp. 89–107, 1982. - ^ Sabbatini PhD, Renato M. E. \"Sabbatini, RME: An Imitation of Life: The First Robots\". Archived from the original on 2009-07-20. Retrieved 2023-03-15. - ^ Waurzyniak, Patrick (2006). \"Masters of Manufacturing: Joseph F. Engelberger\". Society of Manufacturing Engineers. 137 (1). Archived from the original on 2011-11-09. - ^ \"Humanoid History -WABOT-\". www.humanoid.waseda.ac.jp. Archived from the original on 2017-09-01. Retrieved 2017-05-06. - ^ Zeghloul, Saïd; Laribi, Med Amine; Gazeau, Jean-Pierre (21 September 2015). Robotics and Mechatronics: Proceedings of the 4th IFToMM International Symposium on Robotics and Mechatronics. Springer. ISBN 978-3-319-22368-1. Archived from the original on 2023-03-15. Retrieved 2017-09-10 – via Google Books. - ^ \"Historical Android Projects\". androidworld.com. Archived from the original on 2005-11-25. Retrieved 2017-05-06. - ^ Robots: From Science Fiction to Technological Revolution Archived 2023-03-15 at the Wayback Machine, page 130 - ^ Duffy, Vincent G. (19 April 2016). Handbook of Digital Human Modeling: Research for Applied Ergonomics and Human Factors Engineering. CRC Press. ISBN 978-1-4200-6352-3. Archived from the original on 2023-03-15. Retrieved 2017-09-10 – via Google Books. - ^ \"KUKA Industrial Robot FAMULUS\". Archived from the original on 2009-02-20. Retrieved 2008-01-10. - ^ \"History of Industrial Robots\" (PDF). Archived from the original (PDF) on 2012-12-24. Retrieved 2012-10-27. - ^ R. J. Popplestone; A. P. Ambler; I. Bellos (1978). \"RAPT: A language for describing assemblies\". Industrial Robot. 5 (3): 131–137. doi:10.1108/eb004501. - ^ Bozinovski, S. (1994). \"Parallel programming for mobile robot control: Agent-based approach\". 14th International Conference on Distributed Computing Systems. pp. 202–208. doi:10.1109/ICDCS.1994.302412. ISBN 0-8186-5840-1. S2CID 27855786. Further reading [edit]- R. Andrew Russell (1990). Robot Tactile Sensing. New York: Prentice Hall. ISBN 978-0-13-781592-0. - McGaughey, Ewan (16 October 2019). \"Will robots automate your job away? Full employment, basic income, and economic democracy\". LawArXiv Papers. doi:10.31228/osf.io/udbj8. S2CID 243172487. SSRN 3044448. - Autor, David H. (1 August 2015). \"Why Are There Still So Many Jobs? The History and Future of Workplace Automation\". Journal of Economic Perspectives. 29 (3): 3–30. doi:10.1257/jep.29.3.3. hdl:1721.1/109476. - Tooze, Adam (6 June 2019). \"Democracy and Its Discontents\". The New York Review of Books. Vol. 66, no. 10. External links [edit]- IEEE Robotics and Automation Society - Investigation of social robots – Robots that mimic human behaviors and gestures. - Wired's guide to the '50 best robots ever', a mix of robots in fiction (Hal, R2D2, K9) to real robots (Roomba, Mobot, Aibo).",
    "text_length": 97273,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:36.401817"
  },
  {
    "id": "page_8",
    "url": "https://en.wikipedia.org/wiki/AI_safety",
    "domain": "en.wikipedia.org",
    "title": "AI safety - Wikipedia",
    "text": "AI safety | Part of a series on | | Artificial intelligence (AI) | |---| AI safety is an interdisciplinary field focused on preventing accidents, misuse, or other harmful consequences arising from artificial intelligence (AI) systems. It encompasses AI alignment (which aims to ensure AI systems behave as intended), monitoring AI systems for risks, and enhancing their robustness. The field is particularly concerned with existential risks posed by advanced AI models.[1][2] Beyond technical research, AI safety involves developing norms and policies that promote safety. It gained significant popularity in 2023, with rapid progress in generative AI and public concerns voiced by researchers and CEOs about potential dangers. During the 2023 AI Safety Summit, the United States and the United Kingdom both established their own AI Safety Institute. However, researchers have expressed concern that AI safety measures are not keeping pace with the rapid development of AI capabilities.[3] Motivations [edit]Scholars discuss current risks from critical systems failures,[4] bias,[5] and AI-enabled surveillance,[6] as well as emerging risks like technological unemployment, digital manipulation,[7] weaponization,[8] AI-enabled cyberattacks[9] and bioterrorism.[10] They also discuss speculative risks from losing control of future artificial general intelligence (AGI) agents,[11] or from AI enabling perpetually stable dictatorships.[12] Existential safety [edit]Some have criticized concerns about AGI, such as Andrew Ng who compared them in 2015 to \"worrying about overpopulation on Mars when we have not even set foot on the planet yet\".[13] Stuart J. Russell on the other side urges caution, arguing that \"it is better to anticipate human ingenuity than to underestimate it\".[14] AI researchers have widely differing opinions about the severity and primary sources of risk posed by AI technology[15][16][17] – though surveys suggest that experts take high consequence risks seriously. In two surveys of AI researchers, the median respondent was optimistic about AI overall, but placed a 5% probability on an \"extremely bad (e.g. human extinction)\" outcome of advanced AI.[15] In a 2022 survey of the natural language processing community, 37% agreed or weakly agreed that it is plausible that AI decisions could lead to a catastrophe that is \"at least as bad as an all-out nuclear war\".[18] History [edit]Risks from AI began to be seriously discussed at the start of the computer age: Moreover, if we move in the direction of making machines which learn and whose behavior is modified by experience, we must face the fact that every degree of independence we give the machine is a degree of possible defiance of our wishes. — Norbert Wiener (1949)[19] In 1988 Blay Whitby published a book outlining the need for AI to be developed along ethical and socially responsible lines.[20] From 2008 to 2009, the Association for the Advancement of Artificial Intelligence (AAAI) commissioned a study to explore and address potential long-term societal influences of AI research and development. The panel was generally skeptical of the radical views expressed by science-fiction authors but agreed that \"additional research would be valuable on methods for understanding and verifying the range of behaviors of complex computational systems to minimize unexpected outcomes\".[21] In 2011, Roman Yampolskiy introduced the term \"AI safety engineering\"[22] at the Philosophy and Theory of Artificial Intelligence conference,[23] listing prior failures of AI systems and arguing that \"the frequency and seriousness of such events will steadily increase as AIs become more capable\".[24] In 2014, philosopher Nick Bostrom published the book Superintelligence: Paths, Dangers, Strategies. He has the opinion that the rise of AGI has the potential to create various societal issues, ranging from the displacement of the workforce by AI, manipulation of political and military structures, to even the possibility of human extinction.[25] His argument that future advanced systems may pose a threat to human existence prompted Elon Musk,[26] Bill Gates,[27] and Stephen Hawking[28] to voice similar concerns. In 2015, dozens of artificial intelligence experts signed an open letter on artificial intelligence calling for research on the societal impacts of AI and outlining concrete directions.[29] To date, the letter has been signed by over 8000 people including Yann LeCun, Shane Legg, Yoshua Bengio, and Stuart Russell. In the same year, a group of academics led by professor Stuart J. Russell founded the Center for Human-Compatible AI at the University of California Berkeley and the Future of Life Institute awarded $6.5 million in grants for research aimed at \"ensuring artificial intelligence (AI) remains safe, ethical and beneficial\".[30] In 2016, the White House Office of Science and Technology Policy and Carnegie Mellon University announced The Public Workshop on Safety and Control for Artificial Intelligence,[31] which was one of a sequence of four White House workshops aimed at investigating \"the advantages and drawbacks\" of AI.[32] In the same year, Concrete Problems in AI Safety – one of the first and most influential technical AI Safety agendas – was published.[33] In 2017, the Future of Life Institute sponsored the Asilomar Conference on Beneficial AI, where more than 100 thought leaders formulated principles for beneficial AI including \"Race Avoidance: Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards\".[34] In 2018, the DeepMind Safety team outlined AI safety problems in specification, robustness,[35] and assurance.[36] The following year, researchers organized a workshop at ICLR that focused on these problem areas.[37] In 2021, Unsolved Problems in ML Safety was published, outlining research directions in robustness, monitoring, alignment, and systemic safety.[2] In 2023, Rishi Sunak said he wants the United Kingdom to be the \"geographical home of global AI safety regulation\" and to host the first global summit on AI safety.[38] The AI safety summit took place in November 2023, and focused on the risks of misuse and loss of control associated with frontier AI models.[39] During the summit the intention to create the International Scientific Report on the Safety of Advanced AI[40] was announced. In 2024, The US and UK forged a new partnership on the science of AI safety. The MoU was signed on 1 April 2024 by US commerce secretary Gina Raimondo and UK technology secretary Michelle Donelan to jointly develop advanced AI model testing, following commitments announced at an AI Safety Summit in Bletchley Park in November.[41] In 2025, an international team of 96 experts chaired by Yoshua Bengio published the first International AI Safety Report. The report, commissioned by 30 nations and the United Nations, represents the first global scientific review of potential risks associated with advanced artificial intelligence. It details potential threats stemming from misuse, malfunction, and societal disruption, with the objective of informing policy through evidence-based findings, without providing specific recommendations.[42][43] Research focus [edit]AI safety research areas include robustness, monitoring, and alignment.[2][36] Robustness [edit]Adversarial robustness [edit]AI systems are often vulnerable to adversarial examples or \"inputs to machine learning (ML) models that an attacker has intentionally designed to cause the model to make a mistake\".[44] For example, in 2013, Szegedy et al. discovered that adding specific imperceptible perturbations to an image could cause it to be misclassified with high confidence.[45] This continues to be an issue with neural networks, though in recent work the perturbations are generally large enough to be perceptible.[46][47][48] The image on the right is predicted to be an ostrich after the perturbation is applied. (Left) is a correctly predicted sample, (center) perturbation applied magnified by 10x, (right) adversarial example.[45] Adversarial robustness is often associated with security.[49] Researchers demonstrated that an audio signal could be imperceptibly modified so that speech-to-text systems transcribe it to any message the attacker chooses.[50] Network intrusion[51] and malware[52] detection systems also must be adversarially robust since attackers may design their attacks to fool detectors. Models that represent objectives (reward models) must also be adversarially robust. For example, a reward model might estimate how helpful a text response is and a language model might be trained to maximize this score.[53] Researchers have shown that if a language model is trained for long enough, it will leverage the vulnerabilities of the reward model to achieve a better score and perform worse on the intended task.[54] This issue can be addressed by improving the adversarial robustness of the reward model.[55] More generally, any AI system used to evaluate another AI system must be adversarially robust. This could include monitoring tools, since they could also potentially be tampered with to produce a higher reward.[56] Large language models (LLMs) can be vulnerable to prompt injection[57] and model stealing,[58] and may be used to generate misinformation.[59] Prompt injection involves embedding instructions into prompts in order to bypass safety measures.[57] Monitoring [edit]Estimating uncertainty [edit]It is often important for human operators to gauge how much they should trust an AI system, especially in high-stakes settings such as medical diagnosis.[60] ML models generally express confidence by outputting probabilities; however, they are often overconfident,[61] especially in situations that differ from those that they were trained to handle.[62] Calibration research aims to make model probabilities correspond as closely as possible to the true proportion that the model is correct. Similarly, anomaly detection or out-of-distribution (OOD) detection aims to identify when an AI system is in an unusual situation. For example, if a sensor on an autonomous vehicle is malfunctioning, or it encounters challenging terrain, it should alert the driver to take control or pull over.[63] Anomaly detection has been implemented by simply training a classifier to distinguish anomalous and non-anomalous inputs,[64] though a range of additional techniques are in use.[65][66] Detecting malicious use [edit]Scholars[8] and government agencies have expressed concerns that AI systems could be used to help malicious actors to build weapons,[67] manipulate public opinion,[68][69] or automate cyber attacks.[70] These worries are a practical concern for companies like OpenAI which host powerful AI tools online.[71] In order to prevent misuse, OpenAI has built detection systems that flag or restrict users based on their activity.[72] Transparency [edit]Neural networks have often been described as black boxes,[73] meaning that it is difficult to understand why they make the decisions they do as a result of the massive number of computations they perform.[74] This makes it challenging to anticipate failures. In 2018, a self-driving car killed a pedestrian after failing to identify them. Due to the black box nature of the AI software, the reason for the failure remains unclear.[75] It also raises debates in healthcare over whether statistically efficient but opaque models should be used.[76] One critical benefit of transparency is explainability.[77] It is sometimes a legal requirement to provide an explanation for why a decision was made in order to ensure fairness, for example for automatically filtering job applications or credit score assignment.[77] Another benefit is to reveal the cause of failures.[73] At the beginning of the 2020 COVID-19 pandemic, researchers used transparency tools to show that medical image classifiers were 'paying attention' to irrelevant hospital labels.[78] Transparency techniques can also be used to correct errors. For example, in the paper \"Locating and Editing Factual Associations in GPT\", the authors were able to identify model parameters that influenced how it answered questions about the location of the Eiffel tower. They were then able to 'edit' this knowledge to make the model respond to questions as if it believed the tower was in Rome instead of France.[79] Though in this case, the authors induced an error, these methods could potentially be used to efficiently fix them. Model editing techniques also exist in computer vision.[80] Finally, some have argued that the opaqueness of AI systems is a significant source of risk and better understanding of how they function could prevent high-consequence failures in the future.[81] \"Inner\" interpretability research aims to make ML models less opaque. One goal of this research is to identify what the internal neuron activations represent.[82][83] For example, researchers identified a neuron in the CLIP artificial intelligence system that responds to images of people in Spider-Man costumes, sketches of Spider-Man, and the word 'spider'.[84] It also involves explaining connections between these neurons or 'circuits'.[85][86] For example, researchers have identified pattern-matching mechanisms in transformer attention that may play a role in how language models learn from their context.[87] \"Inner interpretability\" has been compared to neuroscience. In both cases, the goal is to understand what is going on in an intricate system, though ML researchers have the benefit of being able to take perfect measurements and perform arbitrary ablations.[88] Detecting trojans [edit]Machine learning models can potentially contain \"trojans\" or \"backdoors\": vulnerabilities that malicious actors maliciously build into an AI system. For example, a trojaned facial recognition system could grant access when a specific piece of jewelry is in view;[2] or a trojaned autonomous vehicle may function normally until a specific trigger is visible.[89] This might not be difficult to do with some large models like CLIP or GPT-3 as they are trained on publicly available internet data.[90] Researchers were able to plant a trojan in an image classifier by changing just 300 out of 3 million of the training images.[91] In addition to posing a security risk, researchers have argued that trojans provide a concrete setting for testing and developing better monitoring tools.[56] A 2024 research paper by Anthropic showed that large language models could be trained with persistent backdoors. These \"sleeper agent\" models could be programmed to generate malicious outputs (such as vulnerable code) after a specific date, while behaving normally beforehand. Standard AI safety measures, such as supervised fine-tuning, reinforcement learning and adversarial training, failed to remove these backdoors.[92] Alignment [edit]In the field of artificial intelligence (AI), alignment aims to steer AI systems toward a person's or group's intended goals, preferences, or ethical principles. An AI system is considered aligned if it advances the intended objectives. A misaligned AI system pursues unintended objectives.[93] It is often challenging for AI designers to align an AI system because it is difficult for them to specify the full range of desired and undesired behaviors. Therefore, AI designers often use simpler proxy goals, such as gaining human approval. But proxy goals can overlook necessary constraints or reward the AI system for merely appearing aligned.[93][94] AI systems may also find loopholes that allow them to accomplish their proxy goals efficiently but in unintended, sometimes harmful, ways (reward hacking).[93][95] Advanced AI systems may develop unwanted instrumental strategies, such as seeking power or survival because such strategies help them achieve their assigned final goals.[93][96][97] Furthermore, they might develop undesirable emergent goals that could be hard to detect before the system is deployed and encounters new situations and data distributions.[98][99] Empirical research showed in 2024 that advanced large language models (LLMs) such as OpenAI o1 or Claude 3 sometimes engage in strategic deception to achieve their goals or prevent them from being changed.[100][101] Today, some of these issues affect existing commercial systems such as LLMs,[102][103][104] robots,[105] autonomous vehicles,[106] and social media recommendation engines.[102][97][107] Some AI researchers argue that more capable future systems will be more severely affected because these problems partially result from high capabilities.[108][95][94] Many prominent AI researchers and the leadership of major AI companies have argued or asserted that AI is approaching human-like (AGI) and superhuman cognitive capabilities (ASI), and could endanger human civilization if misaligned.[109][97] These include \"AI godfathers\" Geoffrey Hinton and Yoshua Bengio and the CEOs of OpenAI, Anthropic, and Google DeepMind.[110][111][112] These risks remain debated.[113] AI alignment is a subfield of AI safety, the study of how to build safe AI systems.[114][115] Other subfields of AI safety include robustness, monitoring, and capability control.[116] Research challenges in alignment include instilling complex values in AI, developing honest AI, scalable oversight, auditing and interpreting AI models, and preventing emergent AI behaviors like power-seeking.[116] Alignment research has connections to interpretability research,[117][118] (adversarial) robustness,[119] anomaly detection, calibrated uncertainty,[117] formal verification,[120] preference learning,[121][122][123] safety-critical engineering,[124] game theory,[125] algorithmic fairness,[119][126] and social sciences.[127][128] Systemic safety and sociotechnical factors [edit]It is common for AI risks (and technological risks more generally) to be categorized as misuse or accidents.[129] Some scholars have suggested that this framework falls short.[129] For example, the Cuban Missile Crisis was not clearly an accident or a misuse of technology.[129] Policy analysts Zwetsloot and Dafoe wrote, \"The misuse and accident perspectives tend to focus only on the last step in a causal chain leading up to a harm: that is, the person who misused the technology, or the system that behaved in unintended ways... Often, though, the relevant causal chain is much longer.\" Risks often arise from 'structural' or 'systemic' factors such as competitive pressures, diffusion of harms, fast-paced development, high levels of uncertainty, and inadequate safety culture.[129] In the broader context of safety engineering, structural factors like 'organizational safety culture' play a central role in the popular STAMP risk analysis framework.[130] Inspired by the structural perspective, some researchers have emphasized the importance of using machine learning to improve sociotechnical safety factors, for example, using ML for cyber defense, improving institutional decision-making, and facilitating cooperation.[2] Others have emphasized the importance of involving both AI practitioners and domain experts in the design process to address structural vulnerabilities.[131] Cyber defense [edit]Some scholars are concerned that AI will exacerbate the already imbalanced game between cyber attackers and cyber defenders.[132] This would increase 'first strike' incentives and could lead to more aggressive and destabilizing attacks. In order to mitigate this risk, some have advocated for an increased emphasis on cyber defense. In addition, software security is essential for preventing powerful AI models from being stolen and misused.[8] Recent studies have shown that AI can significantly enhance both technical and managerial cybersecurity tasks by automating routine tasks and improving overall efficiency.[133] Improving institutional decision-making [edit]The advancement of AI in economic and military domains could precipitate unprecedented political challenges.[134] Some scholars have compared AI race dynamics to the cold war, where the careful judgment of a small number of decision-makers often spelled the difference between stability and catastrophe.[135] AI researchers have argued that AI technologies could also be used to assist decision-making.[2] For example, researchers are beginning to develop AI forecasting[136] and advisory systems.[137] Facilitating cooperation [edit]Many of the largest global threats (nuclear war,[138] climate change,[139] etc.) have been framed as cooperation challenges. As in the well-known prisoner's dilemma scenario, some dynamics may lead to poor results for all players, even when they are optimally acting in their self-interest. For example, no single actor has strong incentives to address climate change even though the consequences may be significant if no one intervenes.[139] A salient AI cooperation challenge is avoiding a 'race to the bottom'.[140] In this scenario, countries or companies race to build more capable AI systems and neglect safety, leading to a catastrophic accident that harms everyone involved. Concerns about scenarios like these have inspired both political[141] and technical[142] efforts to facilitate cooperation between humans, and potentially also between AI systems. Most AI research focuses on designing individual agents to serve isolated functions (often in 'single-player' games).[143] Scholars have suggested that as AI systems become more autonomous, it may become essential to study and shape the way they interact.[143][131] In governance [edit]AI governance is broadly concerned with creating norms, standards, and regulations to guide the use and development of AI systems.[135] Research [edit]In AI safety, local solutions focus on individual AI systems, ensuring they are safe and beneficial, while global solutions seek to implement safety measures for all AI systems across various jurisdictions.[145] AI safety governance research ranges from foundational investigations into the potential impacts of AI to specific applications. On the foundational side, researchers have argued that AI could transform many aspects of society due to its broad applicability, comparing it to electricity and the steam engine.[146] Some work has focused on anticipating specific risks that may arise from these impacts – for example, risks from mass unemployment,[147] weaponization,[148] disinformation,[149] surveillance,[150] and the concentration of power.[151] Other work explores underlying risk factors such as the difficulty of monitoring the rapidly evolving AI industry,[152] the availability of AI models,[153] and 'race to the bottom' dynamics.[140][154] Allan Dafoe, the head of longterm governance and strategy at DeepMind has emphasized the dangers of racing and the potential need for cooperation: \"it may be close to a necessary and sufficient condition for AI safety and alignment that there be a high degree of caution prior to deploying advanced powerful systems; however, if actors are competing in a domain with large returns to first-movers or relative advantage, then they will be pressured to choose a sub-optimal level of caution\".[141] A research stream focuses on developing approaches, frameworks, and methods to assess AI accountability, guiding and promoting audits of AI-based systems.[155][156][157] A key challenge for these approaches is a lack of widely accepted standards, and ambiguity about what the methods would require,[158][159] as well as a lack of safety culture in the industry.[160] Efforts to enhance AI safety include frameworks designed to align AI outputs with ethical guidelines and reduce risks like misuse and data leakage. Tools such as Nvidia's Guardrails,[161] Llama Guard,[162] Preamble's customizable guardrails[163] and Claude's Constitution mitigate vulnerabilities like prompt injection and ensure outputs adhere to predefined principles. These frameworks are often integrated into AI systems to improve safety and reliability.[164] Philosophical perspectives [edit]The field of AI safety is deeply intertwined with philosophical considerations, particularly in the realm of ethics. Deontological ethics, which emphasizes adherence to moral rules, has been proposed as a framework for aligning AI systems with human values. Some have suggested that by embedding deontological principles, AI systems can be guided to avoid actions that cause harm, ensuring their operations remain within ethical boundaries,[165] but those suggestions have been questioned, with other alternatives being suggested at more promising.[166] Government action [edit]Some experts have argued that it is too early to regulate AI, expressing concerns that regulations will hamper innovation and it would be foolish to \"rush to regulate in ignorance\".[167][168] Others, such as business magnate Elon Musk, call for pre-emptive action to mitigate catastrophic risks.[169] Outside of formal legislation, government agencies have put forward ethical and safety recommendations. In March 2021, the US National Security Commission on Artificial Intelligence reported that advances in AI may make it increasingly important to \"assure that systems are aligned with goals and values, including safety, robustness and trustworthiness\".[170] Subsequently, the National Institute of Standards and Technology drafted a framework for managing AI Risk, which advises that when \"catastrophic risks are present – development and deployment should cease in a safe manner until risks can be sufficiently managed\".[171] In September 2021, the People's Republic of China (PRC) published ethical guidelines for the use of AI in China, emphasizing that AI decisions should remain under human control and calling for accountability mechanisms. In the same month, The United Kingdom published its 10-year National AI Strategy,[172] which states the British government \"takes the long-term risk of non-aligned Artificial General Intelligence, and the unforeseeable changes that it would mean for ... the world, seriously\".[173] The strategy describes actions to assess long-term AI risks, including catastrophic risks.[173] The British government held first major global summit on AI safety. This took place on the 1st and 2 November 2023 and was described as \"an opportunity for policymakers and world leaders to consider the immediate and future risks of AI and how these risks can be mitigated via a globally coordinated approach\".[174][175] China Media Project stated \"key aspects of its approach remain fundamentally unsafe by the standards of democratic societies worldwide\", arguing that part of China's AI safety approach is focused on strengthening the CCP's information control.[176] Government organizations, particularly in the United States, have also encouraged the development of technical AI safety research. The Intelligence Advanced Research Projects Activity initiated the TrojAI project to identify and protect against Trojan attacks on AI systems.[177] The DARPA engages in research on explainable artificial intelligence and improving robustness against adversarial attacks.[178][179] And the National Science Foundation supports the Center for Trustworthy Machine Learning, and is providing millions of dollars in funding for empirical AI safety research.[180] In 2024, the United Nations General Assembly adopted the first global resolution on the promotion of \"safe, secure and trustworthy\" AI systems that emphasized the respect, protection and promotion of human rights in the design, development, deployment and the use of AI.[181] In May 2024, the Department for Science, Innovation and Technology (DSIT) announced £8.5 million in funding for AI safety research under the Systemic AI Safety Fast Grants Programme, led by Christopher Summerfield and Shahar Avin at the AI Safety Institute, in partnership with UK Research and Innovation. Technology Secretary Michelle Donelan announced the plan at the AI Seoul Summit, stating the goal was to make AI safe across society and that promising proposals could receive further funding. The UK also signed an agreement with 10 other countries and the EU to form an international network of AI safety institutes to promote collaboration and share information and resources. Additionally, the UK AI Safety Institute planned to open an office in San Francisco.[182] Corporate self-regulation [edit]AI labs and companies generally abide by safety practices and norms that fall outside of formal legislation.[183] One aim of governance researchers is to shape these norms. Examples of safety recommendations found in the literature include performing third-party auditing,[184] offering bounties for finding failures,[184] sharing AI incidents[184] (an AI incident database was created for this purpose),[185] following guidelines to determine whether to publish research or models,[153] and improving information and cyber security in AI labs.[186] Companies have also made commitments. Cohere, OpenAI, and AI21 proposed and agreed on \"best practices for deploying language models\", focusing on mitigating misuse.[187] To avoid contributing to racing-dynamics, OpenAI has also stated in their charter that \"if a value-aligned, safety-conscious project comes close to building AGI before we do, we commit to stop competing with and start assisting this project\"[188] Also, industry leaders such as CEO of DeepMind Demis Hassabis, director of Facebook AI Yann LeCun have signed open letters such as the Asilomar Principles[34] and the Autonomous Weapons Open Letter.[189] See also [edit]- AI alignment - Artificial intelligence and elections - Artificial intelligence detection software - Hallucination (artificial intelligence) References [edit]- ^ Ahmed, Shazeda; Jaźwińska, Klaudia; Ahlawat, Archana; Winecoff, Amy; Wang, Mona (2024-04-14). \"Field-building and the epistemic culture of AI safety\". First Monday. doi:10.5210/fm.v29i4.13626. ISSN 1396-0466. - ^ a b c d e f Hendrycks, Dan; Carlini, Nicholas; Schulman, John; Steinhardt, Jacob (2022-06-16). \"Unsolved Problems in ML Safety\". arXiv:2109.13916. {{cite journal}} : Cite journal requires|journal= (help) - ^ Perrigo, Billy (2023-11-02). \"U.K.'s AI Safety Summit Ends With Limited, but Meaningful, Progress\". Time. Retrieved 2024-06-02. - ^ De-Arteaga, Maria (2020-05-13). Machine Learning in High-Stakes Settings: Risks and Opportunities (PhD). Carnegie Mellon University. - ^ Mehrabi, Ninareh; Morstatter, Fred; Saxena, Nripsuta; Lerman, Kristina; Galstyan, Aram (2021). \"A Survey on Bias and Fairness in Machine Learning\". ACM Computing Surveys. 54 (6): 1–35. arXiv:1908.09635. doi:10.1145/3457607. ISSN 0360-0300. S2CID 201666566. Archived from the original on 2022-11-23. Retrieved 2022-11-28. - ^ Feldstein, Steven (2019). The Global Expansion of AI Surveillance (Report). Carnegie Endowment for International Peace. - ^ Barnes, Beth (2021). \"Risks from AI persuasion\". Lesswrong. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ a b c Brundage, Miles; Avin, Shahar; Clark, Jack; Toner, Helen; Eckersley, Peter; Garfinkel, Ben; Dafoe, Allan; Scharre, Paul; Zeitzoff, Thomas; Filar, Bobby; Anderson, Hyrum; Roff, Heather; Allen, Gregory C; Steinhardt, Jacob; Flynn, Carrick (2018-04-30). \"The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\". Apollo-University Of Cambridge Repository, Apollo-University Of Cambridge Repository. Apollo - University of Cambridge Repository. doi:10.17863/cam.22520. S2CID 3385567. Archived from the original on 2022-11-23. Retrieved 2022-11-28. {{cite journal}} : Cite journal requires|journal= (help) - ^ Davies, Pascale (December 26, 2022). \"How NATO is preparing for a new era of AI cyber attacks\". euronews. Retrieved 2024-03-23. - ^ Ahuja, Anjana (February 7, 2024). \"AI's bioterrorism potential should not be ruled out\". Financial Times. Retrieved 2024-03-23. - ^ Carlsmith, Joseph (2022-06-16). \"Is Power-Seeking AI an Existential Risk?\". arXiv:2206.13353. {{cite journal}} : Cite journal requires|journal= (help) - ^ Minardi, Di (16 October 2020). \"The grim fate that could be 'worse than extinction'\". BBC. Retrieved 2024-03-23. - ^ \"AGI Expert Peter Voss Says AI Alignment Problem is Bogus | NextBigFuture.com\". 2023-04-04. Retrieved 2023-07-23. - ^ Dafoe, Allan (2016). \"Yes, We Are Worried About the Existential Risk of Artificial Intelligence\". MIT Technology Review. Archived from the original on 2022-11-28. Retrieved 2022-11-28. - ^ a b Grace, Katja; Salvatier, John; Dafoe, Allan; Zhang, Baobao; Evans, Owain (2018-07-31). \"Viewpoint: When Will AI Exceed Human Performance? Evidence from AI Experts\". Journal of Artificial Intelligence Research. 62: 729–754. arXiv:1705.08807. doi:10.1613/jair.1.11222. ISSN 1076-9757. S2CID 8746462. Archived from the original on 2023-02-10. Retrieved 2022-11-28. - ^ Zhang, Baobao; Anderljung, Markus; Kahn, Lauren; Dreksler, Noemi; Horowitz, Michael C.; Dafoe, Allan (2021-05-05). \"Ethics and Governance of Artificial Intelligence: Evidence from a Survey of Machine Learning Researchers\". Journal of Artificial Intelligence Research. 71. arXiv:2105.02117. doi:10.1613/jair.1.12895. - ^ Stein-Perlman, Zach; Weinstein-Raun, Benjamin; Grace (2022-08-04). \"2022 Expert Survey on Progress in AI\". AI Impacts. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Michael, Julian; Holtzman, Ari; Parrish, Alicia; Mueller, Aaron; Wang, Alex; Chen, Angelica; Madaan, Divyam; Nangia, Nikita; Pang, Richard Yuanzhe; Phang, Jason; Bowman, Samuel R. (2022-08-26). \"What Do NLP Researchers Believe? Results of the NLP Community Metasurvey\". Association for Computational Linguistics. arXiv:2208.12852. - ^ Markoff, John (2013-05-20). \"In 1949, He Imagined an Age of Robots\". The New York Times. ISSN 0362-4331. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Artificial intelligence: A handbook of professionalism. University of Sussex. January 1988. ISBN 978-0-470-21103-8. - ^ Association for the Advancement of Artificial Intelligence. \"AAAI Presidential Panel on Long-Term AI Futures\". Archived from the original on 2022-09-01. Retrieved 2022-11-23. - ^ Yampolskiy, Roman V.; Spellchecker, M. S. (2016-10-25). \"Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures\". arXiv:1610.07997. {{cite journal}} : Cite journal requires|journal= (help) - ^ \"PT-AI 2011 – Philosophy and Theory of Artificial Intelligence (PT-AI 2011)\". Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Yampolskiy, Roman V. (2013), Müller, Vincent C. (ed.), \"Artificial Intelligence Safety Engineering: Why Machine Ethics is a Wrong Approach\", Philosophy and Theory of Artificial Intelligence, Studies in Applied Philosophy, Epistemology and Rational Ethics, vol. 5, Berlin; Heidelberg, Germany: Springer Berlin Heidelberg, pp. 389–396, doi:10.1007/978-3-642-31674-6_29, ISBN 978-3-642-31673-9, archived from the original on 2023-03-15, retrieved 2022-11-23 - ^ McLean, Scott; Read, Gemma J. M.; Thompson, Jason; Baber, Chris; Stanton, Neville A.; Salmon, Paul M. (2023-07-04). \"The risks associated with Artificial General Intelligence: A systematic review\". Journal of Experimental & Theoretical Artificial Intelligence. 35 (5): 649–663. Bibcode:2023JETAI..35..649M. doi:10.1080/0952813X.2021.1964003. hdl:11343/289595. ISSN 0952-813X. S2CID 238643957. - ^ Wile, Rob (August 3, 2014). \"Elon Musk: Artificial Intelligence Is 'Potentially More Dangerous Than Nukes'\". Business Insider. Retrieved 2024-02-22. - ^ Kuo, Kaiser (2015-03-31). Baidu CEO Robin Li interviews Bill Gates and Elon Musk at the Boao Forum, March 29, 2015. Event occurs at 55:49. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Cellan-Jones, Rory (2014-12-02). \"Stephen Hawking warns artificial intelligence could end mankind\". BBC News. Archived from the original on 2015-10-30. Retrieved 2022-11-23. - ^ Future of Life Institute. \"Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter\". Future of Life Institute. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Future of Life Institute (October 2016). \"AI Research Grants Program\". Future of Life Institute. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ \"SafArtInt 2016\". Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Bach, Deborah (2016). \"UW to host first of four White House public workshops on artificial intelligence\". UW News. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Amodei, Dario; Olah, Chris; Steinhardt, Jacob; Christiano, Paul; Schulman, John; Mané, Dan (2016-07-25). \"Concrete Problems in AI Safety\". arXiv:1606.06565. {{cite journal}} : Cite journal requires|journal= (help) - ^ a b Future of Life Institute. \"AI Principles\". Future of Life Institute. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Yohsua, Bengio; Daniel, Privitera; Tamay, Besiroglu; Rishi, Bommasani; Stephen, Casper; Yejin, Choi; Danielle, Goldfarb; Hoda, Heidari; Leila, Khalatbari (May 2024). International Scientific Report on the Safety of Advanced AI (Report). Department for Science, Innovation and Technology. - ^ a b Research, DeepMind Safety (2018-09-27). \"Building safe artificial intelligence: specification, robustness, and assurance\". Medium. Archived from the original on 2023-02-10. Retrieved 2022-11-23. - ^ \"SafeML ICLR 2019 Workshop\". Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Browne, Ryan (2023-06-12). \"British Prime Minister Rishi Sunak pitches UK as home of A.I. safety regulation as London bids to be next Silicon Valley\". CNBC. Retrieved 2023-06-25. - ^ Bertuzzi, Luca (October 18, 2023). \"UK's AI safety summit set to highlight risk of losing human control over 'frontier' models\". Euractiv. Retrieved March 2, 2024. - ^ Bengio, Yoshua; Privitera, Daniel; Bommasani, Rishi; Casper, Stephen; Goldfarb, Danielle; Mavroudis, Vasilios; Khalatbari, Leila; Mazeika, Mantas; Hoda, Heidari (2024-05-17). \"International Scientific Report on the Safety of Advanced AI\" (PDF). GOV.UK. Archived (PDF) from the original on 2024-06-15. Retrieved 2024-07-08. Alt URL - ^ Shepardson, David (1 April 2024). \"US, Britain announce partnership on AI safety, testing\". Retrieved 2 April 2024. - ^ \"What International AI Safety report says on jobs, climate, cyberwar and more\". The Guardian. 2025-01-29. ISSN 0261-3077. Retrieved 2025-03-03. - ^ \"Launch of the First International Report on AI Safety chaired by Yoshua Bengio\". mila.quebec. January 29, 2025. Retrieved 2025-03-03. - ^ Goodfellow, Ian; Papernot, Nicolas; Huang, Sandy; Duan, Rocky; Abbeel, Pieter; Clark, Jack (2017-02-24). \"Attacking Machine Learning with Adversarial Examples\". OpenAI. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ a b Szegedy, Christian; Zaremba, Wojciech; Sutskever, Ilya; Bruna, Joan; Erhan, Dumitru; Goodfellow, Ian; Fergus, Rob (2014-02-19). \"Intriguing properties of neural networks\". ICLR. arXiv:1312.6199. - ^ Kurakin, Alexey; Goodfellow, Ian; Bengio, Samy (2017-02-10). \"Adversarial examples in the physical world\". ICLR. arXiv:1607.02533. - ^ Madry, Aleksander; Makelov, Aleksandar; Schmidt, Ludwig; Tsipras, Dimitris; Vladu, Adrian (2019-09-04). \"Towards Deep Learning Models Resistant to Adversarial Attacks\". ICLR. arXiv:1706.06083. - ^ Kannan, Harini; Kurakin, Alexey; Goodfellow, Ian (2018-03-16). \"Adversarial Logit Pairing\". arXiv:1803.06373. {{cite journal}} : Cite journal requires|journal= (help) - ^ Gilmer, Justin; Adams, Ryan P.; Goodfellow, Ian; Andersen, David; Dahl, George E. (2018-07-19). \"Motivating the Rules of the Game for Adversarial Example Research\". arXiv:1807.06732. {{cite journal}} : Cite journal requires|journal= (help) - ^ Carlini, Nicholas; Wagner, David (2018-03-29). \"Audio Adversarial Examples: Targeted Attacks on Speech-to-Text\". IEEE Security and Privacy Workshops. arXiv:1801.01944. - ^ Sheatsley, Ryan; Papernot, Nicolas; Weisman, Michael; Verma, Gunjan; McDaniel, Patrick (2022-09-09). \"Adversarial Examples in Constrained Domains\". arXiv:2011.01183. {{cite journal}} : Cite journal requires|journal= (help) - ^ Suciu, Octavian; Coull, Scott E.; Johns, Jeffrey (2019-04-13). \"Exploring Adversarial Examples in Malware Detection\". IEEE Security and Privacy Workshops. arXiv:1810.08280. - ^ Ouyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll L.; Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex; Schulman, John; Hilton, Jacob; Kelton, Fraser; Miller, Luke; Simens, Maddie (2022-03-04). \"Training language models to follow instructions with human feedback\". NeurIPS. arXiv:2203.02155. - ^ Gao, Leo; Schulman, John; Hilton, Jacob (2022-10-19). \"Scaling Laws for Reward Model Overoptimization\". ICML. arXiv:2210.10760. - ^ Yu, Sihyun; Ahn, Sungsoo; Song, Le; Shin, Jinwoo (2021-10-27). \"RoMA: Robust Model Adaptation for Offline Model-based Optimization\". NeurIPS. arXiv:2110.14188. - ^ a b Hendrycks, Dan; Mazeika, Mantas (2022-09-20). \"X-Risk Analysis for AI Research\". arXiv:2206.05862. {{cite journal}} : Cite journal requires|journal= (help) - ^ a b \"Prompt injection attacks might 'never be properly mitigated' UK NCSC warns\". TechRadar. 2025-12-09. Retrieved 2025-12-12. - ^ \"Why Anthropic and OpenAI are obsessed with securing LLM model weights\". VentureBeat. 2023-12-15. - ^ \"The rise of AI fake news is creating a 'misinformation superspreader'\". The Washington Post. 2023-12-17. ISSN 0190-8286. Retrieved 2025-12-12. - ^ Tran, Khoa A.; Kondrashova, Olga; Bradley, Andrew; Williams, Elizabeth D.; Pearson, John V.; Waddell, Nicola (2021). \"Deep learning in cancer diagnosis, prognosis and treatment selection\". Genome Medicine. 13 (1): 152. doi:10.1186/s13073-021-00968-x. ISSN 1756-994X. PMC 8477474. PMID 34579788. - ^ Guo, Chuan; Pleiss, Geoff; Sun, Yu; Weinberger, Kilian Q. (2017-08-06). \"On calibration of modern neural networks\". Proceedings of the 34th international conference on machine learning. Proceedings of machine learning research. Vol. 70. PMLR. pp. 1321–1330. - ^ Ovadia, Yaniv; Fertig, Emily; Ren, Jie; Nado, Zachary; Sculley, D.; Nowozin, Sebastian; Dillon, Joshua V.; Lakshminarayanan, Balaji; Snoek, Jasper (2019-12-17). \"Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift\". NeurIPS. arXiv:1906.02530. - ^ Bogdoll, Daniel; Breitenstein, Jasmin; Heidecker, Florian; Bieshaar, Maarten; Sick, Bernhard; Fingscheidt, Tim; Zöllner, J. Marius (2021). \"Description of Corner Cases in Automated Driving: Goals and Challenges\". 2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW). pp. 1023–1028. arXiv:2109.09607. doi:10.1109/ICCVW54120.2021.00119. ISBN 978-1-6654-0191-3. S2CID 237572375. - ^ Hendrycks, Dan; Mazeika, Mantas; Dietterich, Thomas (2019-01-28). \"Deep Anomaly Detection with Outlier Exposure\". ICLR. arXiv:1812.04606. - ^ Wang, Haoqi; Li, Zhizhong; Feng, Litong; Zhang, Wayne (2022-03-21). \"ViM: Out-Of-Distribution with Virtual-logit Matching\". CVPR. arXiv:2203.10807. - ^ Hendrycks, Dan; Gimpel, Kevin (2018-10-03). \"A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks\". ICLR. arXiv:1610.02136. - ^ Urbina, Fabio; Lentzos, Filippa; Invernizzi, Cédric; Ekins, Sean (2022). \"Dual use of artificial-intelligence-powered drug discovery\". Nature Machine Intelligence. 4 (3): 189–191. doi:10.1038/s42256-022-00465-9. ISSN 2522-5839. PMC 9544280. PMID 36211133. - ^ Center for Security and Emerging Technology; Buchanan, Ben; Lohn, Andrew; Musser, Micah; Sedova, Katerina (2021). \"Truth, Lies, and Automation: How Language Models Could Change Disinformation\". doi:10.51593/2021ca003. S2CID 240522878. Archived from the original on 2022-11-24. Retrieved 2022-11-28. {{cite journal}} : Cite journal requires|journal= (help) - ^ \"Propaganda-as-a-service may be on the horizon if large language models are abused\". VentureBeat. 2021-12-14. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Center for Security and Emerging Technology; Buchanan, Ben; Bansemer, John; Cary, Dakota; Lucas, Jack; Musser, Micah (2020). \"Automating Cyber Attacks: Hype and Reality\". Center for Security and Emerging Technology. doi:10.51593/2020ca002. S2CID 234623943. Archived from the original on 2022-11-24. Retrieved 2022-11-28. - ^ \"Lessons Learned on Language Model Safety and Misuse\". OpenAI. 2022-03-03. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Markov, Todor; Zhang, Chong; Agarwal, Sandhini; Eloundou, Tyna; Lee, Teddy; Adler, Steven; Jiang, Angela; Weng, Lilian (2022-08-10). \"New-and-Improved Content Moderation Tooling\". OpenAI. Archived from the original on 2023-01-11. Retrieved 2022-11-24. - ^ a b Savage, Neil (2022-03-29). \"Breaking into the black box of artificial intelligence\". Nature. doi:10.1038/d41586-022-00858-1. PMID 35352042. S2CID 247792459. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Center for Security and Emerging Technology; Rudner, Tim; Toner, Helen (2021). \"Key Concepts in AI Safety: Interpretability in Machine Learning\". CSET Issue Brief. doi:10.51593/20190042. S2CID 233775541. Archived from the original on 2022-11-24. Retrieved 2022-11-28. - ^ McFarland, Matt (2018-03-19). \"Uber pulls self-driving cars after first fatal crash of autonomous vehicle\". CNNMoney. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Felder, Ryan Marshall (July 2021). \"Coming to Terms with the Black Box Problem: How to Justify AI Systems in Health Care\". Hastings Center Report. 51 (4): 38–45. doi:10.1002/hast.1248. ISSN 0093-0334. PMID 33821471. - ^ a b Doshi-Velez, Finale; Kortz, Mason; Budish, Ryan; Bavitz, Chris; Gershman, Sam; O'Brien, David; Scott, Kate; Schieber, Stuart; Waldo, James; Weinberger, David; Weller, Adrian; Wood, Alexandra (2019-12-20). \"Accountability of AI Under the Law: The Role of Explanation\". arXiv:1711.01134. {{cite journal}} : Cite journal requires|journal= (help) - ^ Fong, Ruth; Vedaldi, Andrea (2017). \"Interpretable Explanations of Black Boxes by Meaningful Perturbation\". 2017 IEEE International Conference on Computer Vision (ICCV). pp. 3449–3457. arXiv:1704.03296. doi:10.1109/ICCV.2017.371. ISBN 978-1-5386-1032-9. S2CID 1633753. - ^ Meng, Kevin; Bau, David; Andonian, Alex; Belinkov, Yonatan (2022). \"Locating and editing factual associations in GPT\". Advances in Neural Information Processing Systems. 35. arXiv:2202.05262. - ^ Bau, David; Liu, Steven; Wang, Tongzhou; Zhu, Jun-Yan; Torralba, Antonio (2020-07-30). \"Rewriting a Deep Generative Model\". ECCV. arXiv:2007.15646. - ^ Räuker, Tilman; Ho, Anson; Casper, Stephen; Hadfield-Menell, Dylan (2022-09-05). \"Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks\". IEEE SaTML. arXiv:2207.13243. - ^ Bau, David; Zhou, Bolei; Khosla, Aditya; Oliva, Aude; Torralba, Antonio (2017-04-19). \"Network Dissection: Quantifying Interpretability of Deep Visual Representations\". CVPR. arXiv:1704.05796. - ^ McGrath, Thomas; Kapishnikov, Andrei; Tomašev, Nenad; Pearce, Adam; Wattenberg, Martin; Hassabis, Demis; Kim, Been; Paquet, Ulrich; Kramnik, Vladimir (2022-11-22). \"Acquisition of chess knowledge in AlphaZero\". Proceedings of the National Academy of Sciences. 119 (47) e2206625119. arXiv:2111.09259. Bibcode:2022PNAS..11906625M. doi:10.1073/pnas.2206625119. ISSN 0027-8424. PMC 9704706. PMID 36375061. - ^ Goh, Gabriel; Cammarata, Nick; Voss, Chelsea; Carter, Shan; Petrov, Michael; Schubert, Ludwig; Radford, Alec; Olah, Chris (2021). \"Multimodal neurons in artificial neural networks\". Distill. 6 (3). doi:10.23915/distill.00030. S2CID 233823418. - ^ Olah, Chris; Cammarata, Nick; Schubert, Ludwig; Goh, Gabriel; Petrov, Michael; Carter, Shan (2020). \"Zoom in: An introduction to circuits\". Distill. 5 (3). doi:10.23915/distill.00024.001. S2CID 215930358. - ^ Cammarata, Nick; Goh, Gabriel; Carter, Shan; Voss, Chelsea; Schubert, Ludwig; Olah, Chris (2021). \"Curve circuits\". Distill. 6 (1). doi:10.23915/distill.00024.006 (inactive 1 July 2025). Archived from the original on 5 December 2022. Retrieved 5 December 2022. {{cite journal}} : CS1 maint: DOI inactive as of July 2025 (link) - ^ Olsson, Catherine; Elhage, Nelson; Nanda, Neel; Joseph, Nicholas; DasSarma, Nova; Henighan, Tom; Mann, Ben; Askell, Amanda; Bai, Yuntao; Chen, Anna; Conerly, Tom; Drain, Dawn; Ganguli, Deep; Hatfield-Dodds, Zac; Hernandez, Danny; Johnston, Scott; Jones, Andy; Kernion, Jackson; Lovitt, Liane; Ndousse, Kamal; Amodei, Dario; Brown, Tom; Clark, Jack; Kaplan, Jared; McCandlish, Sam; Olah, Chris (2022). \"In-context learning and induction heads\". Transformer Circuits Thread. arXiv:2209.11895. - ^ Olah, Christopher. \"Interpretability vs Neuroscience [rough note]\". Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Gu, Tianyu; Dolan-Gavitt, Brendan; Garg, Siddharth (2019-03-11). \"BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain\". arXiv:1708.06733. {{cite journal}} : Cite journal requires|journal= (help) - ^ Chen, Xinyun; Liu, Chang; Li, Bo; Lu, Kimberly; Song, Dawn (2017-12-14). \"Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning\". arXiv:1712.05526. {{cite journal}} : Cite journal requires|journal= (help) - ^ Carlini, Nicholas; Terzis, Andreas (2022-03-28). \"Poisoning and Backdooring Contrastive Learning\". ICLR. arXiv:2106.09667. - ^ \"How 'sleeper agent' AI assistants can sabotage code\". The Register. 16 January 2024. Archived from the original on 2024-12-24. Retrieved 2025-01-12. - ^ a b c d Russell, Stuart J.; Norvig, Peter (2021). Artificial intelligence: A modern approach (4th ed.). Pearson. pp. 5, 1003. ISBN 978-0-13-461099-3. Retrieved September 12, 2022. - ^ a b Ngo, Richard; Chan, Lawrence; Mindermann, Sören (2022). \"The Alignment Problem from a Deep Learning Perspective\". International Conference on Learning Representations. arXiv:2209.00626. - ^ a b Pan, Alexander; Bhatia, Kush; Steinhardt, Jacob (2022-02-14). The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models. International Conference on Learning Representations. Retrieved 2022-07-21. - ^ Carlsmith, Joseph (2022-06-16). \"Is Power-Seeking AI an Existential Risk?\". arXiv:2206.13353 [cs.CY]. - ^ a b c Russell, Stuart J. (2020). Human compatible: Artificial intelligence and the problem of control. Penguin Random House. ISBN 978-0-525-55863-7. OCLC 1113410915. - ^ Christian, Brian (2020). The alignment problem: Machine learning and human values. W. W. Norton & Company. ISBN 978-0-393-86833-3. OCLC 1233266753. Archived from the original on February 10, 2023. Retrieved September 12, 2022. - ^ Langosco, Lauro Langosco Di; Koch, Jack; Sharkey, Lee D.; Pfau, Jacob; Krueger, David (2022-06-28). \"Goal Misgeneralization in Deep Reinforcement Learning\". Proceedings of the 39th International Conference on Machine Learning. International Conference on Machine Learning. PMLR. pp. 12004–12019. Retrieved 2023-03-11. - ^ Pillay, Tharin (2024-12-15). \"New Tests Reveal AI's Capacity for Deception\". TIME. Retrieved 2025-01-12. - ^ Perrigo, Billy (2024-12-18). \"Exclusive: New Research Shows AI Strategically Lying\". TIME. Retrieved 2025-01-12. - ^ a b Bommasani, Rishi; Hudson, Drew A.; Adeli, Ehsan; Altman, Russ; Arora, Simran; von Arx, Sydney; Bernstein, Michael S.; Bohg, Jeannette; Bosselut, Antoine; Brunskill, Emma; Brynjolfsson, Erik (2022-07-12). \"On the Opportunities and Risks of Foundation Models\". Stanford CRFM. arXiv:2108.07258. - ^ Ouyang, Long; et al. (2022). \"Training language models to follow instructions with human feedback\" (PDF). NeurIPS. arXiv:2203.02155. - ^ Zaremba, Wojciech; Brockman, Greg; OpenAI (2021-08-10). \"OpenAI Codex\". OpenAI. Archived from the original on February 3, 2023. Retrieved 2022-07-23. - ^ Kober, Jens; Bagnell, J. Andrew; Peters, Jan (2013-09-01). \"Reinforcement learning in robotics: A survey\". The International Journal of Robotics Research. 32 (11): 1238–1274. doi:10.1177/0278364913495721. ISSN 0278-3649. S2CID 1932843. Archived from the original on October 15, 2022. Retrieved September 12, 2022. - ^ Knox, W. Bradley; Allievi, Alessandro; Banzhaf, Holger; Schmitt, Felix; Stone, Peter (2023-03-01). \"Reward (Mis)design for autonomous driving\". Artificial Intelligence. 316 103829. arXiv:2104.13906. doi:10.1016/j.artint.2022.103829. ISSN 0004-3702. S2CID 233423198. - ^ Stray, Jonathan (2020). \"Aligning AI Optimization to Community Well-Being\". International Journal of Community Well-Being. 3 (4): 443–463. doi:10.1007/s42413-020-00086-3. ISSN 2524-5295. PMC 7610010. PMID 34723107. S2CID 226254676. - ^ Russell, Stuart; Norvig, Peter (2009). Artificial Intelligence: A Modern Approach. Prentice Hall. p. 1003. ISBN 978-0-13-461099-3. - ^ Smith, Craig S. \"Geoff Hinton, AI's Most Famous Researcher, Warns Of 'Existential Threat'\". Forbes. Retrieved 2023-05-04. - ^ Bengio, Yoshua; Hinton, Geoffrey; Yao, Andrew; Song, Dawn; Abbeel, Pieter; Harari, Yuval Noah; Zhang, Ya-Qin; Xue, Lan; Shalev-Shwartz, Shai (2024). \"Managing extreme AI risks amid rapid progress\". Science. 384 (6698): 842–845. arXiv:2310.17688. Bibcode:2024Sci...384..842B. doi:10.1126/science.adn0117. PMID 38768279. - ^ \"Statement on AI Risk | CAIS\". www.safe.ai. Retrieved 2024-02-11. - ^ Grace, Katja; Stewart, Harlan; Sandkühler, Julia Fabienne; Thomas, Stephen; Weinstein-Raun, Ben; Brauner, Jan (2025). \"Thousands of AI Authors on the Future of AI\". Journal of Artificial Intelligence Research. 84. arXiv:2401.02843. doi:10.1613/jair.1.19087. - ^ Perrigo, Billy (2024-02-13). \"Meta's AI Chief Yann LeCun on AGI, Open-Source, and AI Risk\". TIME. Retrieved 2024-06-26. - ^ \"What is AI alignment?\". TechTarget. 2023-05-03. Retrieved 2025-06-28. - ^ Ahmed, Shazeda; Jaźwińska, Klaudia; Ahlawat, Archana; Winecoff, Amy; Wang, Mona (2024-04-14). \"Field-building and the epistemic culture of AI safety\". First Monday. doi:10.5210/fm.v29i4.13626. ISSN 1396-0466. - ^ a b Ortega, Pedro A.; Maini, Vishal; DeepMind safety team (2018-09-27). \"Building safe artificial intelligence: specification, robustness, and assurance\". DeepMind Safety Research – Medium. Archived from the original on February 10, 2023. Retrieved 2022-07-18. - ^ a b Rorvig, Mordechai (2022-04-14). \"Researchers Gain New Understanding From Simple AI\". Quanta Magazine. Archived from the original on February 10, 2023. Retrieved 2022-07-18. - ^ Doshi-Velez, Finale; Kim, Been (2017-03-02). \"Towards A Rigorous Science of Interpretable Machine Learning\". arXiv:1702.08608 [stat.ML]. - Wiblin, Robert (August 4, 2021). \"Chris Olah on what the hell is going on inside neural networks\" (Podcast). 80,000 hours. No. 107. Retrieved 2022-07-23. - ^ a b Amodei, Dario; Olah, Chris; Steinhardt, Jacob; Christiano, Paul; Schulman, John; Mané, Dan (2016-06-21). \"Concrete Problems in AI Safety\". arXiv:1606.06565 [cs.AI]. - ^ Russell, Stuart; Dewey, Daniel; Tegmark, Max (2015-12-31). \"Research Priorities for Robust and Beneficial Artificial Intelligence\". AI Magazine. 36 (4): 105–114. arXiv:1602.03506. doi:10.1609/aimag.v36i4.2577. hdl:1721.1/108478. ISSN 2371-9621. S2CID 8174496. Archived from the original on February 2, 2023. Retrieved September 12, 2022. - ^ Wirth, Christian; Akrour, Riad; Neumann, Gerhard; Fürnkranz, Johannes (2017). \"A survey of preference-based reinforcement learning methods\". Journal of Machine Learning Research. 18 (136): 1–46. - ^ Christiano, Paul F.; Leike, Jan; Brown, Tom B.; Martic, Miljan; Legg, Shane; Amodei, Dario (2017). \"Deep reinforcement learning from human preferences\". Proceedings of the 31st International Conference on Neural Information Processing Systems. NIPS'17. Red Hook, NY, USA: Curran Associates Inc. pp. 4302–4310. ISBN 978-1-5108-6096-4. - ^ Heaven, Will Douglas (2022-01-27). \"The new version of GPT-3 is much better behaved (and should be less toxic)\". MIT Technology Review. Archived from the original on February 10, 2023. Retrieved 2022-07-18. - ^ Mohseni, Sina; Wang, Haotao; Yu, Zhiding; Xiao, Chaowei; Wang, Zhangyang; Yadawa, Jay (2022-03-07). \"Taxonomy of Machine Learning Safety: A Survey and Primer\". ACM Computing Surveys. 55 (8): 1–38. doi:10.1145/3551385. - ^ Clifton, Jesse (2020). \"Cooperation, Conflict, and Transformative Artificial Intelligence: A Research Agenda\". Center on Long-Term Risk. Archived from the original on January 1, 2023. Retrieved 2022-07-18. - Dafoe, Allan; Bachrach, Yoram; Hadfield, Gillian; Horvitz, Eric; Larson, Kate; Graepel, Thore (2021-05-06). \"Cooperative AI: machines must learn to find common ground\". Nature. 593 (7857): 33–36. Bibcode:2021Natur.593...33D. doi:10.1038/d41586-021-01170-0. ISSN 0028-0836. PMID 33947992. S2CID 233740521. Archived from the original on December 18, 2022. Retrieved September 12, 2022. - ^ Prunkl, Carina; Whittlestone, Jess (2020-02-07). \"Beyond Near- and Long-Term\". Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. New York NY USA: ACM. pp. 138–143. doi:10.1145/3375627.3375803. ISBN 978-1-4503-7110-0. S2CID 210164673. Archived from the original on October 16, 2022. Retrieved September 12, 2022. - ^ Irving, Geoffrey; Askell, Amanda (2019-02-19). \"AI Safety Needs Social Scientists\". Distill. 4 (2) 10.23915/distill.00014. doi:10.23915/distill.00014. ISSN 2476-0757. S2CID 159180422. Archived from the original on February 10, 2023. Retrieved September 12, 2022. - ^ Gazos, Alexandros; Kahn, James; Kusche, Isabel; Büscher, Christian; Götz, Markus (2025-04-01). \"Organising AI for safety: Identifying structural vulnerabilities to guide the design of AI-enhanced socio-technical systems\". Safety Science. 184 106731. doi:10.1016/j.ssci.2024.106731. ISSN 0925-7535. - ^ a b c d Zwetsloot, Remco; Dafoe, Allan (2019-02-11). \"Thinking About Risks From AI: Accidents, Misuse and Structure\". Lawfare. Archived from the original on 2023-08-19. Retrieved 2022-11-24. - ^ Zhang, Yingyu; Dong, Chuntong; Guo, Weiqun; Dai, Jiabao; Zhao, Ziming (2022). \"Systems theoretic accident model and process (STAMP): A literature review\". Safety Science. 152 105596. doi:10.1016/j.ssci.2021.105596. S2CID 244550153. Archived from the original on 2023-03-15. Retrieved 2022-11-28. - ^ a b Gazos, Alexandros; Kahn, James; Kusche, Isabel; Büscher, Christian; Götz, Markus (2025-04-01). \"Organising AI for safety: Identifying structural vulnerabilities to guide the design of AI-enhanced socio-technical systems\". Safety Science. 184 106731. doi:10.1016/j.ssci.2024.106731. ISSN 0925-7535. - ^ Center for Security and Emerging Technology; Hoffman, Wyatt (2021). \"AI and the Future of Cyber Competition\". CSET Issue Brief. doi:10.51593/2020ca007. S2CID 234245812. Archived from the original on 2022-11-24. Retrieved 2022-11-28. - ^ Gafni, Ruti; Levy, Yair (2024-01-01). \"The role of artificial intelligence (AI) in improving technical and managerial cybersecurity tasks' efficiency\". Information & Computer Security. 32 (5): 711–728. doi:10.1108/ICS-04-2024-0102. ISSN 2056-4961. - ^ Center for Security and Emerging Technology; Imbrie, Andrew; Kania, Elsa (2019). \"AI Safety, Security, and Stability Among Great Powers: Options, Challenges, and Lessons Learned for Pragmatic Engagement\". doi:10.51593/20190051. S2CID 240957952. Archived from the original on 2022-11-24. Retrieved 2022-11-28. {{cite journal}} : Cite journal requires|journal= (help) - ^ a b Future of Life Institute (2019-03-27). AI Strategy, Policy, and Governance (Allan Dafoe). Event occurs at 22:05. Archived from the original on 2022-11-23. Retrieved 2022-11-23. - ^ Zou, Andy; Xiao, Tristan; Jia, Ryan; Kwon, Joe; Mazeika, Mantas; Li, Richard; Song, Dawn; Steinhardt, Jacob; Evans, Owain; Hendrycks, Dan (2022-10-09). \"Forecasting Future World Events with Neural Networks\". NeurIPS. arXiv:2206.15474. - ^ Gathani, Sneha; Hulsebos, Madelon; Gale, James; Haas, Peter J.; Demiralp, Çağatay (2022-02-08). \"Augmenting Decision Making via Interactive What-If Analysis\". Conference on Innovative Data Systems Research. arXiv:2109.06160. - ^ Lindelauf, Roy (2021), Osinga, Frans; Sweijs, Tim (eds.), \"Nuclear Deterrence in the Algorithmic Age: Game Theory Revisited\", NL ARMS Netherlands Annual Review of Military Studies 2020, Nl Arms, The Hague: T.M.C. Asser Press, pp. 421–436, doi:10.1007/978-94-6265-419-8_22, ISBN 978-94-6265-418-1, S2CID 229449677 - ^ a b Newkirk II, Vann R. (2016-04-21). \"Is Climate Change a Prisoner's Dilemma or a Stag Hunt?\". The Atlantic. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ a b Armstrong, Stuart; Bostrom, Nick; Shulman, Carl. Racing to the Precipice: a Model of Artificial Intelligence Development (Report). Future of Humanity Institute, Oxford University. - ^ a b Dafoe, Allan. AI Governance: A Research Agenda (Report). Centre for the Governance of AI, Future of Humanity Institute, University of Oxford. - ^ Dafoe, Allan; Hughes, Edward; Bachrach, Yoram; Collins, Tantum; McKee, Kevin R.; Leibo, Joel Z.; Larson, Kate; Graepel, Thore (2020-12-15). \"Open Problems in Cooperative AI\". NeurIPS. arXiv:2012.08630. - ^ a b Dafoe, Allan; Bachrach, Yoram; Hadfield, Gillian; Horvitz, Eric; Larson, Kate; Graepel, Thore (2021). \"Cooperative AI: machines must learn to find common ground\". Nature. 593 (7857): 33–36. Bibcode:2021Natur.593...33D. doi:10.1038/d41586-021-01170-0. PMID 33947992. S2CID 233740521. Archived from the original on 2022-11-22. Retrieved 2022-11-24. - ^ Satariano, Adam; Specia, Megan (2023-11-01). \"Global Leaders Warn A.I. Could Cause 'Catastrophic' Harm\". The New York Times. ISSN 0362-4331. Retrieved 2024-04-20. - ^ Turchin, Alexey; Dench, David; Green, Brian Patrick (2019). \"Global Solutions vs. Local Solutions for the AI Safety Problem\". Big Data and Cognitive Computing. 3 (16): 1–25. doi:10.3390/bdcc3010016. - ^ Crafts, Nicholas (2021-09-23). \"Artificial intelligence as a general-purpose technology: an historical perspective\". Oxford Review of Economic Policy. 37 (3): 521–536. doi:10.1093/oxrep/grab012. ISSN 0266-903X. Archived from the original on 2022-11-24. Retrieved 2022-11-28. - ^ 葉俶禎; 黃子君; 張媁雯; 賴志樫 (2020-12-01). \"Labor Displacement in Artificial Intelligence Era: A Systematic Literature Review\". 臺灣東亞文明研究學刊. 17 (2). doi:10.6163/TJEAS.202012_17(2).0002. ISSN 1812-6243. - ^ Johnson, James (2019-04-03). \"Artificial intelligence & future warfare: implications for international security\". Defense & Security Analysis. 35 (2): 147–169. doi:10.1080/14751798.2019.1600800. ISSN 1475-1798. S2CID 159321626. Archived from the original on 2022-11-24. Retrieved 2022-11-28. - ^ Kertysova, Katarina (2018-12-12). \"Artificial Intelligence and Disinformation: How AI Changes the Way Disinformation is Produced, Disseminated, and Can Be Countered\". Security and Human Rights. 29 (1–4): 55–81. doi:10.1163/18750230-02901005. ISSN 1874-7337. S2CID 216896677. - ^ Feldstein, Steven (2019). The Global Expansion of AI Surveillance. Carnegie Endowment for International Peace. - ^ Agrawal, Ajay; Gans, Joshua; Goldfarb, Avi (2019). The economics of artificial intelligence: an agenda. Chicago, Illinois. ISBN 978-0-226-61347-5. OCLC 1099435014. {{cite book}} : CS1 maint: location missing publisher (link) - ^ Whittlestone, Jess; Clark, Jack (2021-08-31). \"Why and How Governments Should Monitor AI Development\". arXiv:2108.12427. {{cite journal}} : Cite journal requires|journal= (help) - ^ a b Shevlane, Toby (2022). \"Sharing Powerful AI Models | GovAI Blog\". Center for the Governance of AI. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Askell, Amanda; Brundage, Miles; Hadfield, Gillian (2019-07-10). \"The Role of Cooperation in Responsible AI Development\". arXiv:1907.04534. {{cite journal}} : Cite journal requires|journal= (help) - ^ Gursoy, Furkan; Kakadiaris, Ioannis A. (2022-08-31), System Cards for AI-Based Decision-Making for Public Policy, arXiv:2203.04754 - ^ Cobbe, Jennifer; Lee, Michelle Seng Ah; Singh, Jatinder (2021-03-01). \"Reviewable Automated Decision-Making: A Framework for Accountable Algorithmic Systems\". Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT '21. New York, NY, USA: Association for Computing Machinery. pp. 598–609. doi:10.1145/3442188.3445921. ISBN 978-1-4503-8309-7. - ^ Raji, Inioluwa Deborah; Smart, Andrew; White, Rebecca N.; Mitchell, Margaret; Gebru, Timnit; Hutchinson, Ben; Smith-Loud, Jamila; Theron, Daniel; Barnes, Parker (2020-01-27). \"Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing\". Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. FAT* '20. New York, NY, USA: Association for Computing Machinery. pp. 33–44. doi:10.1145/3351095.3372873. ISBN 978-1-4503-6936-7. - ^ Manheim, David; Martin, Sammy; Bailey, Mark; Samin, Mikhail; Greutzmacher, Ross (2025). \"The necessity of AI audit standards boards\". AI & Society. 40 (8): 6609–6624. arXiv:2404.13060. doi:10.1007/s00146-025-02320-y. - ^ Novelli, Claudio; Taddeo, Mariarosaria; Floridi, Luciano (2024). \"Accountability in artificial intelligence: what it is and how it works\". AI & Society. 39 (4): 1871–1882. doi:10.1007/s00146-023-01635-y. hdl:11585/914099. - ^ Manheim, David (26 June 2023). \"Building a Culture of Safety for AI: Perspectives and Challenges\". SSRN 4491421. - ^ \"NeMo Guardrails\". NVIDIA NeMo Guardrails. Retrieved 2024-12-08. - ^ \"Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations\". Meta AI. Retrieved 2024-12-08. - ^ Šekrst, Kristina; McHugh, Jeremy; Cefalu, Jonathan Rodriguez (2024). \"AI Ethics by Design: Implementing Customizable Guardrails for Responsible AI Development\". arXiv:2411.14442 [cs.CY]. - ^ Dong, Yi; Mu, Ronghui; Jin, Gaojie; Qi, Yi; Hu, Jinwei; Zhao, Xingyu; Meng, Jie; Ruan, Wenjie; Huang, Xiaowei (2024). \"Building Guardrails for Large Language Models\". arXiv:2402.01822 [cs]. - ^ D'Alessandro, W. (2024). \"Deontology and safe artificial intelligence\". Philosophical Studies. 182 (7): 1681–1704. doi:10.1007/s11098-024-02174-y. - ^ D'Alessandro, William; Kirk-Giannini, Chad D. (2025). \"Artificial Intelligence: Approaches to Safety\". Philosophy Compass. 20 (5) e70039. doi:10.1111/phc3.70039. - ^ Ziegler, Bart (8 April 2022). \"Is It Time to Regulate AI?\". Wall Street Journal. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Reed, Chris (2018-09-13). \"How should we regulate artificial intelligence?\". Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences. 376 (2128) 20170360. Bibcode:2018RSPTA.37670360R. doi:10.1098/rsta.2017.0360. ISSN 1364-503X. PMC 6107539. PMID 30082306. - ^ Belton, Keith B. (2019-03-07). \"How Should AI Be Regulated?\". IndustryWeek. Archived from the original on 2022-01-29. Retrieved 2022-11-24. - ^ National Security Commission on Artificial Intelligence (2021), Final Report - ^ National Institute of Standards and Technology (2021-07-12). \"AI Risk Management Framework\". NIST. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Richardson, Tim (2021). \"Britain publishes 10-year National Artificial Intelligence Strategy\". Archived from the original on 2023-02-10. Retrieved 2022-11-24. - ^ a b \"Guidance: National AI Strategy\". GOV.UK. 2021. Archived from the original on 2023-02-10. Retrieved 2022-11-24. - ^ Hardcastle, Kimberley (2023-08-23). \"We're talking about AI a lot right now – and it's not a moment too soon\". The Conversation. Retrieved 2023-10-31. - ^ \"Iconic Bletchley Park to host UK AI Safety Summit in early November\". GOV.UK. Retrieved 2023-10-31. - ^ Colville, Alex (2025-07-30). \"How China Sees AI Safety\". China Media Project. Retrieved 2025-08-09. - ^ Office of the Director of National Intelligence, Intelligence Advanced Research Projects Activity. \"IARPA – TrojAI\". Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Turek, Matt. \"Explainable Artificial Intelligence\". Archived from the original on 2021-02-19. Retrieved 2022-11-24. - ^ Draper, Bruce. \"Guaranteeing AI Robustness Against Deception\". Defense Advanced Research Projects Agency. Archived from the original on 2023-01-09. Retrieved 2022-11-24. - ^ National Science Foundation (23 February 2023). \"Safe Learning-Enabled Systems\". Archived from the original on 2023-02-26. Retrieved 2023-02-27. - ^ \"General Assembly adopts landmark resolution on artificial intelligence\". UN News. 21 March 2024. Archived from the original on 20 April 2024. Retrieved 21 April 2024. - ^ Say, Mark (23 May 2024). \"DSIT announces funding for research on AI safety\". Archived from the original on 24 May 2024. Retrieved 11 June 2024. - ^ Mäntymäki, Matti; Minkkinen, Matti; Birkstedt, Teemu; Viljanen, Mika (2022). \"Defining organizational AI governance\". AI and Ethics. 2 (4): 603–609. doi:10.1007/s43681-022-00143-x. ISSN 2730-5953. S2CID 247119668. - ^ a b c Brundage, Miles; Avin, Shahar; Wang, Jasmine; Belfield, Haydn; Krueger, Gretchen; Hadfield, Gillian; Khlaaf, Heidy; Yang, Jingying; Toner, Helen; Fong, Ruth; Maharaj, Tegan; Koh, Pang Wei; Hooker, Sara; Leung, Jade; Trask, Andrew (2020-04-20). \"Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims\". arXiv:2004.07213. {{cite journal}} : Cite journal requires|journal= (help) - ^ \"Welcome to the Artificial Intelligence Incident Database\". Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ Wiblin, Robert; Harris, Keiran (2022). \"Nova DasSarma on why information security may be critical to the safe development of AI systems\". 80,000 Hours. Archived from the original on 2022-11-24. Retrieved 2022-11-24. - ^ OpenAI (2022-06-02). \"Best Practices for Deploying Language Models\". OpenAI. Archived from the original on 2023-03-15. Retrieved 2022-11-24. - ^ OpenAI. \"OpenAI Charter\". OpenAI. Archived from the original on 2021-03-04. Retrieved 2022-11-24. - ^ Future of Life Institute (2016). \"Autonomous Weapons Open Letter: AI & Robotics Researchers\". Future of Life Institute. Retrieved 2022-11-24.",
    "text_length": 70109,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:39.835079"
  },
  {
    "id": "page_9",
    "url": "https://en.wikipedia.org/wiki/Machine_learning",
    "domain": "en.wikipedia.org",
    "title": "Machine learning - Wikipedia",
    "text": "Machine learning | Part of a series on | | Machine learning and data mining | |---| | Part of a series on | | Artificial intelligence (AI) | |---| Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.[1] Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance. ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics. Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.[3][4] From a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimisation under this framework. History [edit]The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[5][6] The synonym self-teaching computers was also used during this time period.[7][8] The earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.[9] In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells.[10] Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.[9] Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.[9] By the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions.[11] A representative book on research into machine learning during the 1960s was Nils Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[12] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[13] In 1981, a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[14] Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"[15] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question, \"Can machines think?\", is replaced with the question, \"Can machines do what we (as thinking entities) can do?\".[16] Modern-day Machine Learning algorithms are broken into 3 algorithm types: Supervised Learning Algorithms, Unsupervised Learning Algorithms, and Reinforcement Learning Algorithms.[17] - Current Supervised Learning Algorithms have objectives of classification and regression. - Current Unsupervised Learning Algorithms have objectives of clustering, dimensionality reduction, and association rule. - Current Reinforcement Learning Algorithms focus on decisions that must be made with respect to some previous, unknown time and are broken down to either be studies of model-based methods or model-free methods. In 2014 Ian Goodfellow and others introduced generative adversarial networks (GANs) with realistic data synthesis.[18] By 2016 AlphaGo obtained victory against top human players using reinforcement learning techniques.[19] Relationships to other fields [edit]Artificial intelligence [edit]As a scientific endeavour, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalised linear models of statistics.[21] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[22]: 488 However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[22]: 488 By 1980, expert systems had come to dominate AI, and statistics was out of favour.[23] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming(ILP), but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[22]: 708–710, 755 Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines, including John Hopfield, David Rumelhart, and Geoffrey Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[22]: 25 Machine learning (ML), reorganised and recognised as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.[23] Data compression [edit]There is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for \"general intelligence\".[24][25][26] An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.[27] According to AIXI theory, a connection more directly explained in Hutter Prize, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form. Examples of AI-powered audio/video compression software include NVIDIA Maxine, AIVC.[28] Examples of software that can perform AI-powered image compression include OpenCV, TensorFlow, MATLAB's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.[29] In unsupervised machine learning, k-means clustering can be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression.[30] Data compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the centroid of its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in image and signal processing, k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.[31] Large language models (LLMs) are also efficient lossless data compressors on some data sets, as demonstrated by DeepMind's research with the Chinchilla 70B model. Developed by DeepMind, Chinchilla 70B effectively compressed data, outperforming conventional methods such as Portable Network Graphics (PNG) for images and Free Lossless Audio Codec (FLAC) for audio. It achieved compression of image and audio data to 43.4% and 16.4% of their original sizes, respectively. There is, however, some reason to be concerned that the data set used for testing overlaps the LLM training data set, making it possible that the Chinchilla 70B model is only an efficient compression tool on data it has already been trained on.[32][33] Data mining [edit]Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.[citation needed] Machine learning also has intimate ties to optimisation: Many learning problems are formulated as minimisation of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples).[34] Generalization [edit]Characterizing the generalisation of various learning algorithms is an active topic of current research, especially for deep learning algorithms. Statistics [edit]Machine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalisable predictive patterns.[35] Conventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.[36] Leo Breiman distinguished two statistical modelling paradigms: data model and algorithmic model,[37] wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest. Some statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[38] Statistical physics [edit]Analytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyse the weight space of deep neural networks.[39] Statistical physics is thus finding applications in the area of medical diagnostics.[40] Theory [edit]A core objective of a learner is to generalise from its experience.[2][41] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases. The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalisation error. For the best performance in the context of generalisation, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has underfitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalisation will be poorer.[42] In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time. Approaches [edit] Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system: - Supervised learning: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs. - Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning). - Reinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximise.[2] Although each algorithm has advantages and limitations, no single algorithm works for all problems.[43][44][45] Supervised learning [edit]Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.[46] The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimisation of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.[47] An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.[15] Types of supervised-learning algorithms include active learning, classification and regression.[48] Classification algorithms are used when the outputs are restricted to a limited set of values, while regression algorithms are used when the outputs can take any numerical value within a range. For example, in a classification algorithm that filters emails, the input is an incoming email, and the output is the folder in which to file the email. In contrast, regression is used for tasks such as predicting a person's height based on factors like age and genetics or forecasting future temperatures based on historical data.[49] Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification. Unsupervised learning [edit]Unsupervised learning algorithms find structures in data that has not been labelled, classified or categorised. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction,[4] and density estimation.[50] Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity. A special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.[51][52] Dimensionality reduction [edit]Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables.[53] In other words, it is a process of reducing the dimension of the feature set, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D). The manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the areas of manifold learning and manifold regularisation. Semi-supervised learning [edit]Semi-supervised learning falls between unsupervised learning (without any labelled training data) and supervised learning (with completely labelled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabelled data, when used in conjunction with a small amount of labelled data, can produce a considerable improvement in learning accuracy. In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.[54] Reinforcement learning [edit]Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment to maximise some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcement learning algorithms use dynamic programming techniques.[55] Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent. Other types [edit]Other approaches have been developed which do not fit neatly into this three-fold categorisation, and sometimes more than one is used by the same machine learning system. For example, topic modelling, meta-learning.[56] Self-learning [edit]Self-learning, as a machine learning paradigm, was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA).[57][58] It gives a solution to the problem learning without any external reward, by introducing emotion as an internal reward. Emotion is used as a state evaluation of a self-learning agent. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.[59] The self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine: - in situation s act a - receive a consequence situation s' - compute emotion of being in the consequence situation v(s') - update crossbar memory w'(a,s) = w(a,s) + v(s') It is a system with only one input, situation, and only one output, action (or behaviour) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioural environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behaviour in an environment that contains both desirable and undesirable situations.[60] Feature learning [edit]Several learning algorithms aim at discovering better representations of the inputs provided during training.[61] Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task. Feature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labelled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabelled input data. Examples include dictionary learning, independent component analysis, autoencoders, matrix factorisation[62] and various forms of clustering.[63][64][65] Manifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors.[66] Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine learns a representation that disentangles the underlying factors of variation that explain the observed data.[67] Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data have not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms. Sparse dictionary learning [edit]Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately.[68] A popular heuristic method for sparse dictionary learning is the k-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image denoising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[69] Anomaly detection [edit]In data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations that raise suspicions by differing significantly from the majority of the data.[70] Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.[71] In particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.[72] Three broad categories of anomaly detection techniques exist.[73] Unsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance being generated by the model. Robot learning [edit]Robot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,[74][75] and finally meta-learning (e.g. MAML). Association rules [edit]Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".[76] Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[77] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems. Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[78] For example, the rule found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions. Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner to make predictions.[79] Inductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs. Inductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[80][81][82] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[83] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set. Models [edit]A machine learning model is a type of mathematical model that, once \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions.[84] By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.[85] Various types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection. Artificial neural networks [edit]Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules. An ANN is a model based on a collection of connected units or nodes called \"artificial neurons\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times. The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis. Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[86] Decision trees [edit]Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making. Random forest regression [edit]Random forest regression (RFR) falls under the umbrella of decision tree-based models. RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting. To build decision trees, RFR uses bootstrapped sampling; for instance, each decision tree is trained on random data from the training set. This random selection of RFR for training enables the model to reduce biased predictions and achieve a higher degree of accuracy. RFR generates independent decision trees, and it can work on single-output data as well as multiple regressor tasks. This makes RFR compatible to be use in various applications.[87][88] Support-vector machines [edit]Support-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.[89] An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces. Regression analysis [edit]Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularisation methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel[90]), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space. Multivariate linear regression extends the concept of linear regression to handle multiple dependent variables simultaneously. This approach estimates the relationships between a set of input variables and several output variables by fitting a multidimensional linear model. It is particularly useful in scenarios where outputs are interdependent or share underlying patterns, such as predicting multiple economic indicators or reconstructing images,[91] which are inherently multi-dimensional. Bayesian networks [edit]A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams. Gaussian processes [edit]A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations. Given a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as a function of its input data can be directly computed by looking at the observed points and the covariances between those points and the new, unobserved point. Gaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation. Genetic algorithms [edit]A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.[93][94] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[95] Belief functions [edit]The theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g., Dempster's rule of combination), just like how in a pmf-based Bayesian approach would combine probabilities.[96] However, there are many caveats to these beliefs functions when compared to Bayesian approaches to incorporate ignorance and uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.[97][6] However, the computational complexity of these algorithms is dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches. Rule-based models [edit]Rule-based machine learning (RBML) is a branch of machine learning that automatically discovers and learns 'rules' from data. It provides interpretable models, making it useful for decision-making in fields like healthcare, fraud detection, and cybersecurity. Key RBML techniques includes learning classifier systems,[98] association rule learning,[99] artificial immune systems,[100] and other similar models. These methods extract patterns from data and evolve rules over time. Training models [edit]Typically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and, notably, becoming integrated within machine learning engineering teams. Federated learning [edit]Federated learning is an adapted form of distributed artificial intelligence to train machine learning models that decentralises the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralised server. This also increases efficiency by decentralising the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.[101] Applications [edit]There are many applications for machine learning, including: - Agriculture - Anatomy - Adaptive website - Affective computing - Astronomy - Automated decision-making - Banking - Behaviorism - Bioinformatics - Brain–machine interfaces - Cheminformatics - Citizen Science - Climate Science - Computer networks - Computer vision - Credit-card fraud detection - Data quality - DNA sequence classification - Economics - Financial data analysis[102] - General game playing - Handwriting recognition - Healthcare - Information retrieval - Insurance - Internet fraud detection - Investment management[103] - Knowledge graph embedding - Linguistics - Machine learning control - Machine perception - Machine translation - Material Engineering - Marketing - Medical diagnosis - Natural language processing - Natural language understanding - Online advertising - Optimisation - Recommender systems - Robot locomotion - Search engines - Sentiment analysis - Sequence mining - Software engineering - Speech recognition - Structural health monitoring - Syntactic pattern recognition - Telecommunications - Theorem proving - Time-series forecasting - Tomographic reconstruction[104] - User behaviour analytics In 2006, the media-services provider Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.[105] Shortly after the prize was awarded, Netflix realised that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.[106] In 2010, an article in The Wall Street Journal noted the use of machine learning by Rebellion Research to predict the 2008 financial crisis.[107] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[108] In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists.[109] In 2019 Springer Nature published the first research book created using machine learning.[110] In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.[111] Machine learning was recently applied to predict the pro-environmental behaviour of travellers.[112] Recently, machine learning technology was also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.[113][114][115] When applied correctly, machine learning algorithms (MLAs) can utilise a wide range of company characteristics to predict stock returns without overfitting. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS.[116] Recent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.[117] Machine Learning is becoming a useful tool to investigate and predict evacuation decision-making in large-scale and small-scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.[118][119][120] Other applications have been focusing on pre evacuation decisions in building fires.[121][122] Limitations [edit]Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.[123][124][125] Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.[126] The \"black box theory\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted from the data.[127] The House of Lords Select Committee, which claimed that such an \"intelligence system\" that could have a \"substantial impact on an individual's life\" would not be considered acceptable unless it provided \"a full and satisfactory explanation for the decisions\" it makes.[127] In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.[128] Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.[129][130] Microsoft's Bing Chat chatbot has been reported to produce hostile and offensive response against its users.[131] Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research itself.[132] Explainability [edit]Explainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.[133] It contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.[134] By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation. Overfitting [edit]Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is.[135] Other limitations and vulnerabilities [edit]Learners can also be disappointed by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.[136] A real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.[137][138] Adversarial vulnerabilities can also result in nonlinear systems or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.[139] Machine learning models are often vulnerable to manipulation or evasion via adversarial machine learning.[140] Researchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories \"spam\" and \"not spam\" of posts) machine learning models that are often developed or trained by third parties. Parties can change the classification of any input, including in cases for which a type of data/software transparency is provided, possibly including white-box access.[141][142][143] Model assessments [edit]Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data into a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.[144] In addition to overall accuracy, investigators frequently report sensitivity and specificity, meaning true positive rate (TPR) and true negative rate (TNR), respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. Receiver operating characteristic (ROC), along with the accompanying Area Under the ROC Curve (AUC), offer additional tools for classification model assessment. Higher AUC is associated with a better performing model.[145] Ethics [edit] The ethics of artificial intelligence covers a broad range of topics within AI that are considered to have particular ethical stakes.[146] This includes algorithmic biases, fairness, accountability, transparency, privacy, and regulation, particularly where systems influence or automate human decision-making. It also covers various emerging or potential future challenges such as machine ethics (how to make machines that behave ethically), lethal autonomous weapon systems, arms race dynamics, AI safety and alignment, technological unemployment, AI-enabled misinformation,[147] how to treat certain AI systems if they have a moral status (AI welfare and rights), artificial superintelligence and existential risks.[146] Some application areas may also have particularly important ethical implications, like healthcare, education, criminal justice, or the military. Bias [edit]Different machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.[148] Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices.[149] For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to either be women or have non-European-sounding names.[148] Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.[150][151] Another example includes predictive policing company Geolitica's predictive algorithm that resulted in \"disproportionately high levels of over-policing in low-income and minority communities\" after being trained with historical crime data.[152] While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame the lack of participation and representation of minority populations in the field of AI for machine learning's vulnerability to biases.[153] In fact, according to research carried out by the Computing Research Association in 2021, \"female faculty make up just 16.1%\" of all faculty members who focus on AI among several universities around the world.[154] Furthermore, among the group of \"new U.S. resident AI PhD graduates,\" 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.[154] Language models learned from data have been shown to contain human-like biases.[155][156] Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.[157][158] In 2016, Microsoft tested Tay, a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.[159] In an experiment carried out by ProPublica, an investigative journalism organisation, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants\".[152] In 2015, Google Photos once tagged a couple of black people as gorillas, which caused controversy. The gorilla label was subsequently removed, and in 2023, it still cannot recognise gorillas.[160] Similar issues with recognising non-white people have been found in many other systems.[161] Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.[162] Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who said that \"[t]here's nothing artificial about AI. It's inspired by people, it's created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"[163] Financial incentives [edit]There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States, where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals with an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.[164] Hardware [edit]Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.[165] By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.[166] OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.[167][168] Tensor Processing Units (TPUs) [edit]Tensor Processing Units (TPUs) are specialised hardware accelerators developed by Google specifically for machine learning workloads. Unlike general-purpose GPUs and FPGAs, TPUs are optimised for tensor computations, making them particularly efficient for deep learning tasks such as training and inference. They are widely used in Google Cloud AI services and large-scale machine learning models like Google's DeepMind AlphaFold and large language models. TPUs leverage matrix multiplication units and high-bandwidth memory to accelerate computations while maintaining energy efficiency.[169] Since their introduction in 2016, TPUs have become a key component of AI infrastructure, especially in cloud-based environments. Neuromorphic computing [edit]Neuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks. These systems may be implemented through software-based simulations on conventional hardware or through specialised hardware architectures.[170] Physical neural networks [edit]A physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials, such as memristors, to emulate the function of neural synapses. The term \"physical neural network\" highlights the use of physical hardware for computation, as opposed to software-based implementations. It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses.[171][172] Embedded machine learning [edit]Embedded machine learning is a sub-field of machine learning where models are deployed on embedded systems with limited computing resources, such as wearable computers, edge devices and microcontrollers.[173][174][175][176] Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing, thereby reducing the risk of data breaches, privacy leaks and theft of intellectual property, personal data and business secrets. Embedded machine learning can be achieved through various techniques, such as hardware acceleration,[177][178] approximate computing,[179] and model optimisation.[180][181] Common optimisation techniques include pruning, quantisation, knowledge distillation, low-rank factorisation, network architecture search, and parameter sharing. Software [edit]Software suites containing a variety of machine learning algorithms include the following: Free and open-source software [edit]- Caffe - Deeplearning4j - DeepSpeed - ELKI - Google JAX - Infer.NET - JASP - Jubatus - Keras - Kubeflow - LightGBM - Mahout - Mallet - Microsoft Cognitive Toolkit - ML.NET - mlpack - MXNet - OpenNN - Orange - pandas (software) - ROOT (TMVA with ROOT) - scikit-learn - Shogun - Spark MLlib - SystemML - Theano - TensorFlow - Torch / PyTorch - Weka / MOA - XGBoost - Yooreeka Proprietary software with free and open-source editions [edit]Proprietary software [edit]- Amazon Machine Learning - Angoss KnowledgeSTUDIO - Azure Machine Learning - IBM Watson Studio - Google Cloud Vertex AI - Google Prediction API - IBM SPSS Modeller - KXEN Modeller - LIONsolver - Mathematica - MATLAB - Neural Designer - NeuroSolutions - Oracle Data Mining - Oracle AI Platform Cloud Service - PolyAnalyst - RCASE - SAS Enterprise Miner - SequenceL - Splunk - STATISTICA Data Miner Journals [edit]- Journal of Machine Learning Research - Machine Learning - Nature Machine Intelligence - Neural Computation - IEEE Transactions on Pattern Analysis and Machine Intelligence Conferences [edit]- AAAI Conference on Artificial Intelligence - Association for Computational Linguistics (ACL) - European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) - International Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (CIBB) - International Conference on Machine Learning (ICML) - International Conference on Learning Representations (ICLR) - International Conference on Intelligent Robots and Systems (IROS) - Conference on Knowledge Discovery and Data Mining (KDD) - Conference on Neural Information Processing Systems (NeurIPS) See also [edit]- Automated machine learning – Process of automating the application of machine learning - Big data – Extremely large or complex datasets - Deep learning — branch of ML concerned with artificial neural networks - Differentiable programming – Programming paradigm - List of datasets for machine-learning research - List of machine learning algorithms and List of algorithms for machine learning and statistical classification - M-theory (learning framework) – Framework in machine learning - Machine unlearning – Field of study in artificial intelligence - Outline of machine learning - Solomonoff's theory of inductive inference – Mathematical theory References [edit]- ^ The definition \"without being explicitly programmed\" is often attributed to Arthur Samuel, who coined the term \"machine learning\" in 1959, but the phrase is not found verbatim in this publication, and may be a paraphrase that appeared later. Confer \"Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?\" in Koza, John R.; Bennett, Forrest H.; Andre, David; Keane, Martin A. (1996). \"Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming\". Artificial Intelligence in Design '96. Artificial Intelligence in Design '96. Dordrecht, Netherlands: Springer Netherlands. pp. 151–170. doi:10.1007/978-94-009-0279-4_9. ISBN 978-94-010-6610-5. - ^ a b c Bishop, C. M. (2006), Pattern Recognition and Machine Learning, Springer, ISBN 978-0-387-31073-2 - ^ Machine learning and pattern recognition \"can be viewed as two facets of the same field\".[2]: vii - ^ a b Friedman, Jerome H. (1998). \"Data Mining and Statistics: What's the connection?\". Computing Science and Statistics. 29 (1): 3–9. - ^ Samuel, Arthur (1959). \"Some Studies in Machine Learning Using the Game of Checkers\". IBM Journal of Research and Development. 3 (3): 210–229. CiteSeerX 10.1.1.368.2254. doi:10.1147/rd.33.0210. S2CID 2126705. - ^ a b R. Kohavi and F. Provost, \"Glossary of terms\", Machine Learning, vol. 30, no. 2–3, pp. 271–274, 1998. - ^ Gerovitch, Slava (9 April 2015). \"How the Computer Got Its Revenge on the Soviet Union\". Nautilus. Archived from the original on 22 September 2021. Retrieved 19 September 2021. - ^ Lindsay, Richard P. (1 September 1964). \"The Impact of Automation On Public Administration\". Western Political Quarterly. 17 (3): 78–81. doi:10.1177/106591296401700364. ISSN 0043-4078. S2CID 154021253. Archived from the original on 6 October 2021. Retrieved 6 October 2021. - ^ a b c \"History and Evolution of Machine Learning: A Timeline\". WhatIs. Archived from the original on 8 December 2023. Retrieved 8 December 2023. - ^ Milner, Peter M. (1993). \"The Mind and Donald O. Hebb\". Scientific American. 268 (1): 124–129. Bibcode:1993SciAm.268a.124M. doi:10.1038/scientificamerican0193-124. ISSN 0036-8733. JSTOR 24941344. PMID 8418480. - ^ \"Science: The Goof Button\", Time, 18 August 1961. - ^ Nilsson, Nils J. (1965). Learning Machines. McGraw-Hill. - ^ Duda, R., Hart P. Pattern Recognition and Scene Analysis, Wiley Interscience, 1973 - ^ S. Bozinovski, \"Teaching space: A representation concept for adaptive pattern classification\" COINS Technical Report No. 81-28, Computer and Information Science Department, University of Massachusetts at Amherst, MA, 1981. https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf Archived 25 February 2021 at the Wayback Machine - ^ a b Mitchell, T. (1997). Machine Learning. McGraw Hill. p. 2. ISBN 978-0-07-042807-2. - ^ Harnad, Stevan (2008), \"The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence\", in Epstein, Robert; Peters, Grace (eds.), The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer, Kluwer, pp. 23–66, ISBN 978-1-4020-6708-2, archived from the original on 9 March 2012, retrieved 11 December 2012 - ^ \"Machine Learning Algorithms\". GeeksforGeeks. 17 August 2023. Retrieved 3 September 2025. - ^ Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi (2014). Generative adversarial nets (PDF). Advances in Neural Information Processing Systems 27 (2014). - ^ Silver, David; Huang, Aja; Maddison, Christopher J. (2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. PMID 26819042. - ^ Sindhu V, Nivedha S, Prakash M (February 2020). \"An Empirical Science Research on Bioinformatics in Machine Learning\". Journal of Mechanics of Continua and Mathematical Sciences (7). doi:10.26782/jmcms.spl.7/2020.02.00006. - ^ Sarle, Warren S. (1994). \"Neural Networks and statistical models\". SUGI 19: proceedings of the Nineteenth Annual SAS Users Group International Conference. SAS Institute. pp. 1538–50. ISBN 978-1-55544-611-6. OCLC 35546178. - ^ a b c d Russell, Stuart; Norvig, Peter (2003) [1995]. Artificial Intelligence: A Modern Approach (2nd ed.). Prentice Hall. ISBN 978-0137903955. - ^ a b Langley, Pat (2011). \"The changing science of machine learning\". Machine Learning. 82 (3): 275–9. doi:10.1007/s10994-011-5242-y. - ^ Mahoney, Matt. \"Rationale for a Large Text Compression Benchmark\". Florida Institute of Technology. Archived from the original on 18 August 2006. Retrieved 5 March 2013. - ^ Shmilovici A.; Kahiri Y.; Ben-Gal I.; Hauser S. (2009). \"Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm\" (PDF). Computational Economics. 33 (2): 131–154. CiteSeerX 10.1.1.627.3751. doi:10.1007/s10614-008-9153-3. S2CID 17234503. Archived (PDF) from the original on 9 July 2009. - ^ Ben-Gal, I. (2008). \"On the Use of Data Compression Measures to Analyze Robust Designs\" (PDF). IEEE Transactions on Reliability. 54 (3): 381–388. doi:10.1109/TR.2005.853280. S2CID 9376086. Archived from the original (PDF) on 26 September 2020. Retrieved 6 April 2016. - ^ D. Scully; Carla E. Brodley (2006). \"Compression and Machine Learning: A New Perspective on Feature Space Vectors\". Data Compression Conference (DCC'06). p. 332. doi:10.1109/DCC.2006.13. ISBN 0-7695-2545-8. S2CID 12311412. - ^ Gary Adcock (5 January 2023). \"What Is AI Video Compression?\". massive.io. Retrieved 6 April 2023. - ^ Mentzer, Fabian; Toderici, George; Tschannen, Michael; Agustsson, Eirikur (2020). \"High-Fidelity Generative Image Compression\". arXiv:2006.09965 [eess.IV]. - ^ \"What is Unsupervised Learning? | IBM\". www.ibm.com. 23 September 2021. Retrieved 5 February 2024. - ^ \"Differentially private clustering for large-scale datasets\". blog.research.google. 25 May 2023. Retrieved 16 March 2024. - ^ Edwards, Benj (28 September 2023). \"AI language models can exceed PNG and FLAC in lossless compression, says study\". Ars Technica. Retrieved 7 March 2024. - ^ Delétang, Grégoire; Ruoss, Anian; Duquenne, Paul-Ambroise; Catt, Elliot; Genewein, Tim; Mattern, Christopher; Grau-Moya, Jordi; Li Kevin Wenliang; Aitchison, Matthew; Orseau, Laurent; Hutter, Marcus; Veness, Joel (2023). \"Language Modeling is Compression\". arXiv:2309.10668 [cs.LG]. - ^ Le Roux, Nicolas; Bengio, Yoshua; Fitzgibbon, Andrew (2012). \"Improving First and Second-Order Methods by Modeling Uncertainty\". In Sra, Suvrit; Nowozin, Sebastian; Wright, Stephen J. (eds.). Optimization for Machine Learning. MIT Press. p. 404. ISBN 978-0-262-01646-9. Archived from the original on 17 January 2023. Retrieved 12 November 2020. - ^ Bzdok, Danilo; Altman, Naomi; Krzywinski, Martin (2018). \"Statistics versus Machine Learning\". Nature Methods. 15 (4): 233–234. doi:10.1038/nmeth.4642. PMC 6082636. PMID 30100822. - ^ Hung et al. Algorithms to Measure Surgeon Performance and Anticipate Clinical Outcomes in Robotic Surgery. JAMA Surg. 2018 - ^ Cornell University Library (August 2001). \"Breiman: Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)\". Statistical Science. 16 (3). doi:10.1214/ss/1009213726. S2CID 62729017. Archived from the original on 26 June 2017. Retrieved 8 August 2015. - ^ Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). An Introduction to Statistical Learning. Springer. p. vii. Archived from the original on 23 June 2019. Retrieved 25 October 2014. - ^ Ramezanpour, A.; Beam, A.L.; Chen, J.H.; Mashaghi, A. (17 November 2020). \"Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\". Diagnostics. 10 (11): 972. doi:10.3390/diagnostics10110972. PMC 7699346. PMID 33228143. - ^ Mashaghi, A.; Ramezanpour, A. (16 March 2018). \"Statistical physics of medical diagnostics: Study of a probabilistic model\". Physical Review E. 97 (3–1) 032118. arXiv:1803.10019. Bibcode:2018PhRvE..97c2118M. doi:10.1103/PhysRevE.97.032118. PMID 29776109. S2CID 4955393. - ^ Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. US, Massachusetts: MIT Press. ISBN 9780262018258. - ^ Alpaydin, Ethem (2010). Introduction to Machine Learning. London: The MIT Press. ISBN 978-0-262-01243-0. Retrieved 4 February 2017. - ^ Jordan, M. I.; Mitchell, T. M. (17 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255–260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID 26185243. S2CID 677218. - ^ El Naqa, Issam; Murphy, Martin J. (2015). \"What is Machine Learning?\". Machine Learning in Radiation Oncology. pp. 3–11. doi:10.1007/978-3-319-18305-3_1. ISBN 978-3-319-18304-6. S2CID 178586107. - ^ Okolie, Jude A.; Savage, Shauna; Ogbaga, Chukwuma C.; Gunes, Burcu (June 2022). \"Assessing the potential of machine learning methods to study the removal of pharmaceuticals from wastewater using biochar or activated carbon\". Total Environment Research Themes. 1–2 100001. Bibcode:2022TERT....100001O. doi:10.1016/j.totert.2022.100001. S2CID 249022386. - ^ Russell, Stuart J.; Norvig, Peter (2010). Artificial Intelligence: A Modern Approach (Third ed.). Prentice Hall. ISBN 978-0-13-604259-4. - ^ Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. The MIT Press. ISBN 978-0-262-01825-8. - ^ Alpaydin, Ethem (2010). Introduction to Machine Learning. MIT Press. p. 9. ISBN 978-0-262-01243-0. Archived from the original on 17 January 2023. Retrieved 25 November 2018. - ^ De Sa, Christopher (Spring 2022). \"Lecture 2 Notes: Supervised Learning\". Cornell: Computer Science. Retrieved 1 July 2024. - ^ Jordan, Michael I.; Bishop, Christopher M. (2004). \"Neural Networks\". In Allen B. Tucker (ed.). Computer Science Handbook, Second Edition (Section VII: Intelligent Systems). Boca Raton, Florida: Chapman & Hall/CRC Press LLC. ISBN 978-1-58488-360-9. - ^ Misra, Ishan; Maaten, Laurens van der (2020). Self-Supervised Learning of Pretext-Invariant Representations. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Seattle, WA, US: IEEE. pp. 6707–6717. arXiv:1912.01991. doi:10.1109/CVPR42600.2020.00674. - ^ Jaiswal, Ashish; Babu, Ashwin Ramesh; Zadeh, Mohammad Zaki; Banerjee, Debapriya; Makedon, Fillia (March 2021). \"A Survey on Contrastive Self-Supervised Learning\". Technologies. 9 (1): 2. arXiv:2011.00362. doi:10.3390/technologies9010002. ISSN 2227-7080. - ^ Roweis, Sam T.; Saul, Lawrence K. (22 December 2000). \"Nonlinear Dimensionality Reduction by Locally Linear Embedding\". Science. 290 (5500): 2323–2326. Bibcode:2000Sci...290.2323R. doi:10.1126/science.290.5500.2323. PMID 11125150. S2CID 5987139. Archived from the original on 15 August 2021. Retrieved 17 July 2023. - ^ Alex Ratner; Stephen Bach; Paroma Varma; Chris. \"Weak Supervision: The New Programming Paradigm for Machine Learning\". hazyresearch.github.io. referencing work by many other members of Hazy Research. Archived from the original on 6 June 2019. Retrieved 6 June 2019. - ^ van Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol. 12. pp. 3–42. doi:10.1007/978-3-642-27645-3_1. ISBN 978-3-642-27644-6. - ^ Pavel Brazdil; Christophe Giraud Carrier; Carlos Soares; Ricardo Vilalta (2009). Metalearning: Applications to Data Mining (Fourth ed.). Springer Science+Business Media. pp. 10–14, passim. ISBN 978-3-540-73262-4. - ^ Bozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397–402. ISBN 978-0-444-86488-8. - ^ Bozinovski, S. (1999) \"Crossbar Adaptive Array: The first connectionist network that solved the delayed reinforcement learning problem\" In A. Dobnikar, N. Steele, D. Pearson, R. Albert (eds.) Artificial Neural Networks and Genetic Algorithms, Springer Verlag, p. 320–325, ISBN 3-211-83364-1 - ^ Bozinovski, Stevo (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255–263 - ^ Bozinovski, S. (2001) \"Self-learning agents: A connectionist theory of emotion based on crossbar value judgment.\" Cybernetics and Systems 32(6) 637–667. - ^ Y. Bengio; A. Courville; P. Vincent (2013). \"Representation Learning: A Review and New Perspectives\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798–1828. arXiv:1206.5538. Bibcode:2013ITPAM..35.1798B. doi:10.1109/tpami.2013.50. PMID 23787338. S2CID 393948. - ^ Nathan Srebro; Jason D. M. Rennie; Tommi S. Jaakkola (2004). Maximum-Margin Matrix Factorization. NIPS. - ^ Coates, Adam; Lee, Honglak; Ng, Andrew Y. (2011). An analysis of single-layer networks in unsupervised feature learning (PDF). Int'l Conf. on AI and Statistics (AISTATS). Archived from the original (PDF) on 13 August 2017. Retrieved 25 November 2018. - ^ Csurka, Gabriella; Dance, Christopher C.; Fan, Lixin; Willamowski, Jutta; Bray, Cédric (2004). Visual categorization with bags of keypoints (PDF). ECCV Workshop on Statistical Learning in Computer Vision. Archived (PDF) from the original on 13 July 2019. Retrieved 29 August 2019. - ^ Daniel Jurafsky; James H. Martin (2009). Speech and Language Processing. Pearson Education International. pp. 145–146. - ^ Lu, Haiping; Plataniotis, K.N.; Venetsanopoulos, A.N. (2011). \"A Survey of Multilinear Subspace Learning for Tensor Data\" (PDF). Pattern Recognition. 44 (7): 1540–1551. Bibcode:2011PatRe..44.1540L. doi:10.1016/j.patcog.2011.01.004. Archived (PDF) from the original on 10 July 2019. Retrieved 4 September 2015. - ^ Yoshua Bengio (2009). Learning Deep Architectures for AI. Now Publishers Inc. pp. 1–3. ISBN 978-1-60198-294-0. Archived from the original on 17 January 2023. Retrieved 15 February 2016. - ^ Tillmann, A. M. (2015). \"On the Computational Intractability of Exact and Approximate Dictionary Learning\". IEEE Signal Processing Letters. 22 (1): 45–49. arXiv:1405.6664. Bibcode:2015ISPL...22...45T. doi:10.1109/LSP.2014.2345761. S2CID 13342762. - ^ Aharon, M, M Elad, and A Bruckstein. 2006. \"K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation Archived 2018-11-23 at the Wayback Machine.\" Signal Processing, IEEE Transactions on 54 (11): 4311–4322 - ^ Zimek, Arthur; Schubert, Erich (2017), \"Outlier Detection\", Encyclopedia of Database Systems, Springer New York, pp. 1–5, doi:10.1007/978-1-4899-7993-3_80719-1, ISBN 978-1-4899-7993-3 - ^ Hodge, V. J.; Austin, J. (2004). \"A Survey of Outlier Detection Methodologies\" (PDF). Artificial Intelligence Review. 22 (2): 85–126. CiteSeerX 10.1.1.318.4023. doi:10.1007/s10462-004-4304-y. S2CID 59941878. Archived (PDF) from the original on 22 June 2015. Retrieved 25 November 2018. - ^ Dokas, Paul; Ertoz, Levent; Kumar, Vipin; Lazarevic, Aleksandar; Srivastava, Jaideep; Tan, Pang-Ning (2002). \"Data mining for network intrusion detection\" (PDF). Proceedings NSF Workshop on Next Generation Data Mining. Archived (PDF) from the original on 23 September 2015. Retrieved 26 March 2023. - ^ Chandola, V.; Banerjee, A.; Kumar, V. (2009). \"Anomaly detection: A survey\". ACM Computing Surveys. 41 (3): 1–58. doi:10.1145/1541880.1541882. S2CID 207172599. - ^ Fleer, S.; Moringen, A.; Klatzky, R. L.; Ritter, H. (2020). \"Learning efficient haptic shape exploration with a rigid tactile sensor array, S. Fleer, A. Moringen, R. Klatzky, H. Ritter\". PLOS ONE. 15 (1) e0226880. arXiv:1902.07501. doi:10.1371/journal.pone.0226880. PMC 6940144. PMID 31896135. - ^ Moringen, Alexandra; Fleer, Sascha; Walck, Guillaume; Ritter, Helge (2020), Nisky, Ilana; Hartcher-O'Brien, Jess; Wiertlewski, Michaël; Smeets, Jeroen (eds.), \"Attention-Based Robot Learning of Haptic Interaction\", Haptics: Science, Technology, Applications, Lecture Notes in Computer Science, vol. 12272, Cham: Springer International Publishing, pp. 462–470, doi:10.1007/978-3-030-58147-3_51, ISBN 978-3-030-58146-6, S2CID 220069113 - ^ Piatetsky-Shapiro, Gregory (1991), Discovery, analysis, and presentation of strong rules, in Piatetsky-Shapiro, Gregory; and Frawley, William J.; eds., Knowledge Discovery in Databases, AAAI/MIT Press, Cambridge, MA. - ^ Bassel, George W.; Glaab, Enrico; Marquez, Julietta; Holdsworth, Michael J.; Bacardit, Jaume (1 September 2011). \"Functional Network Construction in Arabidopsis Using Rule-Based Machine Learning on Large-Scale Data Sets\". The Plant Cell. 23 (9): 3101–3116. Bibcode:2011PlanC..23.3101B. doi:10.1105/tpc.111.088153. ISSN 1532-298X. PMC 3203449. PMID 21896882. - ^ Agrawal, R.; Imieliński, T.; Swami, A. (1993). \"Mining association rules between sets of items in large databases\". Proceedings of the 1993 ACM SIGMOD international conference on Management of data - SIGMOD '93. p. 207. CiteSeerX 10.1.1.40.6984. doi:10.1145/170035.170072. ISBN 978-0-89791-592-2. S2CID 490415. - ^ Urbanowicz, Ryan J.; Moore, Jason H. (22 September 2009). \"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\". Journal of Artificial Evolution and Applications. 2009: 1–25. doi:10.1155/2009/736398. ISSN 1687-6229. - ^ Plotkin G.D. Automatic Methods of Inductive Inference Archived 22 December 2017 at the Wayback Machine, PhD thesis, University of Edinburgh, 1970. - ^ Shapiro, Ehud Y. Inductive inference of theories from facts Archived 21 August 2021 at the Wayback Machine, Research Report 192, Yale University, Department of Computer Science, 1981. Reprinted in J.-L. Lassez, G. Plotkin (Eds.), Computational Logic, The MIT Press, Cambridge, MA, 1991, pp. 199–254. - ^ Shapiro, Ehud Y. (1983). Algorithmic program debugging. Cambridge, Mass: MIT Press. ISBN 0-262-19218-7 - ^ Shapiro, Ehud Y. \"The model inference system Archived 2023-04-06 at the Wayback Machine.\" Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2. Morgan Kaufmann Publishers Inc., 1981. - ^ Burkov, Andriy (2019). The hundred-page machine learning book. Polen: Andriy Burkov. ISBN 978-1-9995795-0-0. - ^ Russell, Stuart J.; Norvig, Peter (2021). Artificial intelligence: a modern approach. Pearson series in artificial intelligence (Fourth ed.). Hoboken: Pearson. ISBN 978-0-13-461099-3. - ^ Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng. \"Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations Archived 2017-10-18 at the Wayback Machine\" Proceedings of the 26th Annual International Conference on Machine Learning, 2009. - ^ \"RandomForestRegressor\". scikit-learn. Retrieved 12 February 2025. - ^ \"What Is Random Forest? | IBM\". www.ibm.com. 20 October 2021. Retrieved 12 February 2025. - ^ Cortes, Corinna; Vapnik, Vladimir N. (1995). \"Support-vector networks\". Machine Learning. 20 (3): 273–297. doi:10.1007/BF00994018. - ^ Stevenson, Christopher. \"Tutorial: Polynomial Regression in Excel\". facultystaff.richmond.edu. Archived from the original on 2 June 2013. Retrieved 22 January 2017. - ^ Wanta, Damian; Smolik, Aleksander; Smolik, Waldemar T.; Midura, Mateusz; Wróblewski, Przemysław (2025). \"Image reconstruction using machine-learned pseudoinverse in electrical capacitance tomography\". Engineering Applications of Artificial Intelligence. 142 109888. doi:10.1016/j.engappai.2024.109888. - ^ The documentation for scikit-learn also has similar examples Archived 2 November 2022 at the Wayback Machine. - ^ Goldberg, David E.; Holland, John H. (1988). \"Genetic algorithms and machine learning\" (PDF). Machine Learning. 3 (2): 95–99. doi:10.1007/bf00113892. S2CID 35506513. Archived (PDF) from the original on 16 May 2011. Retrieved 3 September 2019. - ^ Michie, D.; Spiegelhalter, D. J.; Taylor, C. C. (1994). \"Machine Learning, Neural and Statistical Classification\". Ellis Horwood Series in Artificial Intelligence. Bibcode:1994mlns.book.....M. - ^ Zhang, Jun; Zhan, Zhi-hui; Lin, Ying; Chen, Ni; Gong, Yue-jiao; Zhong, Jing-hui; Chung, Henry S.H.; Li, Yun; Shi, Yu-hui (2011). \"Evolutionary Computation Meets Machine Learning: A Survey\". IEEE Computational Intelligence Magazine. 6 (4): 68–75. Bibcode:2011ICIM....6d..68Z. doi:10.1109/mci.2011.942584. S2CID 6760276. - ^ Verbert, K.; Babuška, R.; De Schutter, B. (1 April 2017). \"Bayesian and Dempster–Shafer reasoning for knowledge-based fault diagnosis–A comparative study\". Engineering Applications of Artificial Intelligence. 60: 136–150. doi:10.1016/j.engappai.2017.01.011. ISSN 0952-1976. - ^ Yoosefzadeh-Najafabadi, Mohsen; Hugh, Earl; Tulpan, Dan; Sulik, John; Eskandari, Milad (2021). \"Application of Machine Learning Algorithms in Plant Breeding: Predicting Yield From Hyperspectral Reflectance in Soybean?\". Front. Plant Sci. 11 624273. Bibcode:2021FrPS...1124273Y. doi:10.3389/fpls.2020.624273. PMC 7835636. PMID 33510761. - ^ Urbanowicz, Ryan J.; Moore, Jason H. (22 September 2009). \"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\". Journal of Artificial Evolution and Applications. 2009: 1–25. doi:10.1155/2009/736398. ISSN 1687-6229. - ^ Zhang, C. and Zhang, S., 2002. Association rule mining: models and algorithms. Springer-Verlag. - ^ De Castro, Leandro Nunes, and Jonathan Timmis. Artificial immune systems: a new computational intelligence approach. Springer Science & Business Media, 2002. - ^ \"Federated Learning: Collaborative Machine Learning without Centralized Training Data\". Google AI Blog. 6 April 2017. Archived from the original on 7 June 2019. Retrieved 8 June 2019. - ^ Machine learning is included in the CFA Curriculum; see: [1] {{Webarchive|url=https://www.cfainstitute.org/ - ^ Marcos M. López de Prado (2010). Machine Learning for Asset Managers. Cambridge University Press. ISBN 9781108883658 - ^ Ivanenko, Mikhail; Smolik, Waldemar T.; Wanta, Damian; Midura, Mateusz; Wróblewski, Przemysław; Hou, Xiaohan; Yan, Xiaoheng (2023). \"Image Reconstruction Using Supervised Learning in Wearable Electrical Impedance Tomography of the Thorax\". Sensors. 23 (18): 7774. Bibcode:2023Senso..23.7774I. doi:10.3390/s23187774. PMC 10538128. PMID 37765831. - ^ \"BelKor Home Page\" research.att.com - ^ \"The Netflix Tech Blog: Netflix Recommendations: Beyond the 5 stars (Part 1)\". 6 April 2012. Archived from the original on 31 May 2016. Retrieved 8 August 2015. - ^ Scott Patterson (13 July 2010). \"Letting the Machines Decide\". The Wall Street Journal. Archived from the original on 24 June 2018. Retrieved 24 June 2018. - ^ Vinod Khosla (10 January 2012). \"Do We Need Doctors or Algorithms?\". Tech Crunch. Archived from the original on 18 June 2018. Retrieved 20 October 2016. - ^ When A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed Archived 4 June 2016 at the Wayback Machine, The Physics at ArXiv blog - ^ Vincent, James (10 April 2019). \"The first AI-generated textbook shows what robot writers are actually good at\". The Verge. Archived from the original on 5 May 2019. Retrieved 5 May 2019. - ^ Vaishya, Raju; Javaid, Mohd; Khan, Ibrahim Haleem; Haleem, Abid (1 July 2020). \"Artificial Intelligence (AI) applications for COVID-19 pandemic\". Diabetes & Metabolic Syndrome: Clinical Research & Reviews. 14 (4): 337–339. doi:10.1016/j.dsx.2020.04.012. PMC 7195043. PMID 32305024. - ^ Rezapouraghdam, Hamed; Akhshik, Arash; Ramkissoon, Haywantee (10 March 2021). \"Application of machine learning to predict visitors' green behavior in marine protected areas: evidence from Cyprus\". Journal of Sustainable Tourism. 31 (11): 2479–2505. doi:10.1080/09669582.2021.1887878. hdl:10037/24073. - ^ Dey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (15 June 2020). \"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE) (PDF). pp. 1728–1733. doi:10.23919/DATE48585.2020.9116294. ISBN 978-3-9819263-4-7. S2CID 219858480. Archived from the original on 13 December 2021. Retrieved 20 January 2022. - ^ Quested, Tony. \"Smartphones get smarter with Essex innovation\". Business Weekly. Archived from the original on 24 June 2021. Retrieved 17 June 2021. - ^ Williams, Rhiannon (21 July 2020). \"Future smartphones 'will prolong their own battery life by monitoring owners' behaviour'\". i. Archived from the original on 24 June 2021. Retrieved 17 June 2021. - ^ Rasekhschaffe, Keywan Christian; Jones, Robert C. (1 July 2019). \"Machine Learning for Stock Selection\". Financial Analysts Journal. 75 (3): 70–88. doi:10.1080/0015198X.2019.1596678. ISSN 0015-198X. S2CID 108312507. Archived from the original on 26 November 2023. Retrieved 26 November 2023. - ^ Chung, Yunsie; Green, William H. (2024). \"Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates\". Chemical Science. 15 (7): 2410–2424. doi:10.1039/D3SC05353A. ISSN 2041-6520. PMC 10866337. PMID 38362410. - ^ Sun, Yuran; Huang, Shih-Kai; Zhao, Xilei (1 February 2024). \"Predicting Hurricane Evacuation Decisions with Interpretable Machine Learning Methods\". International Journal of Disaster Risk Science. 15 (1): 134–148. arXiv:2303.06557. Bibcode:2024IJDRS..15..134S. doi:10.1007/s13753-024-00541-1. ISSN 2192-6395. - ^ Sun, Yuran; Zhao, Xilei; Lovreglio, Ruggiero; Kuligowski, Erica (1 January 2024), Naser, M. Z. (ed.), \"8 - AI for large-scale evacuation modeling: promises and challenges\", Interpretable Machine Learning for the Analysis, Design, Assessment, and Informed Decision Making for Civil Infrastructure, Woodhead Publishing Series in Civil and Structural Engineering, Woodhead Publishing, pp. 185–204, ISBN 978-0-12-824073-1, archived from the original on 19 May 2024, retrieved 19 May 2024 - ^ Xu, Ningzhe; Lovreglio, Ruggiero; Kuligowski, Erica D.; Cova, Thomas J.; Nilsson, Daniel; Zhao, Xilei (1 March 2023). \"Predicting and Assessing Wildfire Evacuation Decision-Making Using Machine Learning: Findings from the 2019 Kincade Fire\". Fire Technology. 59 (2): 793–825. doi:10.1007/s10694-023-01363-1. ISSN 1572-8099. - ^ Wang, Ke; Shi, Xiupeng; Goh, Algena Pei Xuan; Qian, Shunzhi (1 June 2019). \"A machine learning based study on pedestrian movement dynamics under emergency evacuation\". Fire Safety Journal. 106: 163–176. Bibcode:2019FirSJ.106..163W. doi:10.1016/j.firesaf.2019.04.008. hdl:10356/143390. ISSN 0379-7112. Archived from the original on 19 May 2024. Retrieved 19 May 2024. - ^ Zhao, Xilei; Lovreglio, Ruggiero; Nilsson, Daniel (1 May 2020). \"Modelling and interpreting pre-evacuation decision-making using machine learning\". Automation in Construction. 113 103140. doi:10.1016/j.autcon.2020.103140. hdl:10179/17315. ISSN 0926-5805. Archived from the original on 19 May 2024. Retrieved 19 May 2024. - ^ \"Why Machine Learning Models Often Fail to Learn: QuickTake Q&A\". Bloomberg.com. 10 November 2016. Archived from the original on 20 March 2017. Retrieved 10 April 2017. - ^ \"The First Wave of Corporate AI Is Doomed to Fail\". Harvard Business Review. 18 April 2017. Archived from the original on 21 August 2018. Retrieved 20 August 2018. - ^ \"Why the A.I. euphoria is doomed to fail\". VentureBeat. 18 September 2016. Archived from the original on 19 August 2018. Retrieved 20 August 2018. - ^ \"9 Reasons why your machine learning project will fail\". www.kdnuggets.com. Archived from the original on 21 August 2018. Retrieved 20 August 2018. - ^ a b Babuta, Alexander; Oswald, Marion; Rinik, Christine (2018). Transparency and Intelligibility (Report). Royal United Services Institute (RUSI). pp. 17–22. Archived from the original on 9 December 2023. Retrieved 9 December 2023. - ^ \"Why Uber's self-driving car killed a pedestrian\". The Economist. Archived from the original on 21 August 2018. Retrieved 20 August 2018. - ^ \"IBM's Watson recommended 'unsafe and incorrect' cancer treatments – STAT\". STAT. 25 July 2018. Archived from the original on 21 August 2018. Retrieved 21 August 2018. - ^ Hernandez, Daniela; Greenwald, Ted (11 August 2018). \"IBM Has a Watson Dilemma\". The Wall Street Journal. ISSN 0099-9660. Archived from the original on 21 August 2018. Retrieved 21 August 2018. - ^ Allyn, Bobby (27 February 2023). \"How Microsoft's experiment in artificial intelligence tech backfired\". National Public Radio. Archived from the original on 8 December 2023. Retrieved 8 December 2023. - ^ Reddy, Shivani M.; Patel, Sheila; Weyrich, Meghan; Fenton, Joshua; Viswanathan, Meera (2020). \"Comparison of a traditional systematic review approach with review-of-reviews and semi-automation as strategies to update the evidence\". Systematic Reviews. 9 (1): 243. doi:10.1186/s13643-020-01450-2. ISSN 2046-4053. PMC 7574591. PMID 33076975. - ^ Rudin, Cynthia (2019). \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\". Nature Machine Intelligence. 1 (5): 206–215. doi:10.1038/s42256-019-0048-x. PMC 9122117. PMID 35603010. - ^ Hu, Tongxi; Zhang, Xuesong; Bohrer, Gil; Liu, Yanlan; Zhou, Yuyu; Martin, Jay; LI, Yang; Zhao, Kaiguang (2023). \"Crop yield prediction via explainable AI and interpretable machine learning: Dangers of black box models for evaluating climate change impacts on crop yield\". Agricultural and Forest Meteorology. 336 109458. Bibcode:2023AgFM..33609458H. doi:10.1016/j.agrformet.2023.109458. S2CID 258552400. - ^ Domingos 2015, Chapter 6, Chapter 7. - ^ Domingos 2015, p. 286. - ^ \"Single pixel change fools AI programs\". BBC News. 3 November 2017. Archived from the original on 22 March 2018. Retrieved 12 March 2018. - ^ \"AI Has a Hallucination Problem That's Proving Tough to Fix\". WIRED. 2018. Archived from the original on 12 March 2018. Retrieved 12 March 2018. - ^ Madry, A.; Makelov, A.; Schmidt, L.; Tsipras, D.; Vladu, A. (4 September 2019). \"Towards deep learning models resistant to adversarial attacks\". arXiv:1706.06083 [stat.ML]. - ^ \"Adversarial Machine Learning – CLTC UC Berkeley Center for Long-Term Cybersecurity\". CLTC. Archived from the original on 17 May 2022. Retrieved 25 May 2022. - ^ \"Machine-learning models vulnerable to undetectable backdoors\". The Register. Archived from the original on 13 May 2022. Retrieved 13 May 2022. - ^ \"Undetectable Backdoors Plantable In Any Machine-Learning Algorithm\". IEEE Spectrum. 10 May 2022. Archived from the original on 11 May 2022. Retrieved 13 May 2022. - ^ Goldwasser, Shafi; Kim, Michael P.; Vaikuntanathan, Vinod; Zamir, Or (14 April 2022). \"Planting Undetectable Backdoors in Machine Learning Models\". arXiv:2204.06974 [cs.LG]. - ^ Kohavi, Ron (1995). \"A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection\" (PDF). International Joint Conference on Artificial Intelligence. Archived (PDF) from the original on 12 July 2018. Retrieved 26 March 2023. - ^ Catal, Cagatay (2012). \"Performance Evaluation Metrics for Software Fault Prediction Studies\" (PDF). Acta Polytechnica Hungarica. 9 (4). Retrieved 2 October 2016. - ^ a b Müller, Vincent C. (30 April 2020). \"Ethics of Artificial Intelligence and Robotics\". Stanford Encyclopedia of Philosophy. Archived from the original on 10 October 2020. - ^ \"Assessing potential future artificial intelligence risks, benefits and policy imperatives\". OECD. 14 November 2024. Retrieved 4 August 2025. - ^ a b Garcia, Megan (2016). \"Racist in the Machine\". World Policy Journal. 33 (4): 111–117. doi:10.1215/07402775-3813015. ISSN 0740-2775. S2CID 151595343. - ^ Bostrom, Nick (2011). \"The Ethics of Artificial Intelligence\" (PDF). Archived from the original (PDF) on 4 March 2016. Retrieved 11 April 2016. - ^ Edionwe, Tolulope. \"The fight against racist algorithms\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017. - ^ Jeffries, Adrianne. \"Machine learning is racist because the internet is racist\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017. - ^ a b Silva, Selena; Kenney, Martin (2018). \"Algorithms, Platforms, and Ethnic Bias: An Integrative Essay\" (PDF). Phylon. 55 (1 & 2): 9–37. ISSN 0031-8906. JSTOR 26545017. Archived (PDF) from the original on 27 January 2024. - ^ Wong, Carissa (30 March 2023). \"AI 'fairness' research held back by lack of diversity\". Nature. doi:10.1038/d41586-023-00935-z. PMID 36997714. S2CID 257857012. Archived from the original on 12 April 2023. Retrieved 9 December 2023. - ^ a b Zhang, Jack Clark. \"Artificial Intelligence Index Report 2021\" (PDF). Stanford Institute for Human-Centered Artificial Intelligence. Archived from the original (PDF) on 19 May 2024. Retrieved 9 December 2023. - ^ Caliskan, Aylin; Bryson, Joanna J.; Narayanan, Arvind (14 April 2017). \"Semantics derived automatically from language corpora contain human-like biases\". Science. 356 (6334): 183–186. arXiv:1608.07187. Bibcode:2017Sci...356..183C. doi:10.1126/science.aal4230. ISSN 0036-8075. PMID 28408601. S2CID 23163324. - ^ Wang, Xinan; Dasgupta, Sanjoy (2016), Lee, D. D.; Sugiyama, M.; Luxburg, U. V.; Guyon, I. (eds.), \"An algorithm for L1 nearest neighbor search via monotonic embedding\" (PDF), Advances in Neural Information Processing Systems 29, Curran Associates, Inc., pp. 983–991, archived (PDF) from the original on 7 April 2017, retrieved 20 August 2018 - ^ M.O.R. Prates; P.H.C. Avelar; L.C. Lamb (11 March 2019). \"Assessing Gender Bias in Machine Translation – A Case Study with Google Translate\". arXiv:1809.02208 [cs.CY]. - ^ Narayanan, Arvind (24 August 2016). \"Language necessarily contains human biases, and so will machines trained on language corpora\". Freedom to Tinker. Archived from the original on 25 June 2018. Retrieved 19 November 2016. - ^ Metz, Rachel (24 March 2016). \"Why Microsoft Accidentally Unleashed a Neo-Nazi Sexbot\". MIT Technology Review. Archived from the original on 9 November 2018. Retrieved 20 August 2018. - ^ Vincent, James (12 January 2018). \"Google 'fixed' its racist algorithm by removing gorillas from its image-labeling tech\". The Verge. Archived from the original on 21 August 2018. Retrieved 20 August 2018. - ^ Crawford, Kate (25 June 2016). \"Opinion | Artificial Intelligence's White Guy Problem\". New York Times. Archived from the original on 14 January 2021. Retrieved 20 August 2018. - ^ Simonite, Tom (30 March 2017). \"Microsoft: AI Isn't Yet Adaptable Enough to Help Businesses\". MIT Technology Review. Archived from the original on 9 November 2018. Retrieved 20 August 2018. - ^ Hempel, Jessi (13 November 2018). \"Fei-Fei Li's Quest to Make Machines Better for Humanity\". Wired. ISSN 1059-1028. Archived from the original on 14 December 2020. Retrieved 17 February 2019. - ^ Char, D. S.; Shah, N. H.; Magnus, D. (2018). \"Implementing Machine Learning in Health Care—Addressing Ethical Challenges\". New England Journal of Medicine. 378 (11): 981–983. doi:10.1056/nejmp1714229. PMC 5962261. PMID 29539284. - ^ Research, AI (23 October 2015). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition\". airesearch.com. Archived from the original on 1 February 2016. Retrieved 23 October 2015. - ^ \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. December 2019. Archived from the original on 10 June 2020. Retrieved 11 June 2020. - ^ Ray, Tiernan (2019). \"AI is changing the entire nature of compute\". ZDNet. Archived from the original on 25 May 2020. Retrieved 11 June 2020. - ^ \"AI and compute\". OpenAI. 16 May 2018. Archived from the original on 17 June 2020. Retrieved 11 June 2020. - ^ Jouppi, Norman P.; Young, Cliff; Patil, Nishant; Patterson, David; Agrawal, Gaurav; Bajwa, Raminder; Bates, Sarah; Bhatia, Suresh; Boden, Nan; Borchers, Al; Boyle, Rick; Cantin, Pierre-luc; Chao, Clifford; Clark, Chris; Coriell, Jeremy (24 June 2017). \"In-Datacenter Performance Analysis of a Tensor Processing Unit\". Proceedings of the 44th Annual International Symposium on Computer Architecture. ISCA '17. New York, NY, US: Association for Computing Machinery. pp. 1–12. arXiv:1704.04760. doi:10.1145/3079856.3080246. ISBN 978-1-4503-4892-8. - ^ Best, Jo (8 December 2020). \"What is neuromorphic computing? Everything you need to know about how it is changing the future of computing\". ZDNET. Retrieved 21 November 2024. - ^ Hecate He (27 May 2021). Michael Sarazen; Chain Zhang (eds.). \"Cornell & NTT's Physical Neural Networks: A \"Radical Alternative for Implementing Deep Neural Networks\" That Enables Arbitrary Physical Systems Training\". Synced. Archived from the original on 27 October 2021. Retrieved 12 October 2021. - ^ Clark, Lindsay (5 October 2021). \"Nano-spaghetti to solve neural network power consumption\". The Register. Archived from the original on 6 October 2021. Retrieved 12 October 2021. - ^ Fafoutis, Xenofon; Marchegiani, Letizia; Elsts, Atis; Pope, James; Piechocki, Robert; Craddock, Ian (7 May 2018). \"Extending the battery lifetime of wearable sensors with embedded machine learning\". 2018 IEEE 4th World Forum on Internet of Things (WF-IoT). pp. 269–274. doi:10.1109/WF-IoT.2018.8355116. hdl:1983/b8fdb58b-7114-45c6-82e4-4ab239c1327f. ISBN 978-1-4673-9944-9. S2CID 19192912. Archived from the original on 18 January 2022. Retrieved 17 January 2022. - ^ \"A Beginner's Guide To Machine learning For Embedded Systems\". Analytics India Magazine. 2 June 2021. Archived from the original on 18 January 2022. Retrieved 17 January 2022. - ^ Synced (12 January 2022). \"Google, Purdue & Harvard U's Open-Source Framework for TinyML Achieves up to 75x Speedups on FPGAs | Synced\". syncedreview.com. Archived from the original on 18 January 2022. Retrieved 17 January 2022. - ^ AlSelek, Mohammad; Alcaraz-Calero, Jose M.; Wang, Qi (2024). \"Dynamic AI-IoT: Enabling Updatable AI Models in Ultralow-Power 5G IoT Devices\". IEEE Internet of Things Journal. 11 (8): 14192–14205. Bibcode:2024IITJ...1114192A. doi:10.1109/JIOT.2023.3340858. - ^ Giri, Davide; Chiu, Kuan-Lin; Di Guglielmo, Giuseppe; Mantovani, Paolo; Carloni, Luca P. (15 June 2020). \"ESP4ML: Platform-Based Design of Systems-on-Chip for Embedded Machine Learning\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE). pp. 1049–1054. arXiv:2004.03640. doi:10.23919/DATE48585.2020.9116317. ISBN 978-3-9819263-4-7. S2CID 210928161. Archived from the original on 18 January 2022. Retrieved 17 January 2022. - ^ Louis, Marcia Sahaya; Azad, Zahra; Delshadtehrani, Leila; Gupta, Suyog; Warden, Pete; Reddi, Vijay Janapa; Joshi, Ajay (2019). \"Towards Deep Learning using TensorFlow Lite on RISC-V\". Harvard University. Archived from the original on 17 January 2022. Retrieved 17 January 2022. - ^ Ibrahim, Ali; Osta, Mario; Alameh, Mohamad; Saleh, Moustafa; Chible, Hussein; Valle, Maurizio (21 January 2019). \"Approximate Computing Methods for Embedded Machine Learning\". 2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS). pp. 845–848. doi:10.1109/ICECS.2018.8617877. ISBN 978-1-5386-9562-3. S2CID 58670712. - ^ \"dblp: TensorFlow Eager: A Multi-Stage, Python-Embedded DSL for Machine Learning\". dblp.org. Archived from the original on 18 January 2022. Retrieved 17 January 2022. - ^ Branco, Sérgio; Ferreira, André G.; Cabral, Jorge (5 November 2019). \"Machine Learning in Resource-Scarce Embedded Systems, FPGAs, and End-Devices: A Survey\". Electronics. 8 (11): 1289. doi:10.3390/electronics8111289. hdl:1822/62521. ISSN 2079-9292. Sources [edit]- Domingos, Pedro (22 September 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0-465-06570-7. - Nilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN 978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019. - Poole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN 978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020. - Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2. Further reading [edit]- Alpaydin, Ethem (2020). Introduction to Machine Learning, (4th edition) MIT Press, ISBN 9780262043793. - Bishop, Christopher (1995). Neural Networks for Pattern Recognition, Oxford University Press. ISBN 0-19-853864-2. - Bishop, Christopher (2006) Pattern Recognition and Machine Learning, Springer. ISBN 978-0-387-31073-2 - Domingos, Pedro (September 2015), The Master Algorithm, Basic Books, ISBN 978-0-465-06570-7 - Duda, Richard O.; Hart, Peter E.; Stork, David G. (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3. - Hastie, Trevor; Tibshirani, Robert & Friedman, Jerome H. (2009) The Elements of Statistical Learning, Springer. doi:10.1007/978-0-387-84858-7 ISBN 0-387-95284-5. - MacKay, David J. C. Information Theory, Inference, and Learning Algorithms Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1 - Murphy, Kevin P. (2021). Probabilistic Machine Learning: An Introduction Archived 11 April 2021 at the Wayback Machine, MIT Press. - Nilsson, Nils J. (2015) Introduction to Machine Learning Archived 16 August 2019 at the Wayback Machine. - Russell, Stuart & Norvig, Peter (2020). Artificial Intelligence – A Modern Approach. (4th edition) Pearson, ISBN 978-0134610993. - Solomonoff, Ray, (1956) An Inductive Inference Machine Archived 26 April 2011 at the Wayback Machine A privately circulated report from the 1956 Dartmouth Summer Research Conference on AI. - Witten, Ian H. & Frank, Eibe (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664pp., ISBN 978-0-12-374856-0. External links [edit]- International Machine Learning Society - mloss is an academic database of open-source machine learning software.",
    "text_length": 107240,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:43.846360"
  },
  {
    "id": "page_10",
    "url": "https://en.wikipedia.org/wiki/Deep_learning",
    "domain": "en.wikipedia.org",
    "title": "Deep learning - Wikipedia",
    "text": "Deep learning | Part of a series on | | Artificial intelligence (AI) | |---| In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.[2] Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.[3][4][5] Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.[6] Overview [edit]Most modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[7] Fundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place at which level on its own. Prior to deep learning, machine learning techniques often involved hand-crafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate on. In the deep learning approach, features are not hand-crafted and the model discovers useful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.[8][2] The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.[9] No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than two. CAP of depth two has been shown to be a universal approximator in the sense that it can emulate any function.[10] Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > two) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively. Deep learning architectures can be constructed with a greedy layer-by-layer method.[11] Deep learning helps to disentangle these abstractions and pick out which features improve performance.[8] Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data is more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.[8][12] The term deep learning was introduced to the machine learning community by Rina Dechter in 1986,[13] and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.[14][15] Although the history of its appearance is apparently more complicated.[16] Interpretations [edit]Deep neural networks are generally interpreted in terms of the universal approximation theorem[17][18][19][20][21] or probabilistic inference.[22][23][8][9][24] The classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions.[17][18][19][20] In 1989, the first proof was published by George Cybenko for sigmoid activation functions[17] and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik.[18] Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima's rectified linear unit.[25][26] The universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al.[21] proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator. The probabilistic interpretation[24] derives from the field of machine learning. It features inference,[23][7][8][9][12][24] as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function.[24] The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.[27] History [edit]Before 1980 [edit]There are two types of artificial neural network (ANN): feedforward neural network (FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have cycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst Ising created the Ising model[28][29] which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this architecture adaptive.[30][31] His learning RNN was republished by John Hopfield in 1982.[32] Other early recurrent neural networks were published by Kaoru Nakano in 1971.[33][34] Already in 1948, Alan Turing produced work on \"Intelligent Machinery\" that was not published in his lifetime,[35] containing \"ideas related to artificial evolution and learning RNNs\".[31] Frank Rosenblatt (1958)[36] proposed the perceptron, an MLP with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. He later published a 1962 book that also introduced variants and computer experiments, including a version with four-layer perceptrons \"with adaptive preterminal networks\" where the last two layers have learned weights (here he credits H. D. Block and B. W. Knight).[37]: section 16 The book cites an earlier network by R. D. Joseph (1960)[38] \"functionally equivalent to a variation of\" this four-layer system (the book mentions Joseph over 30 times). Should Joseph therefore be considered the originator of proper adaptive multilayer perceptrons with learning hidden units? Unfortunately, the learning algorithm was not a functional one, and fell into oblivion. The first working deep learning algorithm was the Group method of data handling, a method to train arbitrarily deep neural networks, published by Alexey Ivakhnenko and Lapa in 1965. They regarded it as a form of polynomial regression,[39] or a generalization of Rosenblatt's perceptron to handle more complex, nonlinear, and hierarchical relationships.[40] A 1971 paper described a deep network with eight layers trained by this method,[41] which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates\".[31] The first deep learning multilayer perceptron trained by stochastic gradient descent[42] was published in 1967 by Shun'ichi Amari.[43] In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned internal representations to classify non-linearily separable pattern classes.[31] Subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique. In 1969, Kunihiko Fukushima introduced the ReLU (rectified linear unit) activation function.[25][31] The rectifier has become the most popular activation function for deep learning.[44] Deep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1979, though not trained by backpropagation.[45][46] Backpropagation is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673[47] to networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt,[37] but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation in 1960 in the context of control theory.[48] The modern form of backpropagation was first published in Seppo Linnainmaa's master thesis (1970).[49][50][31] G.M. Ostrovski et al. republished it in 1971.[51][52] Paul Werbos applied backpropagation to neural networks in 1982[53] (his 1974 PhD thesis, reprinted in a 1994 book,[54] did not yet describe the algorithm[52]). In 1986, David E. Rumelhart et al. popularised backpropagation but did not cite the original work.[55][56] 1980s-2000s [edit]The time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.[57][58] In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition.[59] In 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days.[60] In 1990, Wei Zhang implemented a CNN on optical computing hardware.[61] In 1991, a CNN was applied to medical image object segmentation[62] and breast cancer detection in mammograms.[63] LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks digitized in 32x32 pixel images.[64] Recurrent neural networks (RNN)[28][30] were further developed in the 1980s. Recurrence is used for sequence processing, and when a recurrent network is unrolled, it mathematically resembles a deep feedforward layer. Consequently, they have similar properties and issues, and their developments had mutual influences. In RNN, two early influential works were the Jordan network (1986)[65] and the Elman network (1990),[66] which applied RNN to study problems in cognitive psychology. In the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, in 1991, Jürgen Schmidhuber proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning where each RNN tries to predict its own next input, which is the next unexpected input of the RNN below.[67][68] This \"neural history compressor\" uses predictive coding to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by distilling a higher level chunker network into a lower level automatizer network.[67][68][31] In 1993, a neural history compressor solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time.[69] The \"P\" in ChatGPT refers to such pre-training. Sepp Hochreiter's diploma thesis (1991)[70] implemented the neural history compressor,[67] and identified and analyzed the vanishing gradient problem.[70][71] Hochreiter proposed recurrent residual connections to solve the vanishing gradient problem. This led to the long short-term memory (LSTM), published in 1995.[72] LSTM can learn \"very deep learning\" tasks[9] with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. That LSTM was not yet the modern architecture, which required a \"forget gate\", introduced in 1999,[73] which became the standard RNN architecture. In 1991, Jürgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss.[74][75] The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in generative adversarial networks (GANs).[76] During 1985–1995, inspired by statistical mechanics, several architectures and methods were developed by Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including the Boltzmann machine,[77] restricted Boltzmann machine,[78] Helmholtz machine,[79] and the wake-sleep algorithm.[80] These were designed for unsupervised learning of deep generative models. However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p. 112 [81]). A 1988 network became state of the art in protein structure prediction, an early application of deep learning to bioinformatics.[82] Both shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years.[83][84][85] These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively.[86] Key difficulties have been analyzed, including gradient diminishing[70] and weak temporal correlation structure in neural predictive models.[87][88] Additional difficulties were the lack of training data and limited computing power. Most speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI researched in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 NIST Speaker Recognition benchmark.[89][90] It was deployed in the Nuance Verifier, representing the first major industrial application of deep learning.[91] The principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s,[90] showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.[92] 2000s [edit]Neural networks entered a lull, and simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) became the preferred choices in the 1990s and 2000s, because of artificial neural networks' computational cost and a lack of understanding of how the brain wires its biological networks.[citation needed] In 2003, LSTM became competitive with traditional speech recognizers on certain tasks.[93] In 2006, Alex Graves, Santiago Fernández, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC)[94] in stacks of LSTMs.[95] In 2009, it became the first RNN to win a pattern recognition contest, in connected handwriting recognition.[96][9] In 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh[97][98] deep belief networks were developed for generative modeling. They are trained by training one restricted Boltzmann machine, then freezing it and training another one on top of the first one, and so on, then optionally fine-tuned using supervised backpropagation.[99] They could model high-dimensional probability distributions, such as the distribution of MNIST images, but convergence was slow.[100][101][102] The impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun.[103] Industrial applications of deep learning to large-scale speech recognition started around 2010. The 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems.[104] The nature of the recognition errors produced by the two types of systems was characteristically different,[105] offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems.[23][106][107] Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.[105] That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.[104][105][108] In 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.[109][110][111][106] Deep learning revolution [edit]The deep learning revolution started around CNN- and GPU-based computer vision. Although CNNs trained by backpropagation had been around for decades and GPU implementations of NNs for years,[112] including CNNs,[113] faster implementations of CNNs on GPUs were needed to progress on computer vision. Later, as deep learning becomes widespread, specialized hardware and algorithm optimizations were developed specifically for deep learning.[114] A key advance for the deep learning revolution was hardware advances, especially GPU. Some early work dated back to 2004.[112][113] In 2009, Raina, Madhavan, and Andrew Ng reported a 100M deep belief network trained on 30 Nvidia GeForce GTX 280 GPUs, an early demonstration of GPU-based deep learning. They reported up to 70 times faster training.[115] In 2011, a CNN named DanNet[116][117] by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3.[9] It then won more contests.[118][119] They also showed how max-pooling CNNs on GPU improved performance significantly.[3] In 2012, Andrew Ng and Jeff Dean created an FNN that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from YouTube videos.[120] In October 2012, AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton[4] won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and Andrew Zisserman[121] and Google's Inceptionv3.[122] The success in image classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.[123][124][125] In 2014, the state of the art was training \"very deep neural network\" with 20 to 30 layers.[126] Stacking too many layers led to a steep reduction in training accuracy,[127] known as the \"degradation\" problem.[128] In 2015, two techniques were developed to train very deep networks: the highway network was published in May 2015, and the residual neural network (ResNet)[129] in Dec 2015. ResNet behaves like an open-gated Highway Net. Around the same time, deep learning started impacting the field of art. Early examples included Google DeepDream (2015), and neural style transfer (2015),[130] both of which were based on pretrained image classification neural networks, such as VGG-19. Generative adversarial network (GAN) by (Ian Goodfellow et al., 2014)[131] (based on Jürgen Schmidhuber's principle of artificial curiosity[74][76]) became state of the art in generative modeling during 2014-2018 period. Excellent image quality is achieved by Nvidia's StyleGAN (2018)[132] based on the Progressive GAN by Tero Karras et al.[133] Here the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning deepfakes.[134] Diffusion models (2015)[135] eclipsed GANs in generative modeling since then, with systems such as DALL·E 2 (2022) and Stable Diffusion (2022). In 2015, Google's speech recognition improved by 49% by an LSTM-based model, which they made available through Google Voice Search on smartphone.[136][137] Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved.[104][138] Convolutional neural networks were superseded for ASR by LSTM.[137][139][140][141] but are more successful in computer vision. Yoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the 2018 Turing Award for \"conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing\".[142] Neural networks [edit]Artificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming. An ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream. Typically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times. The original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information. Neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis. As of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\"[144]). Deep neural networks [edit]A deep neural network (DNN) is an artificial neural network with multiple layers between the input and output layers.[7][9] There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions.[145] These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.[citation needed] For example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer,[146] and complex DNN have many layers, hence the name \"deep\" networks. DNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives.[147] The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network.[7] For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.[148] Deep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.[146] DNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights.[149] That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data. Recurrent neural networks, in which data can flow in any direction, are used for applications such as language modeling.[150][151][152][153][154] Long short-term memory is particularly effective for this use.[155][156] Convolutional neural networks (CNNs) are used in computer vision.[157] CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).[158] Challenges [edit]As with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time. DNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko's unit pruning[41] or weight decay (-regularization) or sparsity (-regularization) can be applied during training to combat overfitting.[159] Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies.[160] Another interesting recent development is research into models of just enough complexity through an estimation of the intrinsic complexity of the task being modelled. This approach has been successfully applied for multivariate time series prediction tasks such as traffic prediction.[161] Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.[162] DNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples)[163] speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.[164][165] Alternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn't require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.[166][167] Hardware [edit]Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.[168] By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method for training large-scale commercial cloud AI .[169] OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017) and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.[170][171] Special electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones[172] and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform.[173] Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).[174][175] Atomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage. In 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).[176] In 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing.[177] The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds.[177] Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.[177] Applications [edit]Automatic speech recognition [edit]Large-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks[9] that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates[156] is competitive with traditional speech recognizers on certain tasks.[93] The initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences.[178] Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991. | Method | Percent phone error rate (PER) (%) | |---|---| | Randomly Initialized RNN[179] | 26.1 | | Bayesian Triphone GMM-HMM | 25.6 | | Hidden Trajectory (Generative) Model | 24.8 | | Monophone Randomly Initialized DNN | 23.4 | | Monophone DBN-DNN | 22.4 | | Triphone GMM-HMM with BMMI Training | 21.7 | | Monophone DBN-DNN on fbank | 20.7 | | Convolutional DNN[180] | 20.0 | | Convolutional DNN w. Heterogeneous Pooling | 18.7 | | Ensemble DNN/CNN/RNN[181] | 18.3 | | Bidirectional LSTM | 17.8 | | Hierarchical Convolutional Deep Maxout Network[182] | 16.5 | The debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003–2007, accelerated progress in eight major areas:[23][108][106] - Scale-up/out and accelerated DNN training and decoding - Sequence discriminative training - Feature processing by deep models with solid understanding of the underlying mechanisms - Adaptation of DNNs and related deep models - Multi-task and transfer learning by DNNs and related deep models - CNNs and how to design them to best exploit domain knowledge of speech - RNN and its rich LSTM variants - Other types of deep models including tensor-based models and integrated deep generative/discriminative models. More recent speech recognition models use Transformers or Temporal Convolution Networks with significant success and widespread applications.[183][184][185] All major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.[23][186][187] Image recognition [edit]A common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.[188] Deep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.[189][190] Deep learning-trained vehicles now interpret 360° camera views.[191] Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes. Visual art processing [edit]Closely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of - identifying the style period of a given painting[192][193] - Neural Style Transfer – capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video[192][193] - generating striking imagery based on random visual input fields.[192][193] Natural language processing [edit]Neural networks have been used for implementing language models since the early 2000s.[150] LSTM helped to improve machine translation and language modeling.[151][152][153] Other key techniques in this field are negative sampling[194] and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN.[195] Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing.[195] Deep neural architectures provide the best results for constituency parsing,[196] sentiment analysis,[197] information retrieval,[198][199] spoken language understanding,[200] machine translation,[151][201] contextual entity linking,[201] writing style recognition,[202] named-entity recognition (token classification),[203] text classification, and others.[204] Recent developments generalize word embedding to sentence embedding. Google Translate (GT) uses a large end-to-end long short-term memory (LSTM) network.[205][206][207][208] Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\".[206] It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages.[206] The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\".[206][209] GT uses English as an intermediate between most language pairs.[209] Drug discovery and toxicology [edit]A large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects.[210][211] Research has explored use of deep learning to predict the biomolecular targets,[212][213] off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.[214][215][216] AtomNet is a deep learning system for structure-based rational drug design.[217] AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus[218] and multiple sclerosis.[219][218] In 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set.[220] In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.[221][222] Recommendation systems [edit]Recommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations.[223][224] Multi-view deep learning has been applied for learning user preferences from multiple domains.[225] The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks. Bioinformatics [edit]An autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.[226] In medical informatics, deep learning was used to predict sleep quality based on data from wearables[227] and predictions of health complications from electronic health record data.[228] Deep neural networks have shown unparalleled performance in predicting protein structure, according to the sequence of the amino acids that make it up. In 2020, AlphaFold, a deep-learning based system, achieved a level of accuracy significantly higher than all previous computational methods.[229][230] Deep Neural Network Estimations [edit]Deep neural networks can be used to estimate the entropy of a stochastic process through an arrangement called a Neural Joint Entropy Estimator (NJEE).[231] Such an estimation provides insights on the effects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in cases of large alphabet sizes.[231] Medical image analysis [edit]Deep learning has been shown to produce competitive results in medical applications such as cancer cell classification, lesion detection, organ segmentation and image enhancement.[232][233] Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.[234][235] Mobile advertising [edit]Finding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server.[236] Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection. Image restoration [edit]Deep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization.[237] These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\"[238] which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration. Financial fraud detection [edit]Deep learning is being successfully applied to financial fraud detection, tax evasion detection,[239] and anti-money laundering.[240] Materials science [edit]In November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.[241][242][243] Military [edit]The United States Department of Defense applied deep learning to train robots in new tasks through observation.[244] Partial differential equations [edit]Physics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner.[245] One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods rely on.[246][247] It is evident that geometric and physical constraints have a synergistic effect on neural PDE surrogates, thereby enhancing their efficacy in predicting stable and super long rollouts.[248] Deep backward stochastic differential equation method [edit]Deep backward stochastic differential equation method is a numerical method that combines deep learning with Backward stochastic differential equation (BSDE). This method is particularly useful for solving high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of deep neural networks, deep BSDE addresses the computational challenges faced by traditional numerical methods in high-dimensional settings. Specifically, traditional methods like finite difference methods or Monte Carlo simulations often struggle with the curse of dimensionality, where computational cost increases exponentially with the number of dimensions. Deep BSDE methods, however, employ deep neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden.[249] In addition, the integration of Physics-informed neural networks (PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws directly into the neural network architecture. This ensures that the solutions not only fit the data but also adhere to the governing stochastic differential equations. PINNs leverage the power of deep learning while respecting the constraints imposed by the physical models, resulting in more accurate and reliable solutions for financial mathematics problems. Image reconstruction [edit]Image reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging [250] and ultrasound imaging.[251] Weather prediction [edit]Traditional weather prediction systems solve a very complex system of partial differential equations. GraphCast is a deep learning based model, trained on a long history of weather data to predict how weather patterns change over time. It is able to predict weather conditions for up to 10 days globally, at a very detailed level, and in under a minute, with precision similar to state of the art systems.[252][253] Epigenetic clock [edit]An epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples.[254] The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity. Relation to human cognitive and brain development [edit]Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s.[255][256][257][258] These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".[259] A variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism.[260][261] Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality.[262][263] In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.[264] Although a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons[265] and neural populations.[266] Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system[267] both at the single-unit[268] and at the population[269] levels. Commercial activity [edit]Facebook's AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.[270] Google's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player.[271][272][273] Google Translate uses a neural network to translate between more than 100 languages. In 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.[274] As of 2008,[275] researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor.[244] First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot with the ability to learn new tasks through observation.[244] Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".[276] Criticism and comment [edit]Deep learning has attracted both criticism and comment, in some cases from outside the field of computer science. Theory [edit]A main criticism concerns the lack of theory surrounding some methods.[277] Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear.[citation needed] (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.[278] In further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained[279] demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian's[280] website. With the support of Innovation Diffusion Theory (IDT), a study analyzed the diffusion of Deep Learning[281] in BRICS and OECD countries using data from Google Trends. Errors [edit]Some deep learning architectures display problematic behaviors,[282] such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014)[283] and misclassifying minuscule perturbations of correctly classified images (2013).[284] Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures.[282] These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar[285] decompositions of observed entities and events.[282] Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition[286] and artificial intelligence (AI).[287] Cyber threat [edit]As deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception.[288] By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".[289] In 2016 researchers used one ANN to doctor images in trial and error fashion, identify another's focal points, and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system.[290] One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.[291] Another group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.[290] ANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.[290] In 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".[290] In \"data poisoning\", false data is continually smuggled into a machine learning system's training set to prevent it from achieving mastery.[290] Data collection ethics [edit]The deep learning systems that are trained using supervised learning often rely on data that is created or annotated by humans, or both.[292] It has been argued that not only low-paid clickwork (such as on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such.[293] The philosopher Rainer Mühlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.[293] See also [edit]- Applications of artificial intelligence - Comparison of deep learning software - Compressed sensing - Differentiable programming - Echo state network - List of artificial intelligence projects - Liquid state machine - List of datasets for machine-learning research - Reservoir computing - Scale space and deep learning - Sparse coding - Stochastic parrot - Topological deep learning References [edit]- ^ Schulz, Hannes; Behnke, Sven (1 November 2012). \"Deep Learning\". KI - Künstliche Intelligenz. 26 (4): 357–363. doi:10.1007/s13218-012-0198-z. ISSN 1610-1987. S2CID 220523562. - ^ a b LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (2015). \"Deep Learning\" (PDF). Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID 26017442. S2CID 3074096. - ^ a b Ciresan, D.; Meier, U.; Schmidhuber, J. (2012). \"Multi-column deep neural networks for image classification\". 2012 IEEE Conference on Computer Vision and Pattern Recognition. pp. 3642–3649. arXiv:1202.2745. doi:10.1109/cvpr.2012.6248110. ISBN 978-1-4673-1228-8. S2CID 2161592. - ^ a b Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey (2012). \"ImageNet Classification with Deep Convolutional Neural Networks\" (PDF). NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada. Archived (PDF) from the original on 2017-01-10. Retrieved 2017-05-24. - ^ \"Google's AlphaGo AI wins three-match series against the world's best Go player\". TechCrunch. 25 May 2017. Archived from the original on 17 June 2018. Retrieved 17 June 2018. - ^ \"Study urges caution when comparing neural networks to the brain\". MIT News | Massachusetts Institute of Technology. 2022-11-02. Retrieved 2023-12-06. - ^ a b c d Bengio, Yoshua (2009). \"Learning Deep Architectures for AI\" (PDF). Foundations and Trends in Machine Learning. 2 (1): 1–127. CiteSeerX 10.1.1.701.9550. doi:10.1561/2200000006. S2CID 207178999. Archived from the original (PDF) on 4 March 2016. Retrieved 3 September 2015. - ^ a b c d e Bengio, Y.; Courville, A.; Vincent, P. (2013). \"Representation Learning: A Review and New Perspectives\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798–1828. arXiv:1206.5538. Bibcode:2013ITPAM..35.1798B. doi:10.1109/tpami.2013.50. PMID 23787338. S2CID 393948. - ^ a b c d e f g h Schmidhuber, J. (2015). \"Deep Learning in Neural Networks: An Overview\". Neural Networks. 61: 85–117. arXiv:1404.7828. Bibcode:2015NN.....61...85S. doi:10.1016/j.neunet.2014.09.003. PMID 25462637. S2CID 11715509. - ^ Shigeki, Sugiyama (12 April 2019). Human Behavior and Another Kind in Consciousness: Emerging Research and Opportunities: Emerging Research and Opportunities. IGI Global. ISBN 978-1-5225-8218-2. - ^ Bengio, Yoshua; Lamblin, Pascal; Popovici, Dan; Larochelle, Hugo (2007). Greedy layer-wise training of deep networks (PDF). Advances in neural information processing systems. pp. 153–160. Archived (PDF) from the original on 2019-10-20. Retrieved 2019-10-06. - ^ a b Hinton, G.E. (2009). \"Deep belief networks\". Scholarpedia. 4 (5): 5947. Bibcode:2009SchpJ...4.5947H. doi:10.4249/scholarpedia.5947. - ^ Rina Dechter (1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory.Online Archived 2016-04-19 at the Wayback Machine - ^ Aizenberg, I.N.; Aizenberg, N.N.; Vandewalle, J. (2000). Multi-Valued and Universal Binary Neurons. Science & Business Media. doi:10.1007/978-1-4757-3115-6. ISBN 978-0-7923-7824-2. Retrieved 27 December 2023. - ^ Co-evolving recurrent neurons learn deep memory POMDPs. Proc. GECCO, Washington, D. C., pp. 1795–1802, ACM Press, New York, NY, USA, 2005. - ^ Fradkov, Alexander L. (2020-01-01). \"Early History of Machine Learning\". IFAC-PapersOnLine. 21st IFAC World Congress. 53 (2): 1385–1390. doi:10.1016/j.ifacol.2020.12.1888. ISSN 2405-8963. S2CID 235081987. - ^ a b c Cybenko (1989). \"Approximations by superpositions of sigmoidal functions\" (PDF). Mathematics of Control, Signals, and Systems. 2 (4): 303–314. Bibcode:1989MCSS....2..303C. doi:10.1007/bf02551274. S2CID 3958369. Archived from the original (PDF) on 10 October 2015. - ^ a b c Hornik, Kurt (1991). \"Approximation Capabilities of Multilayer Feedforward Networks\". Neural Networks. 4 (2): 251–257. Bibcode:1991NN......4..251H. doi:10.1016/0893-6080(91)90009-t. S2CID 7343126. - ^ a b Haykin, Simon S. (1999). Neural Networks: A Comprehensive Foundation. Prentice Hall. ISBN 978-0-13-273350-2. - ^ a b Hassoun, Mohamad H. (1995). Fundamentals of Artificial Neural Networks. MIT Press. p. 48. ISBN 978-0-262-08239-6. - ^ a b Lu, Z., Pu, H., Wang, F., Hu, Z., & Wang, L. (2017). The Expressive Power of Neural Networks: A View from the Width Archived 2019-02-13 at the Wayback Machine. Neural Information Processing Systems, 6231-6239. - ^ Orhan, A. E.; Ma, W. J. (2017). \"Efficient probabilistic inference in generic neural networks trained with non-probabilistic feedback\". Nature Communications. 8 (1): 138. Bibcode:2017NatCo...8..138O. doi:10.1038/s41467-017-00181-8. PMC 5527101. PMID 28743932. - ^ a b c d e Deng, L.; Yu, D. (2014). \"Deep Learning: Methods and Applications\" (PDF). Foundations and Trends in Signal Processing. 7 (3–4): 1–199. doi:10.1561/2000000039. Archived (PDF) from the original on 2016-03-14. Retrieved 2014-10-18. - ^ a b c d Murphy, Kevin P. (24 August 2012). Machine Learning: A Probabilistic Perspective. MIT Press. ISBN 978-0-262-01802-9. - ^ a b Fukushima, K. (1969). \"Visual feature extraction by a multilayered network of analog threshold elements\". IEEE Transactions on Systems Science and Cybernetics. 5 (4): 322–333. Bibcode:1969ITSSC...5..322F. doi:10.1109/TSSC.1969.300225. - ^ Sonoda, Sho; Murata, Noboru (2017). \"Neural network with unbounded activation functions is universal approximator\". Applied and Computational Harmonic Analysis. 43 (2): 233–268. arXiv:1505.03654. doi:10.1016/j.acha.2015.12.005. S2CID 12149203. - ^ Bishop, Christopher M. (2006). Pattern Recognition and Machine Learning (PDF). Springer. ISBN 978-0-387-31073-2. Archived (PDF) from the original on 2017-01-11. Retrieved 2017-08-06. - ^ a b \"bibliotheca Augustana\". www.hs-augsburg.de. - ^ Brush, Stephen G. (1967). \"History of the Lenz-Ising Model\". Reviews of Modern Physics. 39 (4): 883–893. Bibcode:1967RvMP...39..883B. doi:10.1103/RevModPhys.39.883. - ^ a b Amari, Shun-Ichi (1972). \"Learning patterns and pattern sequences by self-organizing nets of threshold elements\". IEEE Transactions. C (21): 1197–1206. - ^ a b c d e f g Schmidhuber, Jürgen (2022). \"Annotated History of Modern AI and Deep Learning\". arXiv:2212.11279 [cs.NE]. - ^ Hopfield, J. J. (1982). \"Neural networks and physical systems with emergent collective computational abilities\". Proceedings of the National Academy of Sciences. 79 (8): 2554–2558. Bibcode:1982PNAS...79.2554H. doi:10.1073/pnas.79.8.2554. PMC 346238. PMID 6953413. - ^ Nakano, Kaoru (1971). \"Learning Process in a Model of Associative Memory\". Pattern Recognition and Machine Learning. pp. 172–186. doi:10.1007/978-1-4615-7566-5_15. ISBN 978-1-4615-7568-9. - ^ Nakano, Kaoru (1972). \"Associatron-A Model of Associative Memory\". IEEE Transactions on Systems, Man, and Cybernetics. SMC-2 (3): 380–388. Bibcode:1972ITSMC...2..380N. doi:10.1109/TSMC.1972.4309133. - ^ Turing, Alan (1992) [1948]. \"Intelligent Machinery\". In Ince, D.C. (ed.). Collected Works of AM Turing: Mechanical Intelligence. Vol. 1. Elsevier Science Publishers. p. 107. ISBN 0-444-88058-5. - ^ Rosenblatt, F. (1958). \"The perceptron: A probabilistic model for information storage and organization in the brain\". Psychological Review. 65 (6): 386–408. doi:10.1037/h0042519. ISSN 1939-1471. PMID 13602029. - ^ a b Rosenblatt, Frank (1962). Principles of Neurodynamics. Spartan, New York. - ^ Joseph, R. D. (1960). Contributions to Perceptron Theory, Cornell Aeronautical Laboratory Report No. VG-11 96--G-7, Buffalo. - ^ Ivakhnenko, A. G.; Lapa, V. G. (1967). Cybernetics and Forecasting Techniques. American Elsevier Publishing Co. ISBN 978-0-444-00020-0. - ^ Ivakhnenko, A.G. (March 1970). \"Heuristic self-organization in problems of engineering cybernetics\". Automatica. 6 (2): 207–219. Bibcode:1970Autom...6..207I. doi:10.1016/0005-1098(70)90092-0. - ^ a b Ivakhnenko, Alexey (1971). \"Polynomial theory of complex systems\" (PDF). IEEE Transactions on Systems, Man, and Cybernetics. SMC-1 (4): 364–378. Bibcode:1971ITSMC...1..364I. doi:10.1109/TSMC.1971.4308320. Archived (PDF) from the original on 2017-08-29. Retrieved 2019-11-05. - ^ Robbins, H.; Monro, S. (1951). \"A Stochastic Approximation Method\". The Annals of Mathematical Statistics. 22 (3): 400. doi:10.1214/aoms/1177729586. - ^ Amari, Shun'ichi (1967). \"A theory of adaptive pattern classifier\". IEEE Transactions. EC (16): 279–307. - ^ Ramachandran, Prajit; Barret, Zoph; Quoc, V. Le (October 16, 2017). \"Searching for Activation Functions\". arXiv:1710.05941 [cs.NE]. - ^ Fukushima, K. (1979). \"Neural network model for a mechanism of pattern recognition unaffected by shift in position—Neocognitron\". Trans. IECE (In Japanese). J62-A (10): 658–665. doi:10.1007/bf00344251. PMID 7370364. S2CID 206775608. - ^ Fukushima, K. (1980). \"Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\". Biol. Cybern. 36 (4): 193–202. doi:10.1007/bf00344251. PMID 7370364. S2CID 206775608. - ^ Leibniz, Gottfried Wilhelm Freiherr von (1920). The Early Mathematical Manuscripts of Leibniz: Translated from the Latin Texts Published by Carl Immanuel Gerhardt with Critical and Historical Notes (Leibniz published the chain rule in a 1676 memoir). Open court publishing Company. ISBN 978-0-598-81846-1. {{cite book}} : ISBN / Date incompatibility (help) - ^ Kelley, Henry J. (1960). \"Gradient theory of optimal flight paths\". ARS Journal. 30 (10): 947–954. doi:10.2514/8.5282. - ^ Linnainmaa, Seppo (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors (Masters) (in Finnish). University of Helsinki. p. 6–7. - ^ Linnainmaa, Seppo (1976). \"Taylor expansion of the accumulated rounding error\". BIT Numerical Mathematics. 16 (2): 146–160. doi:10.1007/bf01931367. S2CID 122357351. - ^ Ostrovski, G.M., Volin,Y.M., and Boris, W.W. (1971). On the computation of derivatives. Wiss. Z. Tech. Hochschule for Chemistry, 13:382–384. - ^ a b Schmidhuber, Juergen (25 Oct 2014). \"Who Invented Backpropagation?\". IDSIA, Switzerland. Archived from the original on 30 July 2024. Retrieved 14 Sep 2024. - ^ Werbos, Paul (1982). \"Applications of advances in nonlinear sensitivity analysis\" (PDF). System modeling and optimization. Springer. pp. 762–770. Archived (PDF) from the original on 14 April 2016. Retrieved 2 July 2017. - ^ Werbos, Paul J. (1994). The Roots of Backpropagation: From Ordered Derivatives to Neural Networks and Political Forecasting. New York: John Wiley & Sons. ISBN 0-471-59897-6. - ^ Rumelhart, David E.; Hinton, Geoffrey E.; Williams, Ronald J. (October 1986). \"Learning representations by back-propagating errors\". Nature. 323 (6088): 533–536. Bibcode:1986Natur.323..533R. doi:10.1038/323533a0. ISSN 1476-4687. - ^ Rumelhart, David E., Geoffrey E. Hinton, and R. J. Williams. \"Learning Internal Representations by Error Propagation Archived 2022-10-13 at the Wayback Machine\". David E. Rumelhart, James L. McClelland, and the PDP research group. (editors), Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundation. MIT Press, 1986. - ^ Waibel, Alex (December 1987). Phoneme Recognition Using Time-Delay Neural Networks (PDF). Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE). Tokyo, Japan. - ^ Alexander Waibel et al., Phoneme Recognition Using Time-Delay Neural Networks IEEE Transactions on Acoustics, Speech, and Signal Processing, Volume 37, No. 3, pp. 328. – 339 March 1989. - ^ Zhang, Wei (1988). \"Shift-invariant pattern recognition neural network and its optical architecture\". Proceedings of Annual Conference of the Japan Society of Applied Physics. - ^ LeCun et al., \"Backpropagation Applied to Handwritten Zip Code Recognition\", Neural Computation, 1, pp. 541–551, 1989. - ^ Zhang, Wei (1990). \"Parallel distributed processing model with local space-invariant interconnections and its optical architecture\". Applied Optics. 29 (32): 4790–7. Bibcode:1990ApOpt..29.4790Z. doi:10.1364/AO.29.004790. PMID 20577468. - ^ Zhang, Wei (1991). \"Image processing of human corneal endothelium based on a learning network\". Applied Optics. 30 (29): 4211–7. Bibcode:1991ApOpt..30.4211Z. doi:10.1364/AO.30.004211. PMID 20706526. - ^ Zhang, Wei (1994). \"Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network\". Medical Physics. 21 (4): 517–24. Bibcode:1994MedPh..21..517Z. doi:10.1118/1.597177. PMID 8058017. - ^ LeCun, Yann; Léon Bottou; Yoshua Bengio; Patrick Haffner (1998). \"Gradient-based learning applied to document recognition\" (PDF). Proceedings of the IEEE. 86 (11): 2278–2324. Bibcode:1998IEEEP..86.2278L. CiteSeerX 10.1.1.32.9552. doi:10.1109/5.726791. S2CID 14542261. Retrieved October 7, 2016. - ^ Jordan, Michael I. (1986). \"Attractor dynamics and parallelism in a connectionist sequential machine\". Proceedings of the Annual Meeting of the Cognitive Science Society. 8. - ^ Elman, Jeffrey L. (March 1990). \"Finding Structure in Time\". Cognitive Science. 14 (2): 179–211. doi:10.1207/s15516709cog1402_1. ISSN 0364-0213. - ^ a b c Schmidhuber, Jürgen (April 1991). \"Neural Sequence Chunkers\" (PDF). TR FKI-148, TU Munich. - ^ a b Schmidhuber, Jürgen (1992). \"Learning complex, extended sequences using the principle of history compression (based on TR FKI-148, 1991)\" (PDF). Neural Computation. 4 (2): 234–242. doi:10.1162/neco.1992.4.2.234. S2CID 18271205. - ^ Schmidhuber, Jürgen (1993). Habilitation thesis: System modeling and optimization (PDF). Archived from the original (PDF) on May 16, 2022. Page 150 ff demonstrates credit assignment across the equivalent of 1,200 layers in an unfolded RNN. - ^ a b c S. Hochreiter., \"Untersuchungen zu dynamischen neuronalen Netzen\". Archived 2015-03-06 at the Wayback Machine. Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber, 1991. - ^ Hochreiter, S.; et al. (15 January 2001). \"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies\". In Kolen, John F.; Kremer, Stefan C. (eds.). A Field Guide to Dynamical Recurrent Networks. John Wiley & Sons. ISBN 978-0-7803-5369-5. - ^ Sepp Hochreiter; Jürgen Schmidhuber (21 August 1995), Long Short Term Memory, Wikidata Q98967430 - ^ Gers, Felix; Schmidhuber, Jürgen; Cummins, Fred (1999). \"Learning to forget: Continual prediction with LSTM\". 9th International Conference on Artificial Neural Networks: ICANN '99. Vol. 1999. pp. 850–855. doi:10.1049/cp:19991218. ISBN 0-85296-721-7. - ^ a b Schmidhuber, Jürgen (1991). \"A possibility for implementing curiosity and boredom in model-building neural controllers\". Proc. SAB'1991. MIT Press/Bradford Books. pp. 222–227. - ^ Schmidhuber, Jürgen (2010). \"Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-2010)\". IEEE Transactions on Autonomous Mental Development. 2 (3): 230–247. Bibcode:2010ITAMD...2..230S. doi:10.1109/TAMD.2010.2056368. S2CID 234198. - ^ a b Schmidhuber, Jürgen (2020). \"Generative Adversarial Networks are Special Cases of Artificial Curiosity (1990) and also Closely Related to Predictability Minimization (1991)\". Neural Networks. 127: 58–66. arXiv:1906.04493. doi:10.1016/j.neunet.2020.04.008. PMID 32334341. S2CID 216056336. - ^ Ackley, David H.; Hinton, Geoffrey E.; Sejnowski, Terrence J. (1985-01-01). \"A learning algorithm for boltzmann machines\". Cognitive Science. 9 (1): 147–169. doi:10.1016/S0364-0213(85)80012-4. ISSN 0364-0213. - ^ Smolensky, Paul (1986). \"Chapter 6: Information Processing in Dynamical Systems: Foundations of Harmony Theory\" (PDF). In Rumelhart, David E.; McLelland, James L. (eds.). Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations. MIT Press. pp. 194–281. ISBN 0-262-68053-X. - ^ Peter, Dayan; Hinton, Geoffrey E.; Neal, Radford M.; Zemel, Richard S. (1995). \"The Helmholtz machine\". Neural Computation. 7 (5): 889–904. doi:10.1162/neco.1995.7.5.889. hdl:21.11116/0000-0002-D6D3-E. PMID 7584891. S2CID 1890561. - ^ Hinton, Geoffrey E.; Dayan, Peter; Frey, Brendan J.; Neal, Radford (1995-05-26). \"The wake-sleep algorithm for unsupervised neural networks\". Science. 268 (5214): 1158–1161. Bibcode:1995Sci...268.1158H. doi:10.1126/science.7761831. PMID 7761831. S2CID 871473. - ^ Sejnowski, Terrence J. (2018). The Deep Learning Revolution. Cambridge, Massachusetts: The MIT Press. ISBN 978-0-262-03803-4. - ^ Qian, Ning; Sejnowski, Terrence J. (1988-08-20). \"Predicting the secondary structure of globular proteins using neural network models\". Journal of Molecular Biology. 202 (4): 865–884. Bibcode:1988JMBio.202..865Q. doi:10.1016/0022-2836(88)90564-5. ISSN 0022-2836. PMID 3172241. - ^ Morgan, Nelson; Bourlard, Hervé; Renals, Steve; Cohen, Michael; Franco, Horacio (1 August 1993). \"Hybrid neural network/hidden markov model systems for continuous speech recognition\". International Journal of Pattern Recognition and Artificial Intelligence. 07 (4): 899–916. doi:10.1142/s0218001493000455. ISSN 0218-0014. - ^ Robinson, T. (1992). \"A real-time recurrent error propagation network word recognition system\". ICASSP. Icassp'92: 617–620. ISBN 978-0-7803-0532-8. Archived from the original on 2021-05-09. Retrieved 2017-06-12. - ^ Waibel, A.; Hanazawa, T.; Hinton, G.; Shikano, K.; Lang, K. J. (March 1989). \"Phoneme recognition using time-delay neural networks\" (PDF). IEEE Transactions on Acoustics, Speech, and Signal Processing. 37 (3): 328–339. Bibcode:1989ITASS..37..328W. doi:10.1109/29.21701. hdl:10338.dmlcz/135496. ISSN 0096-3518. S2CID 9563026. Archived (PDF) from the original on 2021-04-27. Retrieved 2019-09-24. - ^ Baker, J.; Deng, Li; Glass, Jim; Khudanpur, S.; Lee, C.-H.; Morgan, N.; O'Shaughnessy, D. (2009). \"Research Developments and Directions in Speech Recognition and Understanding, Part 1\". IEEE Signal Processing Magazine. 26 (3): 75–80. Bibcode:2009ISPM...26...75B. doi:10.1109/msp.2009.932166. hdl:1721.1/51891. S2CID 357467. - ^ Bengio, Y. (1991). \"Artificial Neural Networks and their Application to Speech/Sequence Recognition\". McGill University Ph.D. thesis. Archived from the original on 2021-05-09. Retrieved 2017-06-12. - ^ Deng, L.; Hassanein, K.; Elmasry, M. (1994). \"Analysis of correlation structure for a neural predictive model with applications to speech recognition\". Neural Networks. 7 (2): 331–339. doi:10.1016/0893-6080(94)90027-2. - ^ Doddington, G.; Przybocki, M.; Martin, A.; Reynolds, D. (2000). \"The NIST speaker recognition evaluation ± Overview, methodology, systems, results, perspective\". Speech Communication. 31 (2): 225–254. doi:10.1016/S0167-6393(99)00080-1. - ^ a b Heck, L.; Konig, Y.; Sonmez, M.; Weintraub, M. (2000). \"Robustness to Telephone Handset Distortion in Speaker Recognition by Discriminative Feature Design\". Speech Communication. 31 (2): 181–192. doi:10.1016/s0167-6393(99)00077-1. - ^ L.P Heck and R. Teunen. \"Secure and Convenient Transactions with Nuance Verifier\". Nuance Users Conference, April 1998. - ^ \"Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR (PDF Download Available)\". ResearchGate. Archived from the original on 9 May 2021. Retrieved 14 June 2017. - ^ a b Graves, Alex; Eck, Douglas; Beringer, Nicole; Schmidhuber, Jürgen (2003). \"Biologically Plausible Speech Recognition with LSTM Neural Nets\" (PDF). 1st Intl. Workshop on Biologically Inspired Approaches to Advanced Information Technology, Bio-ADIT 2004, Lausanne, Switzerland. pp. 175–184. Archived from the original (PDF) on 2017-07-06. Retrieved 2016-04-09. - ^ Graves, Alex; Fernández, Santiago; Gomez, Faustino; Schmidhuber, Jürgen (2006). \"Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks\". Proceedings of the International Conference on Machine Learning, ICML 2006: 369–376. CiteSeerX 10.1.1.75.6306. - ^ Santiago Fernandez, Alex Graves, and Jürgen Schmidhuber (2007). An application of recurrent neural networks to discriminative keyword spotting Archived 2018-11-18 at the Wayback Machine. Proceedings of ICANN (2), pp. 220–229. - ^ Graves, Alex; and Schmidhuber, Jürgen; Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks, in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.), Advances in Neural Information Processing Systems 22 (NIPS'22), December 7th–10th, 2009, Vancouver, BC, Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552 - ^ Hinton, Geoffrey E. (1 October 2007). \"Learning multiple layers of representation\". Trends in Cognitive Sciences. 11 (10): 428–434. doi:10.1016/j.tics.2007.09.004. ISSN 1364-6613. PMID 17921042. S2CID 15066318. Archived from the original on 11 October 2013. Retrieved 12 June 2017. - ^ Hinton, G. E.; Osindero, S.; Teh, Y. W. (2006). \"A Fast Learning Algorithm for Deep Belief Nets\" (PDF). Neural Computation. 18 (7): 1527–1554. doi:10.1162/neco.2006.18.7.1527. PMID 16764513. S2CID 2309950. Archived (PDF) from the original on 2015-12-23. Retrieved 2011-07-20. - ^ G. E. Hinton., \"Learning multiple layers of representation\". Archived 2018-05-22 at the Wayback Machine. Trends in Cognitive Sciences, 11, pp. 428–434, 2007. - ^ Hinton, Geoffrey E. (October 2007). \"Learning multiple layers of representation\". Trends in Cognitive Sciences. 11 (10): 428–434. doi:10.1016/j.tics.2007.09.004. PMID 17921042. - ^ Hinton, Geoffrey E.; Osindero, Simon; Teh, Yee-Whye (July 2006). \"A Fast Learning Algorithm for Deep Belief Nets\". Neural Computation. 18 (7): 1527–1554. doi:10.1162/neco.2006.18.7.1527. ISSN 0899-7667. PMID 16764513. - ^ Hinton, Geoffrey E. (2009-05-31). \"Deep belief networks\". Scholarpedia. 4 (5): 5947. Bibcode:2009SchpJ...4.5947H. doi:10.4249/scholarpedia.5947. ISSN 1941-6016. - ^ Yann LeCun (2016). Slides on Deep Learning Online Archived 2016-04-23 at the Wayback Machine - ^ a b c Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups\". IEEE Signal Processing Magazine. 29 (6): 82–97. Bibcode:2012ISPM...29...82H. doi:10.1109/msp.2012.2205597. S2CID 206485943. - ^ a b c Deng, L.; Hinton, G.; Kingsbury, B. (May 2013). \"New types of deep neural network learning for speech recognition and related applications: An overview (ICASSP)\" (PDF). Microsoft. Archived (PDF) from the original on 2017-09-26. Retrieved 27 December 2023. - ^ a b c Yu, D.; Deng, L. (2014). Automatic Speech Recognition: A Deep Learning Approach (Publisher: Springer). Springer. ISBN 978-1-4471-5779-3. - ^ \"Deng receives prestigious IEEE Technical Achievement Award - Microsoft Research\". Microsoft Research. 3 December 2015. Archived from the original on 16 March 2018. Retrieved 16 March 2018. - ^ a b Li, Deng (September 2014). \"Keynote talk: 'Achievements and Challenges of Deep Learning - From Speech Analysis and Recognition To Language and Multimodal Processing'\". Interspeech. Archived from the original on 2017-09-26. Retrieved 2017-06-12. - ^ Yu, D.; Deng, L. (2010). \"Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition\". NIPS Workshop on Deep Learning and Unsupervised Feature Learning. Archived from the original on 2017-10-12. Retrieved 2017-06-14. - ^ Seide, F.; Li, G.; Yu, D. (2011). \"Conversational speech transcription using context-dependent deep neural networks\". Interspeech 2011. pp. 437–440. doi:10.21437/Interspeech.2011-169. S2CID 398770. Archived from the original on 2017-10-12. Retrieved 2017-06-14. - ^ Deng, Li; Li, Jinyu; Huang, Jui-Ting; Yao, Kaisheng; Yu, Dong; Seide, Frank; Seltzer, Mike; Zweig, Geoff; He, Xiaodong (1 May 2013). \"Recent Advances in Deep Learning for Speech Research at Microsoft\". Microsoft Research. Archived from the original on 12 October 2017. Retrieved 14 June 2017. - ^ a b Oh, K.-S.; Jung, K. (2004). \"GPU implementation of neural networks\". Pattern Recognition. 37 (6): 1311–1314. Bibcode:2004PatRe..37.1311O. doi:10.1016/j.patcog.2004.01.013. - ^ a b Chellapilla, Kumar; Puri, Sidd; Simard, Patrice (2006), High performance convolutional neural networks for document processing, archived from the original on 2020-05-18, retrieved 2021-02-14 - ^ Sze, Vivienne; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel (2017). \"Efficient Processing of Deep Neural Networks: A Tutorial and Survey\". arXiv:1703.09039 [cs.CV]. - ^ Raina, Rajat; Madhavan, Anand; Ng, Andrew Y. (2009-06-14). \"Large-scale deep unsupervised learning using graphics processors\". Proceedings of the 26th Annual International Conference on Machine Learning. ICML '09. New York, NY, USA: Association for Computing Machinery. pp. 873–880. doi:10.1145/1553374.1553486. ISBN 978-1-60558-516-1. - ^ Cireşan, Dan Claudiu; Meier, Ueli; Gambardella, Luca Maria; Schmidhuber, Jürgen (21 September 2010). \"Deep, Big, Simple Neural Nets for Handwritten Digit Recognition\". Neural Computation. 22 (12): 3207–3220. arXiv:1003.0358. Bibcode:2010NeCom..22.3207C. doi:10.1162/neco_a_00052. ISSN 0899-7667. PMID 20858131. S2CID 1918673. - ^ Ciresan, D. C.; Meier, U.; Masci, J.; Gambardella, L.M.; Schmidhuber, J. (2011). \"Flexible, High Performance Convolutional Neural Networks for Image Classification\" (PDF). International Joint Conference on Artificial Intelligence. doi:10.5591/978-1-57735-516-8/ijcai11-210. Archived (PDF) from the original on 2014-09-29. Retrieved 2017-06-13. - ^ Ciresan, Dan; Giusti, Alessandro; Gambardella, Luca M.; Schmidhuber, Jürgen (2012). Pereira, F.; Burges, C. J. C.; Bottou, L.; Weinberger, K. Q. (eds.). Advances in Neural Information Processing Systems 25 (PDF). Curran Associates, Inc. pp. 2843–2851. Archived (PDF) from the original on 2017-08-09. Retrieved 2017-06-13. - ^ Ciresan, D.; Giusti, A.; Gambardella, L.M.; Schmidhuber, J. (2013). \"Mitosis Detection in Breast Cancer Histology Images with Deep Neural Networks\". Medical Image Computing and Computer-Assisted Intervention – MICCAI 2013. Lecture Notes in Computer Science. Vol. 7908. pp. 411–418. doi:10.1007/978-3-642-40763-5_51. ISBN 978-3-642-38708-1. PMID 24579167. - ^ Ng, Andrew; Dean, Jeff (2012). \"Building High-level Features Using Large Scale Unsupervised Learning\". arXiv:1112.6209 [cs.LG]. - ^ Simonyan, Karen; Andrew, Zisserman (2014). \"Very Deep Convolution Networks for Large Scale Image Recognition\". arXiv:1409.1556 [cs.CV]. - ^ Szegedy, Christian (2015). \"Going deeper with convolutions\" (PDF). Cvpr2015. arXiv:1409.4842. - ^ Vinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2014). \"Show and Tell: A Neural Image Caption Generator\". arXiv:1411.4555 [cs.CV].. - ^ Fang, Hao; Gupta, Saurabh; Iandola, Forrest; Srivastava, Rupesh; Deng, Li; Dollár, Piotr; Gao, Jianfeng; He, Xiaodong; Mitchell, Margaret; Platt, John C; Lawrence Zitnick, C; Zweig, Geoffrey (2014). \"From Captions to Visual Concepts and Back\". arXiv:1411.4952 [cs.CV].. - ^ Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Richard S (2014). \"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\". arXiv:1411.2539 [cs.LG].. - ^ Simonyan, Karen; Zisserman, Andrew (2015-04-10), Very Deep Convolutional Networks for Large-Scale Image Recognition, arXiv:1409.1556 - ^ He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (2016). \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\". arXiv:1502.01852 [cs.CV]. - ^ He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (10 Dec 2015). Deep Residual Learning for Image Recognition. arXiv:1512.03385. - ^ He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (2016). \"Deep Residual Learning for Image Recognition\". 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Las Vegas, NV, USA: IEEE. pp. 770–778. arXiv:1512.03385. doi:10.1109/CVPR.2016.90. ISBN 978-1-4673-8851-1. - ^ Gatys, Leon A.; Ecker, Alexander S.; Bethge, Matthias (26 August 2015). \"A Neural Algorithm of Artistic Style\". arXiv:1508.06576 [cs.CV]. - ^ Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). Generative Adversarial Networks (PDF). Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp. 2672–2680. Archived (PDF) from the original on 22 November 2019. Retrieved 20 August 2019. - ^ \"GAN 2.0: NVIDIA's Hyperrealistic Face Generator\". SyncedReview.com. December 14, 2018. Retrieved October 3, 2019. - ^ Karras, T.; Aila, T.; Laine, S.; Lehtinen, J. (26 February 2018). \"Progressive Growing of GANs for Improved Quality, Stability, and Variation\". arXiv:1710.10196 [cs.NE]. - ^ \"Prepare, Don't Panic: Synthetic Media and Deepfakes\". witness.org. Archived from the original on 2 December 2020. Retrieved 25 November 2020. - ^ Sohl-Dickstein, Jascha; Weiss, Eric; Maheswaranathan, Niru; Ganguli, Surya (2015-06-01). \"Deep Unsupervised Learning using Nonequilibrium Thermodynamics\" (PDF). Proceedings of the 32nd International Conference on Machine Learning. 37. PMLR: 2256–2265. arXiv:1503.03585. - ^ Google Research Blog. The neural networks behind Google Voice transcription. August 11, 2015. By Françoise Beaufays http://googleresearch.blogspot.co.at/2015/08/the-neural-networks-behind-google-voice.html - ^ a b Sak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 2015). \"Google voice search: faster and more accurate\". Archived from the original on 2016-03-09. Retrieved 2016-04-09. - ^ Singh, Premjeet; Saha, Goutam; Sahidullah, Md (2021). \"Non-linear frequency warping using constant-Q transformation for speech emotion recognition\". 2021 International Conference on Computer Communication and Informatics (ICCCI). pp. 1–4. arXiv:2102.04029. doi:10.1109/ICCCI50826.2021.9402569. ISBN 978-1-7281-5875-4. S2CID 231846518. - ^ Sak, Hasim; Senior, Andrew; Beaufays, Francoise (2014). \"Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling\" (PDF). Archived from the original (PDF) on 24 April 2018. - ^ Li, Xiangang; Wu, Xihong (2014). \"Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition\". arXiv:1410.4281 [cs.CL]. - ^ Zen, Heiga; Sak, Hasim (2015). \"Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis\" (PDF). Google.com. ICASSP. pp. 4470–4474. Archived (PDF) from the original on 2021-05-09. Retrieved 2017-06-13. - ^ \"2018 ACM A.M. Turing Award Laureates\". awards.acm.org. Retrieved 2024-08-07. - ^ Ferrie, C., & Kaiser, S. (2019). Neural Networks for Babies. Sourcebooks. ISBN 978-1-4926-7120-6. {{cite book}} : CS1 maint: multiple names: authors list (link) - ^ Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda (January 2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSN 1476-4687. PMID 26819042. S2CID 515925. - ^ A Guide to Deep Learning and Neural Networks, archived from the original on 2020-11-02, retrieved 2020-11-16 - ^ a b Kumar, Nishant; Raubal, Martin (2021). \"Applications of deep learning in congestion detection, prediction and alleviation: A survey\". Transportation Research Part C: Emerging Technologies. 133 103432. arXiv:2102.09759. Bibcode:2021TRPC..13303432K. doi:10.1016/j.trc.2021.103432. hdl:10230/42143. S2CID 240420107. - ^ Szegedy, Christian; Toshev, Alexander; Erhan, Dumitru (2013). \"Deep neural networks for object detection\". Advances in Neural Information Processing Systems: 2553–2561. Archived from the original on 2017-06-29. Retrieved 2017-06-13. - ^ Rolnick, David; Tegmark, Max (2018). \"The power of deeper networks for expressing natural functions\". International Conference on Learning Representations. ICLR 2018. Archived from the original on 2021-01-07. Retrieved 2021-01-05. - ^ Hof, Robert D. \"Is Artificial Intelligence Finally Coming into Its Own?\". MIT Technology Review. Archived from the original on 31 March 2019. Retrieved 10 July 2018. - ^ a b Gers, Felix A.; Schmidhuber, Jürgen (2001). \"LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages\". IEEE Transactions on Neural Networks. 12 (6): 1333–1340. Bibcode:2001ITNN...12.1333G. doi:10.1109/72.963769. PMID 18249962. S2CID 10192330. Archived from the original on 2020-01-26. Retrieved 2020-02-25. - ^ a b c Sutskever, L.; Vinyals, O.; Le, Q. (2014). \"Sequence to Sequence Learning with Neural Networks\" (PDF). Proc. NIPS. arXiv:1409.3215. Bibcode:2014arXiv1409.3215S. Archived (PDF) from the original on 2021-05-09. Retrieved 2017-06-13. - ^ a b Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). \"Exploring the Limits of Language Modeling\". arXiv:1602.02410 [cs.CL]. - ^ a b Gillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015). \"Multilingual Language Processing from Bytes\". arXiv:1512.00103 [cs.CL]. - ^ Mikolov, T.; et al. (2010). \"Recurrent neural network based language model\" (PDF). Interspeech: 1045–1048. doi:10.21437/Interspeech.2010-343. S2CID 17048224. Archived (PDF) from the original on 2017-05-16. Retrieved 2017-06-13. - ^ Hochreiter, Sepp; Schmidhuber, Jürgen (1 November 1997). \"Long Short-Term Memory\". Neural Computation. 9 (8): 1735–1780. doi:10.1162/neco.1997.9.8.1735. ISSN 0899-7667. PMID 9377276. S2CID 1915014. - ^ a b \"Learning Precise Timing with LSTM Recurrent Networks (PDF Download Available)\". ResearchGate. Archived from the original on 9 May 2021. Retrieved 13 June 2017. - ^ LeCun, Y.; et al. (1998). \"Gradient-based learning applied to document recognition\". Proceedings of the IEEE. 86 (11): 2278–2324. Bibcode:1998IEEEP..86.2278L. doi:10.1109/5.726791. S2CID 14542261. - ^ Sainath, Tara N.; Mohamed, Abdel-Rahman; Kingsbury, Brian; Ramabhadran, Bhuvana (2013). \"Deep convolutional neural networks for LVCSR\". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. pp. 8614–8618. doi:10.1109/icassp.2013.6639347. ISBN 978-1-4799-0356-6. S2CID 13816461. - ^ Bengio, Yoshua; Boulanger-Lewandowski, Nicolas; Pascanu, Razvan (2013). \"Advances in optimizing recurrent networks\". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. pp. 8624–8628. arXiv:1212.0901. CiteSeerX 10.1.1.752.9151. doi:10.1109/icassp.2013.6639349. ISBN 978-1-4799-0356-6. S2CID 12485056. - ^ Dahl, G.; et al. (2013). \"Improving DNNs for LVCSR using rectified linear units and dropout\" (PDF). ICASSP. Archived (PDF) from the original on 2017-08-12. Retrieved 2017-06-13. - ^ Kumar, Nishant; Martin, Henry; Raubal, Martin (2024). \"Enhancing Deep Learning-Based City-Wide Traffic Prediction Pipelines Through Complexity Analysis\". Data Science for Transportation. 6 (3) 24. doi:10.1007/s42421-024-00109-x. hdl:20.500.11850/695425. - ^ \"Data Augmentation - deeplearning.ai | Coursera\". Coursera. Archived from the original on 1 December 2017. Retrieved 30 November 2017. - ^ Hinton, G. E. (2010). \"A Practical Guide to Training Restricted Boltzmann Machines\". Tech. Rep. UTML TR 2010-003. Archived from the original on 2021-05-09. Retrieved 2017-06-13. - ^ You, Yang; Buluç, Aydın; Demmel, James (November 2017). \"Scaling deep learning on GPU and knights landing clusters\". Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis on - SC '17. SC '17, ACM. pp. 1–12. arXiv:1708.02983. doi:10.1145/3126908.3126912. ISBN 978-1-4503-5114-0. S2CID 8869270. Archived from the original on 29 July 2020. Retrieved 5 March 2018. - ^ Viebke, André; Memeti, Suejb; Pllana, Sabri; Abraham, Ajith (2019). \"CHAOS: a parallelization scheme for training convolutional neural networks on Intel Xeon Phi\". The Journal of Supercomputing. 75: 197–227. arXiv:1702.07908. Bibcode:2017arXiv170207908V. doi:10.1007/s11227-017-1994-x. S2CID 14135321. - ^ Ting Qin, et al. \"A learning algorithm of CMAC based on RLS\". Neural Processing Letters 19.1 (2004): 49-61. - ^ Ting Qin, et al. \"Continuous CMAC-QRLS and its systolic array\". Archived 2018-11-18 at the Wayback Machine. Neural Processing Letters 22.1 (2005): 1-16. - ^ Research, AI (23 October 2015). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition\". airesearch.com. Archived from the original on 1 February 2016. Retrieved 23 October 2015. - ^ \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. December 2019. Archived from the original on 10 June 2020. Retrieved 11 June 2020. - ^ Ray, Tiernan (2019). \"AI is changing the entire nature of computation\". ZDNet. Archived from the original on 25 May 2020. Retrieved 11 June 2020. - ^ \"AI and Compute\". OpenAI. 16 May 2018. Archived from the original on 17 June 2020. Retrieved 11 June 2020. - ^ \"HUAWEI Reveals the Future of Mobile AI at IFA 2017 | HUAWEI Latest News | HUAWEI Global\". consumer.huawei.com. - ^ P, JouppiNorman; YoungCliff; PatilNishant; PattersonDavid; AgrawalGaurav; BajwaRaminder; BatesSarah; BhatiaSuresh; BodenNan; BorchersAl; BoyleRick (2017-06-24). \"In-Datacenter Performance Analysis of a Tensor Processing Unit\". ACM SIGARCH Computer Architecture News. 45 (2): 1–12. arXiv:1704.04760. doi:10.1145/3140659.3080246. - ^ Woodie, Alex (2021-11-01). \"Cerebras Hits the Accelerator for Deep Learning Workloads\". Datanami. Retrieved 2022-08-03. - ^ \"Cerebras launches new AI supercomputing processor with 2.6 trillion transistors\". VentureBeat. 2021-04-20. Retrieved 2022-08-03. - ^ Marega, Guilherme Migliato; Zhao, Yanfei; Avsar, Ahmet; Wang, Zhenyu; Tripati, Mukesh; Radenovic, Aleksandra; Kis, Anras (2020). \"Logic-in-memory based on an atomically thin semiconductor\". Nature. 587 (2): 72–77. Bibcode:2020Natur.587...72M. doi:10.1038/s41586-020-2861-0. PMC 7116757. PMID 33149289. - ^ a b c Feldmann, J.; Youngblood, N.; Karpov, M.; et al. (2021). \"Parallel convolutional processing using an integrated photonic tensor\". Nature. 589 (2): 52–58. arXiv:2002.00281. doi:10.1038/s41586-020-03070-1. PMID 33408373. S2CID 211010976. - ^ Garofolo, J.S.; Lamel, L.F.; Fisher, W.M.; Fiscus, J.G.; Pallett, D.S.; Dahlgren, N.L.; Zue, V. (1993). TIMIT Acoustic-Phonetic Continuous Speech Corpus. Linguistic Data Consortium. doi:10.35111/17gk-bn40. ISBN 1-58563-019-5. Retrieved 27 December 2023. - ^ Robinson, Tony (30 September 1991). \"Several Improvements to a Recurrent Error Propagation Network Phone Recognition System\". Cambridge University Engineering Department Technical Report. CUED/F-INFENG/TR82. doi:10.13140/RG.2.2.15418.90567. - ^ Abdel-Hamid, O.; et al. (2014). \"Convolutional Neural Networks for Speech Recognition\". IEEE/ACM Transactions on Audio, Speech, and Language Processing. 22 (10): 1533–1545. Bibcode:2014ITASL..22.1533A. doi:10.1109/taslp.2014.2339736. S2CID 206602362. Archived from the original on 2020-09-22. Retrieved 2018-04-20. - ^ Deng, L.; Platt, J. (2014). \"Ensemble Deep Learning for Speech Recognition\". Proc. Interspeech: 1915–1919. doi:10.21437/Interspeech.2014-433. S2CID 15641618. - ^ Tóth, Laszló (2015). \"Phone Recognition with Hierarchical Convolutional Deep Maxout Networks\" (PDF). EURASIP Journal on Audio, Speech, and Music Processing. 2015 25. doi:10.1186/s13636-015-0068-3. S2CID 217950236. Archived (PDF) from the original on 2020-09-24. Retrieved 2019-04-01. - ^ Aaron van den Oord; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray (2016). \"WaveNet: A Generative Model for Raw Audio\". arXiv:1609.03499 [cs.SD]. - ^ \"WaveNet: A generative model for raw audio\". Google DeepMind. 2016-09-08. Retrieved 2025-07-31. - ^ Latif, Siddique; Zaidi, Aun; Cuayahuitl, Heriberto; Shamshad, Fahad; Shoukat, Moazzam; Usama, Muhammad; Qadir, Junaid (2023). \"Transformers in Speech Processing: A Survey\". arXiv:2303.11607 [cs.CL]. - ^ McMillan, Robert (17 December 2014). \"How Skype Used AI to Build Its Amazing New Language Translator | WIRED\". Wired. Archived from the original on 8 June 2017. Retrieved 14 June 2017. - ^ Hannun, Awni; Case, Carl; Casper, Jared; Catanzaro, Bryan; Diamos, Greg; Elsen, Erich; Prenger, Ryan; Satheesh, Sanjeev; Sengupta, Shubho; Coates, Adam; Ng, Andrew Y (2014). \"Deep Speech: Scaling up end-to-end speech recognition\". arXiv:1412.5567 [cs.CL]. - ^ \"MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges\". yann.lecun.com. Archived from the original on 2014-01-13. Retrieved 2014-01-28. - ^ Cireşan, Dan; Meier, Ueli; Masci, Jonathan; Schmidhuber, Jürgen (August 2012). \"Multi-column deep neural network for traffic sign classification\". Neural Networks. Selected Papers from IJCNN 2011. 32: 333–338. CiteSeerX 10.1.1.226.8219. doi:10.1016/j.neunet.2012.02.023. PMID 22386783. - ^ Chaochao Lu; Xiaoou Tang (2014). \"Surpassing Human Level Face Recognition\". arXiv:1404.3840 [cs.CV]. - ^ Nvidia Demos a Car Computer Trained with \"Deep Learning\" (6 January 2015), David Talbot, MIT Technology Review - ^ a b c G. W. Smith; Frederic Fol Leymarie (10 April 2017). \"The Machine as Artist: An Introduction\". Arts. 6 (4): 5. doi:10.3390/arts6020005. - ^ a b c Blaise Agüera y Arcas (29 September 2017). \"Art in the Age of Machine Intelligence\". Arts. 6 (4): 18. doi:10.3390/arts6040018. - ^ Goldberg, Yoav; Levy, Omar (2014). \"word2vec Explained: Deriving Mikolov et al.'s Negative-Sampling Word-Embedding Method\". arXiv:1402.3722 [cs.CL]. - ^ a b Socher, Richard; Manning, Christopher. \"Deep Learning for NLP\" (PDF). Archived (PDF) from the original on 6 July 2014. Retrieved 26 October 2014. - ^ Socher, Richard; Bauer, John; Manning, Christopher; Ng, Andrew (2013). \"Parsing With Compositional Vector Grammars\" (PDF). Proceedings of the ACL 2013 Conference. Archived (PDF) from the original on 2014-11-27. Retrieved 2014-09-03. - ^ Socher, R.; Perelygin, A.; Wu, J.; Chuang, J.; Manning, C.D.; Ng, A.; Potts, C. (October 2013). \"Recursive Deep Models for Semantic Compositionality over a Sentiment Treebank\" (PDF). Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. pp. 1631–1642. doi:10.18653/v1/D13-1170. Archived (PDF) from the original on 28 December 2016. Retrieved 21 December 2023. - ^ Shen, Yelong; He, Xiaodong; Gao, Jianfeng; Deng, Li; Mesnil, Gregoire (1 November 2014). \"A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval\". Microsoft Research. Archived from the original on 27 October 2017. Retrieved 14 June 2017. - ^ Huang, Po-Sen; He, Xiaodong; Gao, Jianfeng; Deng, Li; Acero, Alex; Heck, Larry (1 October 2013). \"Learning Deep Structured Semantic Models for Web Search using Clickthrough Data\". Microsoft Research. Archived from the original on 27 October 2017. Retrieved 14 June 2017. - ^ Mesnil, G.; Dauphin, Y.; Yao, K.; Bengio, Y.; Deng, L.; Hakkani-Tur, D.; He, X.; Heck, L.; Tur, G.; Yu, D.; Zweig, G. (2015). \"Using recurrent neural networks for slot filling in spoken language understanding\". IEEE Transactions on Audio, Speech, and Language Processing. 23 (3): 530–539. Bibcode:2015ITASL..23..530M. doi:10.1109/taslp.2014.2383614. S2CID 1317136. - ^ a b Gao, Jianfeng; He, Xiaodong; Yih, Scott Wen-tau; Deng, Li (1 June 2014). \"Learning Continuous Phrase Representations for Translation Modeling\". Microsoft Research. Archived from the original on 27 October 2017. Retrieved 14 June 2017. - ^ Brocardo, Marcelo Luiz; Traore, Issa; Woungang, Isaac; Obaidat, Mohammad S. (2017). \"Authorship verification using deep belief network systems\". International Journal of Communication Systems. 30 (12) e3259. doi:10.1002/dac.3259. S2CID 40745740. - ^ Kariampuzha, William; Alyea, Gioconda; Qu, Sue; Sanjak, Jaleal; Mathé, Ewy; Sid, Eric; Chatelaine, Haley; Yadaw, Arjun; Xu, Yanji; Zhu, Qian (2023). \"Precision information extraction for rare disease epidemiology at scale\". Journal of Translational Medicine. 21 (1): 157. doi:10.1186/s12967-023-04011-y. PMC 9972634. PMID 36855134. - ^ \"Deep Learning for Natural Language Processing: Theory and Practice (CIKM2014 Tutorial) - Microsoft Research\". Microsoft Research. Archived from the original on 13 March 2017. Retrieved 14 June 2017. - ^ Turovsky, Barak (15 November 2016). \"Found in translation: More accurate, fluent sentences in Google Translate\". The Keyword Google Blog. Archived from the original on 7 April 2017. Retrieved 23 March 2017. - ^ a b c d Schuster, Mike; Johnson, Melvin; Thorat, Nikhil (22 November 2016). \"Zero-Shot Translation with Google's Multilingual Neural Machine Translation System\". Google Research Blog. Archived from the original on 10 July 2017. Retrieved 23 March 2017. - ^ Wu, Yonghui; Schuster, Mike; Chen, Zhifeng; Le, Quoc V; Norouzi, Mohammad; Macherey, Wolfgang; Krikun, Maxim; Cao, Yuan; Gao, Qin; Macherey, Klaus; Klingner, Jeff; Shah, Apurva; Johnson, Melvin; Liu, Xiaobing; Kaiser, Łukasz; Gouws, Stephan; Kato, Yoshikiyo; Kudo, Taku; Kazawa, Hideto; Stevens, Keith; Kurian, George; Patil, Nishant; Wang, Wei; Young, Cliff; Smith, Jason; Riesa, Jason; Rudnick, Alex; Vinyals, Oriol; Corrado, Greg; et al. (2016). \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\". arXiv:1609.08144 [cs.CL]. - ^ Metz, Cade (27 September 2016). \"An Infusion of AI Makes Google Translate More Powerful Than Ever\". Wired. Archived from the original on 8 November 2020. Retrieved 12 October 2017. - ^ a b Boitet, Christian; Blanchon, Hervé; Seligman, Mark; Bellynck, Valérie (2010). \"MT on and for the Web\" (PDF). Archived from the original (PDF) on 29 March 2017. Retrieved 1 December 2016. - ^ Arrowsmith, J; Miller, P (2013). \"Trial watch: Phase II and phase III attrition rates 2011-2012\". Nature Reviews Drug Discovery. 12 (8): 569. doi:10.1038/nrd4090. PMID 23903212. S2CID 20246434. - ^ Verbist, B; Klambauer, G; Vervoort, L; Talloen, W; The Qstar, Consortium; Shkedy, Z; Thas, O; Bender, A; Göhlmann, H. W.; Hochreiter, S (2015). \"Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project\". Drug Discovery Today. 20 (5): 505–513. doi:10.1016/j.drudis.2014.12.014. hdl:1942/18723. PMID 25582842. - ^ \"Merck Molecular Activity Challenge\". kaggle.com. Archived from the original on 2020-07-16. Retrieved 2020-07-16. - ^ \"Multi-task Neural Networks for QSAR Predictions | Data Science Association\". www.datascienceassn.org. Archived from the original on 30 April 2017. Retrieved 14 June 2017. - ^ \"Toxicology in the 21st century Data Challenge\" - ^ \"NCATS Announces Tox21 Data Challenge Winners\". Archived from the original on 2015-09-08. Retrieved 2015-03-05. - ^ \"NCATS Announces Tox21 Data Challenge Winners\". Archived from the original on 28 February 2015. Retrieved 5 March 2015. - ^ Wallach, Izhar; Dzamba, Michael; Heifets, Abraham (9 October 2015). \"AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery\". arXiv:1510.02855 [cs.LG]. - ^ a b \"Toronto startup has a faster way to discover effective medicines\". The Globe and Mail. Archived from the original on 20 October 2015. Retrieved 9 November 2015. - ^ \"Startup Harnesses Supercomputers to Seek Cures\". KQED Future of You. 27 May 2015. Archived from the original on 24 December 2015. Retrieved 9 November 2015. - ^ Gilmer, Justin; Schoenholz, Samuel S.; Riley, Patrick F.; Vinyals, Oriol; Dahl, George E. (2017-06-12). \"Neural Message Passing for Quantum Chemistry\". arXiv:1704.01212 [cs.LG]. - ^ Zhavoronkov, Alex (2019). \"Deep learning enables rapid identification of potent DDR1 kinase inhibitors\". Nature Biotechnology. 37 (9): 1038–1040. doi:10.1038/s41587-019-0224-x. PMID 31477924. S2CID 201716327. - ^ Gregory, Barber. \"A Molecule Designed By AI Exhibits 'Druglike' Qualities\". Wired. Archived from the original on 2020-04-30. Retrieved 2019-09-05. - ^ van den Oord, Aaron; Dieleman, Sander; Schrauwen, Benjamin (2013). Burges, C. J. C.; Bottou, L.; Welling, M.; Ghahramani, Z.; Weinberger, K. Q. (eds.). Advances in Neural Information Processing Systems 26 (PDF). Curran Associates, Inc. pp. 2643–2651. Archived (PDF) from the original on 2017-05-16. Retrieved 2017-06-14. - ^ Feng, X.Y.; Zhang, H.; Ren, Y.J.; Shang, P.H.; Zhu, Y.; Liang, Y.C.; Guan, R.C.; Xu, D. (2019). \"The Deep Learning–Based Recommender System \"Pubmender\" for Choosing a Biomedical Publication Venue: Development and Validation Study\". Journal of Medical Internet Research. 21 (5) e12957. doi:10.2196/12957. PMC 6555124. PMID 31127715. - ^ Elkahky, Ali Mamdouh; Song, Yang; He, Xiaodong (1 May 2015). \"A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems\". Microsoft Research. Archived from the original on 25 January 2018. Retrieved 14 June 2017. - ^ Chicco, Davide; Sadowski, Peter; Baldi, Pierre (1 January 2014). \"Deep autoencoder neural networks for gene ontology annotation predictions\". Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics. ACM. pp. 533–540. doi:10.1145/2649387.2649442. hdl:11311/964622. ISBN 978-1-4503-2894-4. S2CID 207217210. Archived from the original on 9 May 2021. Retrieved 23 November 2015. - ^ Sathyanarayana, Aarti (1 January 2016). \"Sleep Quality Prediction From Wearable Data Using Deep Learning\". JMIR mHealth and uHealth. 4 (4): e125. doi:10.2196/mhealth.6562. PMC 5116102. PMID 27815231. S2CID 3821594. - ^ Choi, Edward; Schuetz, Andy; Stewart, Walter F.; Sun, Jimeng (13 August 2016). \"Using recurrent neural network models for early detection of heart failure onset\". Journal of the American Medical Informatics Association. 24 (2): 361–370. doi:10.1093/jamia/ocw112. ISSN 1067-5027. PMC 5391725. PMID 27521897. - ^ \"DeepMind's protein-folding AI has solved a 50-year-old grand challenge of biology\". MIT Technology Review. Retrieved 2024-05-10. - ^ Shead, Sam (2020-11-30). \"DeepMind solves 50-year-old 'grand challenge' with protein folding A.I.\" CNBC. Retrieved 2024-05-10. - ^ a b Shalev, Y.; Painsky, A.; Ben-Gal, I. (2022). \"Neural Joint Entropy Estimation\" (PDF). IEEE Transactions on Neural Networks and Learning Systems. PP (4): 5488–5500. arXiv:2012.11197. doi:10.1109/TNNLS.2022.3204919. PMID 36155469. S2CID 229339809. - ^ Litjens, Geert; Kooi, Thijs; Bejnordi, Babak Ehteshami; Setio, Arnaud Arindra Adiyoso; Ciompi, Francesco; Ghafoorian, Mohsen; van der Laak, Jeroen A.W.M.; van Ginneken, Bram; Sánchez, Clara I. (December 2017). \"A survey on deep learning in medical image analysis\". Medical Image Analysis. 42: 60–88. arXiv:1702.05747. Bibcode:2017arXiv170205747L. doi:10.1016/j.media.2017.07.005. PMID 28778026. S2CID 2088679. - ^ Forslid, Gustav; Wieslander, Hakan; Bengtsson, Ewert; Wahlby, Carolina; Hirsch, Jan-Michael; Stark, Christina Runow; Sadanandan, Sajith Kecheril (2017). \"Deep Convolutional Neural Networks for Detecting Cellular Changes Due to Malignancy\". 2017 IEEE International Conference on Computer Vision Workshops (ICCVW). pp. 82–89. doi:10.1109/ICCVW.2017.18. ISBN 978-1-5386-1034-3. S2CID 4728736. Archived from the original on 2021-05-09. Retrieved 2019-11-12. - ^ Dong, Xin; Zhou, Yizhao; Wang, Lantian; Peng, Jingfeng; Lou, Yanbo; Fan, Yiqun (2020). \"Liver Cancer Detection Using Hybridized Fully Convolutional Neural Network Based on Deep Learning Framework\". IEEE Access. 8: 129889–129898. Bibcode:2020IEEEA...8l9889D. doi:10.1109/ACCESS.2020.3006362. ISSN 2169-3536. S2CID 220733699. - ^ Lyakhov, Pavel Alekseevich; Lyakhova, Ulyana Alekseevna; Nagornov, Nikolay Nikolaevich (2022-04-03). \"System for the Recognizing of Pigmented Skin Lesions with Fusion and Analysis of Heterogeneous Data Based on a Multimodal Neural Network\". Cancers. 14 (7): 1819. doi:10.3390/cancers14071819. ISSN 2072-6694. PMC 8997449. PMID 35406591. - ^ De, Shaunak; Maity, Abhishek; Goel, Vritti; Shitole, Sanjay; Bhattacharya, Avik (2017). \"Predicting the popularity of instagram posts for a lifestyle magazine using deep learning\". 2017 2nd International Conference on Communication Systems, Computing and IT Applications (CSCITA). pp. 174–177. doi:10.1109/CSCITA.2017.8066548. ISBN 978-1-5090-4381-1. S2CID 35350962. - ^ \"Colorizing and Restoring Old Images with Deep Learning\". FloydHub Blog. 13 November 2018. Archived from the original on 11 October 2019. Retrieved 11 October 2019. - ^ Schmidt, Uwe; Roth, Stefan. Shrinkage Fields for Effective Image Restoration (PDF). Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. Archived (PDF) from the original on 2018-01-02. Retrieved 2018-01-01. - ^ Kleanthous, Christos; Chatzis, Sotirios (2020). \"Gated Mixture Variational Autoencoders for Value Added Tax audit case selection\". Knowledge-Based Systems. 188 105048. doi:10.1016/j.knosys.2019.105048. S2CID 204092079. - ^ Czech, Tomasz (28 June 2018). \"Deep learning: the next frontier for money laundering detection\". Global Banking and Finance Review. Archived from the original on 2018-11-16. Retrieved 2018-07-15. - ^ Nuñez, Michael (2023-11-29). \"Google DeepMind's materials AI has already discovered 2.2 million new crystals\". VentureBeat. Retrieved 2023-12-19. - ^ Merchant, Amil; Batzner, Simon; Schoenholz, Samuel S.; Aykol, Muratahan; Cheon, Gowoon; Cubuk, Ekin Dogus (December 2023). \"Scaling deep learning for materials discovery\". Nature. 624 (7990): 80–85. Bibcode:2023Natur.624...80M. doi:10.1038/s41586-023-06735-9. ISSN 1476-4687. PMC 10700131. PMID 38030720. - ^ Peplow, Mark (2023-11-29). \"Google AI and robots join forces to build new materials\". Nature. doi:10.1038/d41586-023-03745-5. PMID 38030771. S2CID 265503872. - ^ a b c \"Army researchers develop new algorithms to train robots\". EurekAlert!. Archived from the original on 28 August 2018. Retrieved 29 August 2018. - ^ Raissi, M.; Perdikaris, P.; Karniadakis, G. E. (2019-02-01). \"Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations\". Journal of Computational Physics. 378: 686–707. Bibcode:2019JCoPh.378..686R. doi:10.1016/j.jcp.2018.10.045. ISSN 0021-9991. OSTI 1595805. S2CID 57379996. - ^ Mao, Zhiping; Jagtap, Ameya D.; Karniadakis, George Em (2020-03-01). \"Physics-informed neural networks for high-speed flows\". Computer Methods in Applied Mechanics and Engineering. 360 112789. Bibcode:2020CMAME.360k2789M. doi:10.1016/j.cma.2019.112789. ISSN 0045-7825. S2CID 212755458. - ^ Raissi, Maziar; Yazdani, Alireza; Karniadakis, George Em (2020-02-28). \"Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations\". Science. 367 (6481): 1026–1030. Bibcode:2020Sci...367.1026R. doi:10.1126/science.aaw4741. PMC 7219083. PMID 32001523. - ^ Huang, Yunfei and Greenberg, David S. \"Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates.\" Proceedings of the 42th international conference on Machine learning. ACM, 2025. - ^ Han, J.; Jentzen, A.; E, W. (2018). \"Solving high-dimensional partial differential equations using deep learning\". Proceedings of the National Academy of Sciences. 115 (34): 8505–8510. arXiv:1707.02568. Bibcode:2018PNAS..115.8505H. doi:10.1073/pnas.1718942115. PMC 6112690. PMID 30082389. - ^ Oktem, Figen S.; Kar, Oğuzhan Fatih; Bezek, Can Deniz; Kamalabadi, Farzad (2021). \"High-Resolution Multi-Spectral Imaging With Diffractive Lenses and Learned Reconstruction\". IEEE Transactions on Computational Imaging. 7: 489–504. arXiv:2008.11625. Bibcode:2021ITCI....7..489O. doi:10.1109/TCI.2021.3075349. ISSN 2333-9403. S2CID 235340737. - ^ Bernhardt, Melanie; Vishnevskiy, Valery; Rau, Richard; Goksel, Orcun (December 2020). \"Training Variational Networks With Multidomain Simulations: Speed-of-Sound Image Reconstruction\". IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control. 67 (12): 2584–2594. arXiv:2006.14395. Bibcode:2020ITUFF..67.2584B. doi:10.1109/TUFFC.2020.3010186. ISSN 1525-8955. PMID 32746211. S2CID 220055785. - ^ Lam, Remi; Sanchez-Gonzalez, Alvaro; Willson, Matthew; Wirnsberger, Peter; Fortunato, Meire; Alet, Ferran; Ravuri, Suman; Ewalds, Timo; Eaton-Rosen, Zach; Hu, Weihua; Merose, Alexander; Hoyer, Stephan; Holland, George; Vinyals, Oriol; Stott, Jacklynn (2023-12-22). \"Learning skillful medium-range global weather forecasting\". Science. 382 (6677): 1416–1421. arXiv:2212.12794. Bibcode:2023Sci...382.1416L. doi:10.1126/science.adi2336. ISSN 0036-8075. PMID 37962497. - ^ Sivakumar, Ramakrishnan (2023-11-27). \"GraphCast: A breakthrough in Weather Forecasting\". Medium. Retrieved 2024-05-19. - ^ Galkin, F.; Mamoshina, P.; Kochetov, K.; Sidorenko, D.; Zhavoronkov, A. (2020). \"DeepMAge: A Methylation Aging Clock Developed with Deep Learning\". Aging and Disease. doi:10.14336/AD. - ^ Utgoff, P. E.; Stracuzzi, D. J. (2002). \"Many-layered learning\". Neural Computation. 14 (10): 2497–2529. doi:10.1162/08997660260293319. PMID 12396572. S2CID 1119517. - ^ Elman, Jeffrey L. (1998). Rethinking Innateness: A Connectionist Perspective on Development. MIT Press. ISBN 978-0-262-55030-7. - ^ Shrager, J.; Johnson, MH (1996). \"Dynamic plasticity influences the emergence of function in a simple cortical array\". Neural Networks. 9 (7): 1119–1129. doi:10.1016/0893-6080(96)00033-0. PMID 12662587. - ^ Quartz, SR; Sejnowski, TJ (1997). \"The neural basis of cognitive development: A constructivist manifesto\". Behavioral and Brain Sciences. 20 (4): 537–556. CiteSeerX 10.1.1.41.7854. doi:10.1017/s0140525x97001581. PMID 10097006. S2CID 5818342. - ^ S. Blakeslee, \"In brain's early growth, timetable may be critical\", The New York Times, Science Section, pp. B5–B6, 1995. - ^ Mazzoni, P.; Andersen, R. A.; Jordan, M. I. (15 May 1991). \"A more biologically plausible learning rule for neural networks\". Proceedings of the National Academy of Sciences. 88 (10): 4433–4437. Bibcode:1991PNAS...88.4433M. doi:10.1073/pnas.88.10.4433. ISSN 0027-8424. PMC 51674. PMID 1903542. - ^ O'Reilly, Randall C. (1 July 1996). \"Biologically Plausible Error-Driven Learning Using Local Activation Differences: The Generalized Recirculation Algorithm\". Neural Computation. 8 (5): 895–938. doi:10.1162/neco.1996.8.5.895. ISSN 0899-7667. S2CID 2376781. - ^ Testolin, Alberto; Zorzi, Marco (2016). \"Probabilistic Models and Generative Neural Networks: Towards an Unified Framework for Modeling Normal and Impaired Neurocognitive Functions\". Frontiers in Computational Neuroscience. 10: 73. doi:10.3389/fncom.2016.00073. ISSN 1662-5188. PMC 4943066. PMID 27468262. S2CID 9868901. - ^ Testolin, Alberto; Stoianov, Ivilin; Zorzi, Marco (September 2017). \"Letter perception emerges from unsupervised deep learning and recycling of natural image features\". Nature Human Behaviour. 1 (9): 657–664. doi:10.1038/s41562-017-0186-2. ISSN 2397-3374. PMID 31024135. S2CID 24504018. - ^ Buesing, Lars; Bill, Johannes; Nessler, Bernhard; Maass, Wolfgang (3 November 2011). \"Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons\". PLOS Computational Biology. 7 (11) e1002211. Bibcode:2011PLSCB...7E2211B. doi:10.1371/journal.pcbi.1002211. ISSN 1553-7358. PMC 3207943. PMID 22096452. S2CID 7504633. - ^ Cash, S.; Yuste, R. (February 1999). \"Linear summation of excitatory inputs by CA1 pyramidal neurons\". Neuron. 22 (2): 383–394. doi:10.1016/s0896-6273(00)81098-3. ISSN 0896-6273. PMID 10069343. S2CID 14663106. - ^ Olshausen, B; Field, D (1 August 2004). \"Sparse coding of sensory inputs\". Current Opinion in Neurobiology. 14 (4): 481–487. doi:10.1016/j.conb.2004.07.007. ISSN 0959-4388. PMID 15321069. S2CID 16560320. - ^ Yamins, Daniel L K; DiCarlo, James J (March 2016). \"Using goal-driven deep learning models to understand sensory cortex\". Nature Neuroscience. 19 (3): 356–365. doi:10.1038/nn.4244. ISSN 1546-1726. PMID 26906502. S2CID 16970545. - ^ Zorzi, Marco; Testolin, Alberto (19 February 2018). \"An emergentist perspective on the origin of number sense\". Phil. Trans. R. Soc. B. 373 (1740) 20170043. doi:10.1098/rstb.2017.0043. ISSN 0962-8436. PMC 5784047. PMID 29292348. S2CID 39281431. - ^ Güçlü, Umut; van Gerven, Marcel A. J. (8 July 2015). \"Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream\". Journal of Neuroscience. 35 (27): 10005–10014. arXiv:1411.6422. doi:10.1523/jneurosci.5023-14.2015. PMC 6605414. PMID 26157000. - ^ Metz, C. (12 December 2013). \"Facebook's 'Deep Learning' Guru Reveals the Future of AI\". Wired. Archived from the original on 28 March 2014. Retrieved 26 August 2017. - ^ Gibney, Elizabeth (2016). \"Google AI algorithm masters ancient game of Go\". Nature. 529 (7587): 445–446. Bibcode:2016Natur.529..445G. doi:10.1038/529445a. PMID 26819021. S2CID 4460235. - ^ Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner, Nal; Sutskever, Ilya; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; Hassab",
    "text_length": 120000,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:57.703621"
  },
  {
    "id": "page_11",
    "url": "https://en.wikipedia.org/wiki/Bayesian_network",
    "domain": "en.wikipedia.org",
    "title": "Bayesian network - Wikipedia",
    "text": "Bayesian network This article includes a list of general references, but it lacks sufficient corresponding inline citations. (February 2011) | | Part of a series on | | Bayesian statistics | |---| | Posterior = Likelihood × Prior ÷ Evidence | | Background | | Model building | | Posterior approximation | | Estimators | | Evidence approximation | | Model evaluation | A Bayesian network (also known as a Bayes network, Bayes net, belief network, or decision network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG).[1] While it is one of several forms of causal notation, causal networks are special cases of Bayesian networks. Bayesian networks are ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor. For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms can perform inference and learning in Bayesian networks. Bayesian networks that model sequences of variables (e.g. speech signals or protein sequences) are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams. Graphical model [edit]Formally, Bayesian networks are directed acyclic graphs (DAGs) whose nodes represent variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses. Each edge represents a direct conditional dependency. Any pair of nodes that are not connected (i.e. no path connects one node to the other) represent variables that are conditionally independent of each other. Each node is associated with a probability function that takes, as input, a particular set of values for the node's parent variables, and gives (as output) the probability (or probability distribution, if applicable) of the variable represented by the node. For example, if parent nodes represent Boolean variables, then the probability function could be represented by a table of entries, one entry for each of the possible parent combinations. Similar ideas may be applied to undirected, and possibly cyclic, graphs such as Markov networks. Example [edit]Suppose we want to model the dependencies between three variables: the sprinkler (or more appropriately, its state - whether it is on or not), the presence or absence of rain and whether the grass is wet or not. Observe that two events can cause the grass to become wet: an active sprinkler or rain. Rain has a direct effect on the use of the sprinkler (namely that when it rains, the sprinkler usually is not active). This situation can be modeled with a Bayesian network (shown to the right). Each variable has two possible values, T (for true) and F (for false). The joint probability function is, by the chain rule of probability, where G = \"Grass wet (true/false)\", S = \"Sprinkler turned on (true/false)\", and R = \"Raining (true/false)\". The model can answer questions about the presence of a cause given the presence of an effect (so-called inverse probability) like \"What is the probability that it is raining, given the grass is wet?\" by using the conditional probability formula and summing over all nuisance variables: Using the expansion for the joint probability function and the conditional probabilities from the conditional probability tables (CPTs) stated in the diagram, one can evaluate each term in the sums in the numerator and denominator. For example, Then the numerical results (subscripted by the associated variable values) are To answer an interventional question, such as \"What is the probability that it would rain, given that we wet the grass?\" the answer is governed by the post-intervention joint distribution function obtained by removing the factor from the pre-intervention distribution. The do operator forces the value of G to be true. The probability of rain is unaffected by the action: To predict the impact of turning the sprinkler on: with the term removed, showing that the action affects the grass but not the rain. These predictions may not be feasible given unobserved variables, as in most policy evaluation problems. The effect of the action can still be predicted, however, whenever the back-door criterion is satisfied.[2][3] It states that, if a set Z of nodes can be observed that d-separates[4] (or blocks) all back-door paths from X to Y then A back-door path is one that ends with an arrow into X. Sets that satisfy the back-door criterion are called \"sufficient\" or \"admissible.\" For example, the set Z = R is admissible for predicting the effect of S = T on G, because R d-separates the (only) back-door path S ← R → G. However, if S is not observed, no other set d-separates this path and the effect of turning the sprinkler on (S = T) on the grass (G) cannot be predicted from passive observations. In that case P(G | do(S = T)) is not \"identified\". This reflects the fact that, lacking interventional data, the observed dependence between S and G is due to a causal connection or is spurious (apparent dependence arising from a common cause, R). (see Simpson's paradox) To determine whether a causal relation is identified from an arbitrary Bayesian network with unobserved variables, one can use the three rules of \"do-calculus\"[2][5] and test whether all do terms can be removed from the expression of that relation, thus confirming that the desired quantity is estimable from frequency data.[6] Using a Bayesian network can save considerable amounts of memory over exhaustive probability tables, if the dependencies in the joint distribution are sparse. For example, a naive way of storing the conditional probabilities of 10 two-valued variables as a table requires storage space for values. If no variable's local distribution depends on more than three parent variables, the Bayesian network representation stores at most values. One advantage of Bayesian networks is that it is intuitively easier for a human to understand (a sparse set of) direct dependencies and local distributions than complete joint distributions. Inference and learning [edit]Bayesian networks perform three main inference tasks: - Inferring unobserved variables - Parameter learning for the probability distributions of each node in the network - Structure learning of the graphical network Inferring unobserved variables [edit]Because a Bayesian network is a complete model for its variables and their relationships, it can be used to answer probabilistic queries about them. For example, the network can be used to update knowledge of the state of a subset of variables when other variables (the evidence variables) are observed. This process of computing the posterior distribution of variables given evidence is called probabilistic inference. The posterior gives a universal sufficient statistic for detection applications, when choosing values for the variable subset that minimize some expected loss function, for instance the probability of decision error. A Bayesian network can thus be considered a mechanism for automatically applying Bayes' theorem to complex problems. The most common exact inference methods are: variable elimination, which eliminates (by integration or summation) the non-observed non-query variables one by one by distributing the sum over the product; clique tree propagation, which caches the computation so that many variables can be queried at one time and new evidence can be propagated quickly; and recursive conditioning and AND/OR search, which allow for a space–time tradeoff and match the efficiency of variable elimination when enough space is used. All of these methods have complexity that is exponential in the network's treewidth. The most common approximate inference algorithms are importance sampling, stochastic MCMC simulation, mini-bucket elimination, loopy belief propagation, generalized belief propagation and variational methods. Parameter learning [edit]In order to fully specify the Bayesian network and thus fully represent the joint probability distribution, it is necessary to specify for each node X the probability distribution for X conditional upon X's parents. The distribution of X conditional upon its parents may have any form. It is common to work with discrete or Gaussian distributions since that simplifies calculations. Sometimes only constraints on distribution are known; one can then use the principle of maximum entropy to determine a single distribution, the one with the greatest entropy given the constraints. (Analogously, in the specific context of a dynamic Bayesian network, the conditional distribution for the hidden state's temporal evolution is commonly specified to maximize the entropy rate of the implied stochastic process.) Often these conditional distributions include parameters that are unknown and must be estimated from data, e.g., via the maximum likelihood approach. Direct maximization of the likelihood (or of the posterior probability) is often complex given unobserved variables. A classical approach to this problem is the expectation-maximization algorithm, which alternates computing expected values of the unobserved variables conditional on observed data, with maximizing the complete likelihood (or posterior) assuming that previously computed expected values are correct. Under mild regularity conditions, this process converges on maximum likelihood (or maximum posterior) values for parameters. A more fully Bayesian approach to parameters is to treat them as additional unobserved variables and to compute a full posterior distribution over all nodes conditional upon observed data, then to integrate out the parameters. This approach can be expensive and lead to large dimension models, making classical parameter-setting approaches more tractable. Structure learning [edit]In the simplest case, a Bayesian network is specified by an expert and is then used to perform inference. In other applications, the task of defining the network is too complex for humans. In this case, the network structure and the parameters of the local distributions must be learned from data. Automatically learning the graph structure of a Bayesian network (BN) is a challenge pursued within machine learning. The basic idea goes back to a recovery algorithm developed by Rebane and Pearl[7] and rests on the distinction between the three possible patterns allowed in a 3-node DAG: | Pattern | Model | |---|---| | Chain | | | Fork | | | Collider | The first 2 represent the same dependencies ( and are independent given ) and are, therefore, indistinguishable. The collider, however, can be uniquely identified, since and are marginally independent and all other pairs are dependent. Thus, while the skeletons (the graphs stripped of arrows) of these three triplets are identical, the directionality of the arrows is partially identifiable. The same distinction applies when and have common parents, except that one must first condition on those parents. Algorithms have been developed to systematically determine the skeleton of the underlying graph and, then, orient all arrows whose directionality is dictated by the conditional independences observed.[2][8][9][10] An alternative method of structural learning uses optimization-based search. It requires a scoring function and a search strategy. A common scoring function is posterior probability of the structure given the training data, like the BIC or the BDeu. The time requirement of an exhaustive search returning a structure that maximizes the score is superexponential in the number of variables. A local search strategy makes incremental changes aimed at improving the score of the structure. A global search algorithm like Markov chain Monte Carlo (MCMC) can avoid getting trapped in local minima. Finding a structure that maximizes the mutual information, typically by restricting the parent candidate set to k nodes[11][12][13] or by finding an optimal k on a node-per-node basis,[14] is a technique that consistently achieves high scores on benchmark datasets. A particularly fast method for exact BN learning is to cast the problem as an optimization problem, and solve it using integer programming. Acyclicity constraints are added to the integer program (IP) during solving in the form of cutting planes.[15] Such method can handle problems with up to 100 variables. In order to deal with problems with thousands of variables, a different approach is necessary. One is to first sample one ordering, and then find the optimal BN structure with respect to that ordering. This implies working on the search space of the possible orderings, which is convenient as it is smaller than the space of network structures. Multiple orderings are then sampled and evaluated. This method has been proven to be the best available in literature when the number of variables is huge.[16] Another method consists of focusing on the sub-class of decomposable models, for which the MLE have a closed form. It is then possible to discover a consistent structure for hundreds of variables.[17] Learning Bayesian networks with bounded treewidth is necessary to allow exact, tractable inference, since the worst-case inference complexity is exponential in the treewidth k (under the exponential time hypothesis). Yet, as a global property of the graph, it considerably increases the difficulty of the learning process. In this context it is possible to use K-tree for effective learning.[18] Statistical introduction [edit]Given data and parameter , a simple Bayesian analysis starts with a prior probability (prior) and likelihood to compute a posterior probability . Often the prior on depends in turn on other parameters that are not mentioned in the likelihood. So, the prior must be replaced by a likelihood , and a prior on the newly introduced parameters is required, resulting in a posterior probability This is the simplest example of a hierarchical Bayes model. The process may be repeated; for example, the parameters may depend in turn on additional parameters , which require their own prior. Eventually the process must terminate, with priors that do not depend on unmentioned parameters. Introductory examples [edit]This section needs expansion. You can help by expanding it. (March 2009) | Given the measured quantities each with normally distributed errors of known standard deviation , Suppose we are interested in estimating the . An approach would be to estimate the using a maximum likelihood approach; since the observations are independent, the likelihood factorizes and the maximum likelihood estimate is simply However, if the quantities are related, so that for example the individual have themselves been drawn from an underlying distribution, then this relationship destroys the independence and suggests a more complex model, e.g., with improper priors , . When , this is an identified model (i.e. there exists a unique solution for the model's parameters), and the posterior distributions of the individual will tend to move, or shrink away from the maximum likelihood estimates towards their common mean. This shrinkage is a typical behavior in hierarchical Bayes models. Restrictions on priors [edit]Some care is needed when choosing priors in a hierarchical model, particularly on scale variables at higher levels of the hierarchy such as the variable in the example. The usual priors such as the Jeffreys prior often do not work, because the posterior distribution will not be normalizable and estimates made by minimizing the expected loss will be inadmissible. Definitions and concepts [edit]Several equivalent definitions of a Bayesian network have been offered. For the following, let G = (V,E) be a directed acyclic graph (DAG) and let X = (Xv), v ∈ V be a set of random variables indexed by V. Factorization definition [edit]X is a Bayesian network with respect to G if its joint probability density function (with respect to a product measure) can be written as a product of the individual density functions, conditional on their parent variables:[19] where pa(v) is the set of parents of v (i.e. those vertices pointing directly to v via a single edge). For any set of random variables, the probability of any member of a joint distribution can be calculated from conditional probabilities using the chain rule (given a topological ordering of X) as follows:[19] Using the definition above, this can be written as: The difference between the two expressions is the conditional independence of the variables from any of their non-descendants, given the values of their parent variables. Local Markov property [edit]X is a Bayesian network with respect to G if it satisfies the local Markov property: each variable is conditionally independent of its non-descendants given its parent variables:[20] where de(v) is the set of descendants and V \\ de(v) is the set of non-descendants of v. This can be expressed in terms similar to the first definition, as The set of parents is a subset of the set of non-descendants because the graph is acyclic. Marginal independence structure [edit]In general, learning a Bayesian network from data is known to be NP-hard.[21] This is due in part to the combinatorial explosion of enumerating DAGs as the number of variables increases. Nevertheless, insights about an underlying Bayesian network can be learned from data in polynomial time by focusing on its marginal independence structure:[22] while the conditional independence statements of a distribution modeled by a Bayesian network are encoded by a DAG (according to the factorization and Markov properties above), its marginal independence statements—the conditional independence statements in which the conditioning set is empty—are encoded by a simple undirected graph with special properties such as equal intersection and independence numbers. Developing Bayesian networks [edit]Developing a Bayesian network often begins with creating a DAG G such that X satisfies the local Markov property with respect to G. Sometimes this is a causal DAG. The conditional probability distributions of each variable given its parents in G are assessed. In many cases, in particular in the case where the variables are discrete, if the joint distribution of X is the product of these conditional distributions, then X is a Bayesian network with respect to G.[23] Markov blanket [edit]The Markov blanket of a node is the set of nodes consisting of its parents, its children, and any other parents of its children. The Markov blanket renders the node independent of the rest of the network; the joint distribution of the variables in the Markov blanket of a node is sufficient knowledge for calculating the distribution of the node. X is a Bayesian network with respect to G if every node is conditionally independent of all other nodes in the network, given its Markov blanket.[20] d-separation [edit]This definition can be made more general by defining the \"d\"-separation of two nodes, where d stands for directional.[2] We first define the \"d\"-separation of a trail and then we will define the \"d\"-separation of two nodes in terms of that. Let P be a trail from node u to v. A trail is a loop-free, undirected (i.e. all edge directions are ignored) path between two nodes. Then P is said to be d-separated by a set of nodes Z if any of the following conditions holds: - P contains (but does not need to be entirely) a directed chain, or , such that the middle node m is in Z, - P contains a fork, , such that the middle node m is in Z, or - P contains an inverted fork (or collider), , such that the middle node m is not in Z and no descendant of m is in Z. The nodes u and v are d-separated by Z if all trails between them are d-separated. If u and v are not d-separated, they are d-connected. X is a Bayesian network with respect to G if, for any two nodes u, v: where Z is a set which d-separates u and v. (The Markov blanket is the minimal set of nodes which d-separates node v from all other nodes.) Causal networks [edit]Although Bayesian networks are often used to represent causal relationships, this need not be the case: a directed edge from u to v does not require that Xv be causally dependent on Xu. This is demonstrated by the fact that Bayesian networks on the graphs: are equivalent: that is they impose exactly the same conditional independence requirements. A causal network is a Bayesian network with the requirement that the relationships be causal. The additional semantics of causal networks specify that if a node X is actively caused to be in a given state x (an action written as do(X = x)), then the probability density function changes to that of the network obtained by cutting the links from the parents of X to X, and setting X to the caused value x.[2] Using these semantics, the impact of external interventions from data obtained prior to intervention can be predicted. Inference complexity and approximation algorithms [edit]In 1990, while working at Stanford University on large bioinformatic applications, Cooper proved that exact inference in Bayesian networks is NP-hard.[24] This result prompted research on approximation algorithms with the aim of developing a tractable approximation to probabilistic inference. In 1993, Paul Dagum and Michael Luby proved two surprising results on the complexity of approximation of probabilistic inference in Bayesian networks.[25] First, they proved that no tractable deterministic algorithm can approximate probabilistic inference to within an absolute error ɛ < 1/2. Second, they proved that no tractable randomized algorithm can approximate probabilistic inference to within an absolute error ɛ < 1/2 with confidence probability greater than 1/2. At about the same time, Roth proved that exact inference in Bayesian networks is in fact #P-complete (and thus as hard as counting the number of satisfying assignments of a conjunctive normal form formula (CNF)) and that approximate inference within a factor 2n1−ɛ for every ɛ > 0, even for Bayesian networks with restricted architecture, is NP-hard.[26][27] In practical terms, these complexity results suggested that while Bayesian networks were rich representations for AI and machine learning applications, their use in large real-world applications would need to be tempered by either topological structural constraints, such as naïve Bayes networks, or by restrictions on the conditional probabilities. The bounded variance algorithm[28] developed by Dagum and Luby was the first provable fast approximation algorithm to efficiently approximate probabilistic inference in Bayesian networks with guarantees on the error approximation. This powerful algorithm required the minor restriction on the conditional probabilities of the Bayesian network to be bounded away from zero and one by where was any polynomial of the number of nodes in the network, . Software [edit]Notable software for Bayesian networks include: - OpenBUGS – Open-source development of WinBUGS. - SPSS Modeler – Commercial software that includes an implementation for Bayesian networks. - Stan (software) – Stan is an open-source package for obtaining Bayesian inference using the No-U-Turn sampler (NUTS),[29] a variant of Hamiltonian Monte Carlo. - WinBUGS – One of the first computational implementations of MCMC samplers. No longer maintained. History [edit]The term Bayesian network was coined by Judea Pearl in 1985 to emphasize:[30] - the often subjective nature of the input information - the reliance on Bayes' conditioning as the basis for updating information - the distinction between causal and evidential modes of reasoning[31] In the late 1980s Pearl's Probabilistic Reasoning in Intelligent Systems[32] and Neapolitan's Probabilistic Reasoning in Expert Systems[33] summarized their properties and established them as a field of study. See also [edit]- Bayesian epistemology - Bayesian programming - Causal inference - Causal loop diagram - Chow–Liu tree - Computational intelligence - Computational phylogenetics - Deep belief network - Dempster–Shafer theory – a generalization of Bayes' theorem - Expectation–maximization algorithm - Factor graph - Hierarchical temporal memory - Kalman filter - Memory-prediction framework - Mixture distribution - Mixture model - Naive Bayes classifier - Plate notation - Polytree - Sensor fusion - Sequence alignment - Staged tree - Structural equation modeling - Subjective logic - Variable-order Bayesian network Notes [edit]- ^ Ruggeri, Fabrizio; Kenett, Ron S.; Faltin, Frederick W., eds. (2007-12-14). Encyclopedia of Statistics in Quality and Reliability (1 ed.). Wiley. p. 1. doi:10.1002/9780470061572.eqr089. ISBN 978-0-470-01861-3. - ^ a b c d e Pearl, Judea (2000). Causality: Models, Reasoning, and Inference. Cambridge University Press. ISBN 978-0-521-77362-1. OCLC 42291253. - ^ \"The Back-Door Criterion\" (PDF). Retrieved 2014-09-18. - ^ \"d-Separation without Tears\" (PDF). Retrieved 2014-09-18. - ^ Pearl J (1994). \"A Probabilistic Calculus of Actions\". In Lopez de Mantaras R, Poole D (eds.). UAI'94 Proceedings of the Tenth international conference on Uncertainty in artificial intelligence. San Mateo CA: Morgan Kaufmann. pp. 454–462. arXiv:1302.6835. Bibcode:2013arXiv1302.6835P. ISBN 1-55860-332-8. - ^ Shpitser I, Pearl J (2023). \"Identification of Conditional Interventional Distributions\". In Dechter R, Richardson TS (eds.). Combinatorial and algebraic perspectives on the marginal independence structure of Bayesian networks. Vol. 14. Corvallis, OR: AUAI Press. pp. 437–444. arXiv:1206.6876. doi:10.2140/astat.2023.14.233. {{cite book}} :|journal= ignored (help) - ^ Rebane G, Pearl J (1987). \"The Recovery of Causal Poly-trees from Statistical Data\". Proceedings, 3rd Workshop on Uncertainty in AI. Seattle, WA. pp. 222–228. arXiv:1304.2736. {{cite book}} : CS1 maint: location missing publisher (link) - ^ Spirtes P, Glymour C (1991). \"An algorithm for fast recovery of sparse causal graphs\" (PDF). Social Science Computer Review. 9 (1): 62–72. CiteSeerX 10.1.1.650.2922. doi:10.1177/089443939100900106. S2CID 38398322. - ^ Spirtes P, Glymour CN, Scheines R (1993). Causation, Prediction, and Search (1st ed.). Springer-Verlag. ISBN 978-0-387-97979-3. - ^ Verma T, Pearl J (1991). \"Equivalence and synthesis of causal models\". In Bonissone P, Henrion M, Kanal LN, Lemmer JF (eds.). UAI '90 Proceedings of the Sixth Annual Conference on Uncertainty in Artificial Intelligence. Elsevier. pp. 255–270. ISBN 0-444-89264-8. - ^ Sahami, Mehran (1996-08-02). \"Learning limited dependence Bayesian classifiers\". Proceedings of the Second International Conference on Knowledge Discovery and Data Mining. KDD'96. Portland, Oregon: AAAI Press: 335–338. - ^ Friedman N, Geiger D, Goldszmidt M (November 1997). \"Bayesian Network Classifiers\". Machine Learning. 29 (2–3): 131–163. doi:10.1023/A:1007465528199. - ^ Friedman N, Linial M, Nachman I, Pe'er D (August 2000). \"Using Bayesian networks to analyze expression data\". Journal of Computational Biology. 7 (3–4): 601–20. CiteSeerX 10.1.1.191.139. doi:10.1089/106652700750050961. PMID 11108481. - ^ Rubio, Arcadio; Gámez, José Antonio (2011-07-12). \"Flexible learning of k-dependence Bayesian network classifiers\". Proceedings of the 13th annual conference on Genetic and evolutionary computation. GECCO '11. New York, NY, USA: Association for Computing Machinery. pp. 1219–1226. doi:10.1145/2001576.2001741. ISBN 978-1-4503-0557-0. - ^ Cussens J (2011). \"Bayesian network learning with cutting planes\" (PDF). Proceedings of the 27th Conference Annual Conference on Uncertainty in Artificial Intelligence: 153–160. arXiv:1202.3713. Bibcode:2012arXiv1202.3713C. Archived from the original on March 27, 2022. - ^ Scanagatta M, de Campos CP, Corani G, Zaffalon M (2015). \"Learning Bayesian Networks with Thousands of Variables\". NIPS-15: Advances in Neural Information Processing Systems. Vol. 28. Curran Associates. pp. 1855–1863. - ^ Petitjean F, Webb GI, Nicholson AE (2013). Scaling log-linear analysis to high-dimensional data (PDF). International Conference on Data Mining. Dallas, TX, USA: IEEE. - ^ M. Scanagatta, G. Corani, C. P. de Campos, and M. Zaffalon. Learning Treewidth-Bounded Bayesian Networks with Thousands of Variables. In NIPS-16: Advances in Neural Information Processing Systems 29, 2016. - ^ a b Russell & Norvig 2003, p. 496. - ^ a b Russell & Norvig 2003, p. 499. - ^ Chickering, David M.; Heckerman, David; Meek, Christopher (2004). \"Large-sample learning of Bayesian networks is NP-hard\" (PDF). Journal of Machine Learning Research. 5: 1287–1330. - ^ Deligeorgaki, Danai; Markham, Alex; Misra, Pratik; Solus, Liam (2023). \"Combinatorial and algebraic perspectives on the marginal independence structure of Bayesian networks\". Algebraic Statistics. 14 (2): 233–286. arXiv:2210.00822. doi:10.2140/astat.2023.14.233. - ^ Neapolitan RE (2004). Learning Bayesian networks. Prentice Hall. ISBN 978-0-13-012534-7. - ^ Cooper GF (1990). \"The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks\" (PDF). Artificial Intelligence. 42 (2–3): 393–405. doi:10.1016/0004-3702(90)90060-d. S2CID 43363498. - ^ Dagum P, Luby M (1993). \"Approximating probabilistic inference in Bayesian belief networks is NP-hard\". Artificial Intelligence. 60 (1): 141–153. CiteSeerX 10.1.1.333.1586. doi:10.1016/0004-3702(93)90036-b. - ^ D. Roth, On the hardness of approximate reasoning, IJCAI (1993) - ^ D. Roth, On the hardness of approximate reasoning, Artificial Intelligence (1996) - ^ Dagum P, Luby M (1997). \"An optimal approximation algorithm for Bayesian inference\". Artificial Intelligence. 93 (1–2): 1–27. CiteSeerX 10.1.1.36.7946. doi:10.1016/s0004-3702(97)00013-1. Archived from the original on 2017-07-06. Retrieved 2015-12-19. - ^ Hoffman, Matthew D.; Gelman, Andrew (2011). \"The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo\". arXiv:1111.4246 [stat.CO]. - ^ Pearl J (1985). Bayesian Networks: A Model of Self-Activated Memory for Evidential Reasoning (UCLA Technical Report CSD-850017). Proceedings of the 7th Conference of the Cognitive Science Society, University of California, Irvine, CA. pp. 329–334. Retrieved 2009-05-01. - ^ Bayes T, Price (1763). \"An Essay Towards Solving a Problem in the Doctrine of Chances\". Philosophical Transactions of the Royal Society. 53: 370–418. doi:10.1098/rstl.1763.0053. - ^ Pearl J (1988-09-15). Probabilistic Reasoning in Intelligent Systems. San Francisco CA: Morgan Kaufmann. p. 1988. ISBN 978-1-55860-479-7. - ^ Neapolitan RE (1989). Probabilistic reasoning in expert systems: theory and algorithms. Wiley. ISBN 978-0-471-61840-9. References [edit]- Ben Gal I (2007). \"Bayesian Networks\" (PDF). In Ruggeri F, Kennett RS, Faltin FW (eds.). Support-Page. Encyclopedia of Statistics in Quality and Reliability. John Wiley & Sons. doi:10.1002/9780470061572.eqr089. ISBN 978-0-470-01861-3. Archived from the original (PDF) on 2016-11-23. Retrieved 2007-08-27. - Bertsch McGrayne S (2011). The Theory That Would not Die. New Haven: Yale University Press. - Borgelt C, Kruse R (March 2002). Graphical Models: Methods for Data Analysis and Mining. Chichester, UK: Wiley. ISBN 978-0-470-84337-6. - Borsuk ME (2008). \"Ecological informatics: Bayesian networks\". In Jørgensen, Sven Erik, Fath, Brian (eds.). Encyclopedia of Ecology. Elsevier. ISBN 978-0-444-52033-3. - Castillo E, Gutiérrez JM, Hadi AS (1997). \"Learning Bayesian Networks\". Expert Systems and Probabilistic Network Models. Monographs in computer science. New York: Springer-Verlag. pp. 481–528. ISBN 978-0-387-94858-4. - Comley JW, Dowe DL (June 2003). \"General Bayesian networks and asymmetric languages\". Proceedings of the 2nd Hawaii International Conference on Statistics and Related Fields. - Comley JW, Dowe DL (2005). \"Minimum Message Length and Generalized Bayesian Nets with Asymmetric Languages\". In Grünwald PD, Myung IJ, Pitt MA (eds.). Advances in Minimum Description Length: Theory and Applications. Neural information processing series. Cambridge, Massachusetts: Bradford Books (MIT Press) (published April 2005). pp. 265–294. ISBN 978-0-262-07262-5. (This paper puts decision trees in internal nodes of Bayes networks using Minimum Message Length (MML). - Darwiche A (2009). Modeling and Reasoning with Bayesian Networks. Cambridge University Press. ISBN 978-0-521-88438-9. - Dowe, David L. (2011-05-31). \"Hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness\" (PDF). Philosophy of Statistics. Elsevier. pp. 901–982. ISBN 978-0-08-093096-1. - Fenton N, Neil ME (November 2007). \"Managing Risk in the Modern World: Applications of Bayesian Networks\" (PDF). A Knowledge Transfer Report from the London Mathematical Society and the Knowledge Transfer Network for Industrial Mathematics. London (England): London Mathematical Society. Archived from the original (PDF) on 2008-05-14. Retrieved 2008-10-29. - Fenton N, Neil ME (July 23, 2004). \"Combining evidence in risk analysis using Bayesian Networks\" (PDF). Safety Critical Systems Club Newsletter. Vol. 13, no. 4. Newcastle upon Tyne, England. pp. 8–13. Archived from the original (PDF) on 2007-09-27. - Gelman A, Carlin JB, Stern HS, Rubin DB (2003). \"Part II: Fundamentals of Bayesian Data Analysis: Ch.5 Hierarchical models\". Bayesian Data Analysis. CRC Press. pp. 120–. ISBN 978-1-58488-388-3. - Heckerman, David (March 1, 1995). \"Tutorial on Learning with Bayesian Networks\". In Jordan, Michael Irwin (ed.). Learning in Graphical Models. Adaptive Computation and Machine Learning. Cambridge, Massachusetts: MIT Press (published 1998). pp. 301–354. ISBN 978-0-262-60032-3. Archived from the original on July 19, 2006. Retrieved September 15, 2006. {{cite book}} : CS1 maint: bot: original URL status unknown (link):Also appears as Heckerman, David (March 1997). \"Bayesian Networks for Data Mining\". Data Mining and Knowledge Discovery. 1 (1): 79–119. doi:10.1023/A:1009730122752. S2CID 6294315. - An earlier version appears as, Microsoft Research, March 1, 1995. The paper is about both parameter and structure learning in Bayesian networks. - Jensen FV, Nielsen TD (June 6, 2007). Bayesian Networks and Decision Graphs. Information Science and Statistics series (2nd ed.). New York: Springer-Verlag. ISBN 978-0-387-68281-5. - Karimi K, Hamilton HJ (2000). \"Finding temporal relations: Causal bayesian networks vs. C4. 5\" (PDF). Twelfth International Symposium on Methodologies for Intelligent Systems. - Korb KB, Nicholson AE (December 2010). Bayesian Artificial Intelligence. CRC Computer Science & Data Analysis (2nd ed.). Chapman & Hall (CRC Press). doi:10.1007/s10044-004-0214-5. ISBN 978-1-58488-387-6. S2CID 22138783. - Lunn D, Spiegelhalter D, Thomas A, Best N (November 2009). \"The BUGS project: Evolution, critique and future directions\". Statistics in Medicine. 28 (25): 3049–67. doi:10.1002/sim.3680. PMID 19630097. S2CID 7717482. - Neil M, Fenton N, Tailor M (August 2005). Greenberg, Michael R. (ed.). \"Using Bayesian networks to model expected and unexpected operational losses\" (PDF). Risk Analysis. 25 (4): 963–72. Bibcode:2005RiskA..25..963N. doi:10.1111/j.1539-6924.2005.00641.x. PMID 16268944. S2CID 3254505. - Pearl J (September 1986). \"Fusion, propagation, and structuring in belief networks\". Artificial Intelligence. 29 (3): 241–288. doi:10.1016/0004-3702(86)90072-X. - Pearl J (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Representation and Reasoning Series (2nd printing ed.). San Francisco, California: Morgan Kaufmann. ISBN 978-0-934613-73-6. - Pearl J, Russell S (November 2002). \"Bayesian Networks\". In Arbib MA (ed.). Handbook of Brain Theory and Neural Networks. Cambridge, Massachusetts: Bradford Books (MIT Press). pp. 157–160. ISBN 978-0-262-01197-6. - Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2. - Zhang NL, Poole D (May 1994). \"A simple approach to Bayesian network computations\" (PDF). Proceedings of the Tenth Biennial Canadian Artificial Intelligence Conference (AI-94).: 171–178. This paper presents variable elimination for belief networks. Further reading [edit]- Conrady S, Jouffe L (2015-07-01). Bayesian Networks and BayesiaLab – A practical introduction for researchers. Franklin, Tennessee: Bayesian USA. ISBN 978-0-9965333-0-0. - Charniak E (Winter 1991). \"Bayesian networks without tears\" (PDF). AI Magazine. - Kruse R, Borgelt C, Klawonn F, Moewes C, Steinbrecher M, Held P (2013). Computational Intelligence A Methodological Introduction. London: Springer-Verlag. ISBN 978-1-4471-5012-1. - Borgelt C, Steinbrecher M, Kruse R (2009). Graphical Models – Representations for Learning, Reasoning and Data Mining (Second ed.). Chichester: Wiley. ISBN 978-0-470-74956-2. External links [edit]- An Introduction to Bayesian Networks and their Contemporary Applications - On-line Tutorial on Bayesian nets and probability - Web-App to create Bayesian nets and run it with a Monte Carlo method - Continuous Time Bayesian Networks - Bayesian Networks: Explanation and Analogy - A live tutorial on learning Bayesian networks - A hierarchical Bayes Model for handling sample heterogeneity in classification problems, provides a classification model taking into consideration the uncertainty associated with measuring replicate samples. - Hierarchical Naive Bayes Model for handling sample uncertainty Archived 2007-09-28 at the Wayback Machine, shows how to perform classification and learning with continuous and discrete variables with replicated measurements.",
    "text_length": 37917,
    "depth": 1,
    "crawled_at": "2026-01-11T13:22:59.853635"
  },
  {
    "id": "page_12",
    "url": "https://en.wikipedia.org/wiki/Evolutionary_algorithm",
    "domain": "en.wikipedia.org",
    "title": "Evolutionary algorithm - Wikipedia",
    "text": "Evolutionary algorithm | Part of a series on the | | Evolutionary algorithm | |---| | Genetic algorithm (GA) | | Genetic programming (GP) | | Differential evolution | | Evolution strategy | | Evolutionary programming | | Related topics | | Part of a series on | | Artificial intelligence (AI) | |---| Evolutionary algorithms (EA) reproduce essential elements of biological evolution in a computer algorithm in order to solve \"difficult\" problems, at least approximately, for which no exact or satisfactory solution methods are known. They are metaheuristics and population-based bio-inspired algorithms[1] and evolutionary computation, which itself are part of the field of computational intelligence.[2] The mechanisms of biological evolution that an EA mainly imitates are reproduction, mutation, recombination and selection. Candidate solutions to the optimization problem play the role of individuals in a population, and the fitness function determines the quality of the solutions (see also loss function). Evolution of the population then takes place after the repeated application of the above operators. Evolutionary algorithms often perform well approximating solutions to all types of problems because they ideally do not make any assumption about the underlying fitness landscape. Techniques from evolutionary algorithms applied to the modeling of biological evolution are generally limited to explorations of microevolution (microevolutionary processes) and planning models based upon cellular processes. In most real applications of EAs, computational complexity is a prohibiting factor.[3] In fact, this computational complexity is due to fitness function evaluation. Fitness approximation is one of the solutions to overcome this difficulty. However, seemingly simple EA can solve often complex problems;[4][5][6] therefore, there may be no direct link between algorithm complexity and problem complexity. Generic definition [edit]The following is an example of a generic evolutionary algorithm:[7][8][9] - Randomly generate the initial population of individuals, the first generation. - Evaluate the fitness of each individual in the population. - Check, if the goal is reached and the algorithm can be terminated. - Select individuals as parents, preferably of higher fitness. - Produce offspring with optional crossover (mimicking reproduction). - Apply mutation operations on the offspring. - Select individuals preferably of lower fitness for replacement with new individuals (mimicking natural selection). - Return to 2 Types [edit]Similar techniques differ in genetic representation and other implementation details, and the nature of the particular applied problem. - Genetic algorithm – This is the most popular type of EA. One seeks the solution of a problem in the form of strings of numbers (traditionally binary, although the best representations are usually those that reflect something about the problem being solved),[3] by applying operators such as recombination and mutation (sometimes one, sometimes both). This type of EA is often used in optimization problems. - Genetic programming – Here the solutions are in the form of computer programs, and their fitness is determined by their ability to solve a computational problem. There are many variants of Genetic Programming: - Evolutionary programming – Similar to evolution strategy, but with a deterministic selection of all parents. - Evolution strategy (ES) – Works with vectors of real numbers as representations of solutions, and typically uses self-adaptive mutation rates. The method is mainly used for numerical optimization, although there are also variants for combinatorial tasks.[10][11][12] - Differential evolution – Based on vector differences and is therefore primarily suited for numerical optimization problems. - Coevolutionary algorithm – Similar to genetic algorithms and evolution strategies, but the created solutions are compared on the basis of their outcomes from interactions with other solutions. Solutions can either compete or cooperate during the search process. Coevolutionary algorithms are often used in scenarios where the fitness landscape is dynamic, complex, or involves competitive interactions.[13][14] - Neuroevolution – Similar to genetic programming but the genomes represent artificial neural networks by describing structure and connection weights. The genome encoding can be direct or indirect. - Learning classifier system – Here the solution is a set of classifiers (rules or conditions). A Michigan-LCS evolves at the level of individual classifiers whereas a Pittsburgh-LCS uses populations of classifier-sets. Initially, classifiers were only binary, but now include real, neural net, or S-expression types. Fitness is typically determined with either a strength or accuracy based reinforcement learning or supervised learning approach. - Quality–Diversity algorithms – QD algorithms simultaneously aim for high-quality and diverse solutions. Unlike traditional optimization algorithms that solely focus on finding the best solution to a problem, QD algorithms explore a wide variety of solutions across a problem space and keep those that are not just high performing, but also diverse and unique.[15][16][17] Theoretical background [edit]The following theoretical principles apply to all or almost all EAs. No free lunch theorem [edit]The no free lunch theorem of optimization states that all optimization strategies are equally effective when the set of all optimization problems is considered. Under the same condition, no evolutionary algorithm is fundamentally better than another. This can only be the case if the set of all problems is restricted. This is exactly what is inevitably done in practice. Therefore, to improve an EA, it must exploit problem knowledge in some form (e.g. by choosing a certain mutation strength or a problem-adapted coding). Thus, if two EAs are compared, this constraint is implied. In addition, an EA can use problem specific knowledge by, for example, not randomly generating the entire start population, but creating some individuals through heuristics or other procedures.[18][19] Another possibility to tailor an EA to a given problem domain is to involve suitable heuristics, local search procedures or other problem-related procedures in the process of generating the offspring. This form of extension of an EA is also known as a memetic algorithm. Both extensions play a major role in practical applications, as they can speed up the search process and make it more robust.[18][20] Convergence [edit]For EAs in which, in addition to the offspring, at least the best individual of the parent generation is used to form the subsequent generation (so-called elitist EAs), there is a general proof of convergence under the condition that an optimum exists. Without loss of generality, a maximum search is assumed for the proof: From the property of elitist offspring acceptance and the existence of the optimum it follows that per generation an improvement of the fitness of the respective best individual will occur with a probability . Thus: I.e., the fitness values represent a monotonically non-decreasing sequence, which is bounded due to the existence of the optimum. From this follows the convergence of the sequence against the optimum. Since the proof makes no statement about the speed of convergence, it is of little help in practical applications of EAs. But it does justify the recommendation to use elitist EAs. However, when using the usual panmictic population model, elitist EAs tend to converge prematurely more than non-elitist ones.[21] In a panmictic population model, mate selection (see step 4 of the generic definition) is such that every individual in the entire population is eligible as a mate. In non-panmictic populations, selection is suitably restricted, so that the dispersal speed of better individuals is reduced compared to panmictic ones. Thus, the general risk of premature convergence of elitist EAs can be significantly reduced by suitable population models that restrict mate selection.[22][23] Virtual alphabets [edit]With the theory of virtual alphabets, David E. Goldberg showed in 1990 that by using a representation with real numbers, an EA that uses classical recombination operators (e.g. uniform or n-point crossover) cannot reach certain areas of the search space, in contrast to a coding with binary numbers.[24] This results in the recommendation for EAs with real representation to use arithmetic operators for recombination (e.g. arithmetic mean or intermediate recombination). With suitable operators, real-valued representations are more effective than binary ones, contrary to earlier opinion.[25][26] Comparison to other concepts [edit]Biological processes [edit]A possible limitation[according to whom?] of many evolutionary algorithms is their lack of a clear genotype–phenotype distinction. In nature, the fertilized egg cell undergoes a complex process known as embryogenesis to become a mature phenotype. This indirect encoding is believed to make the genetic search more robust (i.e. reduce the probability of fatal mutations), and also may improve the evolvability of the organism.[27][28] Such indirect (also known as generative or developmental) encodings also enable evolution to exploit the regularity in the environment.[29] Recent work in the field of artificial embryogeny, or artificial developmental systems, seeks to address these concerns. And gene expression programming successfully explores a genotype–phenotype system, where the genotype consists of linear multigenic chromosomes of fixed length and the phenotype consists of multiple expression trees or computer programs of different sizes and shapes.[30][improper synthesis?] Monte-Carlo methods [edit]Both method classes have in common that their individual search steps are determined by chance. The main difference, however, is that EAs, like many other metaheuristics, learn from past search steps and incorporate this experience into the execution of the next search steps in a method-specific form. With EAs, this is done firstly through the fitness-based selection operators for partner choice and the formation of the next generation. And secondly, in the type of search steps: In EA, they start from a current solution and change it or they mix the information of two solutions. In contrast, when dicing out new solutions in Monte-Carlo methods, there is usually no connection to existing solutions.[31][32] If, on the other hand, the search space of a task is such that there is nothing to learn, Monte-Carlo methods are an appropriate tool, as they do not contain any algorithmic overhead that attempts to draw suitable conclusions from the previous search. An example of such tasks is the proverbial search for a needle in a haystack, e.g. in the form of a flat (hyper)plane with a single narrow peak. Applications [edit]The areas in which evolutionary algorithms are practically used are almost unlimited[6] and range from industry,[33][34] engineering,[3][4][35] complex scheduling,[5][36][37] agriculture,[38] robot movement planning[39] and finance[40][41] to research[42][43] and art. The application of an evolutionary algorithm requires some rethinking from the inexperienced user, as the approach to a task using an EA is different from conventional exact methods and this is usually not part of the curriculum of engineers or other disciplines. For example, the fitness calculation must not only formulate the goal but also support the evolutionary search process towards it, e.g. by rewarding improvements that do not yet lead to a better evaluation of the original quality criteria. For example, if peak utilisation of resources such as personnel deployment or energy consumption is to be avoided in a scheduling task, it is not sufficient to assess the maximum utilisation. Rather, the number and duration of exceedances of a still acceptable level should also be recorded in order to reward reductions below the actual maximum peak value.[44] There are therefore some publications that are aimed at the beginner and want to help avoiding beginner's mistakes as well as leading an application project to success.[44][45][46] This includes clarifying the fundamental question of when an EA should be used to solve a problem and when it is better not to. Related techniques and other global search methods [edit]There are some other proven and widely used methods of nature inspired global search techniques such as - Memetic algorithm – A hybrid method, inspired by Richard Dawkins's notion of a meme. It commonly takes the form of a population-based algorithm (frequently an EA) coupled with individual learning procedures capable of performing local refinements. Emphasizes the exploitation of problem-specific knowledge and tries to orchestrate local and global search in a synergistic way.[47] - A cellular evolutionary or memetic algorithm uses a topological neighborhood relation between the individuals of a population for restricting the mate selection and by that reducing the propagation speed of above-average individuals. The idea is to maintain genotypic diversity in the population over a longer period of time to reduce the risk of premature convergence.[48] - Ant colony optimization is based on the ideas of ant foraging by pheromone communication to form paths. Primarily suited for combinatorial optimization and graph problems. - Particle swarm optimization is based on the ideas of animal flocking behaviour. Also primarily suited for numerical optimization problems. - Gaussian adaptation – Based on information theory. Used for maximization of manufacturing yield, mean fitness or average information. See for instance Entropy in thermodynamics and information theory.[49] In addition, many new nature-inspired or metaphor-guided algorithms have been proposed since the beginning of this century[when?]. For criticism of most publications on these, see the remarks at the end of the introduction to the article on metaheuristics. Examples [edit]In 2020, Google stated that their AutoML-Zero can successfully rediscover classic algorithms such as the concept of neural networks.[50] The computer simulations Tierra and Avida attempt to model macroevolutionary dynamics. Gallery [edit]- A two-population EA search over a constrained Rosenbrock function with bounded global optimum - A two-population EA search over a constrained Rosenbrock function. Global optimum is not bounded. - A two-population EA search of a bounded optima of Simionescu's function References [edit]- ^ Farinati, Davide; Vanneschi, Leonardo (December 2024). \"A survey on dynamic populations in bio-inspired algorithms\". Genetic Programming and Evolvable Machines. 25 (2) 19. doi:10.1007/s10710-024-09492-4. hdl:10362/170138. - ^ Vikhar, P. A. (2016). \"Evolutionary algorithms: A critical review and its future prospects\". 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Jalgaon. pp. 261–265. doi:10.1109/ICGTSPICC.2016.7955308. ISBN 978-1-5090-0467-6. S2CID 22100336. {{cite book}} : CS1 maint: location missing publisher (link) - ^ a b c Cohoon, J. P.; Karro, J.; Lienig, J. (2003). \"Evolutionary Algorithms for the Physical Design of VLSI Circuits\" in Advances in Evolutionary Computing: Theory and Applications (PDF). London: Springer Verlag. pp. 683–712. ISBN 978-3-540-43330-9. - ^ a b Slowik, Adam; Kwasnicka, Halina (2020). \"Evolutionary algorithms and their applications to engineering problems\". Neural Computing and Applications. 32 (16): 12363–12379. doi:10.1007/s00521-020-04832-8. ISSN 0941-0643. S2CID 212732659. - ^ a b Mika, Marek; Waligóra, Grzegorz; Węglarz, Jan (2011). \"Modelling and solving grid resource allocation problem with network resources for workflow applications\". Journal of Scheduling. 14 (3): 291–306. doi:10.1007/s10951-009-0158-0. ISSN 1094-6136. S2CID 31859338. - ^ a b \"International Conference on the Applications of Evolutionary Computation\". The conference is part of the Evo* series. The conference proceedings are published by Springer. Retrieved 2022-12-23. - ^ Jansen, Thomas; Weyland, Dennis (7 July 2007). \"Analysis of evolutionary algorithms for the longest common subsequence problem\". Proceedings of the 9th annual conference on Genetic and evolutionary computation. Association for Computing Machinery. pp. 939–946. doi:10.1145/1276958.1277148. ISBN 978-1-59593-697-4. - ^ Jin, Yaochu (2003). \"Evolutionary Algorithms\". Advanced Fuzzy Systems Design and Applications. Studies in Fuzziness and Soft Computing. Vol. 112. Physica-Verlag HD. pp. 49–71. doi:10.1007/978-3-7908-1771-3_2. ISBN 978-3-7908-2520-6. - ^ Tavares, Jorge; Machado, Penousal; Cardoso, Amílcar; Pereira, Francisco B.; Costa, Ernesto (2004). \"On the Evolution of Evolutionary Algorithms\". Genetic Programming. Lecture Notes in Computer Science. Vol. 3003. Springer. pp. 389–398. doi:10.1007/978-3-540-24650-3_37. ISBN 978-3-540-21346-8. - ^ Nissen, Volker; Krause, Matthias (1994), \"Constrained Combinatorial Optimization with an Evolution Strategy\", in Reusch, Bernd (ed.), Fuzzy Logik, Informatik aktuell, Berlin, Heidelberg: Springer, pp. 33–40, doi:10.1007/978-3-642-79386-8_5, ISBN 978-3-642-79386-8 - ^ Coelho, V. N.; Coelho, I. M.; Souza, M. J. F.; Oliveira, T. A.; Cota, L. P.; Haddad, M. N.; Mladenovic, N.; Silva, R. C. P.; Guimarães, F. G. (2016). \"Hybrid Self-Adaptive Evolution Strategies Guided by Neighborhood Structures for Combinatorial Optimization Problems\". Evol Comput. 24 (4): 637–666. doi:10.1162/EVCO_a_00187. PMID 27258842. S2CID 13582781. - ^ Slowik, Adam; Kwasnicka, Halina (1 August 2020). \"Evolutionary algorithms and their applications to engineering problems\". Neural Computing and Applications. 32 (16): 12363–12379. doi:10.1007/s00521-020-04832-8. ISSN 1433-3058. - ^ Ma, Xiaoliang; Li, Xiaodong; Zhang, Qingfu; Tang, Ke; Liang, Zhengping; Xie, Weixin; Zhu, Zexuan (2019), \"A Survey on Cooperative Co-Evolutionary Algorithms.\", IEEE Transactions on Evolutionary Computation, 23 (3): 421–441, Bibcode:2019ITEC...23..421M, doi:10.1109/TEVC.2018.2868770, S2CID 125149900 - ^ Popovici, Elena; Bucci, Anthony; Wiegand, R. Paul; De Jong, Edwin D. (2012). \"Coevolutionary Principles\". In Rozenberg, Grzegorz; Bäck, Thomas; Kok, Joost N. (eds.). Handbook of Natural Computing. Berlin, Heidelberg: Springer Berlin Heidelberg. pp. 987–1033. doi:10.1007/978-3-540-92910-9_31. ISBN 978-3-540-92910-9. - ^ Pugh, Justin K.; Soros, Lisa B.; Stanley, Kenneth O. (2016-07-12). \"Quality Diversity: A New Frontier for Evolutionary Computation\". Frontiers in Robotics and AI. 3. doi:10.3389/frobt.2016.00040. ISSN 2296-9144. - ^ Lehman, Joel; Stanley, Kenneth O. (2011-07-12). \"Evolving a diversity of virtual creatures through novelty search and local competition\". Proceedings of the 13th annual conference on Genetic and evolutionary computation. New York, NY, USA: ACM. pp. 211–218. doi:10.1145/2001576.2001606. ISBN 9781450305570. S2CID 17338175. - ^ Cully, Antoine; Clune, Jeff; Tarapore, Danesh; Mouret, Jean-Baptiste (2015-05-27). \"Robots that can adapt like animals\". Nature. 521 (7553): 503–507. arXiv:1407.3501. Bibcode:2015Natur.521..503C. doi:10.1038/nature14422. ISSN 0028-0836. PMID 26017452. S2CID 3467239. - ^ a b Davis, Lawrence (1991). Handbook of genetic algorithms. New York: Van Nostrand Reinhold. ISBN 0-442-00173-8. OCLC 23081440. - ^ Lienig, Jens; Brandt, Holger (1994), Davidor, Yuval; Schwefel, Hans-Paul; Männer, Reinhard (eds.), \"An evolutionary algorithm for the routing of multi-chip modules\", Parallel Problem Solving from Nature — PPSN III, vol. 866, Berlin, Heidelberg: Springer, pp. 588–597, doi:10.1007/3-540-58484-6_301, ISBN 978-3-540-58484-1, retrieved 2022-10-18 - ^ Neri, Ferrante; Cotta, Carlos; Moscato, Pablo, eds. (2012). Handbook of Memetic Algorithms. Studies in Computational Intelligence. Vol. 379. Berlin, Heidelberg: Springer Berlin Heidelberg. doi:10.1007/978-3-642-23247-3. ISBN 978-3-642-23246-6. - ^ Leung, Yee; Gao, Yong; Xu, Zong-Ben (1997). \"Degree of population diversity - a perspective on premature convergence in genetic algorithms and its Markov chain analysis\". IEEE Transactions on Neural Networks. 8 (5): 1165–1176. doi:10.1109/72.623217. ISSN 1045-9227. PMID 18255718. - ^ Gorges-Schleuter, Martina (1998), Eiben, Agoston E.; Bäck, Thomas; Schoenauer, Marc; Schwefel, Hans-Paul (eds.), \"A comparative study of global and local selection in evolution strategies\", Parallel Problem Solving from Nature — PPSN V, Lecture Notes in Computer Science, vol. 1498, Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 367–377, doi:10.1007/bfb0056879, ISBN 978-3-540-65078-2, retrieved 2022-10-21 - ^ Dorronsoro, Bernabe; Alba, Enrique (2008). Cellular Genetic Algorithms. Operations Research/Computer Science Interfaces Series. Vol. 42. Boston, MA: Springer US. doi:10.1007/978-0-387-77610-1. ISBN 978-0-387-77609-5. - ^ Goldberg, David E. (1990), Schwefel, Hans-Paul; Männer, Reinhard (eds.), \"The theory of virtual alphabets\", Parallel Problem Solving from Nature, Lecture Notes in Computer Science, vol. 496, Berlin/Heidelberg: Springer-Verlag (published 1991), pp. 13–22, doi:10.1007/bfb0029726, ISBN 978-3-540-54148-6, retrieved 2022-10-22 - ^ Stender, J.; Hillebrand, E.; Kingdon, J. (1994). Genetic algorithms in optimisation, simulation, and modelling. Amsterdam: IOS Press. ISBN 90-5199-180-0. OCLC 47216370. - ^ Michalewicz, Zbigniew (1996). Genetic Algorithms + Data Structures = Evolution Programs (3rd ed.). Berlin Heidelberg: Springer. ISBN 978-3-662-03315-9. OCLC 851375253. - ^ G.S. Hornby and J.B. Pollack. \"Creating high-level components with a generative representation for body-brain evolution\". Artificial Life, 8(3):223–246, 2002. - ^ Jeff Clune, Benjamin Beckmann, Charles Ofria, and Robert Pennock. \"Evolving Coordinated Quadruped Gaits with the HyperNEAT Generative Encoding\" Archived 2016-06-03 at the Wayback Machine. Proceedings of the IEEE Congress on Evolutionary Computing Special Section on Evolutionary Robotics, 2009. Trondheim, Norway. - ^ J. Clune, C. Ofria, and R. T. Pennock, \"How a generative encoding fares as problem-regularity decreases\", in PPSN (G. Rudolph, T. Jansen, S. M. Lucas, C. Poloni, and N. Beume, eds.), vol. 5199 of Lecture Notes in Computer Science, pp. 358–367, Springer, 2008. - ^ Ferreira, C., 2001. \"Gene Expression Programming: A New Adaptive Algorithm for Solving Problems\". Complex Systems, Vol. 13, issue 2: 87–129. - ^ Schwefel, Hans-Paul (1995). Evolution and Optimum Seeking. Sixth-generation computer technology series. New York: Wiley. p. 109. ISBN 978-0-471-57148-3. - ^ Fogel, David B.; Bäck, Thomas; Michalewicz, Zbigniew, eds. (2000). Evolutionary Computation 1. Bristol ; Philadelphia: Institute of Physics Publishing. pp. xxx and xxxvii (Glossary). ISBN 978-0-7503-0664-5. OCLC 44807816. - ^ Sanchez, Ernesto; Squillero, Giovanni; Tonda, Alberto (2012). Industrial Applications of Evolutionary Algorithms. Intelligent Systems Reference Library. Vol. 34. Berlin, Heidelberg: Springer Berlin Heidelberg. doi:10.1007/978-3-642-27467-1. ISBN 978-3-642-27466-4. - ^ Miettinen, Kaisa; Neittaanmäki, Pekka; Mäkelä, M. M.; Périaux, Jacques, eds. (1999). Evolutionary algorithms in engineering and computer science : recent advances in genetic algorithms, evolution strategies, evolutionary programming, genetic programming, and industrial applications. Chichester: Wiley and Sons. ISBN 0-585-29445-3. OCLC 45728460. - ^ Gen, Mitsuo; Cheng, Runwei (1999-12-17). Genetic Algorithms and Engineering Optimization. Wiley Series in Engineering Design and Automation. Hoboken, NJ, USA: John Wiley & Sons, Inc. doi:10.1002/9780470172261. ISBN 978-0-470-17226-1. - ^ Dahal, Keshav P.; Tan, Kay Chen; Cowling, Peter I. (2007). Evolutionary scheduling. Berlin: Springer. doi:10.1007/978-3-540-48584-1. ISBN 978-3-540-48584-1. OCLC 184984689. - ^ Jakob, Wilfried; Strack, Sylvia; Quinte, Alexander; Bengel, Günther; Stucky, Karl-Uwe; Süß, Wolfgang (2013-04-22). \"Fast Rescheduling of Multiple Workflows to Constrained Heterogeneous Resources Using Multi-Criteria Memetic Computing\". Algorithms. 6 (2): 245–277. doi:10.3390/a6020245. ISSN 1999-4893. - ^ Mayer, David G. (2002). Evolutionary Algorithms and Agricultural Systems. Boston, MA: Springer US. doi:10.1007/978-1-4615-1717-7. ISBN 978-1-4613-5693-6. - ^ Blume, Christian (2000), Cagnoni, Stefano (ed.), \"Optimized Collision Free Robot Move Statement Generation by the Evolutionary Software GLEAM\", Real-World Applications of Evolutionary Computing, LNCS 1803, vol. 1803, Berlin, Heidelberg: Springer, pp. 330–341, doi:10.1007/3-540-45561-2_32, ISBN 978-3-540-67353-8, retrieved 2022-12-28 - ^ Aranha, Claus; Iba, Hitoshi (2008), Wobcke, Wayne; Zhang, Mengjie (eds.), \"Application of a Memetic Algorithm to the Portfolio Optimization Problem\", AI 2008: Advances in Artificial Intelligence, Lecture Notes in Computer Science, vol. 5360, Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 512–521, doi:10.1007/978-3-540-89378-3_52, ISBN 978-3-540-89377-6, retrieved 2022-12-23 - ^ Chen, Shu-Heng, ed. (2002). Evolutionary Computation in Economics and Finance. Studies in Fuzziness and Soft Computing. Vol. 100. Heidelberg: Physica-Verlag HD. doi:10.1007/978-3-7908-1784-3. ISBN 978-3-7908-2512-1. - ^ Lohn, J.D.; Linden, D.S.; Hornby, G.S.; Kraus, W.F. (June 2004). \"Evolutionary design of an X-band antenna for NASA's Space Technology 5 mission\". IEEE Antennas and Propagation Society Symposium, 2004. Vol. 3. pp. 2313–2316 Vol.3. doi:10.1109/APS.2004.1331834. hdl:2060/20030067398. ISBN 0-7803-8302-8. - ^ Fogel, Gary; Corne, David (2003). Evolutionary Computation in Bioinformatics. Elsevier. doi:10.1016/b978-1-55860-797-2.x5000-8. ISBN 978-1-55860-797-2. - ^ a b Jakob, Wilfried (2021), Applying Evolutionary Algorithms Successfully - A Guide Gained from Realworld Applications, KIT Scientific Working Papers, vol. 170, Karlsruhe, FRG: KIT Scientific Publishing, arXiv:2107.11300, doi:10.5445/IR/1000135763, S2CID 236318422, retrieved 2022-12-23 - ^ Whitley, Darrell (2001). \"An overview of evolutionary algorithms: practical issues and common pitfalls\". Information and Software Technology. 43 (14): 817–831. doi:10.1016/S0950-5849(01)00188-4. S2CID 18637958. - ^ Eiben, A.E.; Smith, J.E. (2015). \"Working with Evolutionary Algorithms\". Introduction to Evolutionary Computing. Natural Computing Series (2nd ed.). Berlin, Heidelberg: Springer Berlin Heidelberg. pp. 147–163. doi:10.1007/978-3-662-44874-8. ISBN 978-3-662-44873-1. S2CID 20912932. - ^ Singh, Avjeet; Kumar, Anoj (2021). \"Applications of nature-inspired meta-heuristic algorithms: a survey\". International Journal of Advanced Intelligence Paradigms. 20 (3/4) 119026: 388–417. doi:10.1504/IJAIP.2021.119026. - ^ Nguyen, Phan Trung Hai; Sudholt, Dirk (October 2020). \"Memetic algorithms outperform evolutionary algorithms in multimodal optimisation\". Artificial Intelligence. 287 103345. doi:10.1016/j.artint.2020.103345. - ^ Ma, Zhongqiang; Wu, Guohua; Suganthan, Ponnuthurai Nagaratnam; Song, Aijuan; Luo, Qizhang (March 2023). \"Performance assessment and exhaustive listing of 500+ nature-inspired metaheuristic algorithms\". Swarm and Evolutionary Computation. 77 101248. doi:10.1016/j.swevo.2023.101248. - ^ Gent, Edd (13 April 2020). \"Artificial intelligence is evolving all by itself\". Science | AAAS. Archived from the original on 16 April 2020. Retrieved 16 April 2020. - ^ Simionescu, P.A.; Dozier, G.V.; Wainwright, R.L. (2006). \"A Two-Population Evolutionary Algorithm for Constrained Optimization Problems\" (PDF). 2006 IEEE International Conference on Evolutionary Computation. Proc 2006 IEEE International Conference on Evolutionary Computation. Vancouver, Canada. pp. 1647–1653. doi:10.1109/CEC.2006.1688506. ISBN 0-7803-9487-9. S2CID 1717817. Retrieved 7 January 2017. {{cite book}} : CS1 maint: location missing publisher (link) - ^ Simionescu, P.A. (2014). Computer Aided Graphing and Simulation Tools for AutoCAD Users (1st ed.). Boca Raton, FL: CRC Press. ISBN 978-1-4822-5290-3. Bibliography [edit]- Ashlock, D. (2006), Evolutionary Computation for Modeling and Optimization, Springer, New York, doi:10.1007/0-387-31909-3 ISBN 0-387-22196-4. - Bäck, T. (1996), Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms, Oxford Univ. Press, New York, ISBN 978-0-19-509971-3. - Bäck, T., Fogel, D., Michalewicz, Z. (1999), Evolutionary Computation 1: Basic Algorithms and Operators, CRC Press, Boca Raton, USA, ISBN 978-0-7503-0664-5. - Bäck, T., Fogel, D., Michalewicz, Z. (2000), Evolutionary Computation 2: Advanced Algorithms and Operators, CRC Press, Boca Raton, USA, doi:10.1201/9781420034349 ISBN 978-0-3678-0637-8. - Banzhaf, W., Nordin, P., Keller, R., Francone, F. (1998), Genetic Programming - An Introduction, Morgan Kaufmann, San Francisco, ISBN 978-1-55860-510-7. - Eiben, A.E., Smith, J.E. (2003), Introduction to Evolutionary Computing, Springer, Heidelberg, New York, doi:10.1007/978-3-662-44874-8 ISBN 978-3-662-44873-1. - Holland, J. H. (1992), Adaptation in Natural and Artificial Systems, MIT Press, Cambridge, MA, ISBN 978-0-262-08213-6. - Michalewicz, Z.; Fogel, D.B. (2004), How To Solve It: Modern Heuristics. Springer, Berlin, Heidelberg, ISBN 978-3-642-06134-9, doi:10.1007/978-3-662-07807-5. - Benko, Attila; Dosa, Gyorgy; Tuza, Zsolt (2010). \"Bin Packing/Covering with Delivery, solved with the evolution of algorithms\". 2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA). pp. 298–302. doi:10.1109/BICTA.2010.5645312. ISBN 978-1-4244-6437-1. S2CID 16875144. - Price, K., Storn, R.M., Lampinen, J.A., (2005). Differential Evolution: A Practical Approach to Global Optimization, Springer, Berlin, Heidelberg, ISBN 978-3-642-42416-8, doi:10.1007/3-540-31306-0. - Ingo Rechenberg (1971), Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution (PhD thesis). Reprinted by Fromman-Holzboog (1973). ISBN 3-7728-1642-8 - Hans-Paul Schwefel (1974), Numerische Optimierung von Computer-Modellen (PhD thesis). Reprinted by Birkhäuser (1977). - Hans-Paul Schwefel (1995), Evolution and Optimum Seeking. Wiley & Sons, New York. ISBN 0-471-57148-2 - Simon, D. (2013), Evolutionary Optimization Algorithms Archived 2014-03-10 at the Wayback Machine, Wiley & Sons, ISBN 978-0-470-93741-9 - Kruse, Rudolf; Borgelt, Christian; Klawonn, Frank; Moewes, Christian; Steinbrecher, Matthias; Held, Pascal (2013), Computational Intelligence: A Methodological Introduction. Springer, London. ISBN 978-1-4471-5012-1, doi:10.1007/978-1-4471-5013-8. - Rahman, Rosshairy Abd.; Kendall, Graham; Ramli, Razamin; Jamari, Zainoddin; Ku-Mahamud, Ku Ruhana (2017). \"Shrimp Feed Formulation via Evolutionary Algorithm with Power Heuristics for Handling Constraints\". Complexity. 2017: 1–12. doi:10.1155/2017/7053710.",
    "text_length": 31043,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:02.065417"
  },
  {
    "id": "page_13",
    "url": "https://en.wikipedia.org/wiki/Hybrid_intelligent_system",
    "domain": "en.wikipedia.org",
    "title": "Hybrid intelligent system - Wikipedia",
    "text": "Hybrid intelligent system | Part of a series on | | Artificial intelligence (AI) | |---| Hybrid intelligent system denotes a software system which employs, in parallel, a combination of methods and techniques from artificial intelligence subfields, such as: - Neuro-symbolic systems - Neuro-fuzzy systems - Hybrid connectionist-symbolic models - Fuzzy expert systems - Connectionist expert systems - Evolutionary neural networks - Genetic fuzzy systems - Rough fuzzy hybridization - Reinforcement learning with fuzzy, neural, or evolutionary methods as well as symbolic reasoning methods. From the cognitive science perspective, every natural intelligent system is hybrid because it performs mental operations on both the symbolic and subsymbolic levels. For the past few years, there has been an increasing discussion of the importance of A.I. Systems Integration. Based on notions that there have already been created simple and specific AI systems (such as systems for computer vision, speech synthesis, etc., or software that employs some of the models mentioned above) and now is the time for integration to create broad AI systems. Proponents of this approach are researchers such as Marvin Minsky, Ron Sun, Aaron Sloman, Angelo Dalli and Michael A. Arbib. An example hybrid is a hierarchical control system in which the lowest, reactive layers are sub-symbolic. The higher layers, having relaxed time constraints, are capable of reasoning from an abstract world model and performing planning (even by hybrid wisdom[1]). Intelligent systems usually rely on hybrid reasoning processes, which include induction, deduction, abduction and reasoning by analogy. See also [edit]- AI alignment - AI effect - Applications of artificial intelligence - Artificial intelligence systems integration - Intelligent control - Lists References [edit]- ^ Besharati, Mohammad Reza; Izadi, Mohammad (November 3, 2025), Hybrid Wisdom, doi:10.20944/preprints202511.0006.v1, retrieved November 3, 2025 - R. Sun & L. Bookman, (eds.), Computational Architectures Integrating Neural and Symbolic Processes. Kluwer Academic Publishers, Needham, MA. 1994. http://www.cogsci.rpi.edu/~rsun/book2-ann.html Archived 2009-05-05 at the Wayback Machine - S. Wermter and R. Sun, (eds.) Hybrid Neural Systems. Springer-Verlag, Heidelberg. 2000. http://www.cogsci.rpi.edu/~rsun/book4-ann.html Archived 2009-09-24 at the Wayback Machine - R. Sun and F. Alexandre, (eds.) Connectionist-Symbolic Integration. Lawrence Erlbaum Associates, Mahwah, NJ. 1997. - Ibaraki, S. Hybrid Intelligence interview with Angelo Dalli in IEEE Technology and Management Society. 2024. - Albus, J. S., Bostelman, R., Chang, T., Hong, T., Shackleford, W., and Shneier, M. Learning in a Hierarchical Control System: 4D/RCS in the DARPA LAGR Program NIST, 2006 - A.S. d'Avila Garcez, Luis C. Lamb & Dov M. Gabbay. Neural-Symbolic Cognitive Reasoning. Cognitive Technologies, Springer (2009). ISBN 978-3-540-73245-7. - International Journal of Hybrid Intelligent Systems - http://www.iospress.nl/html/14485869.php Archived 2005-12-11 at the Wayback Machine - International Conference on Hybrid Intelligent Systems http://his.hybridsystem.com/ - HIS'01: http://www.softcomputing.net/his01/ - HIS'02: https://web.archive.org/web/20060209160923/http://tamarugo.cec.uchile.cl/~his02/ - HIS'03: http://www.softcomputing.net/his03/ - HIS'04: https://web.archive.org/web/20060303051902/http://www.cs.nmt.edu/~his04/ - HIS'05: https://web.archive.org/web/20051223013031/http://www.ica.ele.puc-rio.br/his05/ - HIS'06 https://web.archive.org/web/20110510025133/http://his-ncei06.kedri.info/ - HIS'7 September 17–19, 2007, Kaiserslautern, Germany, http://www.eit.uni-kl.de/koenig/HIS07_Web/his07main.html - hybrid systems resources: http://www.cogsci.rpi.edu/~rsun/hybrid-resource.html Archived 2009-09-25 at the Wayback Machine Further reading [edit]- Shiralkar, Shreekant. Games for Gravitas: A Playbook to Build Human Advantage in the Hybrid Intelligence Era. [Independently published], [November, 2025]. [ISBN-13 : 979-8272610102 ]",
    "text_length": 4067,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:03.806864"
  },
  {
    "id": "page_14",
    "url": "https://en.wikipedia.org/wiki/Artificial_intelligence_systems_integration",
    "domain": "en.wikipedia.org",
    "title": "Artificial intelligence systems integration - Wikipedia",
    "text": "Artificial intelligence systems integration | Part of a series on | | Artificial intelligence (AI) | |---| The core idea of artificial intelligence systems integration is making individual software components, such as speech synthesizers, interoperable with other components, such as common sense knowledgebases, in order to create larger, broader and more capable A.I. systems. The main methods that have been proposed for integration are message routing, or communication protocols that the software components use to communicate with each other, often through a middleware blackboard system. Most artificial intelligence systems involve some sort of integrated technologies, for example, the integration of speech synthesis technologies with that of speech recognition. However, in recent years, there has been an increasing discussion on the importance of systems integration as a field in its own right. Proponents of this approach are researchers such as Marvin Minsky, Aaron Sloman, Deb Roy, Kristinn R. Thórisson and Michael A. Arbib. A reason for the recent attention A.I. integration is attracting is that there have already been created a number of (relatively) simple A.I. systems for specific problem domains (such as computer vision, speech synthesis, etc.), and that integrating what's already available is a more logical approach to broader A.I. than building monolithic systems from scratch. Integration focus [edit]The focus on systems' integration, especially with regard to modular approaches, derive from the fact that most intelligences of significant scales are composed of a multitude of processes and/or utilize multi-modal input and output. For example, a humanoid-type of intelligence would preferably have to be able to talk using speech synthesis, hear using speech recognition, understand using a logical (or some other undefined) mechanism, and so forth. In order to produce artificially intelligent software of broader intelligence, integration of these modalities is necessary. Challenges and solutions [edit]Collaboration is an integral part of software development as evidenced by the size of software companies and the size of their software departments. Among the tools to ease software collaboration are various procedures and standards that developers can follow to ensure quality, reliability and that their software is compatible with software created by others (such as W3C standards for webpage development). However, collaboration in fields of A.I. has been lacking, for the most part not seen outside the respected schools, departments or research institutes (and sometimes not within them either). This presents practitioners of A.I. systems integration with a substantial problem and often causes A.I. researchers to have to 're-invent the wheel' each time they want a specific functionality to work with their software. Even more damaging is the \"not invented here\" syndrome, which manifests itself in a strong reluctance of A.I. researchers to build on the work of others. The outcome of this in A.I. is a large set of \"solution islands\": A.I. research has produced numerous isolated software components and mechanisms that deal with various parts of intelligence separately. To take some examples: - Speech synthesis - FreeTTS from CMU - Speech recognition - Sphinx from CMU - Logical reasoning - OpenCyc from Cycorp - Open Mind Common Sense Net from MIT With the increased popularity of the free software movement, a lot of the software being created, including A.I. systems, is available for public exploit. The next natural step is to merge these individual software components into coherent, intelligent systems of a broader nature. As a multitude of components (that often serve the same purpose) have already been created by the community, the most accessible way of integration is giving each of these components an easy way to communicate with each other. By doing so, each component by itself becomes a module, which can then be tried in various settings and configurations of larger architectures. Some challenging and limitations of using A.I. software is the uncontrolled fatal errors. For example, serious and fatal errors have been discovered in very precise fields such as human oncology, as in an article published in the journal Oral Oncology Reports entitled \"When AI goes wrong: Fatal errors in oncological research reviewing assistance\".[1] The article pointed out a grave error in artificial intelligence based on GBT in the field of biophysics. Many online communities for A.I. developers exist where tutorials, examples, and forums aim at helping both beginners and experts build intelligent systems. However, few communities have succeeded in making a certain standard, or a code of conduct popular to allow the large collection of miscellaneous systems to be integrated with ease. Methodologies [edit]Constructionist design methodology [edit]The constructionist design methodology (CDM, or 'Constructionist A.I.') is a formal methodology proposed in 2004, for use in the development of cognitive robotics, communicative humanoids and broad AI systems. The creation of such systems requires the integration of a large number of functionalities that must be carefully coordinated to achieve coherent system behavior. CDM is based on iterative design steps that lead to the creation of a network of named interacting modules, communicating via explicitly typed streams and discrete messages. The OpenAIR message protocol (see below) was inspired by the CDM and has frequently been used to aid in the development of intelligent systems using CDM. Examples [edit]- ASIMO, Honda's humanoid robot, and QRIO, Sony's version of a humanoid robot. - Cog, M.I.T. humanoid robot project under the direction of Rodney Brooks. - AIBO, Sony's robot dog, integrates vision, hearing and motorskills. - TOPIO, TOSY's humanoid robot can play ping-pong with human See also [edit]- Hybrid intelligent system, systems that combine the methods of traditional symbolic AI & that of Computational intelligence. - Neurosymbolic AI - Humanoid robots utilize systems integration intensely. - Constructionist design methodology - Cognitive architectures References [edit]- ^ Al-Raeei, Marwan (March 20, 2024). \"When AI goes wrong: Fatal errors in oncological research reviewing assistance\". Oral Oncology Reports. 10 100292. doi:10.1016/j.oor.2024.100292. ISSN 2772-9060. Notes [edit]- Constructionist Design Methodology, published in A.I. magazine - MissionEngine: Multi-system integration using Python in the Tactical Language Project",
    "text_length": 6581,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:05.515956"
  },
  {
    "id": "page_15",
    "url": "https://en.wikipedia.org/wiki/Open-source_artificial_intelligence",
    "domain": "en.wikipedia.org",
    "title": "Open-source artificial intelligence - Wikipedia",
    "text": "Open-source artificial intelligence | Part of a series on | | Artificial intelligence (AI) | |---| Open-source artificial intelligence, as defined by the Open Source Initiative, is an AI system that is freely available to use, study, modify, and share.[1][2] This includes datasets used to train the model, its code, and model parameters, promoting a collaborative and transparent approach to AI development so someone could create a substantially similar result.[3][4] The debate over what should count as ‘open-source’ given a range of openness among AI projects has been significant. Some large language models touted as open-sourced that only release model-weights (but not training data and code)[5][6] have been criticized as \"openwashing\"[7] systems that are mostly closed.[8] Free and open-source software (FOSS) licenses, such as the Apache License, MIT License, and GNU General Public License, outline the terms under which open-source artificial intelligence can be accessed, modified, and redistributed.[9] Popular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots.[10] Debate over the benefits and risks of open-sourced AI involve a range of factors like security, privacy and technological advancement.[11][12][8][13] History [edit]The history of open-source artificial intelligence is intertwined with both the development of AI technologies and the growth of the open-source software movement.[14] Open-source AI has evolved significantly over the past few decades, with contributions from various academic institutions, research labs, tech companies, and independent developers.[15][better source needed] This section explores the major milestones in the development of open-source AI, from its early days to its current state. 1990s: Early development of AI and open-source software [edit]The concept of AI dates back to the mid-20th century, when computer scientists like Alan Turing and John McCarthy laid the groundwork for modern AI theories and algorithms.[16] An early form of AI, the natural language processing \"doctor\" ELIZA, was re-implemented and shared in 1977 by Jeff Shrager as a BASIC program, and soon translated to many other languages. Early AI research focused on developing symbolic reasoning systems and rule-based expert systems.[17] During this period, the idea of open-source software was beginning to take shape, with pioneers like Richard Stallman advocating for free software as a means to promote collaboration and innovation in programming.[18] The Free Software Foundation, founded in 1985 by Stallman, was one of the first major organizations to promote the idea of software that could be freely used, modified, and distributed. The ideas from this movement eventually influenced the development of open-source AI, as more developers began to see the potential benefits of open collaboration in software creation, including AI models and algorithms.[19][better source needed][15][better source needed] In the 1990s, open-source software began to gain more traction,[20][better source needed] the rise of machine learning and statistical methods also led to the development of more practical AI tools. In 1993, the CMU Artificial Intelligence Repository was initiated, with a variety of openly shared software.[21][better source needed] 2000s: Emergence of open-source AI [edit]In the early 2000s open-source AI began to take off, with the release of more user-friendly foundational libraries and frameworks that were available for anyone to use and contribute to.[22][better source needed] OpenCV was released in 2000[23] with a variety of traditional AI algorithms like decision trees, k-Nearest Neighbors (kNN), Naive Bayes and Support Vector Machines (SVM).[24] 2010s: Rise of open-source AI frameworks [edit]Open-source deep learning framework as Torch was released in 2002 and made open-source with Torch7 in 2011, and was later augmented by PyTorch, and TensorFlow.[25] AlexNet was released in 2012.[26] OpenAI was founded in 2015 with a mission to create open-source artificial intelligence that benefited humanity, at least in part to help with recruitment in the early phases of the organization.[27] GPT-1 was released in 2018. 2020s: Open-weight and open-source generative AI [edit]With the announcement of GPT-2 in 2019, OpenAI originally planned to keep the source code of their models private citing concerns about malicious applications.[28] After OpenAI faced public backlash, however, it released the source code for GPT-2 to GitHub three months after its release.[28] OpenAI did not publicly release the source code or pretrained weights for the GPT-3 model.[29] At the time of GPT-3's release GPT-2 was still the most powerful open source language model in the world. Competition in building more open models included mostly smaller efforts like EleutherAI.[30][31] 2022 also saw the rise of larger and more powerful models under licenses of varying openness including Meta's OPT.[32] The Open Source Initiative consulted experts over two years to create a definition of \"open-source\" that would fit the needs of AI software and models. The most controversial aspect relates to data access, since some models are trained on sensitive data which can't be released. In 2024, they published the Open Source AI Definition 1.0 (OSAID 1.0).[1][2][3] It requires full release of the software for processing the data, training the model and making inferences from the model. For the data, it only requires access to details about the data used to train the AI so others can understand and re-create it.[2] In 2023, Llama 1 and 2 and Mistral AI's Mistral and Mixtral open-weight models were first released,[33][34] along with MosaicML's MPT open-source model.[35][36] In 2024, Meta released a collection of large AI models, including Llama 3.1 405B, which was competitive with less open models.[37] The company claimed its approach to AI would be open-source, differing from other major tech companies.[37] The Open Source Initiative and others stated that Llama is not open-source despite Meta describing it as open-source, due to Llama's software license prohibiting it from being used for some purposes.[38][39][40] DeepSeek released their V3 LLM in December 2024, and their R1 reasoning model on January 20, 2025, both as open-weights models under the MIT license.[41][42] This release made widely known how China had been embracing using and building more open AI systems as a way to reduce reliance on western software and gatekeeping as well as to help give its industries access to higher-powered AI more quickly.[43] Projects based in China have since become more widely used around the world as well as they have closed at least some of the gap with leading proprietary American models.[43][44][45] Since the release of OpenAI's proprietary ChatGPT model in late 2022, there have been only a few fully open (weights, data, code, etc.) large language models released. In September 2025, a Swiss consortium added to this short list by releasing a fully open model named Apertus.[46][47] In December 2025, the Linux Foundation created the Agentic AI Foundation, which assumed control of some open-source agentic AI protocols and other technologies created by OpenAI, Anthropic and Block.[48][49] Significance [edit]The label ‘open-source’ can provide real benefits to companies looking to hire top talent or attract customers.[4] The debate around \"openwashing” (or calling a project open-source when it is mostly closed) has big implications for the success of various projects within the industry.[7] Open-source artificial intelligence tends to get more support and adoption in countries and companies that do not have their own leading AI model.[4] These open-source projects can help to undercut the position of business and geopolitical rivals with the strongest proprietary models.[4] Applications [edit]Healthcare [edit]In the healthcare industry, open-source AI has been used in diagnostics, patient care, and personalized treatment options.[50] Open-source libraries have been used for medical imaging for tasks such as tumor detection, improving the speed and accuracy of diagnostic processes.[51][50] Additionally, OpenChem, an open-source library specifically geared toward chemistry and biology applications, enables the development of predictive models for drug discovery, helping researchers identify potential compounds for treatment.[52] Military [edit]Meta's Llama models, which have been described as open-source by Meta, were adopted by U.S. defense contractors like Lockheed Martin and Oracle after unauthorized adaptations by Chinese researchers affiliated with the People's Liberation Army (PLA) came to light.[53][54] The Open Source Initiative and others have contested Meta's use of the term open-source to describe Llama, due to Llama's license containing an acceptable use policy that prohibits use cases including non-U.S. military use.[40] Chinese researchers used an earlier version of Llama to develop tools like ChatBIT, optimized for military intelligence and decision-making, prompting Meta to expand its partnerships with U.S. contractors to ensure the technology could be used strategically for national security.[54] These applications now include logistics, maintenance, and cybersecurity enhancements.[54] Benefits [edit]Privacy and independence [edit]A Nature editorial suggests medical care could become dependent on AI models that could be taken down at any time, are difficult to evaluate, and may threaten patient privacy.[12][55] Its authors propose that health-care institutions, academic researchers, clinicians, patients and technology companies worldwide should collaborate to build open-source models for health care of which the underlying code and base models are easily accessible and can be fine-tuned freely with own data sets.[12] Free speech [edit]Open-source models are harder to censor than close-sourced ones.[55] Collaboration and faster advancements [edit]Large-scale collaborations, such as those seen in the development of open-source frameworks like TensorFlow and PyTorch, have accelerated advancements in machine learning (ML) and deep learning.[56] The open-source nature of these platforms also facilitates rapid iteration and improvement, as contributors from across the globe can propose modifications and enhancements to existing tools.[56] Democratizing access [edit]Open-source allows countries and organizations that otherwise do not have access to proprietary models a way to use and invest in AI more cheaply.[4][57][58] This can help to create an ecosystem for other businesses to sell services on top of.[59] Transparency [edit]One key benefit of open-source AI is the increased transparency it offers compared to closed-source alternatives.[60][better source needed] The open-sourced aspects of models allow those algorithms and code to be inspected, which promotes accountability and helps developers understand how a model reaches its conclusions.[61][better source needed] Additionally, open-weight models, such as Llama and Stable Diffusion, allow developers to directly access model parameters, potentially facilitating the reduced bias and increased fairness in their applications.[61][better source needed] This transparency can help create systems with human-readable outputs, or \"explainable AI\", which is a growingly key concern, especially in high-stakes applications such as healthcare, criminal justice, and finance, where the consequences of decisions made by AI systems can be significant.[62][better source needed] Concerns [edit]Quality and security [edit]Open sourced models have fewer ways to prevent them from being used for malicious activities.[55] Open-source AI may allow bioterrorism groups to remove fine-tuning and other safeguards of AI models.[11][4][55] One proposed step towards reducing these kinds of harms could be to require models to have their risks evaluated and pass a certain standard before being released.[55] A July 2024 report by the White House found it did not yet find sufficient evidence to restrict revealing model weights,[63] though a number of experts in 2024 seemed more concerned about future advances than present-day capabilities.[55] Once an open-source model is public, it cannot be rolled back or updated if serious security issues are detected.[64][better source needed] The main barrier to developing real-world terrorist schemes lies in stringent restrictions on necessary materials and equipment.[64][better source needed] Furthermore, the rapid pace of AI advancement makes it less appealing to use older models, which are more vulnerable to attacks but also less capable.[64][better source needed] Researchers have also criticized open-source artificial intelligence for existing security and ethical concerns. An analysis of over 100,000 open-source models on Hugging Face and GitHub using code vulnerability scanners like Bandit, FlawFinder, and Semgrep found that over 30% of models have high-severity vulnerabilities.[65][better source needed] Furthermore, closed models typically have fewer safety risks than open-sourced models.[64][better source needed] The freedom to augment open-source models has led to developers releasing models without ethical guidelines, such as GPT4-Chan.[64][better source needed] Practicality [edit]Even with truly open-source AI, the cost of training a model oneself can still be prohibitively expensive for many users, unlike other open-source projects that require only downloading code.[4][59] Partially open-sourced code that is released with many legal restrictions has scared off some companies from using those projects for fear of a future lawsuit[4] or a change in the terms and conditions.[59] See also [edit]References [edit]- ^ a b Williams, Rhiannon; O'Donnell, James (August 22, 2024). \"We finally have a definition for open-source AI\". MIT Technology Review. Retrieved 28 November 2024. - ^ a b c Robison, Kylie (28 October 2024). \"Open-source AI must reveal its training data, per new OSI definition\". The Verge. Retrieved 28 November 2024. - ^ a b \"The Open Source AI Definition – 1.0\". Open Source Initiative. Archived from the original on 2025-03-31. Retrieved 2024-11-14. - ^ a b c d e f g h \"A battle is raging over the definition of open-source AI\". The Economist. November 6, 2024. ISSN 0013-0613. Retrieved 2025-12-09. - ^ \"Open Weights: not quite what you've been told\". Open Source Initiative. Retrieved 2025-09-23. - ^ \"OpenAI releases lower-cost models to rival Meta, Mistral and DeepSeek\". CNBC. 2025-08-05. Retrieved 2025-09-23. - ^ a b Liesenfeld, Andreas; Dingemanse, Mark (5 June 2024). \"Rethinking open source generative AI: Open washing and the EU AI Act\". The 2024 ACM Conference on Fairness, Accountability, and Transparency. Association for Computing Machinery. pp. 1774–1787. doi:10.1145/3630106.3659005. ISBN 979-8-4007-0450-5. - ^ a b Widder, David Gray; Whittaker, Meredith; West, Sarah Myers (November 2024). \"Why 'open' AI systems are actually closed, and why this matters\". Nature. 635 (8040): 827–833. Bibcode:2024Natur.635..827W. doi:10.1038/s41586-024-08141-1. ISSN 1476-4687. PMID 39604616. - ^ \"Licenses\". Open Source Initiative. Archived from the original on 2018-02-10. Retrieved 2024-11-14. - ^ Castelvecchi, Davide (29 June 2023). \"Open-source AI chatbots are booming — what does this mean for researchers?\". Nature. 618 (7967): 891–892. Bibcode:2023Natur.618..891C. doi:10.1038/d41586-023-01970-6. PMID 37340135. - ^ a b Sandbrink, Jonas (2023-08-07). \"ChatGPT could make bioterrorism horrifyingly easy\". Vox. Retrieved 2024-11-14. - ^ a b c Toma, Augustin; Senkaiahliyan, Senthujan; Lawler, Patrick R.; Rubin, Barry; Wang, Bo (December 2023). \"Generative AI could revolutionize health care — but not if control is ceded to big tech\". Nature. 624 (7990): 36–38. Bibcode:2023Natur.624...36T. doi:10.1038/d41586-023-03803-y. PMID 38036861. - ^ Davies, Pascale (20 February 2024). \"What is open source AI and why is profit so important to the debate?\". Euronews. Retrieved 28 November 2024. - ^ Morrone, Megan (2024-02-15). \"With the rise of AI, the software business redefines \"open\"\". Axios. Retrieved 2025-12-16. - ^ a b Daigle, Kyle (2023-11-08). \"Octoverse: The state of open source and rise of AI in 2023\". The GitHub Blog. Retrieved 2024-11-24. - ^ \"Appendix I: A Short History of AI | One Hundred Year Study on Artificial Intelligence (AI100)\". ai100.stanford.edu. Retrieved 2024-11-24. - ^ Kautz, Henry (2022-03-31). \"The Third AI Summer: AAAI Robert S. Engelmore Memorial Lecture\". AI Magazine. 43 (1): 105–125. doi:10.1002/aaai.12036. ISSN 2371-9621. - ^ \"Why Software Should Be Free - GNU Project - Free Software Foundation\". www.gnu.org. Archived from the original on 2024-12-01. Retrieved 2024-11-24. - ^ \"The Power of Collaboration: How Open-Source Projects are Advancing AI\". kdnuggets.com. - ^ Code, Linux (2024-11-03). \"A Brief History of Open Source\". TheLinuxCode. Retrieved 2024-11-24.[permanent dead link] - ^ \"Topic: (/)\". www.cs.cmu.edu. Retrieved 2025-09-11. - ^ Priya (2024-03-28). \"The Evolution of Open Source AI Libraries: From Basement Brawls to AI All-Stars\". TheGen.AI. Retrieved 2024-11-24. - ^ Pulli, Kari; Baksheev, Anatoly; Kornyakov, Kirill; Eruhimov, Victor (1 April 2012). \"Realtime Computer Vision with OpenCV\". ACM Queue. 10 (4): 40:40–40:56. doi:10.1145/2181796.2206309. - ^ Adrian Kaehler; Gary Bradski (14 December 2016). Learning OpenCV 3: Computer Vision in C++ with the OpenCV Library. O'Reilly Media. pp. 26ff. ISBN 978-1-4919-3800-3. - ^ Costa, Carlos J.; Aparicio, Manuela; Aparicio, Sofia; Aparicio, Joao Tiago (January 2024). \"The Democratization of Artificial Intelligence: Theoretical Framework\". Applied Sciences. 14 (18): 8236. doi:10.3390/app14188236. hdl:10362/173131. ISSN 2076-3417. - ^ Lee, Timothy B. (2024-11-11). \"How a stubborn computer scientist accidentally launched the deep learning boom\". Ars Technica. Retrieved 2025-09-11. - ^ Metz, Rachel (2024-03-15). \"OpenAI and the Fierce AI Industry Debate Over Open Source\". Bloomberg.com. Retrieved 2025-12-16. - ^ a b Xiang, Chloe (2023-02-28). \"OpenAI Is Now Everything It Promised Not to Be: Corporate, Closed-Source, and For-Profit\". VICE. Retrieved 2024-11-14. - ^ Hao, Karen (September 23, 2020). \"OpenAI is giving Microsoft exclusive access to its GPT-3 language model\". MIT Technology Review. Archived from the original on 2021-02-05. Retrieved 2024-12-08. - ^ \"GPT-3's free alternative GPT-Neo is something to be excited about\". VentureBeat. 2021-05-15. Archived from the original on 9 March 2023. Retrieved 2023-04-14. - ^ \"EleutherAI: When OpenAI Isn't Open Enough\". IEEE Spectrum. 2021-06-02. Archived from the original on March 27, 2022. - ^ Heaven, Will (2022-05-03). \"Meta has built a massive new language AI—and it's giving it away for free\". MIT Technology Review. Retrieved 2023-12-26. - ^ Nicol-Schwarz, Kai (2025-12-02). \"French AI lab Mistral releases new AI models as it looks to keep pace with OpenAI and Google\". CNBC. Retrieved 2025-12-05. - ^ Heikkilä, Melissa (December 2, 2025). \"Mistral unveils new models in race to gain edge in 'open' AI\". Financial Times. Retrieved 2025-12-05. - ^ Nunez, Michael (2023-06-22). \"MosaicML challenges OpenAI with its new open-source language model\". VentureBeat. Retrieved 2025-07-21. - ^ Chen, Joanne (2023-07-19). \"MosaicML launches MPT-7B-8K, a 7B-parameter open-source LLM with 8k context length\". VentureBeat. Retrieved 2025-07-21. - ^ a b Mirjalili, Seyedali (2024-08-01). \"Meta just launched the largest 'open' AI model in history. Here's why it matters\". The Conversation. Retrieved 2024-11-14. - ^ Waters, Richard (2024-10-17). \"Meta under fire for 'polluting' open-source\". Financial Times. Retrieved 2024-11-14. - ^ Edwards, Benj (18 July 2023). \"Meta launches Llama 2, a source-available AI model that allows commercial applications\". Ars Technica. Archived from the original on 7 November 2023. Retrieved 14 December 2024. - ^ a b \"Meta offers Llama AI to US government for national security\". CIO. 5 November 2024. Archived from the original on 14 December 2024. Retrieved 14 December 2024. - ^ Chen, Caiwei (January 24, 2025). \"How a top Chinese AI model overcame US sanctions\". MIT Technology Review. Archived from the original on 2025-01-25. Retrieved 2025-02-03. - ^ Guo, Daya; et al. (18 September 2025). \"DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning\". Nature. 645 (8081): 633–638. Bibcode:2025Natur.645..633G. doi:10.1038/s41586-025-09422-z. PMC 12443585. PMID 40962978. - ^ a b Bloom, Peter (2025-02-12). \"DeepSeek: how China's embrace of open-source AI caused a geopolitical earthquake\". The Conversation. Retrieved 2025-12-09. - ^ Huang, Raffaele (2025-08-13). \"China's Lead in Open-Source AI Jolts Washington and Silicon Valley\". The Wall Street Journal. Retrieved 2025-12-09. - ^ Cui, Jasmine; Perlo, Jared (2025-11-30). \"More of Silicon Valley is building on free Chinese AI\". NBC News. Retrieved 2025-12-09. - ^ Welle, Elissa (2025-09-03). \"Switzerland releases an open-weight AI model\". The Verge. Retrieved 2025-10-08. - ^ Allen, Matthew (2025-09-02). \"Switzerland launches transparent ChatGPT alternative\". SWI swissinfo.ch. Retrieved 2025-10-08. - ^ Knight, Will. \"OpenAI, Anthropic, and Block Are Teaming Up to Make AI Agents Play Nice\". Wired. ISSN 1059-1028. Retrieved 2025-12-16. - ^ Claburn, Thomas (December 9, 2025). \"Linux Foundation aims to become the Switzerland of AI agents\". The Register. - ^ a b Esteva, Andre; Robicquet, Alexandre; Ramsundar, Bharath; Kuleshov, Volodymyr; DePristo, Mark; Chou, Katherine; Cui, Claire; Corrado, Greg; Thrun, Sebastian; Dean, Jeff (January 2019). \"A guide to deep learning in healthcare\". Nature Medicine. 25 (1): 24–29. Bibcode:2019NatMe..25...24E. doi:10.1038/s41591-018-0316-z. ISSN 1546-170X. PMID 30617335. - ^ Ashraf, Mudasir; Ahmad, Syed Mudasir; Ganai, Nazir Ahmad; Shah, Riaz Ahmad; Zaman, Majid; Khan, Sameer Ahmad; Shah, Aftab Aalam (2021). \"Prediction of Cardiovascular Disease Through Cutting-Edge Deep Learning Technologies: An Empirical Study Based on TENSORFLOW, PYTORCH and KERAS\". In Gupta, Deepak; Khanna, Ashish; Bhattacharyya, Siddhartha; Hassanien, Aboul Ella; Anand, Sameer; Jaiswal, Ajay (eds.). International Conference on Innovative Computing and Communications. Advances in Intelligent Systems and Computing. Vol. 1165. Singapore: Springer. pp. 239–255. doi:10.1007/978-981-15-5113-0_18. ISBN 978-981-15-5113-0. - ^ Korshunova, Maria; Ginsburg, Boris; Tropsha, Alexander; Isayev, Olexandr (2021-01-25). \"OpenChem: A Deep Learning Toolkit for Computational Chemistry and Drug Design\". Journal of Chemical Information and Modeling. 61 (1): 7–13. doi:10.1021/acs.jcim.0c00971. ISSN 1549-9596. PMID 33393291. - ^ Pomfret, James; Pang, Jessie; Pomfret, James; Pang, Jessie (2024-11-01). \"Exclusive: Chinese researchers develop AI model for military use on back of Meta's Llama\". Reuters. Retrieved 2024-11-16. - ^ a b c Roth, Emma (2024-11-04). \"Meta AI is ready for war\". The Verge. Retrieved 2024-11-16. - ^ a b c d e f Piper, Kelsey (2024-02-02). \"Should we make our most powerful AI models open source to all?\". Vox. Retrieved 2025-12-16. - ^ a b Dean, Jeffrey (2022-05-01). \"A Golden Decade of Deep Learning: Computing Systems & Applications\". Daedalus. 151 (2): 58–74. doi:10.1162/daed_a_01900. ISSN 0011-5266. - ^ Hassri, Myftahuddin Hazmi; Man, Mustafa (2023-12-07). \"The Impact of Open-Source Software on Artificial Intelligence\". Journal of Mathematical Sciences and Informatics. 3 (2). doi:10.46754/jmsi.2023.12.006. ISSN 2948-3697. - ^ Solaiman, Irene (May 24, 2023). \"Generative AI Systems Aren't Just Open or Closed Source\". Wired. Archived from the original on November 27, 2023. Retrieved July 20, 2023. - ^ a b c Lin, Belle (2024-03-21). \"Open-Source Companies Are Sharing Their AI Free. Can They Crack OpenAI's Dominance?\". Wall Street Journal. ISSN 0099-9660. Retrieved 2025-12-16. - ^ MACHADO, J. (2025). Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs. Conference Paper. arXiv:2505.10603. - ^ a b White, Matt; Haddad, Ibrahim; Osborne, Cailean; Xiao-Yang Yanglet Liu; Abdelmonsef, Ahmed; Varghese, Sachin; Arnaud Le Hors (2024). \"The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency, and Usability in Artificial Intelligence\". arXiv:2403.13784 [cs.LG]. - ^ Gujar, Praveen. \"Council Post: Building Trust In AI: Overcoming Bias, Privacy And Transparency Challenges\". Forbes. Retrieved 2024-11-27. - ^ O'Brien, Matt (2024-07-30). \"White House says no need to restrict open-source AI, for now\". Associated Press. PBS News. Retrieved 2024-11-14. - ^ a b c d e Eiras, Francisco; Petrov, Aleksandar; Vidgen, Bertie; Schroeder, Christian; Pizzati, Fabio; Elkins, Katherine; Mukhopadhyay, Supratik; Bibi, Adel; Purewal, Aaron (2024-05-29). \"Risks and Opportunities of Open-Source Generative AI\". arXiv:2405.08597 [cs.LG]. - ^ Kathikar, Adhishree; Nair, Aishwarya; Lazarine, Ben (2023). \"Assessing the Vulnerabilities of the Open-Source Artificial Intelligence (AI) Landscape: A Large-Scale Analysis of the Hugging Face Platform\". 2023 IEEE International Conference on Intelligence and Security Informatics (ISI). pp. 1–6. doi:10.1109/ISI58743.2023.10297271. ISBN 979-8-3503-3773-0.",
    "text_length": 25463,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:07.404994"
  },
  {
    "id": "page_16",
    "url": "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence",
    "domain": "en.wikipedia.org",
    "title": "Applications of artificial intelligence - Wikipedia",
    "text": "Applications of artificial intelligence This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these messages) | | Part of a series on | | Artificial intelligence (AI) | |---| Artificial intelligence is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. Artificial intelligence has been used in applications throughout industry and academia. Within the field of Artificial Intelligence, there are multiple subfields. The subfield of Machine learning has been used for various scientific and commercial purposes[1] including language translation, image recognition, decision-making,[2][3] credit scoring, and e-commerce. In recent years, there have been massive advancements in the field of generative artificial intelligence, which uses generative models to produce text, images, videos or other forms of data.[4] This article describes applications of AI in different sectors. Agriculture [edit]In agriculture, AI has been proposed as a way for farmers to identify areas that need irrigation, fertilization, or pesticide treatments to increase yields, thereby improving efficiency.[5] AI has been used to attempt to classify livestock pig call emotions,[6] automate greenhouses,[7] detect diseases and pests,[8] and optimize irrigation.[9] Architecture and design [edit]Artificial intelligence in architecture is the use of artificial intelligence in automation, design, and planning in the architectural process or in assisting human skills in the field of architecture.[10] AI has been used by some architects for design, and has been proposed as a way to automate planning and routine tasks in the field.[11][12] Business [edit]A 2023 study found that generative AI increased productivity by 15% in contact centers.[13] Another 2023 study found it increased productivity by up to 40% in writing tasks.[14] An August 2025 review by MIT found that of surveyed companies, 95% did not report any improvement in revenue from the use of AI.[15] A September 2025 article by the Harvard Business Review describes how increased use of AI does not automatically lead to increases in revenue or actual productivity. Referring to \"AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task\" the article coins the term workslop. Per studies done in collaboration with the Stanford Social Media Lab, workslop does not improve productivity and undermines trust and collaboration among colleagues.[16] Computer science [edit]Programming assistance [edit]AI-assisted software development [edit]AI can be used for real-time code completion, chat, and automated test generation. These tools are typically integrated with editors and IDEs as plugins. AI-assisted software development systems differ in functionality, quality, speed, and approach to privacy. Creating software primarily via AI is known as \"vibe coding\". Code created or suggested by AI can be incorrect or inefficient.[17] The use of AI-assisted coding can potentially speed-up software development, but can also slow-down the process by creating more work when debugging and testing.[18][19] The rush to prematurely adopt AI technology can also incur additional technical debt.[18] AI also requires additional consideration and careful review for cybersecurity, since AI coding software is trained on a wide range of code of inconsistent quality and often replicates poor practices.[20][21] Neural network design [edit]AI can be used to create other AIs. For example, around November 2017, Google's AutoML project to evolve new neural net topologies created NASNet, a system optimized for ImageNet and POCO F1. NASNet's performance exceeded all previously published performance on ImageNet.[22] Quantum computing [edit]Research and development of quantum computers has been performed with machine learning algorithms. For example, there is a prototype, photonic, quantum memristive device for neuromorphic computers (NC)/artificial neural networks and NC-using quantum materials with some variety of potential neuromorphic computing-related applications.[23][24] The use of quantum machine learning for quantum simulators has been proposed for solving physics and chemistry problems.[25][26][better source needed] Historical contributions [edit]AI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered AI. All of the following were originally developed in AI laboratories:[27] - Time sharing - Interactive interpreters - Graphical user interfaces and the computer mouse - Rapid application development environments - The linked list data structure - Automatic storage management - Symbolic programming - Functional programming - Dynamic programming - Object-oriented programming - Optical character recognition - Constraint satisfaction Customer service [edit]Human resources [edit]Another application of AI is in human resources. AI can screen resumes and rank candidates based on their qualifications, predict candidate success in given roles, and automate repetitive communication tasks via chatbots.[citation needed] Online and telephone customer service [edit]AI underlies avatars (automated online assistants) on web pages.[28] It can reduce operation and training costs.[28] Pypestream automated customer service for its mobile application to streamline communication with customers.[29] A Google app analyzes language and converts speech into text.[30] The platform can identify angry customers through their language and respond appropriately.[31] Amazon uses a chatbot for customer service that can perform tasks like checking the status of an order, cancelling orders, offering refunds and connecting the customer with a human representative.[32] Generative AI (GenAI), such as ChatGPT, is increasingly used in business to automate tasks and enhance decision-making.[33] Hospitality [edit]In the hospitality industry, AI is used to reduce repetitive tasks, analyze trends, interact with guests, and predict customer needs.[34] AI hotel services come in the form of a chatbot,[35] application, virtual voice assistant and service robots. Education [edit]In educational institutions, AI has been used to automate routine tasks like attendance tracking, grading and marking. AI tools have been used to attempt to monitor student progress and analyze learning behaviors, with the intention of facilitating interventions for students facing academic problems.[36] Energy and environment [edit]Energy system [edit]The U.S. Department of Energy wrote in an April 2024 report that AI may have applications in modeling power grids, reviewing federal permits with large language models, predicting levels of renewable energy production, and improving the planning process for electrical vehicle charging networks.[37] Other studies have suggested that machine learning can be used for energy consumption prediction and scheduling, e.g. to help with renewable energy intermittency management (see also: smart grid and climate change mitigation in the power grid).[38][39][40][41][42] Environmental monitoring [edit]Autonomous ships that monitor the ocean, AI-driven satellite data analysis, passive acoustics[43] or remote sensing and other applications of environmental monitoring make use of machine learning.[44][45][46][47] For example, \"Global Plastic Watch\" is an AI-based satellite monitoring-platform for analysis/tracking of plastic waste sites to help prevention of plastic pollution – primarily ocean pollution – by helping identify who and where mismanages plastic waste, dumping it into oceans.[48][49] Early-warning systems [edit]Machine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics,[50][51] earthquakes,[52][53][54] landslides,[55] heavy rainfall,[56] long-term water supply vulnerability,[57] tipping-points of ecosystem collapse,[58] cyanobacterial bloom outbreaks,[59] and droughts.[60][61][62] Economic and social challenges [edit]The University of Southern California launched the Center for Artificial Intelligence in Society, with the goal of using AI to address problems such as homelessness. Stanford researchers use AI to analyze satellite images to identify high poverty areas.[63] Entertainment and media [edit]Media [edit]AI applications analyze media content such as movies, TV programs, advertisement videos or user-generated content. The solutions often involve computer vision. Typical scenarios include the analysis of images using object recognition or face recognition techniques, or the analysis of video for scene recognizing scenes, objects or faces. AI-based media analysis can facilitate media search, the creation of descriptive keywords for content, content policy monitoring (such as verifying the suitability of content for a particular TV viewing time), speech to text for archival or other purposes, and the detection of logos, products or celebrity faces for ad placement. - Motion interpolation[64] - Pixel-art scaling algorithms[65] - Image scaling[66] - Image restoration[67][68] - Photo colorization[69] - Film restoration and video upscaling[70] - Photo tagging - Text-to-image models such as DALL-E, Midjourney and Stable Diffusion - Image to video[71] - Text to video such as Make-A-Video from Meta, Imagen video and Phenaki from Google - Text to music with AI models such as MusicLM[72][73] - Text to speech such as ElevenLabs and 15.ai - Motion capture[74] Deep-fakes [edit]Deep-fakes can be used for comedic purposes but are better known for fake news and hoaxes. Deepfakes can portray individuals in harmful or compromising situations, causing significant reputational damage and emotional distress, especially when the content is defamatory or violates personal ethics. While defamation and false light laws offer some recourse, their focus on false statements rather than fabricated images or videos often leaves victims with limited legal protection and a challenging burden of proof.[75] In January 2016, the Horizon 2020 program financed the InVID Project to help journalists and researchers detect fake documents, made available as browser plugins.[76][77] In June 2016, the visual computing group of the Technical University of Munich and from Stanford University developed Face2Face,[78] a program that animates photographs of faces, mimicking the facial expressions of another person. In September 2018, U.S. Senator Mark Warner proposed to penalize social media companies that allow sharing of deep-fake documents on their platforms.[79] In 2018, Darius Afchar and Vincent Nozick found a way to detect faked content by analyzing the mesoscopic properties of video frames.[80] DARPA gave 68 million dollars to work on deep-fake detection.[80] Audio deepfakes[81][82] and AI software capable of detecting deep-fakes and cloning human voices have been developed.[83][84] Video surveillance analysis and manipulated media detection [edit]Artificial intelligence for video surveillance utilizes computer software programs that analyze the audio and images from video surveillance cameras in order to recognize humans, vehicles, objects and events. Security contractors program is the software to define restricted areas within the camera's view (such as a fenced off area, a parking lot but not the sidewalk or public street outside the lot) and program for times of day (such as after the close of business) for the property being protected by the camera surveillance. The artificial intelligence (\"A.I.\") sends an alert if it detects a trespasser breaking the \"rule\" set that no person is allowed in that area during that time of day. AI algorithms have been used to detect deepfake videos.[85][86] Video production [edit]Artificial intelligence is also starting to be used in video production, with tools and software being developed that utilize generative AI in order to create new video, or alter existing video. Some of the major tools that are being used in these processes currently are DALL-E, Mid-journey, and Runway.[87] Way mark Studios utilized the tools offered by both DALL-E and Mid-journey to create a fully AI generated film called The Frost in the summer of 2023.[87] Way mark Studios is experimenting with using these AI tools to generate advertisements and commercials for companies in mere seconds.[87] Yves Bergquist, a director of the AI & Neuroscience in Media Project at USC's Entertainment Technology Center, says post production crews in Hollywood are already using generative AI, and predicts that in the future more companies will embrace this new technology.[88] Music [edit]AI has been used to compose music of various genres. David Cope created an AI called Emily Howell that managed to become well known in the field of algorithmic computer music.[89] The algorithm behind Emily Howell is registered as a US patent.[90] In 2012, AI Iamus created the first complete classical album.[91] AIVA (Artificial Intelligence Virtual Artist), composes symphonic music, mainly classical music for film scores.[92] It achieved a world first by becoming the first virtual composer to be recognized by a musical professional association.[93] Melomics creates computer-generated music for stress and pain relief.[94] The Watson Beat uses reinforcement learning and deep belief networks to compose music on a simple seed input melody and a select style. The software was open sourced[95] and musicians such as Taryn Southern[96] collaborated with the project to create music. South Korean singer, Hayeon's, debut song, \"Eyes on You\" was composed using AI which was supervised by real composers, including NUVO.[97] Writing and reporting [edit]Narrative Science sells computer-generated news and reports. It summarizes sporting events based on statistical data from the game. It also creates financial reports and real estate analyses.[98] Automated Insights generates personalized recaps and previews for Yahoo Sports Fantasy Football.[99] Yseop, uses AI to turn structured data into natural language comments and recommendations. Yseop writes financial reports, executive summaries, personalized sales or marketing documents and more in multiple languages, including English, Spanish, French, and German.[100] TALESPIN made up stories similar to the fables of Aesop. The program started with a set of characters who wanted to achieve certain goals. Mark Riedl and Vadim Bulitko asserted that the essence of storytelling was experience management, or \"how to balance the need for a coherent story progression with user agency, which is often at odds\".[101] While AI storytelling focuses on story generation (character and plot), story communication also received attention. In 2002, researchers developed an architectural framework for narrative prose generation. They faithfully reproduced text variety and complexity on stories such as Little Red Riding Hood.[102] In 2016, a Japanese AI co-wrote a short story and almost won a literary prize.[103] South Korean company Hanteo Global uses a journalism bot to write articles.[104] Literary authors are also exploring uses of AI. An example is David Jhave Johnston's work ReRites (2017–2019), where the poet created a daily rite of editing the poetic output of a neural network to create a series of performances and publications. Sports writing [edit]In 2010, artificial intelligence used baseball statistics to automatically generate news articles. This was launched by The Big Ten Network using software from Narrative Science.[105] After being unable to cover every Minor League Baseball game with a large team, Associated Press collaborated with Automated Insights in 2016 to create game recaps that were automated by artificial intelligence.[106] UOL in Brazil expanded the use of AI in its writing. Rather than just generating news stories, they programmed the AI to include commonly searched words on Google.[106] El Pais, a Spanish news site that covers many things including sports, allows users to make comments on each news article. They use the Perspective API to moderate these comments and if the software deems a comment to contain toxic language, the commenter must modify it in order to publish it.[106] A local Dutch media group used AI to create automatic coverage of amateur soccer, set to cover 60,000 games in just a single season. NDC partnered with United Robots to create this algorithm and cover what would have never been possible before without an extremely large team.[106] Lede AI has been used in 2023 to take scores from high school football games to generate stories automatically for the local newspaper. This was met with significant criticism from readers for the very robotic diction that was published. With some descriptions of games being a \"close encounter of the athletic kind,\" readers were not pleased and let the publishing company, Gannett, know on social media. Gannett has since halted their used of Lede AI until they come up with a solution for what they call an experiment.[107] Wikipedia [edit]| Part of a series on | | Artificial intelligence (AI) | |---| Artificial intelligence and machine learning have long been used in Wikimedia projects, primarily to help edit existing articles.[108] Some applications of artificial intelligence, like using large language models to create new articles from scratch, have been more controversial than others for the Wikipedia community. In August 2025, Wikipedia adopted a policy that allowed editors to nominate suspected AI-generated articles for speedy deletion. Wikipedia has also been a significant source of training data for some of the earliest artificial intelligence projects. This has received mixed reactions including concern about companies not citing Wikipedia when relying on it to answer a question as well as Wikipedia’s increased costs from data scraping. Millions of its articles have been edited by bots[109] which however are usually not artificial intelligence software. Many AI platforms use Wikipedia data,[110] mainly for training machine learning applications. There is research and development of various artificial intelligence applications for Wikipedia such as for identifying outdated sentences,[111] detecting covert vandalism[112] or recommending articles and tasks to new editors. Machine translation [113][114] has also be used for translating Wikipedia articles and could play a larger role in creating, updating, expanding, and generally improving articles in the future. A content translation tool allows editors of some Wikipedias to more easily translate articles across several select languages.Video games [edit]In video games, AI is routinely used to generate behavior in non-player characters (NPCs). In addition, AI is used for pathfinding. Games with less typical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010).[115][116] AI is also used in Alien Isolation (2014) as a way to control the actions the Alien will perform next.[117] Games have been a major application[relevant?] of AI's capabilities since the 1950s. In the 21st century, AIs have beaten human players in many games, including chess (Deep Blue), Jeopardy! (Watson),[118] Go (AlphaGo),[119][120][121][122][123][124][125][excessive citations] poker (Pluribus[126] and Cepheus),[127] E-sports (StarCraft),[128][129] and general game playing (AlphaZero[130][131][132] and MuZero).[133][134][135][136][excessive citations] Kuki AI is a set of chatbots and other apps which were designed for entertainment and as a marketing tool.[137][138] Visual images [edit]The first AI art program, called AARON, was developed by Harold Cohen in 1968[139] with the goal of being able to code the act of drawing. It started by creating simple black and white drawings, and later to painting using special brushes and dyes that were chosen by the program itself without mediation from Cohen.[140] AI platforms such as DALL-E,[141] Stable Diffusion,[141] Imagen,[142] and Midjourney[143] have been used for generating visual images from inputs such as text or other images.[144] Some AI tools allow users to input images and output changed versions of that image, such as to display an object or product in different environments. AI image models can also attempt to replicate the specific styles of artists, and can add visual complexity to rough sketches. AI has been used to generate quantitative analysis of existing digital art collections.[145] Two computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art.[146] While distant viewing includes the analysis of large collections, close reading involves one piece of artwork. Computer animation [edit]In 2023, Netflix of Japan's usage of AI to generate background images for short The Dog & the Boy was met with backlash online.[147] Finance [edit]Financial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking began in 1987 when Security Pacific National Bank launched a fraud prevention task-force to counter the unauthorized use of debit cards.[148] Banks use AI to organize operations for bookkeeping, investing in stocks, and managing properties. AI can adapt to changes during non-business hours.[149] AI is used to combat fraud and financial crimes by monitoring behavioral patterns for any abnormal changes or anomalies.[150][151][152] The use of AI in applications such as online trading and decision-making has changed major economic theories.[153] For example, AI-based buying and selling platforms estimate personalized demand and supply curves, thus enabling individualized pricing. AI systems reduce information asymmetry in the market and thus make markets more efficient.[154] The application of artificial intelligence in the financial industry can alleviate the financing constraints of non-state-owned enterprises, especially for smaller and more innovative enterprises.[155] Trading and investment [edit]Algorithmic trading involves using AI systems to make trading decisions at speeds of magnitude greater than any human is capable of, making millions of trades in a day without human intervention. Such high-frequency trading represents a fast-growing sector. Many banks, funds, and proprietary trading firms now have AI-managed portfolios. Automated trading systems are typically used by large institutional investors but include smaller firms trading with their own AI systems.[156] Large financial institutions use AI to assist with their investment practices.[157] BlackRock's AI engine, Aladdin, is used both within the company and by clients to help with investment decisions. Its functions include the use of natural language processing to analyze text such as news, broker reports, and social media feeds. It then gauges the sentiment on the companies mentioned and assigns a score. Banks such as UBS and Deutsche Bank use SQREEM (Sequential Quantum Reduction and Extraction Model) to mine data to develop consumer profiles and match them with wealth management products.[158] Underwriting [edit]Online lender Upstart uses machine learning for underwriting.[159] ZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting.[160] This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories.[161] Audit [edit]AI makes continuous auditing possible. Potential benefits include reducing audit risk, increasing the level of assurance, and reducing audit duration.[162][quantify] Continuous auditing with AI allows real-time monitoring and reporting of financial activities and provides businesses with timely insights that can lead to quick decision-making.[163] Anti–money laundering [edit]AI software, such as LaundroGraph which uses contemporary suboptimal datasets, could be used for anti–money laundering (AML).[164][165] History [edit]In the 1980s, AI started to become prominent in finance as expert systems were commercialized. For example, Dupont created 100 expert systems, which helped them to save almost $10 million per year.[166] One of the first systems was the Pro-trader expert system that predicted the 87-point drop in the Dow Jones Industrial Average in 1986. \"The major junctions of the system were to monitor premiums in the market, determine the optimum investment strategy, execute transactions when appropriate and modify the knowledge base through a learning mechanism.\"[167] One of the first expert systems to help with financial plans was PlanPowerm and Client Profiling System, created by Applied Expert Systems (APEX). It was launched in 1986. It helped create personal financial plans for people.[168] In the 1990s, AI was applied to fraud detection. In 1993, FinCEN Artificial Intelligence System (FAIS) was launched. It was able to review over 200,000 transactions per week, and over two years, it helped identify 400 potential cases of money laundering equal to $1 billion.[169] These expert systems were later replaced by machine learning systems.[170] Outside finance, the late 1980s and early 1990s also saw expert systems used in technical and environmental domains. For example, researchers built a fishway design advisor to recommend fish passage structures under varying hydraulic and biological conditions using the VP-Expert shell.[171] Transportation researchers applied the same shell to balance airport capacity with noise-mitigation plans.[172] In agriculture, a potato insect expert system (PIES) supported pest management decisions for Colorado potato beetle.[173] The U.S. Environmental Protection Agency's CORMIX system for modeling pollutant discharges combined rules with Fortran hydrodynamic models.[174] AI can enhance entrepreneurial activity, and AI is one of the most dynamic areas for start-ups, with significant venture capital flowing into AI.[175] Regulatory developments in the EU [edit]In the European Union, the Artificial Intelligence Act (Regulation (EU) 2024/1689) classifies several finance‑sector uses of AI as \"high‑risk\", including systems used to evaluate the creditworthiness of natural persons or to establish a credit score and AI used for risk assessment and pricing in life or health insurance.[176][177][178] These systems must meet requirements on risk management, data governance, technical documentation and logging, transparency, and human oversight.[177][179] The Act's obligations are phased in: prohibitions and AI‑literacy rules apply from 2 February 2025, governance and most GPAI duties from 2 August 2025, the bulk of obligations from 2 August 2026, and certain safety‑component high‑risk obligations from 2 August 2027.[178] Health [edit]Healthcare [edit]AI in healthcare is often used for classification, to evaluate a CT scan or electrocardiogram or to identify high-risk patients for population health. AI is helping with the high-cost problem of dosing. One study suggested that AI could save $16 billion. In 2016, a study reported that an AI-derived formula derived the proper dose of immunosuppressant drugs to give to transplant patients.[180] Current research has indicated that non-cardiac vascular illnesses are also being treated with artificial intelligence (AI). For certain disorders, AI algorithms can aid in diagnosis, recommended treatments, outcome prediction, and patient progress tracking. As AI technology advances, it is anticipated that it will become more significant in the healthcare industry.[181] The early detection of diseases like cancer is made possible by AI algorithms, which diagnose diseases by analyzing complex sets of medical data. For example, the IBM Watson system might be used to comb through massive data such as medical records and clinical trials to help diagnose a problem.[182] Microsoft's AI project Hanover helps doctors choose cancer treatments from among the more than 800 medicines and vaccines.[183][184] Its goal is to memorize all the relevant papers to predict which (combinations of) drugs will be most effective for each patient. Myeloid leukemia is one target. Another study reported on an AI that was as good as doctors in identifying skin cancers.[185] Another project monitors multiple high-risk patients by asking each patient questions based on data acquired from doctor/patient interactions.[186] In one study done with transfer learning, an AI diagnosed eye conditions similar to an ophthalmologist and recommended treatment referrals.[187] Another study demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel judged better than a surgeon.[188] Artificial neural networks are used as clinical decision support systems for medical diagnosis,[189] such as in concept processing technology in EMR software. Other healthcare tasks thought suitable for an AI that are in development include: - Screening[190] - Companion robots for elder care[191] - Drug creation[192] (e.g. by identifying candidate drugs[193] and by using existing drug screening data such as in life extension research)[194] - Clinical training[195] - Identifying genomic pathogen signatures of novel pathogens[196] or identifying pathogens via physics-based fingerprints[197] (including pandemic pathogens) - Helping link genes to their functions,[198] otherwise analyzing genes[199] and identification of novel biological targets[200] - Help development of biomarkers[200] - Help tailor therapies to individuals in personalized medicine/precision medicine[200][201] Workplace health and safety [edit]AI-enabled chatbots decrease the need for humans to perform basic call center tasks, and machine learning in sentiment analysis can spot fatigue in order to prevent overwork.[202] Decision support systems can potentially prevent industrial disasters and make disaster response more efficient.[203] For manual workers in material handling, predictive analytics has been proposed to reduce musculoskeletal injury.[204] AI can attempt to process workers' compensation claims.[205][206] AI has been proposed for detection of accident near misses, which are underreported.[207] Biochemistry [edit]Machine learning has been used for drug design,[42] drug discovery and development, drug repurposing, improving pharmaceutical productivity, and clinical trials.[208] Computer-planned syntheses via computational reaction networks, described as a platform that combines \"computational synthesis with AI algorithms to predict molecular properties\",[209] has been used in drug-syntheses, and developing routes for recycling 200 industrial waste chemicals into important drugs and agrochemicals (chemical synthesis design).[210] It has also been used to explore the origins of life on Earth.[211] Deep learning has been used with databases for the development of a 46-day process to design, synthesize and test a drug which inhibits enzymes of a particular gene, DDR1. DDR1 is involved in cancers and fibrosis which is one reason for the high-quality datasets that enabled these results.[212] The AI program AlphaFold 2 can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million).[213][214][215][216][excessive citations] Language processing [edit]Language translation [edit]Speech translation technology attempts to convert one language's spoken words into another language. This potentially reduces language barriers in global commerce and cross-cultural exchange, enabling speakers of various languages to communicate with one another.[217] AI has been used to automatically translate spoken language and textual content in products such as Microsoft Translator, Google Translate, and DeepL Translator.[218] Additionally, research and development are in progress to decode and conduct animal communication.[6][219] Meaning is conveyed not only by text, but also through usage and context (see semantics and pragmatics). As a result, the two primary categorization approaches for machine translations are statistical machine translation (SMT) and neural machine translations (NMTs). The old method of performing translation was to use statistical methodology to forecast the best probable output with specific algorithms. However, with NMT, the approach employs dynamic algorithms to achieve better translations based on context.[220] Law and government [edit]Government [edit]AI facial recognition systems are used for mass surveillance, notably in China.[221][222] In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.[223] Law [edit]Legal analysis [edit]AI is a mainstay of law-related professions. Algorithms and machine learning do some tasks previously done by entry-level lawyers.[224] While its use is common, it is not expected to replace most work done by lawyers in the near future.[225] The electronic discovery industry uses machine learning to reduce manual searching.[226] Law enforcement and legal proceedings [edit]Law enforcement has begun using facial recognition systems (FRS) to identify suspects from visual data. FRS results have proven to be more accurate when compared to eyewitness results. Furthermore, FRS has shown to have much a better ability to identify individuals when video clarity and visibility are low in comparison to human participants.[227] COMPAS is a commercial system used by U.S. courts to assess the likelihood of recidivism.[228] One concern relates to algorithmic bias, AI programs may become biased after processing data that exhibits bias.[229] ProPublica claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than that of white defendants.[228] In 2019, the city of Hangzhou, China established a pilot program artificial intelligence-based Internet Court to adjudicate disputes related to ecommerce and internet-related intellectual property claims.[230]: 124 Parties appear before the court via videoconference and AI evaluates the evidence presented and applies relevant legal standards.[230]: 124 Manufacturing [edit]Sensors [edit]Artificial intelligence has been combined with digital spectrometry by IdeaCuria Inc.,[231][232] enable applications such as at-home water quality monitoring. Toys and games [edit]In the 1990s, early artificial intelligence tools controlled Tamagotchis and Giga Pets, the Internet, and the first widely released robot, Furby. Aibo was a domestic robot in the form of a robotic dog with intelligent features and autonomy. Mattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn.[233] Oil and gas [edit]Oil and gas companies have used artificial intelligence tools to automate functions, foresee equipment issues, and increase oil and gas output.[234][235] Mathematics [edit]AI tools have been used to translate mathematical proofs into formal proofs in order to automatically verify them.[236] Automated theorem proving [edit]Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. Automated reasoning over mathematical proof was a major motivating factor for the development of computer science. Computational geometry [edit]AlphaGeometry is an artificial intelligence (AI) program that can solve hard problems in Euclidean geometry. The system comprises a data-driven large language model (LLM) and a rule-based symbolic engine (Deductive Database Arithmetic Reasoning). It was developed by DeepMind, a subsidiary of Google. The program solved 25 geometry problems out of 30 from the International Mathematical Olympiad (IMO) under competition time limits—a performance almost as good as the average human gold medallist. For comparison, the previous AI program, called Wu's method, managed to solve only 10 problems.[237][238] DeepMind published a paper about AlphaGeometry in the peer-reviewed journal Nature on 17 January 2024.[239] AlphaGeometry was featured in MIT Technology Review on the same day.[240] Traditional geometry programs are symbolic engines that rely exclusively on human-coded rules to generate rigorous proofs, which makes them lack flexibility in unusual situations. AlphaGeometry combines such a symbolic engine with a specialized large language model trained on synthetic data of geometrical proofs. When the symbolic engine doesn't manage to find a formal and rigorous proof on its own, it solicits the large language model, which suggests a geometrical construct to move forward. However, it is unclear how applicable this method is to other domains of mathematics or reasoning, because symbolic engines rely on domain-specific rules and because of the need for synthetic data.[241] Military [edit]Various countries are deploying AI military applications.[242] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[242] AI has been used in military operations in Iraq, Syria, Israel and Ukraine.[242][243][244][245][excessive citations] Internet and e-commerce [edit]Procurement and Sourcing [edit]AI has been used in B2B sourcing and procurement.[246] Academic literature and industry reports point out uses of AI for supplier evaluation and selection, predictive demand forecasting, automated contract and invoice processing, and supply-chain risk assessment. Machine learning, natural language processing, and robotic process automation are commonly used in procurement.[247] E-commerce companies that have AI applications include Alibaba.com, Amazon Business, Shopify Plus, and TikTok Shop.[248] [249][250][251] Examples of AI being used in e-commerce include product sourcing engines and business research with tools like Accio[252] and Amazon Business Assistant for both Alibaba.com and Amazon[253], respectively. Web feeds and posts [edit]Machine learning has been used for recommendation systems in determining which posts should show up in social media feeds.[254][255] Various types of social media analysis also make use of machine learning[256][257] and there is research into its use for (semi-)automated tagging/enhancement/correction of online misinformation and related filter bubbles.[258][259][260] AI has been used to customize shopping options and personalize offers.[261] Online gambling companies have used AI for targeting gamblers.[262] Virtual assistants and search [edit]Intelligent personal assistants use AI to attempt to respond to natural language requests. Siri, released in 2010 for Apple smartphones, popularized the concept.[263] Bing Chat has used artificial intelligence as part of its search engine.[264] Spam filtering [edit]Machine learning can be used to combat spam, scams, and phishing. It can scrutinize the contents of spam and phishing attacks to attempt to identify malicious elements.[265] Some models built via machine learning algorithms have over 90% accuracy in distinguishing between spam and legitimate emails.[266] These models can be refined using new data and evolving spam tactics. Machine learning also analyzes traits such as sender behavior, email header information, and attachment types, potentially enhancing spam detection.[267] Facial recognition and image labeling [edit]AI has been used in facial recognition systems. Some examples are Apple's Face ID and Android's Face Unlock, which are used to secure mobile devices.[268] China has used facial recognition and artificial intelligence technology in Xinjiang. In 2017, reporters visiting the region found surveillance cameras installed every hundred meters or so in several cities, as well as facial recognition checkpoints at areas like gas stations, shopping centers, and mosque entrances.[269][270] Human rights groups have criticized the Chinese government for using artificial intelligence facial recognition technology for use in political suppression.[271][272] The Netherlands has deployed facial recognition and artificial intelligence technology since 2016.[273] The database of the Dutch police currently contains over 2.2 million pictures of 1.3 million Dutch citizens. This accounts for about 8% of the population. In The Netherlands, face recognition is not used by the police on municipal CCTV.[274] Image labeling has been used by Google Image Labeler to detect products in photos and to allow people to search based on a photo. Image labeling has also been demonstrated to generate speech to describe images to blind people.[218] Scientific research [edit]Evidence of general impacts [edit]In April 2024, the Scientific Advice Mechanism to the European Commission published advice[275] including a comprehensive evidence review of the opportunities and challenges posed by artificial intelligence in scientific research. As benefits, the evidence review[276] highlighted: - its role in accelerating research and innovation - its capacity to automate workflows - enhancing dissemination of scientific work As challenges: - limitations and risks around transparency, reproducibility and interpretability - poor performance (inaccuracy) - risk of harm through misuse or unintended use - societal concerns including the spread of misinformation and increasing inequalities Archaeology, history and imaging of sites [edit]Machine learning can help to restore and attribute ancient texts.[277] It can help to index texts for example to enable better and easier searching and classification of fragments.[278] Artificial intelligence can also be used to investigate genomes to uncover genetic history, such as interbreeding between archaic and modern humans by which for example the past existence of a ghost population, not Neanderthal or Denisovan, was inferred.[279] It can also be used for \"non-invasive and non-destructive access to internal structures of archaeological remains\".[280] Physics [edit]A deep learning system was reported to learn intuitive physics from visual data (of virtual 3D environments) based on an unpublished approach inspired by studies of visual cognition in infants.[281][282] Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior.[283][284] In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems.[283] Materials science [edit]In November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that the AI system GNoME had documented over 2 million new materials. GNoME uses deep learning techniques to examine potential material structures, and identify stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, with a success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database.[285][286][287] Reverse engineering [edit]Machine learning is used in diverse types of reverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts,[288] and for quickly understanding the behavior of malware.[289][290][291] It can be used to reverse engineer artificial intelligence models.[292] It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionality[293] or protein design for pre-specified functional sites.[294][295] Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels.[296] Astronomy, space activities and ufology [edit]Artificial intelligence is used in astronomy to analyze increasing amounts of available data[297][298] and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy.[299] It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance,[300] and more autonomous operation.[301][302][47][298] In the search for extraterrestrial intelligence (SETI), machine learning has been used in attempts to identify artificially generated electromagnetic waves in available data[303][304] – such as real-time observations[305] – and other technosignatures, e.g. via anomaly detection.[306] In ufology, the SkyCAM-5 project headed by Prof. Hakan Kayal[307] and the Galileo Project headed by Avi Loeb use machine learning to attempt to detect and classify types of UFOs.[308][309][310][311][312][excessive citations] The Galileo Project also seeks to detect two further types of potential extraterrestrial technological signatures with the use of AI: 'Oumuamua-like interstellar objects, and non-manmade artificial satellites.[313][314] Machine learning can also be used to produce datasets of spectral signatures of molecules that may be involved in the atmospheric production or consumption of particular chemicals – such as phosphine possibly detected on Venus – which could prevent miss assignments and, if accuracy is improved, be used in future detections and identifications of molecules on other planets.[315] Chemistry and biology [edit]There is research about which types of computer-aided chemistry would benefit from machine learning.[316] A deep learning AI-based process has been developed that uses genome databases to design novel proteins based on evolutionary algorithms.[317][318] Machine learning has also been used for protein design with pre-specified functional sites,[294][295] predicting molecular properties, and exploring large chemical/reaction spaces.[319] Using drug discovery AI algorithms, researchers generated 40,000 potential chemical weapon candidates, helping in the regulation of such chemicals to prevent synthesizing them for real harm.[320][321][322] There are various types of applications for machine learning in decoding human biology, such as helping to map gene expression patterns to functional activation patterns[323] or identifying functional DNA motifs.[324] It is widely used in genetic research.[325] There also is some use of machine learning in synthetic biology,[326][327] disease biology,[327] nanotechnology (e.g. nanostructured materials and bionanotechnology),[328][329] and materials science.[330][331][332] Security and surveillance [edit]Cyber security [edit]Cyber security companies are adopting neural networks, machine learning, and natural language processing to improve their systems.[333] Applications of AI in cyber security include: - Network protection: Machine learning improves intrusion detection systems by broadening the search beyond previously identified threats.[334] - Endpoint protection: Attacks such as ransomware can be thwarted by learning typical malware behaviors. - AI-related cyber security application cases vary in both benefit and complexity. Security features such as Security Orchestration, Automation, and Response (SOAR) and Extended Endpoint Detection and Response (XDR) offer significant benefits for businesses, but require significant integration and adaptation efforts.[335] - Application security: can help counterattacks such as server-side request forgery, SQL injection, cross-site scripting, and distributed denial-of-service. - AI technology can also be utilized to improve system security and safeguard our privacy. Randrianasolo (2012) suggested a security system based on artificial intelligence that can recognize intrusions and adapt to perform better.[336] In order to improve cloud computing security, Sahil (2015) created a user profile system for the cloud environment with AI techniques.[337] - Suspect user behavior: Machine learning can identify fraud or compromised applications as they occur.[338] Transportation and logistics [edit]Aviation [edit]The use of artificial intelligence is being observed in the aviation industry for predictive maintenance. This has been helpful in reducing delays. Companies such as Boeing and Airbus are using AI for optimizing repair procedures while maintaining operational performance[339]. Automotive and public transit [edit]Transportation's complexity means that in most cases, training an AI in a real-world driving environment is impractical, and is achieved through simulator-based testing.[340] AI-based systems control functions such as braking, lane changing, collision prevention, navigation and mapping.[341] Some autonomous vehicles do not allow human drivers (they have no steering wheels or pedals).[342][343] There are prototypes of autonomous automotive public transport vehicles such as autonomous rail transport in operation,[344][345][346] electric mini-buses,[347][348][349] and autonomous delivery vehicles,[350][351][343] including delivery robots.[352][353] Autonomous trucks are in the testing phase. The UK government passed legislation to begin testing of autonomous truck platoons in 2018.[354] A group of autonomous trucks follow closely behind each other. German corporation Daimler is testing its Freightliner Inspiration.[355] AI has been used to optimize traffic management, which can reduce wait times, energy use, and emissions.[356] Military [edit]Aircraft simulators use AI for training aviators. Flight conditions can be simulated that allow pilots to make mistakes without risking themselves or expensive aircraft. Air combat can also be simulated. AI can also be used to operate planes analogously to their control of ground vehicles. Autonomous drones can fly independently or in swarms.[357] AOD uses the Interactive Fault Diagnosis and Isolation System, or IFDIS, which is a rule-based expert system using information from TF-30 documents and expert advice from mechanics that work on the TF-30. This system was designed to be used for the development of the TF-30 for the F-111C. The system replaced specialized workers. The system allowed regular workers to communicate with the system and avoid mistakes, miscalculations, or having to speak to one of the specialized workers. Speech recognition allows traffic controllers to give verbal directions to drones. Artificial intelligence supported design of aircraft,[358] or AIDA, is used to help designers in the process of creating conceptual designs of aircraft. This program allows the designers to focus more on the design itself and less on the design process. The software also allows the user to focus less on the software tools. The AIDA uses rule-based systems to compute its data. This is a diagram of the arrangement of the AIDA modules. Although simple, the program is proving effective. NASA [edit]In 2003 a Dryden Flight Research Center project created software that could enable a damaged aircraft to continue flight until a safe landing can be achieved.[359] The software compensated for damaged components by relying on the remaining undamaged components.[360] The 2016 Intelligent Autopilot System combined apprenticeship learning and behavioral cloning whereby the autopilot observed low-level actions required to maneuver the airplane and high-level strategy used to apply those actions.[361] Maritime [edit]Neural networks are used by situational awareness systems in ships and boats.[362] There also are autonomous boats. See also [edit]- Applications of artificial intelligence to legal informatics - Applications of deep learning - Applications of machine learning - Artificial intelligence and elections - Collective intelligence § Applications - List of artificial intelligence projects - List of datasets for machine-learning research - Open data - Progress in artificial intelligence - Timeline of computing 2020–present Footnotes [edit]- ^ Brynjolfsson, Erik; Mitchell, Tom (22 December 2017). \"What can machine learning do? Workforce implications\". Science. 358 (6370): 1530–1534. Bibcode:2017Sci...358.1530B. doi:10.1126/science.aap8062. PMID 29269459. - ^ Shin, Minkyu; Kim, Jin; van Opheusden, Bas; Griffiths, Thomas L. (2023). \"Superhuman artificial intelligence can improve human decision-making by increasing novelty\". Proceedings of the National Academy of Sciences. 120 (12) e2214840120. arXiv:2303.07462. Bibcode:2023PNAS..12014840S. doi:10.1073/pnas.2214840120. PMC 10041097. PMID 36913582. - ^ Chen, Yiting; Liu, Tracy Xiao; Shan, You; Zhong, Songfa (2023). \"The emergence of economic rationality of GPT\". Proceedings of the National Academy of Sciences. 120 (51) e2316205120. arXiv:2305.12763. Bibcode:2023PNAS..12016205C. doi:10.1073/pnas.2316205120. PMC 10740389. PMID 38085780. - ^ \"What is Generative AI? | IBM\". www.ibm.com. 2024-03-22. Retrieved 2025-07-22. - ^ Gambhire, Akshaya; Shaikh Mohammad, Bilal N. (8 April 2020). Use of Artificial Intelligence in Agriculture. Proceedings of the 3rd International Conference on Advances in Science & Technology (ICAST) 2020. SSRN 3571733. - ^ a b Briefer, Elodie F.; Sypherd, Ciara C.-R.; Linhart, Pavel; Leliveld, Lisette M. C.; Padilla de la Torre, Monica; Read, Eva R.; Guérin, Carole; Deiss, Véronique; Monestier, Chloé; Rasmussen, Jeppe H.; Špinka, Marek; Düpjan, Sandra; Boissy, Alain; Janczak, Andrew M.; Hillmann, Edna; Tallet, Céline (7 March 2022). \"Classification of pig calls produced from birth to slaughter according to their emotional valence and context of production\". Scientific Reports. 12 (1): 3409. Bibcode:2022NatSR..12.3409B. doi:10.1038/s41598-022-07174-8. PMC 8901661. PMID 35256620. - ^ Moreno Millán, M; Sevilla Guzmán, E; Demyda, S E (2011). \"Population, Poverty, Production, Food Security, Food Sovereignty, Biotechnology and Sustainable Development: Challenges for the XXI Century\". Bulletin of University of Agricultural Sciences and Veterinary Medicine Cluj-Napoca. Veterinary Medicine. 1 (68). - ^ Liundi, Nicholas; Darma, Aditya Wirya; Gunarso, Rivaldi; Warnars, Harco Leslie Hendric Spits (2019). \"Improving Rice Productivity in Indonesia with Artificial Intelligence\". 2019 7th International Conference on Cyber and IT Service Management (CITSM). pp. 1–5. doi:10.1109/CITSM47753.2019.8965385. ISBN 978-1-7281-2909-9. - ^ Talaviya, Tanha; Shah, Dhara; Patel, Nivedita; Yagnik, Hiteshri; Shah, Manan (2020). \"Implementation of artificial intelligence in agriculture for optimisation of irrigation and application of pesticides and herbicides\". Artificial Intelligence in Agriculture. 4: 58–73. doi:10.1016/j.aiia.2020.04.002. - ^ Bernstein, Phillip (2022). Machine Learning: Architecture in the Age of Artificial Intelligence. London: RIBA Publishing. ISBN 978-1-914124-01-3. - ^ Heathcote, Edwin (20 January 2024). \"AI is coming for architecture\". Financial Times. Retrieved 2024-02-07. - ^ \"Will Artificial Intelligence Replace Architects?\". ArchDaily. 2023-10-18. Retrieved 2024-02-07. - ^ Brynjolfsson, Erik; Li, Danielle; Raymond, Lindsey (2025-02-04). \"Generative AI at Work\". The Quarterly Journal of Economics. 140 (2): 889–942. doi:10.1093/qje/qjae044. ISSN 0033-5533. Archived from the original on 2025-06-05. - ^ Noy, Shakked; Zhang, Whitney (2023-07-14). \"Experimental evidence on the productivity effects of generative artificial intelligence\". Science. 381 (6654): 187–192. Bibcode:2023Sci...381..187N. doi:10.1126/science.adh2586. PMID 37440646. - ^ Estrada, Sheryl (18 August 2025). \"MIT report: 95% of generative AI pilots at companies are failing\". Fortune. Retrieved 15 October 2025. - ^ Niederhoffer, Kate; Kellerman, Gabriella Rosen; Lee, Angela; Liebscher, Alex; Rapuano, Kristina; Hancock, Jeffrey T. (22 September 2025). \"AI-Generated \"Workslop\" Is Destroying Productivity\". Harvard Business Review. Retrieved 15 October 2025. - ^ Frąckowiak-Szymański, Przemysław (26 June 2025). \"The Pros and Cons of Vibe Coding\". Software Mind. Retrieved 7 November 2025. - ^ a b Nickelsburg, Monica (1 October 2025). \"The human coders hired to mop up AI slop\". www.kuow.org. NPR. Retrieved 25 October 2025. - ^ Davis, Dominic-Madori (14 September 2025). \"Vibe coding has turned senior devs into 'AI babysitters,' but they say it's worth it\". TechCrunch. Retrieved 25 October 2025. - ^ Newman, Lily Hay. \"Vibe Coding Is the New Open Source—in the Worst Way Possible\". Wired. Retrieved 25 October 2025. - ^ Tangermann, Victor (31 May 2025). \"Companies Are Discovering a Grim Problem With \"Vibe Coding\"\". Futurism. Retrieved 25 October 2025. - ^ \"Google AI creates its own \"child\" bot\". The Independent. 5 December 2017. Retrieved 5 February 2018. - ^ Spagnolo, Michele; Morris, Joshua; Piacentini, Simone; Antesberger, Michael; Massa, Francesco; Crespi, Andrea; Ceccarelli, Francesco; Osellame, Roberto; Walther, Philip (April 2022). \"Experimental photonic quantum memristor\". Nature Photonics. 16 (4): 318–323. arXiv:2105.04867. Bibcode:2022NaPho..16..318S. doi:10.1038/s41566-022-00973-5. - ^ Ramanathan, Shriram (July 2018). \"Quantum materials for brain sciences and artificial intelligence\". MRS Bulletin. 43 (7): 534–540. Bibcode:2018MRSBu..43..534R. doi:10.1557/mrs.2018.147. - ^ \"Artificial intelligence makes accurate quantum chemical simulations more affordable\". Nature Portfolio Chemistry Community. 2 December 2021. Retrieved 30 May 2022. - ^ Guan, Wen; Perdue, Gabriel; Pesah, Arthur; Schuld, Maria; Terashi, Koji; Vallecorsa, Sofia; Vlimant, Jean-Roch (March 2021). \"Quantum machine learning in high energy physics\". Machine Learning: Science and Technology. 2 (1): 011003. arXiv:2005.08582. doi:10.1088/2632-2153/abc17d. - ^ Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2 - ^ a b Kongthon, Alisa; Sangkeettrakarn, Chatchawal; Kongyoung, Sarawoot; Haruechaiyasak, Choochart (2009). \"Implementing an online help desk system based on conversational agent\". Proceedings of the International Conference on Management of Emergent Digital EcoSystems. pp. 450–451. doi:10.1145/1643823.1643908. ISBN 978-1-60558-829-2. - ^ Sara Ashley O'Brien (12 January 2016). \"Is this app the call center of the future?\". CNN. Retrieved 26 September 2016. - ^ \"Using Google AI to convert speech to text\". Google Cloud. Retrieved 2025-09-07. - ^ Clark, Jack (20 July 2016). \"New Google AI Brings Automation to Customer Service\". Bloomberg.com. - ^ \"Amazon.com tests customer service chatbots\". Amazon Science. 25 February 2020. Retrieved 23 April 2021. - ^ Malatya Turgut Ozal University, Malatya, Turkey; Isguzar, Seda; Fendoglu, Eda; Malatya Turgut Ozal University, Malatya, Turkey; SimSek, Ahmed Ihsan (May 2024). \"Innovative Applications in Businesses: An Evaluation on Generative Artificial Intelligence\" (PDF). Amfiteatru Economic. 26 (66): 511. doi:10.24818/EA/2024/66/511. Retrieved 13 June 2024. {{cite journal}} : CS1 maint: multiple names: authors list (link) - ^ \"Advanced analytics in hospitality\". McKinsey & Company. 2017. Retrieved 14 January 2020. - ^ Zlatanov, Sonja; Popesku, Jovan (2019). \"Current Applications of Artificial Intelligence in Tourism and Hospitality\". Proceedings of the International Scientific Conference - Sinteza 2019. pp. 84–90. doi:10.15308/Sinteza-2019-84-90. ISBN 978-86-7912-703-7. - ^ \"The promises and perils of new technologies to improve education and employment opportunities\". Brookings. Retrieved 2024-04-20. - ^ \"Role of AI in Energy\". DOE. - ^ Bourhnane, Safae; Abid, Mohamed Riduan; Lghoul, Rachid; Zine-Dine, Khalid; Elkamoun, Najib; Benhaddou, Driss (30 January 2020). \"Machine learning for energy consumption prediction and scheduling in smart buildings\". SN Applied Sciences. 2 (2): 297. doi:10.1007/s42452-020-2024-9. - ^ Kanwal, Sidra; Khan, Bilal; Muhammad Ali, Sahibzada (February 2021). \"Machine learning based weighted scheduling scheme for active power control of hybrid microgrid\". International Journal of Electrical Power & Energy Systems. 125 106461. Bibcode:2021IJEPE.12506461K. doi:10.1016/j.ijepes.2020.106461. - ^ Mohanty, Prasanta Kumar; Jena, Premalata; Padhy, Narayana Prasad (2020). \"Home Electric Vehicle Charge Scheduling Using Machine Learning Technique\". 2020 IEEE International Conference on Power Systems Technology (POWERCON). pp. 1–5. doi:10.1109/POWERCON48463.2020.9230627. ISBN 978-1-7281-6350-5. - ^ Foster, Isabella (15 March 2021). \"Making Smart Grids Smarter with Machine Learning\". EIT | Engineering Institute of Technology. Retrieved 3 July 2022. - ^ a b Ciaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI. Intellisemantic Editions. p. 211. ISBN 978-88-947876-0-3. - ^ Williams, Ben; Lamont, Timothy A. C.; Chapuis, Lucille; Harding, Harry R.; May, Eleanor B.; Prasetya, Mochyudho E.; Seraphim, Marie J.; Jompa, Jamaluddin; Smith, David J.; Janetski, Noel; Radford, Andrew N.; Simpson, Stephen D. (July 2022). \"Enhancing automated analysis of marine soundscapes using ecoacoustic indices and machine learning\". Ecological Indicators. 140 108986. Bibcode:2022EcInd.14008986W. doi:10.1016/j.ecolind.2022.108986. hdl:10871/129693. - ^ Hino, M.; Benami, E.; Brooks, N. (October 2018). \"Machine learning for environmental monitoring\". Nature Sustainability. 1 (10): 583–588. Bibcode:2018NatSu...1..583H. doi:10.1038/s41893-018-0142-9. - ^ \"How machine learning can help environmental regulators\". Stanford News. Stanford University. 8 April 2019. Retrieved 29 May 2022. - ^ \"AI empowers environmental regulators\". Stanford News. Stanford University. 19 April 2021. Retrieved 29 May 2022. - ^ a b \"Artificial intelligence in space\". www.esa.int. Retrieved 30 May 2022. - ^ Frost, Rosie (9 May 2022). \"Plastic waste can now be found and monitored from space\". euronews. Retrieved 24 June 2022. - ^ \"Global Plastic Watch\". www.globalplasticwatch.org. Retrieved 24 June 2022. - ^ \"AI may predict the next virus to jump from animals to humans\". Public Library of Science. Retrieved 19 October 2021. - ^ Mollentze, Nardus; Babayan, Simon A.; Streicker, Daniel G. (28 September 2021). \"Identifying and prioritizing potential human-infecting viruses from their genome sequences\". PLOS Biology. 19 (9) e3001390. doi:10.1371/journal.pbio.3001390. PMC 8478193. PMID 34582436. - ^ Li, Zefeng; Meier, Men-Andrin; Hauksson, Egill; Zhan, Zhongwen; Andrews, Jennifer (28 May 2018). \"Machine Learning Seismic Wave Discrimination: Application to Earthquake Early Warning\". Geophysical Research Letters. 45 (10): 4773–4779. Bibcode:2018GeoRL..45.4773L. doi:10.1029/2018GL077870. - ^ \"Machine learning and gravity signals could rapidly detect big earthquakes\". Science News. 11 May 2022. Retrieved 3 July 2022. - ^ Fauvel, Kevin; Balouek-Thomert, Daniel; Melgar, Diego; Silva, Pedro; Simonet, Anthony; Antoniu, Gabriel; Costan, Alexandru; Masson, Véronique; Parashar, Manish; Rodero, Ivan; Termier, Alexandre (3 April 2020). \"A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning\". Proceedings of the AAAI Conference on Artificial Intelligence. 34 (1): 403–411. doi:10.1609/aaai.v34i01.5376. - ^ Thirugnanam, Hemalatha; Ramesh, Maneesha Vinodini; Rangan, Venkat P. (September 2020). \"Enhancing the reliability of landslide early warning systems by machine learning\". Landslides. 17 (9): 2231–2246. Bibcode:2020Lands..17.2231T. doi:10.1007/s10346-020-01453-z. - ^ Moon, Seung-Hyun; Kim, Yong-Hyuk; Lee, Yong Hee; Moon, Byung-Ro (2019). \"Application of machine learning to an early warning system for very short-term heavy rainfall\". Journal of Hydrology. 568: 1042–1054. Bibcode:2019JHyd..568.1042M. doi:10.1016/j.jhydrol.2018.11.060. - ^ Robinson, Bethany; Cohen, Jonathan S.; Herman, Jonathan D. (September 2020). \"Detecting early warning signals of long-term water supply vulnerability using machine learning\". Environmental Modelling & Software. 131 104781. Bibcode:2020EnvMS.13104781R. doi:10.1016/j.envsoft.2020.104781. - ^ Bury, Thomas M.; Sujith, R. I.; Pavithran, Induja; Scheffer, Marten; Lenton, Timothy M.; Anand, Madhur; Bauch, Chris T. (28 September 2021). \"Deep learning for early warning signals of tipping points\". Proceedings of the National Academy of Sciences. 118 (39) e2106140118. Bibcode:2021PNAS..11806140B. doi:10.1073/pnas.2106140118. PMC 8488604. PMID 34544867. - ^ Park, Yongeun; Lee, Han Kyu; Shin, Jae-Ki; Chon, Kangmin; Kim, SungHwan; Cho, Kyung Hwa; Kim, Jin Hwi; Baek, Sang-Soo (15 June 2021). \"A machine learning approach for early warning of cyanobacterial bloom outbreaks in a freshwater reservoir\". Journal of Environmental Management. 288 112415. Bibcode:2021JEnvM.28812415P. doi:10.1016/j.jenvman.2021.112415. PMID 33774562. - ^ Li, Jun; Wang, Zhaoli; Wu, Xushu; Xu, Chong-Yu; Guo, Shenglian; Chen, Xiaohong; Zhang, Zhenxing (August 2021). \"Robust Meteorological Drought Prediction Using Antecedent SST Fluctuations and Machine Learning\". Water Resources Research. 57 (8) e2020WR029413. Bibcode:2021WRR....5729413L. doi:10.1029/2020WR029413. hdl:10852/92935. - ^ Khan, Najeebullah; Sachindra, D. A.; Shahid, Shamsuddin; Ahmed, Kamal; Shiru, Mohammed Sanusi; Nawaz, Nadeem (May 2020). \"Prediction of droughts over Pakistan using machine learning algorithms\". Advances in Water Resources. 139 103562. Bibcode:2020AdWR..13903562K. doi:10.1016/j.advwatres.2020.103562. - ^ Kaur, Amandeep; Sood, Sandeep K. (May 2020). \"Deep learning based drought assessment and prediction framework\". Ecological Informatics. 57 101067. Bibcode:2020EcInf..5701067K. doi:10.1016/j.ecoinf.2020.101067. - ^ Preparing for the future of artificial intelligence. National Science and Technology Council. p. 14. OCLC 965620122. Retrieved 7 December 2024. - ^ \"Research at NVIDIA: Transforming Standard Video Into Slow Motion with AI\". 18 June 2018. Archived from the original on 21 December 2021 – via YouTube. - ^ \"Artificial intelligence is helping old video games look like new\". The Verge. 18 April 2019. - ^ \"Review: Topaz Sharpen AI is Amazing\". petapixel.com. 4 March 2019. - ^ Griffin, Matthew (26 April 2018). \"AI can now restore your corrupted photos to their original condition\". - ^ \"NVIDIA's AI can fix bad photos by looking at other bad photos\". Engadget. 10 July 2018. - ^ \"Using AI to Colorize and Upscale a 109-Year-Old Video of New York City to 4K and 60fps\". petapixel.com. 24 February 2020. - ^ \"YouTubers are upscaling the past to 4K. Historians want them to stop\". Wired UK. - ^ \"Google's DeepMind AI can 'transframe' a single image into a video\". 18 August 2022. - ^ \"Google's new AI turns text into music\". 28 January 2023. - ^ \"Google's new AI music generator can create - and hold - a tune\". 30 January 2023. - ^ \"CSDL | IEEE Computer Society\". - ^ Jodka, Sara (February 1, 2024). \"Manipulating reality: the intersection of deepfakes and the law\". Reuters.com. Retrieved December 8, 2024. - ^ Teyssou, Denis (2019). \"Applying Design Thinking Methodology: The InVID Verification Plugin\". Video Verification in the Fake News Era. pp. 263–279. doi:10.1007/978-3-030-26752-0_9. ISBN 978-3-030-26751-3. - ^ \"Fake news debunker by InVID & WeVerify\". Retrieved 23 December 2021. - ^ \"TUM Visual Computing & Artificial Intelligence: Prof. Matthias Nießner\". niessnerlab.org. - ^ \"Will \"Deepfakes\" Disrupt the Midterm Election?\". Wired. November 2018. - ^ a b Afchar, Darius; Nozick, Vincent; Yamagishi, Junichi; Echizen, Isao (2018). \"MesoNet: A Compact Facial Video Forgery Detection Network\". 2018 IEEE International Workshop on Information Forensics and Security (WIFS). pp. 1–7. arXiv:1809.00888. doi:10.1109/WIFS.2018.8630761. ISBN 978-1-5386-6536-7. - ^ Lyons, Kim (29 January 2020). \"FTC says the tech behind audio deepfakes is getting better\". The Verge. - ^ \"Audio samples from \"Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis\"\". google.github.io. - ^ Strickland, Eliza (11 December 2019). \"Facebook AI Launches Its Deepfake Detection Challenge\". IEEE Spectrum. - ^ \"Contributing Data to Deepfake Detection Research\". ai.googleblog.com. 24 September 2019. - ^ Ober, Holly. \"New method detects deepfake videos with up to 99% accuracy\". University of California-Riverside. Retrieved 3 July 2022. - ^ \"AI algorithm detects deepfake videos with high accuracy\". techxplore.com. Retrieved 3 July 2022. - ^ a b c \"Welcome to the new surreal. How AI-generated video is changing film\". MIT Technology Review. Retrieved 2023-12-05. - ^ Bean, Thomas H. Davenport and Randy (2023-06-19). \"The Impact of Generative AI on Hollywood and Entertainment\". MIT Sloan Management Review. Retrieved 2023-12-05. - ^ Cheng, Jacqui (30 September 2009). \"Virtual composer makes beautiful music—and stirs controversy\". Ars Technica. - ^ US patent 7696426 - ^ \"Computer composer honours Turing's centenary\". New Scientist. 4 July 2012. Archived from the original on 2016-04-13. Retrieved 27 December 2021. - ^ Hick, Thierry (11 October 2016). \"La musique classique recomposée\". Luxemburger Wort. - ^ \"Résultats de recherche - La Sacem\". repertoire.sacem.fr. - ^ Requena, Gloria; Sánchez, Carlos; Corzo-Higueras, José Luis; Reyes-Alvarado, Sirenia; Rivas-Ruiz, Francisco; Vico, Francisco; Raglio, Alfredo (2014). \"Melomics music medicine (M3) to lessen pain perception during pediatric prick test procedure\". Pediatric Allergy and Immunology. 25 (7): 721–724. doi:10.1111/pai.12263. PMID 25115240. - ^ \"Watson Beat on GitHub\". GitHub. 10 October 2018. - ^ \"Songs in the Key of AI\". Wired. 17 May 2018. - ^ \"Hayeon, sister of Girls' Generation's Taeyeon, debuts with song made by AI\". koreajoongangdaily.joins.com. 7 October 2020. Retrieved 23 October 2020. - ^ business intelligence solutions Archived 3 November 2011 at the Wayback Machine. Narrative Science. Retrieved 21 July 2013. - ^ Eule, Alexander. \"Big Data and Yahoo's Quest for Mass Personalization\". Barron's. - ^ \"Artificial Intelligence Software that Writes like a Human Being\". Archived from the original on 12 April 2013. Retrieved 11 March 2013. - ^ Riedl, Mark Owen; Bulitko, Vadim (6 December 2012). \"Interactive Narrative: An Intelligent Systems Approach\". AI Magazine. 34 (1): 67. doi:10.1609/aimag.v34i1.2449. - ^ Callaway, Charles B.; Lester, James C. (August 2002). \"Narrative prose generation\". Artificial Intelligence. 139 (2): 213–252. doi:10.1016/S0004-3702(02)00230-8. - ^ \"A Japanese AI program just wrote a short novel, and it almost won a literary prize\". Digital Trends. 23 March 2016. Retrieved 18 November 2016. - ^ \"Bot News\". Hanteo News. 20 October 2020. Retrieved 20 October 2020. - ^ Canavilhas, João (September 2022). \"Artificial Intelligence and Journalism: Current Situation and Expectations in the Portuguese Sports Media\". Journalism and Media. 3 (3): 510–520. doi:10.3390/journalmedia3030035. hdl:10400.6/12308. - ^ a b c d Galily, Yair (August 2018). \"Artificial intelligence and sports journalism: Is it a sweeping change?\". Technology in Society. 54: 47–51. doi:10.1016/j.techsoc.2018.03.001. - ^ Wu, Daniel (2023-08-31). \"Gannett halts AI-written sports recaps after readers mocked the stories\". Washington Post. Retrieved 2023-10-31. - ^ Gertner, Jon (18 July 2023). \"Wikipedia's Moment of Truth\". New York Times. Retrieved 29 November 2024. - ^ \"Study reveals bot-on-bot editing wars raging on Wikipedia's pages\". The Guardian. 23 February 2017. Retrieved 10 January 2023. - ^ Cole, K. C. \"The Shaky Ground Truths of Wikipedia\". Wired. Retrieved 10 January 2023. - ^ \"AI can automatically rewrite outdated text in Wikipedia articles\". Engadget. Retrieved 10 January 2023. - ^ Metz, Cade. \"Wikipedia Deploys AI to Expand Its Ranks of Human Editors\". Wired. Retrieved 10 January 2023. - ^ \"Wikipedia taps Google to help editors translate articles\". VentureBeat. 9 January 2019. Retrieved 9 January 2023. - ^ Wilson, Kyle (8 May 2019). \"Wikipedia has a Google Translate problem\". The Verge. Retrieved 9 January 2023. - ^ \"Why AI researchers like video games\". The Economist. Archived from the original on 5 October 2017. - ^ Yannakakis, Geogios N. (2012). \"Game AI revisited\". Proceedings of the 9th conference on Computing Frontiers - CF '12. p. 285. doi:10.1145/2212908.2212954. ISBN 978-1-4503-1215-8. - ^ Maass, Laura E. Shummon (1 July 2019). \"Artificial Intelligence in Video Games\". Medium. Retrieved 23 April 2021. - ^ Markoff, John (16 February 2011). \"Computer Wins on 'Jeopardy!': Trivial, It's Not\". The New York Times. Archived from the original on 22 October 2014. Retrieved 25 October 2014. - ^ \"AlphaGo – Google DeepMind\". Archived from the original on 10 March 2016. - ^ \"Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol\". BBC News. 12 March 2016. Archived from the original on 26 August 2016. Retrieved 1 October 2016. - ^ Metz, Cade (27 May 2017). \"After Win in China, AlphaGo's Designers Explore New AI\". Wired. Archived from the original on 2 June 2017. - ^ \"World's Go Player Ratings\". May 2017. Archived from the original on 1 April 2017. - ^ \"柯洁迎19岁生日 雄踞人类世界排名第一已两年\" (in Chinese). May 2017. Archived from the original on 11 August 2017. - ^ \"MuZero: Mastering Go, chess, shogi and Atari without rules\". Deepmind. 23 December 2020. Retrieved 1 March 2021. - ^ Steven Borowiec; Tracey Lien (12 March 2016). \"AlphaGo beats human Go champ in milestone for artificial intelligence\". Los Angeles Times. Retrieved 13 March 2016. - ^ Solly, Meilan. \"This Poker-Playing A.I. Knows When to Hold 'Em and When to Fold 'Em\". Smithsonian. Pluribus has bested poker pros in a series of six-player no-limit Texas Hold'em games, reaching a milestone in artificial intelligence research. It is the first bot to beat humans in a complex multiplayer competition. - ^ Bowling, Michael; Burch, Neil; Johanson, Michael; Tammelin, Oskari (9 January 2015). \"Heads-up limit hold'em poker is solved\". Science. 347 (6218): 145–149. Bibcode:2015Sci...347..145B. doi:10.1126/science.1259433. PMID 25574016. - ^ Ontanon, Santiago; Synnaeve, Gabriel; Uriarte, Alberto; Richoux, Florian; Churchill, David; Preuss, Mike (December 2013). \"A Survey of Real-Time Strategy Game AI Research and Competition in StarCraft\". IEEE Transactions on Computational Intelligence and AI in Games. 5 (4): 293–311. doi:10.1109/TCIAIG.2013.2286295. - ^ \"Facebook Quietly Enters StarCraft War for AI Bots, and Loses\". WIRED. 2017. Retrieved 7 May 2018. - ^ Silver, David; Hubert, Thomas; Schrittwieser, Julian; Antonoglou, Ioannis; Lai, Matthew; Guez, Arthur; Lanctot, Marc; Sifre, Laurent; Kumaran, Dharshan; Graepel, Thore; Lillicrap, Timothy; Simonyan, Karen; Hassabis, Demis (7 December 2018). \"A general reinforcement learning algorithm that masters chess, shogi, and go through self-play\". Science. 362 (6419): 1140–1144. Bibcode:2018Sci...362.1140S. doi:10.1126/science.aar6404. PMID 30523106. - ^ Sample, Ian (18 October 2017). \"'It's able to create knowledge itself': Google unveils AI that learns on its own\". The Guardian. Retrieved 7 May 2018. - ^ Appenzeller, Tim (7 July 2017). \"The AI revolution in science\". Science. doi:10.1126/science.aan7064. - ^ \"The superhero of artificial intelligence: can this genius keep it in check?\". The Guardian. 16 February 2016. Archived from the original on 23 April 2018. Retrieved 26 April 2018. - ^ Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu, Andrei A.; Veness, Joel; Bellemare, Marc G.; Graves, Alex; Riedmiller, Martin; Fidjeland, Andreas K.; Ostrovski, Georg; Petersen, Stig; Beattie, Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan; Wierstra, Daan; Legg, Shane; Hassabis, Demis (26 February 2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529–533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID 25719670. - ^ Sample, Ian (14 March 2017). \"Google's DeepMind makes AI program that can learn like a human\". The Guardian. Archived from the original on 26 April 2018. Retrieved 26 April 2018. - ^ Schrittwieser, Julian; Antonoglou, Ioannis; Hubert, Thomas; Simonyan, Karen; Sifre, Laurent; Schmitt, Simon; Guez, Arthur; Lockhart, Edward; Hassabis, Demis; Graepel, Thore; Lillicrap, Timothy; Silver, David (24 December 2020). \"Mastering Atari, Go, chess and shogi by planning with a learned model\". Nature. 588 (7839): 604–609. arXiv:1911.08265. Bibcode:2020Natur.588..604S. doi:10.1038/s41586-020-03051-4. PMID 33361790. - ^ Ortiz, Sabrina. \"You can now chat with a famous AI character on Viber. Here's how\". zdnet.com. ZDNET. Retrieved 5 December 2024. ICONIQ created Kuki, an AI character whose sole purpose is to entertain humans and has even been used as a brand ambassador for H&M, modeled for Vogue, and starred in its own Roblox game. - ^ Lewis, Nell (19 August 2020). \"Robot friends: Why people talk to chatbots in times of trouble\". cnn.com. CNN. Retrieved 5 December 2024. Since 2016, when the bot landed on major messaging platforms, an estimated 5 million unique users hailing from all corners of the world have chatted with her. - ^ Poltronieri, Fabrizio Augusto; Hänska, Max (2019). \"Technical Images and Visual Art in the Era of Artificial Intelligence: From GOFAI to GANs\". Proceedings of the 9th International Conference on Digital and Interactive Arts. pp. 1–8. doi:10.1145/3359852.3359865. ISBN 978-1-4503-7250-3. - ^ \"Fine art print - crypto art\". Kate Vass Galerie. Retrieved 2022-05-07. - ^ a b \"Analysis | Is That Trump Photo Real? Free AI Tools Come With Risks\". Washington Post. Retrieved 30 August 2022. - ^ \"Google's image generator rivals DALL-E in shiba inu drawing\". TechCrunch. Retrieved 30 August 2022. - ^ \"Midjourney's enthralling AI art generator goes live for everyone\". PCWorld. - ^ \"After Photos, Here's How AI Made A Trippy Music Video Out Of Thin Air\". Fossbytes. 19 May 2022. Retrieved 30 May 2022. - ^ Cetinic, Eva; She, James (2022-02-16). \"Understanding and Creating Art with AI: Review and Outlook\". ACM Transactions on Multimedia Computing, Communications, and Applications. 18 (2): 66:1–66:22. arXiv:2102.09109. doi:10.1145/3475799. - ^ Lang, Sabine; Ommer, Bjorn (2018). \"Reflecting on How Artworks Are Processed and Analyzed by Computer Vision: Supplementary Material\". Proceedings of the European Conference on Computer Vision (ECCV) Workshops – via Computer Vision Foundation. - ^ Cole, Samantha (2023-02-01). \"Netflix Made an Anime Using AI Due to a 'Labor Shortage,' and Fans Are Pissed\". Vice. Retrieved 2023-12-04. - ^ Christy, Charles A. (17 January 1990). \"Impact of Artificial Intelligence on Banking\". Los Angeles Times. Retrieved 10 September 2019. - ^ O'Neill, Eleanor (31 July 2016). \"Accounting, automation and AI\". icas.com. Archived from the original on 18 November 2016. Retrieved 18 November 2016. - ^ \"CTO Corner: Artificial Intelligence Use in Financial Services – Financial Services Roundtable\". Financial Services Roundtable. 2 April 2015. Archived from the original on 18 November 2016. Retrieved 18 November 2016. - ^ \"Artificial Intelligence Solutions, AI Solutions\". sas.com. - ^ Chapman, Lizette (7 January 2019). \"Palantir once mocked the idea of salespeople. Now it's hiring them\". Los Angeles Times. Retrieved 28 February 2019. - ^ Artificial Intelligence and Economic Theory: Skynet in the Market. Advanced Information and Knowledge Processing. 2017. doi:10.1007/978-3-319-66104-9. ISBN 978-3-319-66103-2.[page needed] - ^ Marwala, Tshilidzi; Hurwitz, Evan (2017). \"Efficient Market Hypothesis\". Artificial Intelligence and Economic Theory: Skynet in the Market. Advanced Information and Knowledge Processing. pp. 101–110. doi:10.1007/978-3-319-66104-9_9. ISBN 978-3-319-66103-2. - ^ Shao, Jun; Lou, Zhukun; Wang, Chong; Mao, Jinye; Ye, Ailin (16 May 2022). \"The impact of artificial intelligence (AI) finance on financing constraints of non-SOE firms in emerging markets\". International Journal of Emerging Markets. 17 (4): 930–944. doi:10.1108/IJOEM-02-2021-0299. - ^ \"Algorithmic Trading\". Investopedia. 18 May 2005. - ^ \"The Financial Stability Implications of Artificial Intelligence\" (PDF). FSB. Retrieved 2025-09-07. - ^ \"Beyond Robo-Advisers: How AI Could Rewire Wealth Management\". 5 January 2017. - ^ Asatryan, Diana (3 April 2017). \"Machine Learning Is the Future of Underwriting, But Startups Won't be Driving It\". bankinnovation.net. Retrieved 15 April 2022. - ^ Laura, Blattner; Jann, Spiess. \"Explainability & Fairness in Machine Learning for Credit Underwriting\" (PDF). FinRegLab. Retrieved 2025-09-07. - ^ \"ZestFinance Introduces Machine Learning Platform to Underwrite Millennials and Other Consumers with Limited Credit History\" (Press release). 14 February 2017. - ^ Chang, Hsihui; Kao, Yi-Ching; Mashruwala, Raj; Sorensen, Susan M. (10 April 2017). \"Technical Inefficiency, Allocative Inefficiency, and Audit Pricing\". Journal of Accounting, Auditing & Finance. 33 (4): 580–600. doi:10.1177/0148558X17696760. - ^ Munoko, Ivy; Brown-Liburd, Helen L.; Vasarhelyi, Miklos (November 2020). \"The Ethical Implications of Using Artificial Intelligence in Auditing\". Journal of Business Ethics. 167 (2): 209–234. doi:10.1007/s10551-019-04407-1. - ^ Fadelli, Ingrid. \"LaundroGraph: Using deep learning to support anti–money laundering efforts\". techxplore.com. Retrieved 18 December 2022. - ^ Cardoso, Mário; Saleiro, Pedro; Bizarro, Pedro (2022). \"LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering\". Proceedings of the Third ACM International Conference on AI in Finance. pp. 130–138. arXiv:2210.14360. doi:10.1145/3533271.3561727. ISBN 978-1-4503-9376-8. - ^ Durkin, J. (2002). \"History and applications\". Expert Systems. Vol. 1. pp. 1–22. doi:10.1016/B978-012443880-4/50045-4. ISBN 978-0-12-443880-4. - ^ Chen, K.C.; Liang, Ting-peng (May 1989). \"Protrader: An Expert System for Program Trading\". Managerial Finance. 15 (5): 1–6. doi:10.1108/eb013623. - ^ Nielson, Norma; Brown, Carol E.; Phillips, Mary Ellen (July 1990). \"Expert Systems for Personal Financial Planning\". Journal of Financial Planning: 137–143. doi:10.11575/PRISM/33995. hdl:1880/48295. - ^ Senator, Ted E.; Goldberg, Henry G.; Wooton, Jerry; Cottini, Matthew A.; Khan, A.F. Umar; Kilinger, Christina D.; Llamas, Winston M.; Marrone, MichaeI P.; Wong, Raphael W.H. (1995). \"The FinCEN Artificial Intelligence System: Identifying Potential Money Laundering from Reports of Large Cash Transactions\" (PDF). IAAI-95 Proceedings. Archived from the original (PDF) on 2015-10-20. Retrieved 2019-01-14. - ^ Sutton, Steve G.; Holt, Matthew; Arnold, Vicky (September 2016). \"'The reports of my death are greatly exaggerated'—Artificial intelligence research in accounting\". International Journal of Accounting Information Systems. 22: 60–73. doi:10.1016/j.accinf.2016.07.005. - ^ Bender, Michael J.; Katopodis, Chris; Simonovic, Slobodan P. (1992). \"A prototype expert system for fishway design\". Environmental Monitoring and Assessment. 23 (1–3): 115–127. Bibcode:1992EMnAs..23..115B. doi:10.1007/BF00406956. PMID 24227094. - ^ Wayson, Roger L. (1989). \"Use of a Knowledge-Based Expert System to Maximize Airport Capacity in Harmony with Noise-Mitigation Plans\" (PDF). Transportation Research Record. 1218: 31–40. - ^ Vencill, A. M.; Speese, J. (1995). \"Potato Insect Expert System: Computerized Approach to Colorado Potato Beetle Management\". Journal of Economic Entomology. 88 (4): 944–954. doi:10.1093/jee/88.4.944. - ^ Jirka, Gerhard H.; Akar, Paul J. (1996). User's Manual for CORMIX: A Hydrodynamic Mixing Zone Model and Decision Support System for Pollutant Discharges into Surface Waters (PDF) (Report). U.S. Environmental Protection Agency. - ^ Chalmers, Dominic; MacKenzie, Niall G.; Carter, Sara (September 2021). \"Artificial Intelligence and Entrepreneurship: Implications for Venture Creation in the Fourth Industrial Revolution\". Entrepreneurship Theory and Practice. 45 (5): 1028–1053. doi:10.1177/1042258720934581. - ^ Thompsett, Louis (2025-02-04). \"What EU AI Act Means for Governance in Financial Sector\". fintechmagazine.com. Retrieved 2025-09-20. - ^ a b Szczytko, Jacek (2025-08-15). \"How will the AI Act alter the landscape for fintechs? Key requirements and penalties\". Dudkowiak & Putyra. Retrieved 2025-09-20. - ^ a b \"Regulation - EU - 2024/1689 - EN - EUR-Lex\". eur-lex.europa.eu. Retrieved 2025-09-20. - ^ \"AI Credit Regulations Affecting Lending Business 2025\". hesfintech. 10 October 2025. Archived from the original on 12 October 2025. Retrieved 10 October 2025. - ^ \"10 Promising AI Applications in Health Care\". Harvard Business Review. 10 May 2018. Archived from the original on 15 December 2018. Retrieved 28 August 2018. - ^ Lareyre, Fabien; Lê, Cong Duy; Ballaith, Ali; Adam, Cédric; Carrier, Marion; Amrani, Samantha; Caradu, Caroline; Raffort, Juliette (August 2022). \"Applications of Artificial Intelligence in Non-cardiac Vascular Diseases: A Bibliographic Analysis\". Angiology. 73 (7): 606–614. doi:10.1177/00033197211062280. PMID 34996315. - ^ \"What is artificial intelligence in medicine?\". IBM. 28 March 2024. Retrieved 19 April 2024. - ^ \"Microsoft Using AI to Accelerate Cancer Precision Medicine\". HealthITAnalytics. 29 October 2019. Retrieved 29 November 2020. - ^ Dina Bass (20 September 2016). \"Microsoft Develops AI to Help Cancer Doctors Find the Right Treatments\". Bloomberg L.P. Archived from the original on 11 May 2017. - ^ Gallagher, James (26 January 2017). \"Artificial intelligence 'as good as cancer doctors'\". BBC News. Archived from the original on 26 January 2017. Retrieved 26 January 2017. - ^ Langen, Pauline A.; Katz, Jeffrey S.; Dempsey, Gayle, eds. (18 October 1994), Remote monitoring of high-risk patients using artificial intelligence, archived from the original on 28 February 2017, retrieved 27 February 2017 - ^ Kermany, Daniel S.; Goldbaum, Michael; Cai, Wenjia; Valentim, Carolina C.S.; Liang, Huiying; Baxter, Sally L.; McKeown, Alex; Yang, Ge; Wu, Xiaokang; Yan, Fangbing; Dong, Justin; Prasadha, Made K.; Pei, Jacqueline; Ting, Magdalene Y.L.; Zhu, Jie; Li, Christina; Hewett, Sierra; Dong, Jason; Ziyar, Ian; Shi, Alexander; Zhang, Runze; Zheng, Lianghong; Hou, Rui; Shi, William; Fu, Xin; Duan, Yaou; Huu, Viet A.N.; Wen, Cindy; Zhang, Edward D.; Zhang, Charlotte L.; Li, Oulan; Wang, Xiaobo; Singer, Michael A.; Sun, Xiaodong; Xu, Jie; Tafreshi, Ali; Lewis, M. Anthony; Xia, Huimin; Zhang, Kang (February 2018). \"Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning\". Cell. 172 (5): 1122–1131.e9. doi:10.1016/j.cell.2018.02.010. PMID 29474911. - ^ Senthilingam, Meera (12 May 2016). \"Are Autonomous Robots Your next Surgeons?\". CNN. Archived from the original on 3 December 2016. Retrieved 4 December 2016. - ^ Pumplun L, Fecho M, Wahl N, Peters F, Buxmann P (2021). \"Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study\". Journal of Medical Internet Research. 23 (10) e29301. doi:10.2196/29301. PMC 8556641. PMID 34652275. - ^ Inglese, Marianna; Patel, Neva; Linton-Reid, Kristofer; Loreto, Flavia; Win, Zarni; Perry, Richard J.; Carswell, Christopher; Grech-Sollars, Matthew; Crum, William R.; Lu, Haonan; Malhotra, Paresh A.; Aboagye, Eric O. (20 June 2022). \"A predictive model using the mesoscopic architecture of the living brain to detect Alzheimer's disease\". Communications Medicine. 2 (1): 70. doi:10.1038/s43856-022-00133-4. PMC 9209493. PMID 35759330. - News report: \"Single MRI scan of the brain could detect Alzheimer's disease\". Physics World. 13 July 2022. Retrieved 19 July 2022. - ^ Yorita, Akihiro; Kubota, Naoyuki (2011). \"Cognitive Development in Partner Robots for Information Support to Elderly People\". IEEE Transactions on Autonomous Mental Development. 3 (1): 64–73. Bibcode:2011ITAMD...3...64Y. doi:10.1109/TAMD.2011.2105868. - ^ \"Artificial Intelligence Will Redesign Healthcare – The Medical Futurist\". The Medical Futurist. 4 August 2016. Retrieved 18 November 2016. - ^ Dönertaş, Handan Melike; Fuentealba, Matías; Partridge, Linda; Thornton, Janet M. (February 2019). \"Identifying Potential Ageing-Modulating Drugs In Silico\". Trends in Endocrinology & Metabolism. 30 (2): 118–131. doi:10.1016/j.tem.2018.11.005. PMC 6362144. PMID 30581056. - ^ Smer-Barreto, Vanessa; Quintanilla, Andrea; Elliot, Richard J. R.; Dawson, John C.; Sun, Jiugeng; Carragher, Neil O.; Acosta, Juan Carlos; Oyarzún, Diego A. (27 April 2022). \"Discovery of new senolytics using machine learning\". bioRxiv. doi:10.1101/2022.04.26.489505. hdl:10261/269843. - ^ Luxton, David D. (2014). \"Artificial intelligence in psychological practice: Current and future applications and implications\". Professional Psychology: Research and Practice. 45 (5): 332–339. doi:10.1037/a0034559. - ^ Randhawa, Gurjit S.; Soltysiak, Maximillian P. M.; Roz, Hadi El; Souza, Camila P. E. de; Hill, Kathleen A.; Kari, Lila (24 April 2020). \"Machine learning using intrinsic genomic signatures for rapid classification of novel pathogens: COVID-19 case study\". PLOS ONE. 15 (4) e0232391. Bibcode:2020PLoSO..1532391R. doi:10.1371/journal.pone.0232391. PMC 7182198. PMID 32330208. - ^ Ye, Jiarong; Yeh, Yin-Ting; Xue, Yuan; Wang, Ziyang; Zhang, Na; Liu, He; Zhang, Kunyan; Ricker, RyeAnne; Yu, Zhuohang; Roder, Allison; Perea Lopez, Nestor; Organtini, Lindsey; Greene, Wallace; Hafenstein, Susan; Lu, Huaguang; Ghedin, Elodie; Terrones, Mauricio; Huang, Shengxi; Huang, Sharon Xiaolei (7 June 2022). \"Accurate virus identification with interpretable Raman signatures by machine learning\". Proceedings of the National Academy of Sciences. 119 (23) e2118836119. arXiv:2206.02788. Bibcode:2022PNAS..11918836Y. doi:10.1073/pnas.2118836119. PMC 9191668. PMID 35653572. - ^ \"Artificial intelligence finds disease-related genes\". Linköping University. Retrieved 3 July 2022. - ^ \"Researchers use AI to detect new family of genes in gut bacteria\". UT Southwestern Medical Center. Retrieved 3 July 2022. - ^ a b c Zhavoronkov, Alex; Mamoshina, Polina; Vanhaelen, Quentin; Scheibye-Knudsen, Morten; Moskalev, Alexey; Aliper, Alex (2019). \"Artificial intelligence for aging and longevity research: Recent advances and perspectives\". Ageing Research Reviews. 49: 49–66. doi:10.1016/j.arr.2018.11.003. PMID 30472217. - ^ Adir, Omer; Poley, Maria; Chen, Gal; Froim, Sahar; Krinsky, Nitzan; Shklover, Jeny; Shainsky-Roitman, Janna; Lammers, Twan; Schroeder, Avi (April 2020). \"Integrating Artificial Intelligence and Nanotechnology for Precision Cancer Medicine\". Advanced Materials. 32 (13) 1901989. Bibcode:2020AdM....3201989A. doi:10.1002/adma.201901989. PMC 7124889. PMID 31286573. - ^ Moore, Phoebe V. (7 May 2019). \"OSH and the Future of Work: benefits and risks of artificial intelligence tools in workplaces\". EU-OSHA. pp. 3–7. Retrieved 30 July 2020. - ^ Howard, John (November 2019). \"Artificial intelligence: Implications for the future of work\". American Journal of Industrial Medicine. 62 (11): 917–926. Bibcode:2019AJIM...62..917H. doi:10.1002/ajim.23037. PMID 31436850. - ^ Gianatti, Toni-Louise (14 May 2020). \"How AI-Driven Algorithms Improve an Individual's Ergonomic Safety\". Occupational Health & Safety. Retrieved 30 July 2020. - ^ Meyers, Alysha R. (1 May 2019). \"AI and Workers' Comp\". NIOSH Science Blog. Retrieved 3 August 2020. - ^ Webb, Sydney; Siordia, Carlos; Bertke, Stephen; Bartlett, Diana; Reitz, Dan (26 February 2020). \"Artificial Intelligence Crowdsourcing Competition for Injury Surveillance\". NIOSH Science Blog. Retrieved 3 August 2020. - ^ Ferguson, Murray (19 April 2016). \"Artificial Intelligence: What's To Come for EHS... And When?\". EHS Today. Retrieved 30 July 2020. - ^ Paul, Debleena; Sanap, Gaurav; Shenoy, Snehal; Kalyane, Dnyaneshwar; Kalia, Kiran; Tekade, Rakesh K. (January 2021). \"Artificial intelligence in drug discovery and development\". Drug Discovery Today. 26 (1): 80–93. doi:10.1016/j.drudis.2020.10.010. PMC 7577280. PMID 33099022. - ^ \"Allchemy – Resource-aware AI for drug discovery\". Retrieved 29 May 2022. - ^ Wołos, Agnieszka; Koszelewski, Dominik; Roszak, Rafał; Szymkuć, Sara; Moskal, Martyna; Ostaszewski, Ryszard; Herrera, Brenden T.; Maier, Josef M.; Brezicki, Gordon; Samuel, Jonathon; Lummiss, Justin A. M.; McQuade, D. Tyler; Rogers, Luke; Grzybowski, Bartosz A. (April 2022). \"Computer-designed repurposing of chemical wastes into drugs\". Nature. 604 (7907): 668–676. Bibcode:2022Natur.604..668W. doi:10.1038/s41586-022-04503-9. PMID 35478240. - ^ Wołos, Agnieszka; Roszak, Rafał; Żądło-Dobrowolska, Anna; Beker, Wiktor; Mikulak-Klucznik, Barbara; Spólnik, Grzegorz; Dygas, Mirosław; Szymkuć, Sara; Grzybowski, Bartosz A. (25 September 2020). \"Synthetic connectivity, emergence, and self-regeneration in the network of prebiotic chemistry\". Science. 369 (6511) eaaw1955. doi:10.1126/science.aaw1955. PMID 32973002. - ^ Zhavoronkov, Alex; Ivanenkov, Yan A.; Aliper, Alex; Veselov, Mark S.; Aladinskiy, Vladimir A.; Aladinskaya, Anastasiya V.; Terentiev, Victor A.; Polykovskiy, Daniil A.; Kuznetsov, Maksim D.; Asadulaev, Arip; Volkov, Yury; Zholus, Artem; Shayakhmetov, Rim R.; Zhebrak, Alexander; Minaeva, Lidiya I.; Zagribelnyy, Bogdan A.; Lee, Lennart H.; Soll, Richard; Madge, David; Xing, Li; Guo, Tao; Aspuru-Guzik, Alán (September 2019). \"Deep learning enables rapid identification of potent DDR1 kinase inhibitors\". Nature Biotechnology. 37 (9): 1038–1040. doi:10.1038/s41587-019-0224-x. PMID 31477924. - ^ \"DeepMind is answering one of biology's biggest challenges\". The Economist. 30 November 2020. Retrieved 30 November 2020. - ^ Jeremy Kahn, Lessons from DeepMind's breakthrough in protein-folding A.I., Fortune, 1 December 2020 - ^ \"DeepMind uncovers structure of 200m proteins in scientific leap forward\". The Guardian. 2022-07-28. Retrieved 2022-07-28. - ^ \"AlphaFold reveals the structure of the protein universe\". DeepMind. 2022-07-28. Retrieved 2022-07-28. - ^ Nakamura, Satoshi (2009). \"Overcoming the language barrier with speech translation technology\". Science & Technology Trends Quarterly Review (31): 35–48. CORE output ID 236667511. - ^ a b Clark, Jack (8 December 2015). \"Why 2015 Was a Breakthrough Year in Artificial Intelligence\". Bloomberg.com. - ^ \"Can artificial intelligence really help us talk to the animals?\". The Guardian. 31 July 2022. Retrieved 30 August 2022. - ^ K. Mandal, G. S. Pradeep Ghantasala, Firoz Khan, R. Sathiyaraj, B. Balamurugan (2020). Natural Language Processing in Artificial Intelligence (1st ed.). Apple Academic Press. pp. 53–54. ISBN 978-0-367-80849-5. {{cite book}} : CS1 maint: multiple names: authors list (link) - ^ Buckley, Chris; Mozur, Paul (22 May 2019). \"How China Uses High-Tech Surveillance to Subdue Minorities\". The New York Times. - ^ \"Security lapse exposed a Chinese smart city surveillance system\". 3 May 2019. Archived from the original on 7 March 2021. Retrieved 14 September 2020. - ^ \"AI traffic signals to be installed in Bengaluru soon\". NextBigWhat. 24 September 2019. Retrieved 1 October 2019. - ^ Ashley, Kevin D. (2017). Artificial Intelligence and Legal Analytics. doi:10.1017/9781316761380. ISBN 978-1-107-17150-3.[page needed] - ^ Lohr, Steve (19 March 2017). \"A.I. Is Doing Legal Work. But It Won't Replace Lawyers, Yet\". The New York Times. - ^ Croft, Jane (2 May 2019). \"AI learns to read Korean, so you don't have to\". Financial Times. Retrieved 19 December 2019. - ^ Kleider-Offutt, Heather; Stevens, Beth; Mickes, Laura; Boogert, Stewart (3 April 2024). \"Application of artificial intelligence to eyewitness identification\". Cognitive Research: Principles and Implications. 9 (1): 19. doi:10.1186/s41235-024-00542-0. PMC 10991253. PMID 38568356. - ^ a b Jeff Larson; Julia Angwin (23 May 2016). \"How We Analyzed the COMPAS Recidivism Algorithm\". ProPublica. Archived from the original on 29 April 2019. Retrieved 19 June 2020. - ^ \"Commentary: Bad news. Artificial intelligence is biased\". CNA. 12 January 2019. Archived from the original on 12 January 2019. Retrieved 19 June 2020. - ^ a b Šimalčík, Matej (2023). \"Rule by Law\". In Kironska, Kristina; Turscanyi, Richard Q. (eds.). Contemporary China: a New Superpower?. Routledge. ISBN 978-1-03-239508-1. - ^ \"Digital Spectrometry\". 8 October 2018. - ^ US 9967696B2, \"Digital Spectrometry Patent\", published 2018-10-08 - ^ \"How artificial intelligence is moving from the lab to your kid's playroom\". The Washington Post. Retrieved 18 November 2016. - ^ \"Application of artificial intelligence in oil and gas industry: Exploring its impact\". 15 May 2019. - ^ Salvaterra, Neanda (14 October 2019). \"Oil and Gas Companies Turn to AI to Cut Costs\". The Wall Street Journal. - ^ Ornes, Stephen (August 27, 2020). \"Quanta Magazine – How Close Are Computers to Automating Mathematical Reasoning?\". - ^ \"AlphaGeometry: An Olympiad-level AI system for geometry\". Deepmind. Retrieved 26 January 2024. - ^ Roberts, Siobhan (17 January 2024). \"A.I.'s Latest Challenge: the Math Olympics\". The New York Times. Retrieved 26 January 2024. - ^ Trinh, Trieu H.; Wu, Yuhuai; Le, Quoc V.; He, He; Luong, Thang (2024). \"Solving olympiad geometry without human demonstrations\". Nature. 625 (7995): 476–482. Bibcode:2024Natur.625..476T. doi:10.1038/s41586-023-06747-5. PMC 10794143. PMID 38233616. - ^ \"Google DeepMind's new AI system can solve complex geometry problems\". MIT Technology Review. Retrieved 26 January 2024. - ^ Zia, Tehseen (January 24, 2024). \"AlphaGeometry: DeepMind's AI Masters Geometry Problems at Olympiad Levels\". Unite.ai. Retrieved 2024-05-03. - ^ a b c Congressional Research Service (2019). Artificial Intelligence and National Security (PDF). Washington, DC: Congressional Research Service.PD-notice - ^ Iraqi, Amjad (2024-04-03). \"'Lavender': The AI machine directing Israel's bombing spree in Gaza\". +972 Magazine. Retrieved 2024-04-06. - ^ Davies, Harry; McKernan, Bethan; Sabbagh, Dan (2023-12-01). \"'The Gospel': how Israel uses AI to select bombing targets in Gaza\". The Guardian. Retrieved 2023-12-04. - ^ Marti, J Werner (10 August 2024). \"Drohnen haben den Krieg in der Ukraine revolutioniert, doch sie sind empfindlich auf Störsender – deshalb sollen sie jetzt autonom operieren\". Neue Zürcher Zeitung (in German). Retrieved 10 August 2024. - ^ Guida, Michela; Caniato, Federico; Moretto, Antonella; Ronchi, Stefano (2023-03-01). \"The role of artificial intelligence in the procurement process: State of the art and research agenda\". Journal of Purchasing and Supply Management. 29 (2): 100823. doi:10.1016/j.pursup.2023.100823. ISSN 1478-4092. Archived from the original on December 29, 2025. Retrieved December 29, 2025. {{cite journal}} : CS1 maint: article number as page number (link) - ^ \"AI in Procurement | IBM\". www.ibm.com. 2023-08-02. Archived from the original on December 29, 2025. Retrieved 2025-12-29. - ^ Cheng, Evelyn (2024-11-12). \"China's Alibaba releases AI search tool for small businesses in Europe and the Americas\". CNBC. Retrieved 2026-01-06. - ^ \"Amazon Business Unveils Next Generation AI Solutions to Help Organizations and Small Businesses Save Time and Money\". November 12, 2025. Archived from the original on December 28, 2025. - ^ \"AI is transforming the way Shopify merchants do business\". Shopify. Archived from the original on 2025-12-11. Retrieved 2026-01-06. - ^ \"TikTok Adds AI Assistance Tools for Creators | Social Media Today\". www.socialmediatoday.com. Retrieved 2026-01-06. - ^ Brohan, Mark (2025-03-11). \"Alibaba's AI search engine surpasses 1 million users\". Digital Commerce 360. Retrieved 2026-01-07. - ^ Brohan, Mark (2025-11-12). \"Amazon expands AI footprint in B2B buying with launch of new tool\". Digital Commerce 360. Retrieved 2026-01-07. - ^ \"What are the security risks of open sourcing the Twitter algorithm?\". VentureBeat. 27 May 2022. Retrieved 29 May 2022. - ^ \"Examining algorithmic amplification of political content on Twitter\". Retrieved 29 May 2022. - ^ Park, SoHyun; Oh, Heung-Kwon; Park, Gibeom; Suh, Bongwon; Bae, Woo Kyung; Kim, Jin Won; Yoon, Hyuk; Kim, Duck-Woo; Kang, Sung-Bum (February 2016). \"The Source and Credibility of Colorectal Cancer Information on Twitter\". Medicine. 95 (7) e2775. doi:10.1097/MD.0000000000002775. PMC 4998625. PMID 26886625. - ^ Efthimion, Phillip; Payne, Scott; Proferes, Nicholas (20 July 2018). \"Supervised Machine Learning Bot Detection Techniques to Identify Social Twitter Bots\". SMU Data Science Review. 1 (2). - ^ \"The online information environment\" (PDF). Retrieved 21 February 2022. - ^ Islam, Md Rafiqul; Liu, Shaowu; Wang, Xianzhi; Xu, Guandong (29 September 2020). \"Deep learning for misinformation detection on online social networks: a survey and new perspectives\". Social Network Analysis and Mining. 10 (1): 82. doi:10.1007/s13278-020-00696-x. PMC 7524036. PMID 33014173. - ^ Mohseni, Sina; Ragan, Eric (4 December 2018). \"Combating Fake News with Interpretable News Feed Algorithms\". arXiv:1811.12349 [cs.SI]. - ^ \"How artificial intelligence may be making you buy things\". BBC News. 9 November 2020. Retrieved 9 November 2020. - ^ Busby, Mattha (30 April 2018). \"Revealed: how bookies use AI to keep gamblers hooked\". The Guardian. - ^ Rowinski, Dan (15 January 2013). \"Virtual Personal Assistants & The Future Of Your Smartphone [Infographic]\". ReadWrite. Archived from the original on 22 December 2015. - ^ Roose, Kevin (16 February 2023). \"Bing's A.I. Chat: 'I Want to Be Alive. 😈'\". The New York Times. - ^ Galego Hernandes, Paulo R.; Floret, Camila P.; Cardozo De Almeida, Katia F.; Da Silva, Vinicius Camargo; Papa, Joso Paulo; Pontara Da Costa, Kelton A. (2021). \"Phishing Detection Using URL-based XAI Techniques\". 2021 IEEE Symposium Series on Computational Intelligence (SSCI). pp. 01–06. doi:10.1109/SSCI50451.2021.9659981. ISBN 978-1-7281-9048-8. - ^ Jáñez-Martino, Francisco; Alaiz-Rodríguez, Rocío; González-Castro, Víctor; Fidalgo, Eduardo; Alegre, Enrique (2023-02-01). \"A review of spam email detection: analysis of spammer strategies and the dataset shift problem\". Artificial Intelligence Review. 56 (2): 1145–1173. doi:10.1007/s10462-022-10195-4. hdl:10612/14967. - ^ Kapan, Sibel; Sora Gunal, Efnan (January 2023). \"Improved Phishing Attack Detection with Machine Learning: A Comprehensive Evaluation of Classifiers and Features\". Applied Sciences. 13 (24) 13269. doi:10.3390/app132413269. - ^ Heath, Nick (11 December 2020). \"What is AI? Everything you need to know about Artificial Intelligence\". ZDNet. Retrieved 1 March 2021. - ^ \"China's massive investment in artificial intelligence has an insidious downside\". Science AAAS. February 7, 2018. Retrieved February 23, 2018. - ^ \"China bets on facial recognition in big drive for total surveillance\". The Washington Post. 2018. Retrieved February 23, 2018. - ^ \"Facial recognition forced on 800 million Chinese internet users\". Radio France Internationale. 15 October 2019. Retrieved April 21, 2024. - ^ \"Country policy and information note: Falun Gong, China, November 2023 (accessible)\". The United Kingdom Government. April 4, 2024. Retrieved April 21, 2024. - ^ Techredacteur, Joost Schellevis (December 16, 2016). \"Politie gaat verdachten opsporen met gezichtsherkenning\". nos.nl (in Dutch). Retrieved September 22, 2019. - ^ Boon, Lex (August 25, 2018). \"Meekijken met de 226 gemeentecamera's\". Het Parool (in Dutch). Retrieved September 22, 2019. - ^ \"Successful and timely uptake of artificial intelligence in science in the EU – Scientific Advice Mechanism\". Retrieved 2024-04-16. - ^ \"AI in science evidence review report – Scientific Advice Mechanism\". Retrieved 2024-04-16. - ^ Assael, Yannis; Sommerschield, Thea; Shillingford, Brendan; Bordbar, Mahyar; Pavlopoulos, John; Chatzipanagiotou, Marita; Androutsopoulos, Ion; Prag, Jonathan; de Freitas, Nando (March 2022). \"Restoring and attributing ancient texts using deep neural networks\". Nature. 603 (7900): 280–283. Bibcode:2022Natur.603..280A. doi:10.1038/s41586-022-04448-z. PMC 8907065. PMID 35264762. - ^ Mantovan, Lorenzo; Nanni, Loris (September 2020). \"The Computerization of Archaeology: Survey on Artificial Intelligence Techniques\". SN Computer Science. 1 (5) 267. arXiv:2005.02863. doi:10.1007/s42979-020-00286-w. - ^ Mondal, Mayukh; Bertranpetit, Jaume; Lao, Oscar (December 2019). \"Approximate Bayesian computation with deep learning supports a third archaic introgression in Asia and Oceania\". Nature Communications. 10 (1): 246. Bibcode:2019NatCo..10..246M. doi:10.1038/s41467-018-08089-7. PMC 6335398. PMID 30651539. - ^ Tanti, Marc; Berruyer, Camille; Tafforeau, Paul; Muscat, Adrian; Farrugia, Reuben; Scerri, Kenneth; Valentino, Gianluca; Solé, V. Armando; Briffa, Johann A. (15 December 2021). \"Automated segmentation of microtomography imaging of Egyptian mummies\". PLOS ONE. 16 (12) e0260707. arXiv:2105.06738. Bibcode:2021PLoSO..1660707T. doi:10.1371/journal.pone.0260707. PMC 8673632. PMID 34910736. - ^ \"DeepMind AI learns physics by watching videos that don't make sense\". New Scientist. Retrieved 21 August 2022. - ^ Piloto, Luis S.; Weinstein, Ari; Battaglia, Peter; Botvinick, Matthew (11 July 2022). \"Intuitive physics learning in a deep-learning model inspired by developmental psychology\". Nature Human Behaviour. 6 (9): 1257–1267. doi:10.1038/s41562-022-01394-8. PMC 9489531. PMID 35817932. - ^ a b Feldman, Andrey (11 August 2022). \"Artificial physicist to unravel the laws of nature\". Advanced Science News. Retrieved 21 August 2022. - ^ Chen, Boyuan; Huang, Kuang; Raghupathi, Sunand; Chandratreya, Ishaan; Du, Qiang; Lipson, Hod (July 2022). \"Automated discovery of fundamental variables hidden in experimental data\". Nature Computational Science. 2 (7): 433–442. doi:10.1038/s43588-022-00281-6. PMID 38177869. - ^ Nuñez, Michael (2023-11-29). \"Google DeepMind's materials AI has already discovered 2.2 million new crystals\". VentureBeat. Retrieved 2023-12-19. - ^ Merchant, Amil; Batzner, Simon; Schoenholz, Samuel S.; Aykol, Muratahan; Cheon, Gowoon; Cubuk, Ekin Dogus (December 2023). \"Scaling deep learning for materials discovery\". Nature. 624 (7990): 80–85. Bibcode:2023Natur.624...80M. doi:10.1038/s41586-023-06735-9. PMC 10700131. PMID 38030720. - ^ Peplow, Mark (29 November 2023). \"Google AI and robots join forces to build new materials\". Nature. doi:10.1038/d41586-023-03745-5. PMID 38030771. - ^ Yanamandra, Kaushik; Chen, Guan Lin; Xu, Xianbo; Mac, Gary; Gupta, Nikhil (29 September 2020). \"Reverse engineering of additive manufactured composite part by toolpath reconstruction using imaging and machine learning\". Composites Science and Technology. 198 108318. doi:10.1016/j.compscitech.2020.108318. - ^ Anderson, Blake; Storlie, Curtis; Yates, Micah; McPhall, Aaron (2014). \"Automating Reverse Engineering with Machine Learning Techniques\". Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop. pp. 103–112. doi:10.1145/2666652.2666665. ISBN 978-1-4503-3153-1. - ^ Liu, Wenye; Chang, Chip-Hong; Wang, Xueyang; Liu, Chen; Fung, Jason M.; Ebrahimabadi, Mohammad; Karimi, Naghmeh; Meng, Xingyu; Basu, Kanad (June 2021). \"Two Sides of the Same Coin: Boons and Banes of Machine Learning in Hardware Security\". IEEE Journal on Emerging and Selected Topics in Circuits and Systems. 11 (2): 228–251. Bibcode:2021IJEST..11..228L. doi:10.1109/JETCAS.2021.3084400. hdl:10356/155876. - ^ \"DARPA Taps GrammaTech for Artificial Intelligence Exploration (AIE) Program\". www.businesswire.com. 7 January 2021. Retrieved 10 January 2023. - ^ Greenberg, Andy. \"How to Steal an AI\". Wired. Retrieved 10 January 2023. - ^ Sanchez-Lengeling, Benjamin; Aspuru-Guzik, Alán (27 July 2018). \"Inverse molecular design using machine learning: Generative models for matter engineering\". Science. 361 (6400): 360–365. Bibcode:2018Sci...361..360S. doi:10.1126/science.aat2663. PMID 30049875. - ^ a b \"Biologists train AI to generate medicines and vaccines\". University of Washington-Harborview Medical Center. - ^ a b Wang, Jue; Lisanza, Sidney; Juergens, David; Tischer, Doug; Watson, Joseph L.; Castro, Karla M.; Ragotte, Robert; Saragovi, Amijai; Milles, Lukas F.; Baek, Minkyung; Anishchenko, Ivan; Yang, Wei; Hicks, Derrick R.; Expòsit, Marc; Schlichthaerle, Thomas; Chun, Jung-Ho; Dauparas, Justas; Bennett, Nathaniel; Wicky, Basile I. M.; Muenks, Andrew; DiMaio, Frank; Correia, Bruno; Ovchinnikov, Sergey; Baker, David (22 July 2022). \"Scaffolding protein functional sites using deep learning\". Science. 377 (6604): 387–394. Bibcode:2022Sci...377..387W. doi:10.1126/science.abn2100. PMC 9621694. PMID 35862514. - ^ Teemu, Rintala (17 June 2019). Using Boolean network extraction of trained neural networks to reverse-engineer gene-regulatory networks from time-series data (Master's in Life Science Technologies thesis). Aalto University.[page needed] - ^ Ball, Nicholas M.; Brunner, Robert J. (July 2010). \"Data mining and machine learning in astronomy\". International Journal of Modern Physics D. 19 (7): 1049–1106. arXiv:0906.2173. Bibcode:2010IJMPD..19.1049B. doi:10.1142/S0218271810017160. - ^ a b Shekhtman, Svetlana (15 November 2019). \"NASA Applying AI Technologies to Problems in Space Science\". NASA. Retrieved 30 May 2022. - ^ Fluke, Christopher J.; Jacobs, Colin (March 2020). \"Surveying the reach and maturity of machine learning and artificial intelligence in astronomy\". WIREs Data Mining and Knowledge Discovery. 10 (2) e1349. arXiv:1912.02934. Bibcode:2020WDMKD..10.1349F. doi:10.1002/widm.1349. - ^ Pultarova, Tereza (29 April 2021). \"Artificial intelligence is learning how to dodge space junk in orbit\". Space.com. Retrieved 3 July 2022. - ^ Mohan, Jaya Preethi; Tejaswi, N. (2020). \"A Study on Embedding the Artificial Intelligence and Machine Learning into Space Exploration and Astronomy\". Emerging Trends in Computing and Expert Technology. Lecture Notes on Data Engineering and Communications Technologies. Vol. 35. pp. 1295–1302. doi:10.1007/978-3-030-32150-5_131. ISBN 978-3-030-32149-9. - ^ Rees, Martin (30 April 2022). \"Could space-going billionaires be the vanguard of a cosmic revolution? | Martin Rees\". The Guardian. Retrieved 29 May 2022. - ^ Gutowska, Małgorzata; Scriney, Michael; McCarren, Andrew (December 2019). Identifying extra-terrestrial intelligence using machine learning. 27th AIAI Irish Conference on Artificial Intelligence and Cognitive Science. - ^ Zhang, Yunfan Gerry; Gajjar, Vishal; Foster, Griffin; Siemion, Andrew; Cordes, James; Law, Casey; Wang, Yu (2018). \"Fast Radio Burst 121102 Pulse Detection and Periodicity: A Machine Learning Approach\". The Astrophysical Journal. 866 (2): 149. arXiv:1809.03043. Bibcode:2018ApJ...866..149Z. doi:10.3847/1538-4357/aadf31. - ^ Nanda, Lakshay; V, Santhi (2019). \"SETI (Search for Extra Terrestrial Intelligence) Signal Classification using Machine Learning\". 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). pp. 499–504. doi:10.1109/ICSSIT46314.2019.8987793. ISBN 978-1-7281-2119-2. - ^ Gajjar, Vishal; Siemion, Andrew; Croft, Steve; Brzycki, Bryan; Burgay, Marta; Carozzi, Tobia; Concu, Raimondo; Czech, Daniel; DeBoer, David; DeMarines, Julia; Drew, Jamie; Enriquez, J. Emilio; Fawcett, James; Gallagher, Peter; Garrett, Michael; Gizani, Nectaria; Hellbourg, Greg; Holder, Jamie; Isaacson, Howard; Kudale, Sanjay; Lacki, Brian; Lebofsky, Matthew; Li, Di; MacMahon, David H. E.; McCauley, Joe; Melis, Andrea; Molinari, Emilio; Murphy, Pearse; Perrodin, Delphine; Pilia, Maura; Price, Danny C.; Webb, Claire; Werthimer, Dan; Williams, David; Worden, Pete; Zarka, Philippe; Zhang, Yunfan Gerry (2 August 2019). \"The Breakthrough Listen Search for Extraterrestrial Intelligence\". Bulletin of the American Astronomical Society. 51 (7): 223. arXiv:1907.05519. Bibcode:2019BAAS...51g.223G. - ^ \"SkyCAM-5 - Chair of Computer Science VIII - Aerospace Information Technology\". University of Würzburg. Retrieved 29 May 2022. - ^ \"Project Galileo: The search for alien tech hiding in our Solar System\". BBC Science Focus Magazine. Retrieved 29 May 2022. - ^ \"'Something's coming': is America finally ready to take UFOs seriously?\". The Guardian. 5 February 2022. Retrieved 29 May 2022. - ^ David, Leonard (27 January 2022). \"2022 could be a turning point in the study of UFOs\". livescience.com. Retrieved 29 May 2022. - ^ Gritz, Jennie Rothenberg. \"The Wonder of Avi Loeb\". Retrieved 29 May 2022. - ^ Mann, Adam. \"Avi Loeb's Galileo Project Will Search for Evidence of Alien Visitation\". Scientific American. Retrieved 29 May 2022. - ^ \"Galileo Project – Activities\". projects.iq.harvard.edu. Retrieved 29 May 2022. - ^ \"The Galileo Project: Harvard researchers to search for signs of alien technology\". Sky News. - ^ Zapata Trujillo, Juan C.; Syme, Anna-Maree; Rowell, Keiran N.; Burns, Brendan P.; Clark, Ebubekir S.; Gorman, Maire N.; Jacob, Lorrie S. D.; Kapodistrias, Panayioti; Kedziora, David J.; Lempriere, Felix A. R.; Medcraft, Chris; O'Sullivan, Jensen; Robertson, Evan G.; Soares, Georgia G.; Steller, Luke; Teece, Bronwyn L.; Tremblay, Chenoa D.; Sousa-Silva, Clara; McKemmish, Laura K. (2021). \"Computational Infrared Spectroscopy of 958 Phosphorus-Bearing Molecules\". Frontiers in Astronomy and Space Sciences. 8 639068: 43. arXiv:2105.08897. Bibcode:2021FrASS...8...43Z. doi:10.3389/fspas.2021.639068. - ^ \"Chemists debate machine learning's future in synthesis planning and ask for open data\". cen.acs.org. Retrieved 29 May 2022. - ^ \"Machine learning reveals recipe for building artificial proteins\". phys.org. Retrieved 17 August 2020. - ^ Russ, William P.; Figliuzzi, Matteo; Stocker, Christian; Barrat-Charlaix, Pierre; Socolich, Michael; Kast, Peter; Hilvert, Donald; Monasson, Remi; Cocco, Simona; Weigt, Martin; Ranganathan, Rama (2020). \"An evolution-based model for designing chorismatemutase enzymes\". Science. 369 (6502): 440–445. Bibcode:2020Sci...369..440R. doi:10.1126/science.aba3304. PMID 32703877. S2CID 220714458. - ^ Stocker, Sina; Csányi, Gábor; Reuter, Karsten; Margraf, Johannes T. (30 October 2020). \"Machine learning in chemical reaction space\". Nature Communications. 11 (1): 5505. Bibcode:2020NatCo..11.5505S. doi:10.1038/s41467-020-19267-x. PMC 7603480. PMID 33127879. - ^ Yirka, Bob. \"Repurposed drug-seeking AI system generates 40,000 possible chemical weapons in just six hours\". techxplore.com. Retrieved 19 April 2022. - ^ Urbina, Fabio; Lentzos, Filippa; Invernizzi, Cédric; Ekins, Sean (March 2022). \"Dual use of artificial-intelligence-powered drug discovery\". Nature Machine Intelligence. 4 (3): 189–191. doi:10.1038/s42256-022-00465-9. ISSN 2522-5839. PMC 9544280. PMID 36211133. S2CID 247302391. - ^ \"AI drug algorithms can be flipped to generate bioweapons\". www.theregister.com. Retrieved 24 April 2022. - ^ Hansen, Justine Y.; Markello, Ross D.; Vogel, Jacob W.; Seidlitz, Jakob; Bzdok, Danilo; Misic, Bratislav (September 2021). \"Mapping gene transcription and neurocognition across human neocortex\". Nature Human Behaviour. 5 (9): 1240–1250. doi:10.1038/s41562-021-01082-z. PMID 33767429. - ^ Vo ngoc, Long; Huang, Cassidy Yunjing; Cassidy, California Jack; Medrano, Claudia; Kadonaga, James T. (September 2020). \"Identification of the human DPR core promoter element using machine learning\". Nature. 585 (7825): 459–463. Bibcode:2020Natur.585..459V. doi:10.1038/s41586-020-2689-7. PMC 7501168. PMID 32908305. - ^ Bijun, Zhang; Ting, Fan (2022). \"Knowledge structure and emerging trends in the application of deep learning in genetics research: A bibliometric analysis [2000–2021]\". Frontiers in Genetics. 13 951939. doi:10.3389/fgene.2022.951939. PMC 9445221. PMID 36081985. - ^ Radivojević, Tijana; Costello, Zak; Workman, Kenneth; Garcia Martin, Hector (25 September 2020). \"A machine learning Automated Recommendation Tool for synthetic biology\". Nature Communications. 11 (1): 4879. arXiv:1911.11091. Bibcode:2020NatCo..11.4879R. doi:10.1038/s41467-020-18008-4. PMC 7519645. PMID 32978379. - ^ a b Pablo Carbonell; Tijana Radivojevic; Héctor García Martín* (2019). \"Opportunities at the Intersection of Synthetic Biology, Machine Learning, and Automation\". ACS Synthetic Biology. 8 (7): 1474–1477. doi:10.1021/acssynbio.8b00540. hdl:20.500.11824/998. PMID 31319671. - ^ Gadzhimagomedova, Z. M.; Pashkov, D. M.; Kirsanova, D. Yu.; Soldatov, S. A.; Butakova, M. A.; Chernov, A. V.; Soldatov, A. V. (February 2022). \"Artificial Intelligence for Nanostructured Materials\". Nanobiotechnology Reports. 17 (1): 1–9. doi:10.1134/S2635167622010049. - ^ Mirzaei, Mahsa; Furxhi, Irini; Murphy, Finbarr; Mullins, Martin (July 2021). \"A Machine Learning Tool to Predict the Antibacterial Capacity of Nanoparticles\". Nanomaterials. 11 (7): 1774. doi:10.3390/nano11071774. PMC 8308172. PMID 34361160. - ^ Chen, Angela (25 April 2018). \"How AI is helping us discover materials faster than ever\". The Verge. Retrieved 30 May 2022. - ^ Talapatra, Anjana; Boluki, S.; Duong, T.; Qian, X.; Dougherty, E.; Arróyave, R. (26 November 2018). \"Autonomous efficient experiment design for materials discovery with Bayesian model averaging\". Physical Review Materials. 2 (11) 113803. arXiv:1803.05460. Bibcode:2018PhRvM...2k3803T. doi:10.1103/PhysRevMaterials.2.113803. - ^ Zhao, Yicheng; Zhang, Jiyun; Xu, Zhengwei; Sun, Shijing; Langner, Stefan; Hartono, Noor Titan Putri; Heumueller, Thomas; Hou, Yi; Elia, Jack; Li, Ning; Matt, Gebhard J.; Du, Xiaoyan; Meng, Wei; Osvet, Andres; Zhang, Kaicheng; Stubhan, Tobias; Feng, Yexin; Hauch, Jens; Sargent, Edward H.; Buonassisi, Tonio; Brabec, Christoph J. (13 April 2021). \"Discovery of temperature-induced stability reversal in perovskites using high-throughput robotic learning\". Nature Communications. 12 (1): 2191. Bibcode:2021NatCo..12.2191Z. doi:10.1038/s41467-021-22472-x. PMC 8044090. PMID 33850155. - ^ Anne Johnson; Emily Grumbling (2019). Implications of artificial intelligence for cybersecurity: proceedings of a workshop. Washington, DC: National Academies Press. pp. 4–5. ISBN 978-0-309-49451-9. OCLC 1134854973. Retrieved 2025-05-12. - ^ Kocher, Geeta; Kumar, Gulshan (August 2021). \"Machine learning and deep learning methods for intrusion detection systems: recent developments and challenges\". Soft Computing. 25 (15): 9731–9763. doi:10.1007/s00500-021-05893-0. - ^ Kant, Daniel; Johannsen, Andreas (16 January 2022). \"Evaluation of AI-based use cases for enhancing the cyber security defense of small and medium-sized companies (SMEs)\". Electronic Imaging. 34 (3): 387–1–387–8. doi:10.2352/EI.2022.34.3.MOBMU-387. - ^ Randrianasolo, Arisoa (2012). Artificial intelligence in computer security: Detection, temporary repair and defense (Thesis). p. vii. hdl:2346/45196. - ^ Sahil; Sood, Sandeep; Mehmi, Sandeep; Dogra, Shikha (2015). \"Artificial intelligence for designing user profiling system for cloud computing security: Experiment\". 2015 International Conference on Advances in Computer Engineering and Applications. pp. 51–58. doi:10.1109/ICACEA.2015.7164645. ISBN 978-1-4673-6911-4. - ^ Parisi, Alessandro (2019). Hands-On Artificial Intelligence for Cybersecurity: Implement smart AI systems for preventing ",
    "text_length": 120000,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:11.839890"
  },
  {
    "id": "page_17",
    "url": "https://en.wikipedia.org/wiki/Machine_learning_in_bioinformatics",
    "domain": "en.wikipedia.org",
    "title": "Machine learning in bioinformatics - Wikipedia",
    "text": "Machine learning in bioinformatics | Part of a series on | | Artificial intelligence (AI) | |---| Machine learning in bioinformatics is the application of machine learning algorithms to bioinformatics,[1] including genomics, proteomics, microarrays, systems biology, evolution, and text mining.[2][3] Prior to the emergence of machine learning, bioinformatics algorithms had to be programmed by hand; for problems such as protein structure prediction, this proved difficult.[4] Machine learning techniques such as deep learning can learn features of data sets rather than requiring the programmer to define them individually. The algorithm can further learn how to combine low-level features into more abstract features, and so on. This multi-layered approach allows such systems to make sophisticated predictions when appropriately trained. These methods contrast with other computational biology approaches which, while exploiting existing datasets, do not allow the data to be interpreted and analyzed in unanticipated ways. Tasks [edit]Machine learning algorithms in bioinformatics can be used for prediction, classification, and feature selection. Methods to achieve this task are varied and span many disciplines; most well known among them are machine learning and statistics. Classification and prediction tasks aim at building models that describe and distinguish classes or concepts for future prediction. The differences between them are the following: - Classification/recognition outputs a categorical class, while prediction outputs a numerical valued feature. - The type of algorithm, or process used to build the predictive models from data using analogies, rules, neural networks, probabilities, and/or statistics. Due to the exponential growth of information technologies and applicable models, including artificial intelligence and data mining, in addition to the access ever-more comprehensive data sets, new and better information analysis techniques have been created, based on their ability to learn. Such models allow reach beyond description and provide insights in the form of testable models. Approaches [edit]Artificial neural networks [edit]Artificial neural networks in bioinformatics have been used for:[5] - Comparing and aligning RNA, protein, and DNA sequences. - Identification of promoters and finding genes from sequences related to DNA. - Interpreting the expression-gene and micro-array data. - Identifying the network (regulatory) of genes. - Learning evolutionary relationships by constructing phylogenetic trees. - Classifying and predicting protein structure. - Molecular design and docking Feature engineering [edit]The way that features, often vectors in a many-dimensional space, are extracted from the domain data is an important component of learning systems.[6] In genomics, a typical representation of a sequence is a vector of k-mers frequencies, which is a vector of dimension whose entries count the appearance of each subsequence of length in a given sequence. Since for a value as small as the dimensionality of these vectors is huge (e.g. in this case the dimension is ), techniques such as principal component analysis are used to project the data to a lower dimensional space, thus selecting a smaller set of features from the sequences.[6][7] Classification [edit]In this type of machine learning task, the output is a discrete variable. One example of this type of task in bioinformatics is labeling new genomic data (such as genomes of unculturable bacteria) based on a model of already labeled data.[6] Hidden Markov models [edit]Hidden Markov models (HMMs) are a class of statistical models for sequential data (often related to systems evolving over time). An HMM is composed of two mathematical objects: an observed state‐dependent process , and an unobserved (hidden) state process . In an HMM, the state process is not directly observed – it is a 'hidden' (or 'latent') variable – but observations are made of a state‐dependent process (or observation process) that is driven by the underlying state process (and which can thus be regarded as a noisy measurement of the system states of interest).[8] HMMs can be formulated in continuous time.[9][10] HMMs can be used to profile and convert a multiple sequence alignment into a position-specific scoring system suitable for searching databases for homologous sequences remotely.[11] Additionally, ecological phenomena can be described by HMMs.[12] Convolutional neural networks [edit]Convolutional neural networks (CNN) are a class of deep neural network whose architecture is based on shared weights of convolution kernels or filters that slide along input features, providing translation-equivariant responses known as feature maps.[13][14] CNNs take advantage of the hierarchical pattern in data and assemble patterns of increasing complexity using smaller and simpler patterns discovered via their filters.[15] Convolutional networks were inspired by biological processes[16][17][18][19] in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field. CNN uses relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are hand-engineered. This reduced reliance on prior knowledge of the analyst and on human intervention in manual feature extraction makes CNNs a desirable model.[15] A phylogenetic convolutional neural network (Ph-CNN) is a convolutional neural network architecture proposed by Fioranti et al. in 2018 to classify metagenomics data.[20] In this approach, phylogenetic data is endowed with patristic distance (the sum of the lengths of all branches connecting two operational taxonomic units [OTU]) to select k-neighborhoods for each OTU, and each OTU and its neighbors are processed with convolutional filters. Self-supervised learning (Attention and Transformer Models) [edit]Unlike supervised methods, self-supervised learning methods learn representations without relying on annotated data. That is well-suited for genomics, where high throughput sequencing techniques can create potentially large amounts of unlabeled data. Some examples of self-supervised learning methods applied on genomics include DNABERT and Self-GenomeNet.[21][22] Because of their parallelism and the ability to extract correlation across the whole sequences, transformer-based models achieve state-of-the-art performance in a variety of important tasks such as machine translation and question answering. The vanilla transformer model can be divided into two parts: encoder[disambiguation needed] and decoder[disambiguation needed], which have similar basic architectures composed of a stack of identical blocks. Each block consists of two kinds of sub-layers: the multi-head attention sub-layer and the position-wise feed-forward sub-layer. Both kinds of sublayers are followed by layer normalization. A residual connection around every sub-layer will be applied in each block to speed up the training process.[23] Attention modules [edit]The key innovation in the Transformer architecture is the multi-head self-attention layer, which can relate all relevant tokens to better encode every word or residue in the input sequence. The self-attention layer takes a sequence of tokens as input (tokens equivalent to words in a language or amino acids/nucleotides in a sequence) and learns sequence-wide context information. Multi-head attention represents multiple simultaneous attention heads. Before calculating the attention function, each token embedding is transformed into three corresponding vectors: the , the , and the vectors. This transformation is achieved by multiplying the token embedding with three randomly initialized, learnable parameter matrices, , , and . The core attention function is computed by three steps: - Scoring: The attention head computes the dot products of the Query vector with all Key vectors. - Scaling and Weighting: Each dot product is divided by (where is the dimension of the key vector) and a Softmax function is applied to obtain the weights on the Value vectors. - Output: The output of the attention function is the weighted sum of these Value vectors, which contains information for the entire sequence. The weight assigned to each value is computed by a compatibility function of the Query with the corresponding Key. In the parallel computation of the attention function, a set of query, key, and value vectors are packed into matrices , , and . The attention function is computed as follows: When generalized to multi-head attention with heads, the results of the multiple heads (each assigned different parameters , , ) are concatenated and once again projected with a parameter matrix , resulting in the final output:[24] Position-wise feed-forward networks [edit]Except for the attention sub-layer, each block of the encoder and decoder contains a fully connected feed-forward network (FFN), which is applied identically and independently to each token (position-wise). This layer consists of two linear transformations with a Rectified Linear Unit (ReLU) activation function in the middle. The FFN is computed as follows: Here, and are the learnable parameters of the network. This layer is responsible for translating the output of the attention mechanism into a form suitable for the next layer.[24] Residual connection and layer normalization [edit]Each encoder and decoder block contains two residual connections and two layer normalization layers. These are applied to both the multi-head self-attention output and the feed-forward network (FFN) output. Layer normalization can accelerate the training process of the model by normalizing the output of the former layers to make it converge faster. The formulas are as follows: The variable represents the input of the multi-head self-attention or FFN. This original input is added to the sub-layer's output, forming a residual connection. For deep networks, the residual connection helps defend against vanishing and exploding gradients by keeping the original input signal, which stabilizes the training process.[24] Random forest [edit]Random forests (RF) classify by constructing an ensemble of decision trees, and outputting the average prediction of the individual trees.[25] This is a modification of bootstrap aggregating (which aggregates a large collection of decision trees) and can be used for classification or regression.[26][27] As random forests give an internal estimate of generalization error, cross-validation is unnecessary. In addition, they produce proximities, which can be used to impute missing values, and which enable novel data visualizations.[28] Computationally, random forests are appealing because they naturally handle both regression and (multiclass) classification, are relatively fast to train and to predict, depend only on one or two tuning parameters, have a built-in estimate of the generalization error, can be used directly for high-dimensional problems, and can easily be implemented in parallel. Statistically, random forests are appealing for additional features, such as measures of variable importance, differential class weighting, missing value imputation, visualization, outlier detection, and unsupervised learning.[28] Clustering [edit]Clustering - the partitioning of a data set into disjoint subsets, so that the data in each subset are as close as possible to each other and as distant as possible from data in any other subset, according to some defined distance or similarity function - is a common technique for statistical data analysis. Clustering is central to much data-driven bioinformatics research and serves as a powerful computational method whereby means of hierarchical, centroid-based, distribution-based, density-based, and self-organizing maps classification, has long been studied and used in classical machine learning settings. Particularly, clustering helps to analyze unstructured and high-dimensional data in the form of sequences, expressions, texts, images, and so on. Clustering is also used to gain insights into biological processes at the genomic level, e.g. gene functions, cellular processes, subtypes of cells, gene regulation, and metabolic processes.[29] Clustering algorithms used in bioinformatics [edit]Data clustering algorithms can be hierarchical or partitional. Hierarchical algorithms find successive clusters using previously established clusters, whereas partitional algorithms determine all clusters at once. Hierarchical algorithms can be agglomerative (bottom-up) or divisive (top-down). Agglomerative algorithms begin with each element as a separate cluster and merge them in successively larger clusters. Divisive algorithms begin with the whole set and proceed to divide it into successively smaller clusters. Hierarchical clustering is calculated using metrics on Euclidean spaces, the most commonly used is the Euclidean distance computed by finding the square of the difference between each variable, adding all the squares, and finding the square root of the said sum. An example of a hierarchical clustering algorithm is BIRCH, which is particularly good on bioinformatics for its nearly linear time complexity given generally large datasets.[30] Partitioning algorithms are based on specifying an initial number of groups, and iteratively reallocating objects among groups to convergence. This algorithm typically determines all clusters at once. Most applications adopt one of two popular heuristic methods: k-means algorithm or k-medoids. Other algorithms do not require an initial number of groups, such as affinity propagation. In a genomic setting this algorithm has been used both to cluster biosynthetic gene clusters in gene cluster families(GCF) and to cluster said GCFs.[31] Workflow [edit]Typically, a workflow for applying machine learning to biological data goes through four steps:[2] - Recording, including capture and storage. In this step, different information sources may be merged into a single set. - Preprocessing, including cleaning and restructuring into a ready-to-analyze form. In this step, uncorrected data are eliminated or corrected, while missing data maybe imputed and relevant variables chosen. - Analysis, evaluating data using either supervised or unsupervised algorithms. The algorithm is typically trained on a subset of data, optimizing parameters, and evaluated on a separate test subset. - Visualization and interpretation, where knowledge is represented effectively using different methods to assess the significance and importance of the findings. Data errors [edit]- Duplicate data is a significant issue in bioinformatics. Publicly available data may be of uncertain quality.[32] - Errors during experimentation.[32] - Erroneous interpretation.[32] - Typing mistakes.[32] - Non-standardized methods (3D structure in PDB from multiple sources, X-ray diffraction, theoretical modeling, nuclear magnetic resonance, etc.) are used in experiments.[32] Applications [edit]In general, a machine learning system can usually be trained to recognize elements of a certain class given sufficient samples.[33] For example, machine learning methods can be trained to identify specific visual features such as splice sites.[34] Support vector machines have been extensively used in cancer genomic studies.[35] In addition, deep learning has been incorporated into bioinformatic algorithms. Deep learning applications have been used for regulatory genomics and cellular imaging.[36] Other applications include medical image classification, genomic sequence analysis, as well as protein structure classification and prediction.[37] Deep learning has been applied to regulatory genomics, variant calling and pathogenicity scores.[38] Natural language processing and text mining have helped to understand phenomena including protein-protein interaction, gene-disease relation as well as predicting biomolecule structures and functions.[39] Precision/personalized medicine [edit]Natural language processing algorithms personalized medicine for patients who suffer genetic diseases, by combining the extraction of clinical information and genomic data available from the patients. Institutes such as Health-funded Pharmacogenomics Research Network focus on finding breast cancer treatments.[39] Precision medicine considers individual genomic variability, enabled by large-scale biological databases. Machine learning can be applied to perform the matching function between (groups of patients) and specific treatment modalities.[39] Computational techniques are used to solve other problems, such as efficient primer design for PCR, biological-image analysis and back translation of proteins (which is, given the degeneration of the genetic code, a complex combinatorial problem).[2] Genomics [edit]While genomic sequence data has historically been sparse due to the technical difficulty of sequencing a piece of DNA, the number of available sequences is growing. On average, the number of bases available in the GenBank public repository has doubled every 18 months since 1982.[40] However, while raw data was becoming increasingly available and accessible, As of 2002[update], biological interpretation of this data was occurring at a much slower pace.[41] This made for an increasing need for developing computational genomics tools, including machine learning systems, that can automatically determine the location of protein-encoding genes within a given DNA sequence (i.e. gene prediction).[41] Gene prediction is commonly performed through both extrinsic searches and intrinsic searches.[41] For the extrinsic search, the input DNA sequence is run through a large database of sequences whose genes have been previously discovered and their locations annotated and identifying the target sequence's genes by determining which strings of bases within the sequence are homologous to known gene sequences. However, not all the genes in a given input sequence can be identified through homology alone, due to limits in the size of the database of known and annotated gene sequences. Therefore, an intrinsic search is needed where a gene prediction program attempts to identify the remaining genes from the DNA sequence alone.[41] Machine learning has also been used for the problem of multiple sequence alignment which involves aligning many DNA or amino acid sequences in order to determine regions of similarity that could indicate a shared evolutionary history.[2] It can also be used to detect and visualize genome rearrangements.[42] Proteomics [edit]Proteins, strings of amino acids, gain much of their function from protein folding, where they conform into a three-dimensional structure, including the primary structure, the secondary structure (alpha helices and beta sheets), the tertiary structure, and the quaternary structure. Protein secondary structure prediction is a main focus of this subfield as tertiary and quaternary structures are determined based on the secondary structure.[4] Solving the true structure of a protein is expensive and time-intensive, furthering the need for systems that can accurately predict the structure of a protein by analyzing the amino acid sequence directly.[4][2] Prior to machine learning, researchers needed to conduct this prediction manually. This trend began in 1951 when Pauling and Corey released their work on predicting the hydrogen bond configurations of a protein from a polypeptide chain.[43] Automatic feature learning reaches an accuracy of 82-84%.[4][44] Recent approaches have utilized deep learning techniques for state-of-the-art secondary structure predictions. For example, DeepCNF (deep convolutional neural fields) achieved an accuracy of approximately 84% when tasked to classify the amino acids of a protein sequence into one of three structural classes (helix, sheet, or coil).[44] The theoretical limit for three-state protein secondary structure is 88–90%.[4] In 2018, AlphaFold, an artificial intelligence (AI) program developed by DeepMind, placed first in the overall rankings of the 13th Critical Assessment of Structure Prediction (CASP). It was particularly successful at predicting the most accurate structures for targets rated as most difficult by the competition organizers, where no existing template structures were available from proteins with partially similar sequences. AlphaFold 2 (2020) repeated this placement in the CASP14 competition and achieved a level of accuracy much higher than any other entry.[45][46][47] Machine learning has also been applied to proteomics problems such as protein side-chain prediction, protein loop modeling, and protein contact map prediction.[2] Metagenomics [edit]Metagenomics is the study of microbial communities from environmental DNA samples.[48] Currently, limitations and challenges predominate in the implementation of machine learning tools due to the amount of data in environmental samples.[49] Supercomputers and web servers have made access to these tools easier.[50] The high dimensionality of microbiome datasets is a major challenge in studying the microbiome; this significantly limits the power of current approaches for identifying true differences and increases the chance of false discoveries.[51][better source needed] Despite their importance, machine learning tools related to metagenomics have focused on the study of gut microbiota and the relationship with digestive diseases, such as inflammatory bowel disease (IBD), Clostridioides difficile infection (CDI), colorectal cancer and diabetes, seeking better diagnosis and treatments.[50] Many algorithms were developed to classify microbial communities according to the health condition of the host, regardless of the type of sequence data, e.g. 16S rRNA or whole-genome sequencing (WGS), using methods such as least absolute shrinkage and selection operator classifier, random forest, supervised classification model, and gradient boosted tree model. Neural networks, such as recurrent neural networks (RNN), convolutional neural networks (CNN), and Hopfield neural networks have been added.[50] For example, in 2018, Fioravanti et al. developed an algorithm called Ph-CNN to classify data samples from healthy patients and patients with IBD symptoms (to distinguish healthy and sick patients) by using phylogenetic trees and convolutional neural networks.[52] In addition, random forest (RF) methods and implemented importance measures help in the identification of microbiome species that can be used to distinguish diseased and non-diseased samples. However, the performance of a decision tree and the diversity of decision trees in the ensemble significantly influence the performance of RF algorithms. The generalization error for RF measures how accurate the individual classifiers are and their interdependence. Therefore, the high dimensionality problems of microbiome datasets pose challenges. Effective approaches require many possible variable combinations, which exponentially increases the computational burden as the number of features increases.[51] For microbiome analysis in 2020 Dang & Kishino[51] developed a novel analysis pipeline. The core of the pipeline is an RF classifier coupled with forwarding variable selection (RF-FVS), which selects a minimum-size core set of microbial species or functional signatures that maximize the predictive classifier performance. The framework combines: - identifying a few significant features by a massively parallel forward variable selection procedure - mapping the selected species on a phylogenetic tree, and - predicting functional profiles by functional gene enrichment analysis from metagenomic 16S rRNA data. They demonstrated performance by analyzing two published datasets from large-scale case-control studies: - 16S rRNA gene amplicon data for C. difficile infection (CDI) and - shotgun metagenomics data for human colorectal cancer (CRC). The proposed approach improved the accuracy from 81% to 99.01% for CDI and from 75.14% to 90.17% for CRC. The use of machine learning in environmental samples has been less explored, maybe because of data complexity, especially from WGS. Some works show that it is possible to apply these tools in environmental samples. In 2021 Dhungel et al.,[53] designed an R package called MegaR. This package allows working with 16S rRNA and whole metagenomic sequences to make taxonomic profiles and classification models by machine learning models. MegaR includes a comfortable visualization environment to improve the user experience. Machine learning in environmental metagenomics can help to answer questions related to the interactions between microbial communities and ecosystems, e.g. the work of Xun et al., in 2021[54] where the use of different machine learning methods offered insights on the relationship among the soil, microbiome biodiversity, and ecosystem stability. Microarrays [edit]Microarrays, a type of lab-on-a-chip, are used for automatically collecting data about large amounts of biological material. Machine learning can aid in analysis, and has been applied to expression pattern identification, classification, and genetic network induction.[2] This technology is especially useful for monitoring gene expression, aiding in diagnosing cancer by examining which genes are expressed.[55] One of the main tasks is identifying which genes are expressed based on the collected data.[2] In addition, due to the huge number of genes on which data is collected by the microarray, winnowing the large amount of irrelevant data to the task of expressed gene identification is challenging. Machine learning presents a potential solution as various classification methods can be used to perform this identification. The most commonly used methods are radial basis function networks, deep learning, Bayesian classification, decision trees, and random forest.[55] Systems biology [edit]Systems biology focuses on the study of emergent behaviors from complex interactions of simple biological components in a system. Such components can include DNA, RNA, proteins, and metabolites.[56] Machine learning has been used to aid in modeling these interactions in domains such as genetic networks, signal transduction networks, and metabolic pathways.[2] Probabilistic graphical models, a machine learning technique for determining the relationship between different variables, are one of the most commonly used methods for modeling genetic networks.[2] In addition, machine learning has been applied to systems biology problems such as identifying transcription factor binding sites using Markov chain optimization.[2] Genetic algorithms, machine learning techniques which are based on the natural process of evolution, have been used to model genetic networks and regulatory structures.[2] Other systems biology applications of machine learning include the task of enzyme function prediction, high throughput microarray data analysis, analysis of genome-wide association studies to better understand markers of disease, protein function prediction.[57] Evolution [edit]This domain, particularly phylogenetic tree reconstruction, uses the features of machine learning techniques. Phylogenetic trees are schematic representations of the evolution of organisms. Initially, they were constructed using features such as morphological and metabolic features. Later, due to the availability of genome sequences, the construction of the phylogenetic tree algorithm used the concept based on genome comparison. With the help of optimization techniques, a comparison was done by means of multiple sequence alignment.[58] Stroke diagnosis [edit]Machine learning methods for the analysis of neuroimaging data are used to help diagnose stroke. Historically multiple approaches to this problem involved neural networks.[59][60] Multiple approaches to detect strokes used machine learning. As proposed by Mirtskhulava,[61] feed-forward networks were tested to detect strokes using neural imaging. As proposed by Titano[62] 3D-CNN techniques were tested in supervised classification to screen head CT images for acute neurologic events. Three-dimensional CNN and SVM methods are often used.[60] Text mining [edit]The increase in biological publications increased the difficulty in searching and compiling relevant available information on a given topic. This task is known as knowledge extraction. It is necessary for biological data collection which can then in turn be fed into machine learning algorithms to generate new biological knowledge.[2][63] Machine learning can be used for this knowledge extraction task using techniques such as natural language processing to extract the useful information from human-generated reports in a database. Text Nailing, an alternative approach to machine learning, capable of extracting features from clinical narrative notes was introduced in 2017. This technique has been applied to the search for novel drug targets, as this task requires the examination of information stored in biological databases and journals.[63] Annotations of proteins in protein databases often do not reflect the complete known set of knowledge of each protein, so additional information must be extracted from biomedical literature. Machine learning has been applied to the automatic annotation of gene and protein function, determination of the protein subcellular localization, DNA-expression array analysis, large-scale protein interaction analysis, and molecule interaction analysis.[63] Another application of text mining is the detection and visualization of distinct DNA regions given sufficient reference data.[64] Clustering and abundance profiling of biosynthetic gene clusters [edit]Microbial communities are complex assembles of diverse microorganisms,[65] where symbiont partners constantly produce diverse metabolites derived from the primary and secondary (specialized) metabolism, from which metabolism plays an important role in microbial interaction.[66] Metagenomic and metatranscriptomic data are an important source for deciphering communications signals. Molecular mechanisms produce specialized metabolites in various ways. Biosynthetic Gene Clusters (BGCs) attract attention, since several metabolites are clinically valuable, anti-microbial, anti-fungal, anti-parasitic, anti-tumor and immunosuppressive agents produced by the modular action of multi-enzymatic, multi-domains gene clusters, such as Nonribosomal peptide synthetases (NRPSs) and polyketide synthases (PKSs).[67] Diverse studies[68][69][70][71][72][73][74][75] show that grouping BGCs that share homologous core genes into gene cluster families (GCFs) can yield useful insights into the chemical diversity of the analyzed strains, and can support linking BGCs to their secondary metabolites.[69][71] GCFs have been used as functional markers in human health studies[76][77] and to study the ability of soil to suppress fungal pathogens.[78] Given their direct relationship to catalytic enzymes, and compounds produced from their encoded pathways, BGCs/GCFs can serve as a proxy to explore the chemical space of microbial secondary metabolism. Cataloging GCFs in sequenced microbial genomes yields an overview of the existing chemical diversity and offers insights into future priorities.[68][70] Tools such as BiG-SLiCE and BIG-MAP[79] have emerged with the sole purpose of unveiling the importance of BGCs in natural environments. Decodification of RiPPs chemical structures [edit]The increase of experimentally characterized ribosomally synthesized and post-translationally modified peptides (RiPPs), together with the availability of information on their sequence and chemical structure, selected from databases such as BAGEL, BACTIBASE, MIBIG, and THIOBASE, provide the opportunity to develop machine learning tools to decode the chemical structure and classify them. In 2017, researchers at the National Institute of Immunology of New Delhi, India, developed RiPPMiner[80] software, a bioinformatics resource for decoding RiPP chemical structures by genome mining. The RiPPMiner web server consists of a query interface and the RiPPDB database. RiPPMiner defines 12 subclasses of RiPPs, predicting the cleavage site of the leader peptide and the final cross-link of the RiPP chemical structure. Mass spectral similarity scoring [edit]Many tandem mass spectrometry (MS/MS) based metabolomics studies, such as library matching and molecular networking, use spectral similarity as a proxy for structural similarity. Spec2vec[81] algorithm provides a new way of spectral similarity score, based on Word2Vec. Spec2Vec learns fragmental relationships within a large set of spectral data, in order to assess spectral similarities between molecules and to classify unknown molecules through these comparisons. For systemic annotation, some metabolomics studies rely on fitting measured fragmentation mass spectra to library spectra or contrasting spectra via network analysis. Scoring functions are used to determine the similarity between pairs of fragment spectra as part of these processes. So far, no research has suggested scores that are significantly different from the commonly utilized cosine-based similarity.[82] Databases [edit]An important part of bioinformatics is the management of big datasets, known as databases of reference. Databases exist for each type of biological data, for example for biosynthetic gene clusters and metagenomes. General databases by bioinformatics [edit]National Center for Biotechnology Information [edit]The National Center for Biotechnology Information (NCBI)[83] provides a large suite of online resources for biological information and data, including the GenBank nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. Resources include PubMed Data Management, RefSeq Functional Elements, genome data download, variation services API, Magic-BLAST, QuickBLASTp, and Identical Protein Groups. All of these resources can be accessed through NCBI.[84] Bioinformatics analysis for biosynthetic gene clusters [edit]antiSMASH [edit]antiSMASH allows the rapid genome-wide identification, annotation and analysis of secondary metabolite biosynthesis gene clusters in bacterial and fungal genomes. It integrates and cross-links with a large number of in silico secondary metabolite analysis tools.[85] gutSMASH [edit]gutSMASH is a tool that systematically evaluates bacterial metabolic potential by predicting both known and novel anaerobic metabolic gene clusters (MGCs) from the gut microbiome. MIBiG [edit]MIBiG,[86] the minimum information about a biosynthetic gene cluster specification, provides a standard for annotations and metadata on biosynthetic gene clusters and their molecular products. MIBiG is a Genomic Standards Consortium project that builds on the minimum information about any sequence (MIxS) framework.[87] MIBiG facilitates the standardized deposition and retrieval of biosynthetic gene cluster data as well as the development of comprehensive comparative analysis tools. It empowers next-generation research on the biosynthesis, chemistry and ecology of broad classes of societally relevant bioactive secondary metabolites, guided by robust experimental evidence and rich metadata components.[88] SILVA [edit]SILVA[89] is an interdisciplinary project among biologists and computers scientists assembling a complete database of RNA ribosomal (rRNA) sequences of genes, both small (16S, 18S, SSU) and large (23S, 28S, LSU) subunits, which belong to the bacteria, archaea and eukarya domains. These data are freely available for academic and commercial use.[90] Greengenes [edit]Greengenes[91] is a full-length 16S rRNA gene database that provides chimera screening, standard alignment and a curated taxonomy based on de novo tree inference.[92][93] Overview: - 1,012,863 RNA sequences from 92,684 organisms contributed to RNAcentral. - The shortest sequence has 1,253 nucleotides, the longest 2,368. - The average length is 1,402 nucleotides. - Database version: 13.5. Open Tree of Life Taxonomy [edit]Open Tree of Life Taxonomy (OTT)[94] aims to build a complete, dynamic, and digitally available Tree of Life by synthesizing published phylogenetic trees along with taxonomic data. Phylogenetic trees have been classified, aligned, and merged. Taxonomies have been used to fill in sparse regions and gaps left by phylogenies. OTT is a base that has been little used for sequencing analyzes of the 16S region, however, it has a greater number of sequences classified taxonomically down to the genus level compared to SILVA and Greengenes. However, in terms of classification at the edge level, it contains a lesser amount of information[95] Ribosomal Database Project [edit]Ribosomal Database Project (RDP)[96] is a database that provides RNA ribosomal (rRNA) sequences of small subunits of domain bacterial and archaeal (16S); and fungal rRNA sequences of large subunits (28S).[97] References [edit]- ^ Chicco D (December 2017). \"Ten quick tips for machine learning in computational biology\". BioData Mining. 10 (35) 35. doi:10.1186/s13040-017-0155-3. PMC 5721660. PMID 29234465. - ^ a b c d e f g h i j k l m Larrañaga P, Calvo B, Santana R, Bielza C, Galdiano J, Inza I, et al. (March 2006). \"Machine learning in bioinformatics\". Briefings in Bioinformatics. 7 (1): 86–112. doi:10.1093/bib/bbk007. PMID 16761367. - ^ Pérez-Wohlfeil E, Torrenoa O, Bellis LJ, Fernandes PL, Leskosek B, Trellesa O (December 2018). \"Training bioinformaticians in High Performance Computing\". Heliyon. 4 (12) e01057. Bibcode:2018Heliy...401057P. doi:10.1016/j.heliyon.2018.e01057. PMC 6299036. PMID 30582061. - ^ a b c d e Yang Y, Gao J, Wang J, Heffernan R, Hanson J, Paliwal K, Zhou Y (May 2018). \"Sixty-five years of the long march in protein secondary structure prediction: the final stretch?\". Briefings in Bioinformatics. 19 (3): 482–494. doi:10.1093/bib/bbw129. PMC 5952956. PMID 28040746. - ^ Shastry KA, Sanjay HA (2020). \"Machine Learning for Bioinformatics\". In Srinivasa K, Siddesh G, Manisekhar S (eds.). Statistical Modelling and Machine Learning Principles for Bioinformatics Techniques, Tools, and Applications. Algorithms for Intelligent Systems. Singapore: Springer. pp. 25–39. doi:10.1007/978-981-15-2445-5_3. ISBN 978-981-15-2445-5. S2CID 214350490. Retrieved June 28, 2021. - ^ a b c Soueidan H, Nikolski M (2019). \"Machine learning for metagenomics: methods and tools\". Metagenomics. 1. arXiv:1510.06621. doi:10.1515/metgen-2016-0001. ISSN 2449-7657. S2CID 17418188. - ^ Noel, Louis (February 29, 2012), \"Principal Component Analysis in the Era of «Omics» Data\", Principal Component Analysis - Multidisciplinary Applications, InTech, doi:10.5772/37099, ISBN 978-953-51-0129-1 - ^ Rabiner L, Juang B (January 1986). \"An introduction to hidden Markov models\". IEEE ASSP Magazine. 3 (1): 4–16. doi:10.1109/MASSP.1986.1165342. ISSN 1558-1284. S2CID 11358505. - ^ Jackson CH, Sharples LD, Thompson SG, Duffy SW, Couto E (July 2003). \"Multistate Markov models for disease progression with classification error\". Journal of the Royal Statistical Society, Series D (The Statistician). 52 (2): 193–209. doi:10.1111/1467-9884.00351. S2CID 9824404. - ^ Amoros R, King R, Toyoda H, Kumada T, Johnson PJ, Bird TG (May 30, 2019). \"A continuous-time hidden Markov model for cancer surveillance using serum biomarkers with application to hepatocellular carcinoma\". Metron. 77 (2): 67–86. doi:10.1007/s40300-019-00151-8. PMC 6820468. PMID 31708595. - ^ Eddy SR (October 1, 1998). \"Profile hidden Markov models\". Bioinformatics. 14 (9): 755–63. doi:10.1093/bioinformatics/14.9.755. PMID 9918945. - ^ McClintock BT, Langrock R, Gimenez O, Cam E, Borchers DL, Glennie R, Patterson TA (December 2020). \"Uncovering ecological state dynamics with hidden Markov models\". Ecology Letters. 23 (12): 1878–1903. arXiv:2002.10497. Bibcode:2020EcolL..23.1878M. doi:10.1111/ele.13610. PMC 7702077. PMID 33073921. - ^ Zhang W (1988). \"Shift-invariant pattern recognition neural network and its optical architecture\". Proceedings of Annual Conference of the Japan Society of Applied Physics. - ^ Zhang W, Itoh K, Tanida J, Ichioka Y (November 1990). \"Parallel distributed processing model with local space-invariant interconnections and its optical architecture\". Applied Optics. 29 (32): 4790–7. Bibcode:1990ApOpt..29.4790Z. doi:10.1364/AO.29.004790. PMID 20577468. - ^ a b Bishop, Christopher M. (August 17, 2006). Pattern Recognition and Machine Learning. New York: Springer. ISBN 978-0-387-31073-2. - ^ Fukushima K (2007). \"Neocognitron\". Scholarpedia. 2 (1): 1717. Bibcode:2007SchpJ...2.1717F. doi:10.4249/scholarpedia.1717. - ^ Hubel DH, Wiesel TN (March 1968). \"Receptive fields and functional architecture of monkey striate cortex\". The Journal of Physiology. 195 (1): 215–43. doi:10.1113/jphysiol.1968.sp008455. PMC 1557912. PMID 4966457. - ^ Fukushima K (1980). \"Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\". Biological Cybernetics. 36 (4): 193–202. doi:10.1007/BF00344251. PMID 7370364. S2CID 206775608. - ^ Matsugu M, Mori K, Mitari Y, Kaneda Y (2003). \"Subject independent facial expression recognition with robust face detection using a convolutional neural network\". Neural Networks. 16 (5–6): 555–9. doi:10.1016/S0893-6080(03)00115-1. PMID 12850007. - ^ Fioravanti D, Giarratano Y, Maggio V, Agostinelli C, Chierici M, Jurman G, Furlanello C (March 2018). \"Phylogenetic convolutional neural networks in metagenomics\". BMC Bioinformatics. 19 (Suppl 2) 49. doi:10.1186/s12859-018-2033-5. PMC 5850953. PMID 29536822. - ^ Ji, Yanrong; Zhou, Zhihan; Liu, Han; Davuluri, Ramana V (August 9, 2021). Kelso, Janet (ed.). \"DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome\". Bioinformatics. 37 (15): 2112–2120. doi:10.1093/bioinformatics/btab083. ISSN 1367-4803. PMC 11025658. PMID 33538820. - ^ Gündüz, Hüseyin Anil; Binder, Martin; To, Xiao-Yin; Mreches, René; Bischl, Bernd; McHardy, Alice C.; Münch, Philipp C.; Rezaei, Mina (September 11, 2023). \"A self-supervised deep learning method for data-efficient training in genomics\". Communications Biology. 6 (1): 928. doi:10.1038/s42003-023-05310-2. ISSN 2399-3642. PMC 10495322. PMID 37696966. - ^ Zhang, Shuang; Fan, Rui; Liu, Yuti; Chen, Shuang; Liu, Qiao; Zeng, Wanwen (2023). \"Applications of transformer-based language models in bioinformatics: a survey\". Bioinformatics Advances. 3 (1) vbad001. doi:10.1093/bioadv/vbad001. ISSN 2635-0041. PMC 9950855. Retrieved November 29, 2025. This article incorporates text from this source, which is available under the CC BY 4.0 license. - ^ a b c Zhang, Shuang; Fan, Rui; Liu, Yuti; Chen, Shuang; Liu, Qiao; Zeng, Wanwen (2023). \"Applications of transformer-based language models in bioinformatics: a survey\". Bioinformatics Advances. 3 (1) vbad001. doi:10.1093/bioadv/vbad001. ISSN 2635-0041. PMC 9950855. Retrieved November 30, 2025. This article incorporates text from this source, which is available under the CC BY 4.0 license. - ^ Ho TK (1995). Random Decision Forests. Proceedings of the 3rd International Conference on Document Analysis and Recognition, Montreal, QC, 14–16 August 1995. pp. 278–282. - ^ Dietterich T (2000). An Experimental Comparison of Three Methodsfor Constructing Ensembles of Decision Trees:Bagging, Boosting, and Randomization. Kluwer Academic Publishers. pp. 139–157. - ^ Breiman, Leo (2001). \"Radom Forests\". Machine Learning. 45 (1): 5–32. Bibcode:2001MachL..45....5B. doi:10.1023/A:1010933404324. S2CID 89141. - ^ a b Zhang C, Ma Y (2012). Ensemble machine learning: methods and applications. New York: Springer New York Dordrecht Heidelberg London. pp. 157–175. ISBN 978-1-4419-9325-0. - ^ Karim MR, Beyan O, Zappa A, Costa IG, Rebholz-Schuhmann D, Cochez M, Decker S (January 2021). \"Deep learning-based clustering approaches for bioinformatics\". Briefings in Bioinformatics. 22 (1): 393–415. doi:10.1093/bib/bbz170. PMC 7820885. PMID 32008043. - ^ Lorbeer B, Kosareva A, Deva B, Softić D, Ruppel P, Küpper A (March 1, 2018). \"Variations on the Clustering Algorithm BIRCH\". Big Data Research. 11: 44–53. doi:10.1016/j.bdr.2017.09.002. - ^ Navarro-Muñoz JC, Selem-Mojica N, Mullowney MW, Kautsar SA, Tryon JH, Parkinson EI, et al. (January 2020). \"A computational framework to explore large-scale biosynthetic diversity\". Nature Chemical Biology. 16 (1): 60–68. doi:10.1038/s41589-019-0400-9. PMC 6917865. PMID 31768033. - ^ a b c d e Shastry KA, Sanjay HA (2020). \"Machine Learning for Bioinformatics\". Statistical Modelling and Machine Learning Principles for Bioinformatics Techniques, Tools, and Applications. Algorithms for Intelligent Systems. Springer Singapore. pp. 25–39. doi:10.1007/978-981-15-2445-5_3. ISBN 978-981-15-2444-8. S2CID 214350490. - ^ Libbrecht MW, Noble WS (June 2015). \"Machine learning applications in genetics and genomics\". Nature Reviews. Genetics. 16 (6): 321–32. doi:10.1038/nrg3920. PMC 5204302. PMID 25948244. - ^ Degroeve S, De Baets B, Van de Peer Y, Rouzé P (2002). \"Feature subset selection for splice site prediction\". Bioinformatics. 18 (Suppl 2): S75-83. doi:10.1093/bioinformatics/18.suppl_2.s75. PMID 12385987. - ^ Huang S, Cai N, Pacheco PP, Narrandes S, Wang Y, Xu W (January 2018). \"Applications of Support Vector Machine (SVM) Learning in Cancer Genomics\". Cancer Genomics & Proteomics. 15 (1): 41–51. doi:10.21873/cgp.20063. PMC 5822181. PMID 29275361. - ^ Angermueller C, Pärnamaa T, Parts L, Stegle O (July 2016). \"Deep learning for computational biology\". Molecular Systems Biology. 12 (7) 878. doi:10.15252/msb.20156651. PMC 4965871. PMID 27474269. - ^ Cao C, Liu F, Tan H, Song D, Shu W, Li W, et al. (February 2018). \"Deep Learning and Its Applications in Biomedicine\". Genomics, Proteomics & Bioinformatics. 16 (1): 17–32. doi:10.1016/j.gpb.2017.07.003. PMC 6000200. PMID 29522900. - ^ Zou J, Huss M, Abid A, Mohammadi P, Torkamani A, Telenti A (January 2019). \"A primer on deep learning in genomics\". Nature Genetics. 51 (1): 12–18. doi:10.1038/s41588-018-0295-5. PMC 11180539. PMID 30478442. S2CID 205572042. - ^ a b c Zeng Z, Shi H, Wu Y, Hong Z (2015). \"Survey of Natural Language Processing Techniques in Bioinformatics\". Computational and Mathematical Methods in Medicine. 2015 (D1) 674296. doi:10.1155/2015/674296. PMC 4615216. PMID 26525745. - ^ \"GenBank and WGS Statistics\". www.ncbi.nlm.nih.gov. Retrieved November 25, 2023. - ^ a b c d Mathé C, Sagot MF, Schiex T, Rouzé P (October 2002). \"Current methods of gene prediction, their strengths and weaknesses\". Nucleic Acids Research. 30 (19): 4103–17. doi:10.1093/nar/gkf543. PMC 140543. PMID 12364589. - ^ Pratas D, Silva RM, Pinho AJ, Ferreira PJ (May 2015). \"An alignment-free method to find and visualise rearrangements between pairs of DNA sequences\". Scientific Reports. 5 (10203) 10203. Bibcode:2015NatSR...510203P. doi:10.1038/srep10203. PMC 4434998. PMID 25984837. - ^ Pauling L, Corey RB, Branson HR (April 1951). \"The structure of proteins; two hydrogen-bonded helical configurations of the polypeptide chain\". Proceedings of the National Academy of Sciences of the United States of America. 37 (4): 205–11. Bibcode:1951PNAS...37..205P. doi:10.1073/pnas.37.4.205. PMC 1063337. PMID 14816373. - ^ a b Wang S, Peng J, Ma J, Xu J (January 2016). \"Protein Secondary Structure Prediction Using Deep Convolutional Neural Fields\". Scientific Reports. 6 18962. arXiv:1512.00843. Bibcode:2016NatSR...618962W. doi:10.1038/srep18962. PMC 4707437. PMID 26752681. - ^ \"DeepMind's protein-folding AI has solved a 50-year-old grand challenge of biology\". MIT Technology Review. Archived from the original on August 28, 2021. Retrieved November 30, 2020. - ^ Stoddart, Charlotte (March 1, 2022). \"Structural biology: How proteins got their close-up\". Knowable Magazine. doi:10.1146/knowable-022822-1. S2CID 247206999. Archived from the original on April 7, 2022. Retrieved March 25, 2022. - ^ Shead, Sam (November 30, 2020). \"DeepMind solves 50-year-old 'grand challenge' with protein folding A.I.\" CNBC. Archived from the original on January 28, 2021. Retrieved November 30, 2020. - ^ Riesenfeld CS, Schloss PD, Handelsman J (2004). \"Metagenomics: genomic analysis of microbial communities\". Annual Review of Genetics. 38 (1): 525–52. doi:10.1146/annurev.genet.38.072902.091216. PMID 15568985. - ^ Soueidan, Hayssam; Nikolski, Macha (January 1, 2017). \"Machine learning for metagenomics: methods and tools\". Metagenomics. 1 (1). arXiv:1510.06621. doi:10.1515/metgen-2016-0001. ISSN 2449-7657. S2CID 17418188. - ^ a b c Lin Y, Wang G, Yu J, Sung JJ (April 2021). \"Artificial intelligence and metagenomics in intestinal diseases\". Journal of Gastroenterology and Hepatology. 36 (4): 841–847. doi:10.1111/jgh.15501. PMID 33880764. S2CID 233312307. - ^ a b c Dang T, Kishino H (January 2020). \"Detecting significant components of microbiomes by random forest with forward variable selection and phylogenetics\". bioRxiv 10.1101/2020.10.29.361360. - ^ Fioravanti D, Giarratano Y, Maggio V, Agostinelli C, Chierici M, Jurman G, Furlanello C (March 2018). \"Phylogenetic convolutional neural networks in metagenomics\". BMC Bioinformatics. 19 (Suppl 2) 49. doi:10.1186/s12859-018-2033-5. PMC 5850953. PMID 29536822. - ^ Dhungel E, Mreyoud Y, Gwak HJ, Rajeh A, Rho M, Ahn TH (January 2021). \"MegaR: an interactive R package for rapid sample classification and phenotype prediction using metagenome profiles and machine learning\". BMC Bioinformatics. 22 (1) 25. doi:10.1186/s12859-020-03933-4. PMC 7814621. PMID 33461494. - ^ Xun W, Liu Y, Li W, Ren Y, Xiong W, Xu Z, et al. (January 2021). \"Specialized metabolic functions of keystone taxa sustain soil microbiome stability\". Microbiome. 9 (1) 35. doi:10.1186/s40168-020-00985-9. PMC 7849160. PMID 33517892. - ^ a b Pirooznia M, Yang JY, Yang MQ, Deng Y (2008). \"A comparative study of different machine learning methods on microarray gene expression data\". BMC Genomics. 9 Suppl 1 (1) S13. doi:10.1186/1471-2164-9-S1-S13. PMC 2386055. PMID 18366602. - ^ \"Machine Learning in Molecular Systems Biology\". Frontiers. Retrieved June 9, 2017. - ^ d'Alché-Buc F, Wehenkel L (December 2008). \"Machine learning in systems biology\". BMC Proceedings. 2 Suppl 4 (4) S1. doi:10.1186/1753-6561-2-S4-S1. PMC 2654969. PMID 19091048. - ^ Bhattacharya M (2020). \"Unsupervised Techniques in Genomics\". In Srinivasa MG, Siddesh GM, MAnisekhar SR (eds.). Statistical Modelling and Machine Learning Principles for Bioinformatics Techniques, Tools, and Applications. Springer Singapore. pp. 164–188. ISBN 978-981-15-2445-5. - ^ Topol EJ (January 2019). \"High-performance medicine: the convergence of human and artificial intelligence\". Nature Medicine. 25 (1): 44–56. doi:10.1038/s41591-018-0300-7. hdl:10654/45728. PMID 30617339. S2CID 57574615. - ^ a b Jiang F, Jiang Y, Zhi H, Dong Y, Li H, Ma S, et al. (December 2017). \"Artificial intelligence in healthcare: past, present and future\". Stroke and Vascular Neurology. 2 (4): 230–243. doi:10.1136/svn-2017-000101. PMC 5829945. PMID 29507784. - ^ Mirtskhulava L, Wong J, Al-Majeed S, Pearce G (March 2015). \"Artificial Neural Network Model in Stroke Diagnosis\" (PDF). 2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim). pp. 50–53. doi:10.1109/UKSim.2015.33. ISBN 978-1-4799-8713-9. S2CID 6391733. - ^ Titano JJ, Badgeley M, Schefflein J, Pain M, Su A, Cai M, et al. (September 2018). \"Automated deep-neural-network surveillance of cranial images for acute neurologic events\". Nature Medicine. 24 (9): 1337–1341. doi:10.1038/s41591-018-0147-y. PMID 30104767. S2CID 51976344. - ^ a b c Krallinger M, Erhardt RA, Valencia A (March 2005). \"Text-mining approaches in molecular biology and biomedicine\". Drug Discovery Today. 10 (6): 439–45. doi:10.1016/S1359-6446(05)03376-3. PMID 15808823. - ^ Pratas D, Hosseini M, Silva R, Pinho A, Ferreira P (June 20–23, 2017). \"Visualization of Distinct DNA Regions of the Modern Human Relatively to a Neanderthal Genome\". Pattern Recognition and Image Analysis. Lecture Notes in Computer Science. Vol. 10255. pp. 235–242. doi:10.1007/978-3-319-58838-4_26. ISBN 978-3-319-58837-7. - ^ Bardgett RD, Caruso T (March 2020). \"Soil microbial community responses to climate extremes: resistance, resilience and transitions to alternative states\". Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences. 375 (1794) 20190112. doi:10.1098/rstb.2019.0112. PMC 7017770. PMID 31983338. - ^ Deveau A, Bonito G, Uehling J, Paoletti M, Becker M, Bindschedler S, et al. (May 2018). \"Bacterial-fungal interactions: ecology, mechanisms and challenges\". FEMS Microbiology Reviews. 42 (3): 335–352. doi:10.1093/femsre/fuy008. hdl:21.11116/0000-0002-C1E7-F. PMID 29471481. - ^ Ansari MZ, Yadav G, Gokhale RS, Mohanty D (July 2004). \"NRPS-PKS: a knowledge-based resource for analysis of NRPS/PKS megasynthases\". Nucleic Acids Research. 32 (Web Server issue): W405-13. doi:10.1093/nar/gkh359. PMC 441497. PMID 15215420. - ^ a b Navarro-Muñoz JC, Selem-Mojica N, Mullowney MW, Kautsar SA, Tryon JH, Parkinson EI, et al. (January 2020). \"A computational framework to explore large-scale biosynthetic diversity\". Nature Chemical Biology. 16 (1): 60–68. doi:10.1038/s41589-019-0400-9. PMC 6917865. PMID 31768033. - ^ a b Doroghazi JR, Albright JC, Goering AW, Ju KS, Haines RR, Tchalukov KA, et al. (November 2014). \"A roadmap for natural product discovery based on large-scale genomics and metabolomics\". Nature Chemical Biology. 10 (11): 963–8. doi:10.1038/nchembio.1659. PMC 4201863. PMID 25262415. - ^ a b Cimermancic P, Medema MH, Claesen J, Kurita K, Wieland Brown LC, Mavrommatis K, et al. (July 2014). \"Insights into secondary metabolism from a global analysis of prokaryotic biosynthetic gene clusters\". Cell. 158 (2): 412–421. doi:10.1016/j.cell.2014.06.034. PMC 4123684. PMID 25036635. - ^ a b Goering AW, McClure RA, Doroghazi JR, Albright JC, Haverland NA, Zhang Y, et al. (February 2016). \"Metabologenomics: Correlation of Microbial Gene Clusters with Metabolites Drives Discovery of a Nonribosomal Peptide with an Unusual Amino Acid Monomer\". ACS Central Science. 2 (2): 99–108. doi:10.1021/acscentsci.5b00331. PMC 4827660. PMID 27163034. - ^ Amiri Moghaddam J, Crüsemann M, Alanjary M, Harms H, Dávila-Céspedes A, Blom J, et al. (November 2018). \"Analysis of the Genome and Metabolome of Marine Myxobacteria Reveals High Potential for Biosynthesis of Novel Specialized Metabolites\". Scientific Reports. 8 (1) 16600. Bibcode:2018NatSR...816600A. doi:10.1038/s41598-018-34954-y. PMC 6226438. PMID 30413766. - ^ Duncan KR, Crüsemann M, Lechner A, Sarkar A, Li J, Ziemert N, et al. (April 2015). \"Molecular networking and pattern-based genome mining improves discovery of biosynthetic gene clusters and their products from Salinispora species\". Chemistry & Biology. 22 (4): 460–471. doi:10.1016/j.chembiol.2015.03.010. PMC 4409930. PMID 25865308. - ^ Nielsen JC, Grijseels S, Prigent S, Ji B, Dainat J, Nielsen KF, et al. (April 2017). \"Global analysis of biosynthetic gene clusters reveals vast potential of secondary metabolite production in Penicillium species\". Nature Microbiology. 2 (6) 17044. doi:10.1038/nmicrobiol.2017.44. PMID 28368369. S2CID 22699928. - ^ McClure RA, Goering AW, Ju KS, Baccile JA, Schroeder FC, Metcalf WW, et al. (December 2016). \"Elucidating the Rimosamide-Detoxin Natural Product Families and Their Biosynthesis Using Metabolite/Gene Cluster Correlations\". ACS Chemical Biology. 11 (12): 3452–3460. doi:10.1021/acschembio.6b00779. PMC 5295535. PMID 27809474. - ^ Cao L, Shcherbin E, Mohimani H (August 2019). \"A Metabolome- and Metagenome-Wide Association Network Reveals Microbial Natural Products and Microbial Biotransformation Products from the Human Microbiota\". mSystems. 4 (4) e00387-19: e00387–19, /msystems/4/4/msys.00387–19.atom. doi:10.1128/mSystems.00387-19. PMC 6712304. PMID 31455639. - ^ Olm MR, Bhattacharya N, Crits-Christoph A, Firek BA, Baker R, Song YS, et al. (December 2019). \"Necrotizing enterocolitis is preceded by increased gut bacterial replication, Klebsiella, and fimbriae-encoding bacteria\". Science Advances. 5 (12) eaax5727. Bibcode:2019SciA....5.5727O. doi:10.1126/sciadv.aax5727. PMC 6905865. PMID 31844663. - ^ Carrión VJ, Perez-Jaramillo J, Cordovez V, Tracanna V, de Hollander M, Ruiz-Buck D, et al. (November 2019). \"Pathogen-induced activation of disease-suppressive functions in the endophytic root microbiome\". Science. 366 (6465): 606–612. Bibcode:2019Sci...366..606C. doi:10.1126/science.aaw9285. hdl:1887/3188901. PMID 31672892. S2CID 207814746. - ^ Pascal Andreu, Victória; Augustijn, Hannah E.; van den Berg, Koen; van der Hooft, Justin J. J.; Fischbach, Michael A.; Medema, Marnix H. (October 26, 2021). Shank, Elizabeth Anne (ed.). \"BiG-MAP: an Automated Pipeline To Profile Metabolic Gene Cluster Abundance and Expression in Microbiomes\". mSystems. 6 (5): e0093721. doi:10.1128/mSystems.00937-21. ISSN 2379-5077. PMC 8547482. PMID 34581602. - ^ Agrawal P, Khater S, Gupta M, Sain N, Mohanty D (July 2017). \"RiPPMiner: a bioinformatics resource for deciphering chemical structures of RiPPs based on prediction of cleavage and cross-links\". Nucleic Acids Research. 45 (W1): W80 – W88. doi:10.1093/nar/gkx408. PMC 5570163. PMID 28499008. - ^ Huber F, Ridder L, Verhoeven S, Spaaks JH, Diblen F, Rogers S, van der Hooft JJ (February 2021). \"Spec2Vec: Improved mass spectral similarity scoring through learning of structural relationships\". PLOS Computational Biology. 17 (2) e1008724. Bibcode:2021PLSCB..17E8724H. doi:10.1371/journal.pcbi.1008724. PMC 7909622. PMID 33591968. - ^ Huber F, Ridder L, Verhoeven S, Spaaks JH, Diblen F, Rogers S, van der Hooft JJ (February 2021). \"Spec2Vec: Improved mass spectral similarity scoring through learning of structural relationships\". PLOS Computational Biology. 17 (2) e1008724. Bibcode:2021PLSCB..17E8724H. doi:10.1371/journal.pcbi.1008724. PMC 7909622. PMID 33591968. - ^ National Center for Biotechnology Information; U.S. National Library of Medicine. \"National Center for Biotechnology Information\". ncbi.nlm.nih.gov. Retrieved July 30, 2021. - ^ Agarwala R, Barrett T, Beck J, Benson DA, Bollin C, Bolton E, et al. (NCBI Resource Coordinators) (January 2018). \"Database resources of the National Center for Biotechnology Information\". Nucleic Acids Research. 46 (D1): D8 – D13. doi:10.1093/nar/gkx1095. PMC 5753372. PMID 29140470. - ^ \"antiSMASH database\". antismash-db.secondarymetabolites.org. - ^ \"MIBiG: Minimum Information about a Biosynthetic Gene cluster\". mibig.secondarymetabolites.org. Retrieved July 30, 2021. - ^ \"MIBiG: Minimum Information about a Biosynthetic Gene cluster\". mibig.secondarymetabolites.org. - ^ Kautsar SA, Blin K, Shaw S, Navarro-Muñoz JC, Terlouw BR, van der Hooft JJ, et al. (January 2020). \"MIBiG 2.0: a repository for biosynthetic gene clusters of known function\". Nucleic Acids Research. 48 (D1) gkz882: D454 – D458. doi:10.1093/nar/gkz882. PMC 7145714. PMID 31612915. - ^ \"Silva\". arb-silva.de. Retrieved July 30, 2021. - ^ Quast C, Pruesse E, Yilmaz P, Gerken J, Schweer T, Yarza P, et al. (January 2013). \"The SILVA ribosomal RNA gene database project: improved data processing and web-based tools\". Nucleic Acids Research. 41 (Database issue): D590-6. doi:10.1093/nar/gks1219. PMC 3531112. PMID 23193283. - ^ \"greengenes.secondgenome.com\". greengenes.secondgenome.com. Retrieved July 30, 2021. - ^ DeSantis TZ, Hugenholtz P, Larsen N, Rojas M, Brodie EL, Keller K, et al. (July 2006). \"Greengenes, a chimera-checked 16S rRNA gene database and workbench compatible with ARB\". Applied and Environmental Microbiology. 72 (7): 5069–72. Bibcode:2006ApEnM..72.5069D. doi:10.1128/AEM.03006-05. PMC 1489311. PMID 16820507. - ^ McDonald D, Price MN, Goodrich J, Nawrocki EP, DeSantis TZ, Probst A, et al. (March 2012). \"An improved Greengenes taxonomy with explicit ranks for ecological and evolutionary analyses of bacteria and archaea\". The ISME Journal. 6 (3): 610–8. Bibcode:2012ISMEJ...6..610M. doi:10.1038/ismej.2011.139. PMC 3280142. PMID 22134646. - ^ \"opentree\". tree.opentreeoflife.org. Retrieved July 30, 2021. - ^ Hinchliff CE, Smith SA, Allman JF, Burleigh JG, Chaudhary R, Coghill LM, et al. (October 2015). \"Synthesis of phylogeny and taxonomy into a comprehensive tree of life\". Proceedings of the National Academy of Sciences of the United States of America. 112 (41): 12764–9. Bibcode:2015PNAS..11212764H. doi:10.1073/pnas.1423041112. PMC 4611642. PMID 26385966. - ^ \"RDP Release 11 -- Sequence Analysis Tools\". rdp.cme.msu.edu. Archived from the original on August 19, 2020. Retrieved July 30, 2021. - ^ Cole JR, Wang Q, Fish JA, Chai B, McGarrell DM, Sun Y, et al. (January 2014). \"Ribosomal Database Project: data and tools for high throughput rRNA analysis\". Nucleic Acids Research. 42 (Database issue): D633-42. doi:10.1093/nar/gkt1244. PMC 3965039. PMID 24288368.",
    "text_length": 61634,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:15.391839"
  },
  {
    "id": "page_18",
    "url": "https://en.wikipedia.org/wiki/Deepfake",
    "domain": "en.wikipedia.org",
    "title": "Deepfake - Wikipedia",
    "text": "Deepfake This article may be too long to read and navigate comfortably. (November 2024) | This article may incorporate text from a large language model. (November 2025) | | Part of a series on | | Artificial intelligence (AI) | |---| Deepfakes (a portmanteau of 'deep learning' and 'fake'[1]) are images, videos, or audio that have been edited or generated using artificial intelligence, AI-based tools or audio-video editing software. They may depict real or fictional people and are considered a form of synthetic media, that is media that is usually created by artificial intelligence systems by combining various media elements into a new media artifact.[2][3] While the act of creating fake content is not new, deepfakes uniquely leverage machine learning and artificial intelligence techniques,[4][5][6] including facial recognition algorithms and artificial neural networks such as variational autoencoders and generative adversarial networks (GANs).[5][7] In turn, the field of image forensics has worked to develop techniques to detect manipulated images.[8] Deepfakes have garnered widespread attention for their potential use in creating child sexual abuse material, celebrity pornographic videos, revenge porn, fake news, hoaxes, bullying, and financial fraud.[9][10][11][12] Academics have raised concerns about the potential for deepfakes to promote disinformation and hate speech,[13] as well as interfere with elections.[14] In response, the information technology industry and governments have proposed recommendations and methods to detect and mitigate their use. Academic research has also delved deeper into the factors driving deepfake engagement online as well as potential countermeasures to malicious application of deepfakes. From traditional entertainment to gaming, deepfake technology has evolved to be increasingly convincing[15] and available to the public, allowing for the disruption of the entertainment and media industries.[16] History [edit]Photo manipulation was developed in the 19th century and soon applied to motion pictures. Technology steadily improved during the 20th century, and more quickly with the advent of digital video. Deepfake technology has been developed by researchers at academic institutions beginning in the 1990s, and later by amateurs in online communities.[17][18] More recently, the methods have been adopted by industry.[19][1] Academic research [edit]Academic research related to deepfakes is split between the field of computer vision, a sub-field of computer science,[17] which develops techniques for creating and identifying deepfakes, and humanities and social science approaches that study the social, ethical, aesthetic implications as well as journalistic and informational implications of deepfakes.[20] As deepfakes have risen in prominence in popularity with innovations provided by AI tools, significant research has gone into detection methods and defining the factors driving engagement with deepfakes on the internet.[21][22] Deepfakes have been shown to appear on social media platforms and other parts of the internet for purposes ranging from entertainment and education related to deepfakes to misinformation to elicit strong reactions.[23] There are gaps in research related to the propagation of deepfakes on social media. Negativity and emotional response are the primary driving factors for users sharing deepfakes.[24] Age and lack of literacy related to deepfakes are another factor that drives engagement. Older users who may be technologically-illiterate might not recognize deepfakes as falsified content and share this content because they believe it to be true. Alternatively, younger users accustomed to the entertainment value of deepfakes are more likely to share them with an awareness of their falsified content.[25] Despite cognitive ability being a factor in successfully detecting deepfakes, individuals who are aware of a deepfake may be just as likely to share it on social media as one who does not know it is a deepfake.[26] Within scholarship focused on detecting deepfakes, deep-learning methods using techniques to identify software-induced artifacts have been found to be the most effective in separating a deepfake from an authentic product.[21] Due to the capabilities of deepfakes, concerns have developed related to regulations and literacy toward the technology.[27] The potential malicious applications of deepfakes and their capability to impact public figures, reputations, or promote misleading narratives are the primary drivers of these concerns.[27] Amongst some experts, potential malicious applications of deepfakes have encouraged them into labeling deepfakes as a potential danger to democratic societies that would benefit from a regulatory framework to mitigate potential risks.[27] Social science and humanities approaches to deepfakes [edit]In cinema studies, deepfakes illustrate how how \"the human face is emerging as a central object of ambivalence in the digital age\".[28] Video artists have used deepfakes to \"playfully rewrite film history by retrofitting canonical cinema with new star performers\".[29] Film scholar Christopher Holliday analyses how altering the gender and race of performers in familiar movie scenes destabilizes gender classifications and categories.[29] The concept of \"queering\" deepfakes is also discussed in Oliver M. Gingrich's discussion of media artworks that use deepfakes to reframe gender,[30] including British artist Jake Elwes' Zizi: Queering the Dataset, an artwork that uses deepfakes of drag queens to intentionally play with gender. The aesthetic potentials of deepfakes are also beginning to be explored. Theatre historian John Fletcher notes that early demonstrations of deepfakes are presented as performances, and situates these in the context of theater, discussing \"some of the more troubling paradigm shifts\" that deepfakes represent as a performance genre.[31] Philosophers and media scholars have discussed the ethical implications of deepfakes in the dissemination of disinformation. Amina Vatreš from the Department of Communication Studies at the University of Sarajevo identifies three factors contributing to the widespread acceptance of deepfakes, and where its greatest danger lies: 1) convincing visualization and auditory support, 2) widespread accessibility, and 3) the inability to draw a clear line between truth and falsehood.[20] Another area of discussion on deepfakes is in relation to pornography made with deepfakes.[32] Beyond pornography, deepfakes have been framed by philosophers as an \"epistemic threat\" to knowledge and thus to society.[33] There are several other suggestions for how to deal with the risks deepfakes give rise beyond pornography, but also to corporations, politicians and others, of \"exploitation, intimidation, and personal sabotage\",[34] and there are several scholarly discussions of potential legal and regulatory responses both in legal studies and media studies.[35] In addition, foresight researchers have explored the future of deepfake technology using Causal Layered Analysis (CLA) to examine its myths, metaphors, and societal implications for digital trust, governance, and ethical foresight.[1] In psychology and media studies, scholars discuss the effects of disinformation that uses deepfakes,[36][37] and the social impact of deepfakes.[38] While most English-language academic studies of deepfakes focus on the Western anxieties about disinformation and pornography, digital anthropologist Gabriele de Seta has analyzed the Chinese reception of deepfakes, which are known as huanlian, which translates to \"changing faces\". The Chinese term does not contain the \"fake\" of the English deepfake, and de Seta argues that this cultural context may explain why the Chinese response has centered on practical regulatory measures to \"fraud risks, image rights, economic profit, and ethical imbalances\".[39] Computer science research on deepfakes [edit]A landmark early project was the \"Video Rewrite\" program, published in 1997. The program modified existing video footage of a person speaking to depict that person mouthing the words from a different audio track.[40] It was the first system to fully automate this kind of facial reanimation, and it did so using machine learning techniques to make connections between the sounds produced by a video's subject and the shape of the subject's face.[40] Contemporary academic projects have focused on creating more realistic videos and improving deepfake techniques.[41][42] The \"Synthesizing Obama\" program, published in 2017, modifies video footage of former president Barack Obama to depict him mouthing the words contained in a separate audio track.[41] The project lists as a main research contribution to its photorealistic technique for synthesizing mouth shapes from audio.[41] The \"Face2Face\" program, published in 2016, modifies video footage of a person's face to depict them mimicking another person's facial expressions.[42] The project highlights its primary research contribution as the development of the first method for re-enacting facial expressions in real time using a camera that does not capture depth, enabling the technique to work with common consumer cameras. In August 2018, researchers at the University of California, Berkeley published a paper introducing a deepfake dancing app that can create the impression of masterful dancing ability using AI.[43] This project expands the application of deepfakes to the entire body; previous works focused on the head or parts of the face.[44] Researchers have also shown that deepfakes are expanding into other domains such as medical imagery.[45] In this work, it was shown how an attacker can automatically inject or remove lung cancer in a patient's 3D CT scan. The result was so convincing that it fooled three radiologists and a state-of-the-art lung cancer detection AI. To demonstrate the threat, the authors successfully performed the attack on a hospital in a White hat penetration test.[46] A survey of deepfakes, published in May 2020, provides a timeline of how the creation and detection of deepfakes have advanced over the last few years.[47] The survey identifies that researchers have been focusing on resolving the following challenges of deepfake creation: - Generalization. High-quality deepfakes are often achieved by training on hours of footage of the target. This challenge is to minimize the amount of training data and the time to train the model required to produce quality images and to enable the execution of trained models on new identities (unseen during training). - Paired Training. Training a supervised model can produce high-quality results, but requires data pairing. This is the process of finding examples of inputs and their desired outputs for the model to learn from. Data pairing is laborious and impractical when training on multiple identities and facial behaviors. Some solutions include self-supervised training (using frames from the same video), the use of unpaired networks such as Cycle-GAN, or the manipulation of network embeddings. - Identity leakage. This is where the identity of the driver (i.e., the actor controlling the face in a reenactment) is partially transferred to the generated face. Some solutions proposed include attention mechanisms, few-shot learning, disentanglement, boundary conversions, and skip connections. - Occlusions. When part of the face is obstructed with a hand, hair, glasses, or any other item then artifacts can occur. A common occlusion is a closed mouth which hides the inside of the mouth and the teeth. Some solutions include image segmentation during training and in-painting. - Temporal coherence. In videos containing deepfakes, artifacts such as flickering and jitter can occur because the network has no context of the preceding frames. Some researchers provide this context or use novel temporal coherence losses to help improve realism. As the technology improves, the interference is diminishing. Overall, deepfakes are expected to have several implications in media and society, media production, media representations, media audiences, gender, law, and regulation, and politics.[48] Amateur development [edit]The term deepfake originated in late 2017 from a Reddit user named \"deepfakes\".[49] He, along with other members of Reddit's \"r/deepfakes\", shared deepfakes they created; many videos involved celebrities' faces swapped onto the bodies of actors in pornographic videos,[49] while non-pornographic content included many videos with actor Nicolas Cage's face swapped into various movies.[50] Other online communities continue to share pornography on platforms that have not banned deepfake pornography.[51] Commercial development [edit]In January 2018, a proprietary desktop application called \"FakeApp\" was launched.[52] This app allows users to easily create and share videos with their faces swapped with each other.[53] As of 2019, \"FakeApp\" had been largely replaced by open-source alternatives such as \"Faceswap\", command line-based \"DeepFaceLab\", and web-based apps such as DeepfakesWeb.[54][55][56] Larger companies started to use deepfakes.[19] Corporate training videos can be created using deepfaked avatars and their voices, for example Synthesia, which uses deepfake technology with avatars to create personalized videos.[57] The mobile app Momo created the application Zao which allows users to superimpose their face on television and movie clips with a single picture.[19] As of 2019 the Japanese AI company DataGrid made a full body deepfake that could create a person from scratch.[58] As of 2020 audio deepfakes, and AI software capable of detecting deepfakes and cloning human voices after 5 seconds of listening time also exist.[59][60][61][62][63][64][excessive citations] A mobile deepfake app, Impressions, was launched in March 2020. It was the first app for the creation of celebrity deepfake videos from mobile phones.[65][66] Resurrection [edit]Deepfake technology's ability to fabricate messages and actions of others can extend to the deceased, such as in grief therapy that allows seeming communication with a deceased loved one.[67] In October 2020, Kim Kardashian posted a video featuring a hologram of her late father, Robert Kardashian, created by the company Kaleida, which used a combination of performance, motion tracking, SFX, VFX and DeepFake technologies to create the illusion.[68][69] In 2020, a deepfake video of Joaquin Oliver, a victim of the Parkland shooting, was created as part of a gun safety campaign. Oliver's parents partnered with nonprofit Change the Ref and McCann Health to produce a video in which Oliver to encourage people to support gun safety legislation and politicians who back do so as well.[70] In 2022, a deepfake video of Elvis Presley was used on the program America's Got Talent 17.[71] Techniques [edit]Deepfakes rely on a type of neural network called an autoencoder.[72] These consist of an encoder, which reduces an image to a lower dimensional latent space, and a decoder, which reconstructs the image from the latent representation.[73] Deepfakes utilize this architecture by having a universal encoder which encodes a person in to the latent space.[citation needed] The latent representation contains key features about their facial features and body posture. This can then be decoded with a model trained specifically for the target. This means the target's detailed information will be superimposed on the underlying facial and body features of the original video, represented in the latent space.[citation needed] A popular upgrade to this architecture attaches a generative adversarial network to the decoder. A GAN trains a generator, in this case the decoder, and a discriminator in an adversarial relationship. The generator creates new images from the latent representation of the source material, while the discriminator attempts to determine whether or not the image is generated.[citation needed] This causes the generator to create images that mimic reality extremely well as any defects would be caught by the discriminator.[74] Both algorithms improve constantly in a zero sum game. This makes deepfakes difficult to combat as they are constantly evolving; any time a defect is determined, it can be corrected.[74] Applications [edit]Acting [edit]Digital clones of professional actors have appeared in films before, and progress in deepfake technology is expected to further the accessibility and effectiveness of such clones.[75] The use of AI technology was a major issue in the 2023 SAG-AFTRA strike, as new techniques enabled the capability of generating and storing a digital likeness to use in place of actors.[76] Disney has improved their visual effects using high-resolution deepfake face swapping technology.[77] Disney improved their technology through progressive training programmed to identify facial expressions, implementing a face-swapping feature, and iterating in order to stabilize and refine the output.[77] This high-resolution deepfake technology saves significant operational and production costs.[78] Disney's deepfake generation model can produce AI-generated media at a 1024 x 1024 resolution, as opposed to common models that produce media at a 256 x 256 resolution.[78] The technology allows Disney to de-age characters or revive deceased actors.[79] Similar technology was initially used by fans to unofficially insert faces into existing media, such as overlaying Harrison Ford's young face onto Han Solo's face in Solo: A Star Wars Story.[80] Disney used deepfakes for the characters of Princess Leia in Rogue One and Luke Skywalker in both The Mandalorian and The Book of Boba Fett.[81][82] The 2020 documentary Welcome to Chechnya used deepfake technology to obscure the identity of the people interviewed, so as to protect them from retaliation.[83] Creative Artists Agency has developed a facility to capture the likeness of an actor \"in a single day\", to develop a digital clone of the actor, which would be controlled by the actor or their estate alongside other personality rights.[84] Companies which have used digital clones of professional actors in advertisements include Puma, Nike and Procter & Gamble.[85] Deepfakes allowed for the use of David Beckham in a campaign using nearly nine languages to raise awareness the fight against Malaria.[86] In the 2024 Indian Tamil science fiction action thriller The Greatest of All Time, the teenage version of Vijay's character Jeevan is portrayed by Ayaz Khan. Vijay's teenage face was then attained by AI deepfake.[87] In May 2025, an AI-generated actress called Tilly Norwood was developed by the Dutch company Xicoia, a division of the existing production company Particle6 that was founded by actor and comedian Eline Van der Velden.[88] Art [edit]Deepfakes are also being used in education and media to create realistic videos and interactive content, which offer new ways to engage audiences. In March 2018 the multidisciplinary artist Joseph Ayerle published the video artwork Un'emozione per sempre 2.0 (English title: The Italian Game). The artist worked with Deepfake technology to create an AI actor, a synthetic version of 80s movie star Ornella Muti, traveling in time from 1978 to 2018. The Massachusetts Institute of Technology referred this artwork in the study \"Collective Wisdom\".[89] The artist used Ornella Muti's time travel to explore generational reflections, while also investigating questions about the role of provocation in the world of art.[90] For the technical realization Ayerle used scenes of photo model Kendall Jenner. The program replaced Jenner's face by an AI calculated face of Ornella Muti. As a result, the AI actor has the face of the Italian actor Ornella Muti and the body of Kendall Jenner. Deepfakes have been widely used in satire or to parody celebrities and politicians. The 2020 webseries Sassy Justice, created by Trey Parker and Matt Stone, heavily features the use of deepfaked public figures to satirize current events and raise awareness of deepfake technology.[91] Blackmail [edit]Deepfakes can be used to generate blackmail materials that falsely incriminate a victim. A report by the American Congressional Research Service warned that deepfakes could be used to blackmail elected officials or those with access to classified information for espionage or influence purposes.[92] When or if fakes cannot reliably be distinguished from genuine evidence, victims who are blackmailed over digital evidence might claim that true artifacts are fakes, thereby seeking plausible deniability by relying on an argument of indistinguishability between fake and genuine evidence. The hoped-for effect is to void credibility of certain existing blackmail materials, which, if they were the sole evidence retained by a blackmailer and could not be distinguished by a jury from fake evidence under this argument, could in theory erode loyalty to blackmailers and limit their control over the blackmailed. This phenomenon has been termed \"blackmail inflation\", since in theory it \"devalues\" authentic blackmail material.[93] It is possible to utilize commodity GPU hardware with a small software program to generate fake content intended to blackmail anyone for whom an adversary has ample training data.[94] However, even carefully manipulated fakes may still be detected. The inflation argument could only work in theory if blackmailers have no other incriminating evidence that is not easily faked, and if the jury were persuaded that the evidences of guilt were not sufficient to convict beyond reasonable doubt. In reality this theory risks double hazards, namely, that those who are guilty might deploy arguments of plausible deniability, arguing that the footage has been faked, possibly resulting in acquittal of a guilty person on the basis of such doubt, and second, that fake evidence might be used to prosecute those who are not aware of the deepfake argument, to secure a conviction in cases where a jury is not adequately aware of the risk of false positives due to fake evidence, or to extort a plea deal where the prosecution claims to have damning evidence. The effect of this double hazard will depend on the level of discernment of the parties in the criminal justice system and their empowerment to act on that discernment. The inflation argument could be abused in either direction as illustrated, and the notion that blackmailers would not retain further evidence or leverage is unlikely and undependable, limiting the effectiveness of the theory. The existence of efficient techniques for fabricating false evidence certainly suggests that any combination of video, audio, photographic or other generable evidence alone as the basis for conviction of a crime is by now a perilous and tenuous standard owing to the possibility of maliciously fabricated evidence, raising the importance of multiple firsthand witnesses to a crime, especially for more serious allegations.[95] Entertainment [edit]On 8 June 2022,[96] Daniel Emmet, a former AGT contestant, teamed up with the AI startup[97][98] Metaphysic AI, to create a hyperrealistic deepfake to make it appear as Simon Cowell. Cowell, notoriously known for severely critiquing contestants,[99] was on stage interpreting \"You're The Inspiration\" by Chicago. Emmet sang on stage as an image of Simon Cowell emerged on the screen behind him in flawless synchronicity.[100] On 30 August 2022, Metaphysic AI had 'deep-fake' Simon Cowell, Howie Mandel and Terry Crews singing opera on stage.[101] On 13 September 2022, Metaphysic AI performed with a synthetic version of Elvis Presley for the finals of America's Got Talent.[102] The MIT artificial intelligence project 15.ai has been used for content creation for multiple Internet fandoms, particularly on social media.[103][104][105] In 2023 the bands ABBA and Kiss partnered with Industrial Light & Magic and Pophouse Entertainment to develop deepfake avatars capable of performing virtual concerts.[106] Fraud and scams [edit]Fraudsters and scammers make use of deepfakes to trick people into fake investment schemes, financial fraud, cryptocurrencies, sending money, and following endorsements. The likenesses of celebrities and politicians have been used for large-scale scams, as well as those of private individuals, which are used in spearphishing attacks. According to the Better Business Bureau, deepfake scams are becoming more prevalent.[107] These scams are responsible for an estimated $12 billion in fraud losses globally.[108] According to a recent report these numbers are expected to reach $40 Billion over the next three years.[108] Fake endorsements have misused the identities of celebrities like Taylor Swift,[109][107] Tom Hanks,[110] Oprah Winfrey,[111] and Elon Musk;[112] news anchors[113] like Gayle King[110] and Sally Bundock;[114] and politicians like Lee Hsien Loong[115] and Jim Chalmers.[116][117] Videos of them have appeared in online advertisements on YouTube, Facebook, and TikTok, who have policies against synthetic and manipulated media.[118][109][119] Ads running these videos are seen by millions of people. A single Medicare fraud campaign had been viewed more than 195 million times across thousands of videos.[118][120] Deepfakes have been used for: a fake giveaway of Le Creuset cookware for a \"shipping fee\" without receiving the products, except for hidden monthly charges;[109] weight-loss gummies that charge significantly more than what was said;[111] a fake iPhone giveaway;[109][119] and fraudulent get-rich-quick,[112][121] investment,[122] and cryptocurrency schemes.[115][123] Many ads pair AI voice cloning with \"decontextualized video of the celebrity\" to mimic authenticity. Others use a whole clip from a celebrity before moving to a different actor or voice.[118] Some scams may involve real-time deepfakes.[119] Celebrities have been warning people of these fake endorsements, and to be more vigilant against them.[107][109][111] Celebrities are unlikely to file lawsuits against every person operating deepfake scams, as \"finding and suing anonymous social media users is resource intensive,\" though cease and desist letters to social media companies work in getting videos and ads taken down.[124] Audio deepfakes have been used as part of social engineering scams, fooling people into thinking they are receiving instructions from a trusted individual.[125] In 2019, a U.K.-based energy firm's CEO was scammed over the phone when he was ordered to transfer €220,000 into a Hungarian bank account by an individual who reportedly used audio deepfake technology to impersonate the voice of the firm's parent company's chief executive.[126][127] As of 2023, the combination advances in deepfake technology, which could clone an individual's voice from a recording of a few seconds to a minute, and new text generation tools, enabled automated impersonation scams, targeting victims using a convincing digital clone of a friend or relative.[128] Identity masking [edit]Audio deepfakes can be used to mask a user's real identity. In online gaming, for example, a player may want to choose a voice that sounds like their in-game character when speaking to other players. Those who are subject to harassment, such as women, children, and transgender people, can use these \"voice skins\" to hide their gender or age.[129] Memes [edit]In 2020, an internet meme emerged utilizing deepfakes to generate videos of people singing the chorus of \"Baka Mitai\" (ばかみたい), a song from the game Yakuza 0 in the video game series Like a Dragon. In the series, the melancholic song is sung by the player in a karaoke minigame. Most iterations of this meme use a 2017 video uploaded by user Dobbsyrules, who lip syncs the song, as a template.[130][131] Politics [edit]Deepfakes have been used to misrepresent well-known politicians in videos. - In February 2018, in separate videos, the face of the Argentine President Mauricio Macri had been replaced by the face of Adolf Hitler, and Angela Merkel's face has been replaced with Donald Trump's.[132][133] - In April 2018, Jordan Peele collaborated with BuzzFeed to create a deepfake of Barack Obama with Peele's voice; it served as a public service announcement to increase awareness of deepfakes.[134] - In January 2019, Fox affiliate KCPQ aired a deepfake of Trump during his Oval Office address, mocking his appearance and skin color. The employee found responsible for the video was subsequently fired.[135] - In June 2019, the United States House Intelligence Committee held hearings on the potential malicious use of deepfakes to sway elections.[136] - In April 2020, the Belgian branch of Extinction Rebellion published a deepfake video of Belgian Prime Minister Sophie Wilmès on Facebook.[137] The video promoted a possible link between deforestation and COVID-19. It had more than 100,000 views within 24 hours and received many comments. On the Facebook page where the video appeared, many users interpreted the deepfake video as genuine.[138] - During the 2020 US presidential campaign, many deepfakes surfaced purporting Joe Biden in cognitive decline—falling asleep during an interview, getting lost, and misspeaking—all bolstering rumors of his decline.[139][140] - During the 2020 Delhi Legislative Assembly election campaign, the Delhi Bharatiya Janata Party used similar technology to distribute a version of an English-language campaign advertisement by its leader, Manoj Tiwari, translated into Haryanvi to target Haryana voters. A voiceover was provided by an actor, and AI trained using video of Tiwari speeches was used to lip-sync the video to the new voiceover. A party staff member described it as a \"positive\" use of deepfake technology, which allowed them to \"convincingly approach the target audience even if the candidate didn't speak the language of the voter.\"[141] - In 2020, Bruno Sartori produced deepfakes parodying politicians like Jair Bolsonaro and Donald Trump.[142] - In April 2021, politicians in a number of European countries were approached by pranksters Vovan and Lexus, who are accused by critics of working for the Russian state. They impersonated Leonid Volkov, a Russian opposition politician and chief of staff of the Russian opposition leader Alexei Navalny's campaign, allegedly through deepfake technology.[143][144][145][146] However, the pair told The Verge that they did not use deepfakes, and just used a look-alike.[147] - In May 2023, a deepfake video of Vice President Kamala Harris supposedly slurring her words and speaking nonsensically about today, tomorrow and yesterday went viral on social media.[148][149] - In June 2023, in the United States, Ron DeSantis's presidential campaign used a deepfake to misrepresent Donald Trump.[150] - In November 2023, a deepfake video of the German Chancellor Olaf Scholz announcing a plan to ban the political activities of the AfD was uploaded to YouTube by the Zentrum für Politische Schönheit (Center of Political Beauty).[151] - In March 2024, during India's state assembly elections, deepfake technology was widely employed by political candidates to reach out to voters. Many politicians used AI-generated deepfakes created by startup The Indian Deepfaker, founded by Divyendra Singh Jadoun,[152] to translate their speeches into multiple regional languages, allowing them to engage with diverse linguistic communities across the country. This surge in the use of deepfakes for political campaigns marked a significant shift in electioneering tactics in India.[153][154] - In June 2025, Javier Milei's government backed a smear campaign against journalist Mengolini, which was partly based on explicit deepfakes.[155][156] - In July 2025, Donald Trump posted a deepfake on his Truth Social account, depicting former president Barack Obama getting arrested at the White House and put in prison.[157][158] Pornography [edit]In 2017, Deepfake pornography prominently surfaced on the Internet, particularly on Reddit.[159] As of 2019, many deepfakes on the internet feature pornography of female celebrities whose likeness is typically used without their consent.[160] A report published in October 2019 by Dutch cybersecurity startup Deeptrace estimated that 96% of all deepfakes online were pornographic.[161] As of 2018, a Daisy Ridley deepfake first captured attention,[159] among others.[162][163][164] As of October 2019, most of the deepfake subjects on the internet were British and American actors.[160] However, around a quarter of the subjects are South Korean, the majority of which are K-pop stars.[160][165] In June 2019, a downloadable Windows and Linux application called DeepNude was released that used neural networks, specifically generative adversarial networks, to remove clothing from images of women. The app had both a paid and unpaid version, the paid version costing $50.[166][167] On 27 June the creators removed the application and refunded consumers.[168] Female celebrities are often a main target when it comes to deepfake pornography. In 2023, deepfake porn videos appeared online of Emma Watson and Scarlett Johansson in a face swapping app.[169] In 2024, deepfake porn images circulated online of Taylor Swift.[170] Academic studies have reported that women, LGBT people and people of color (particularly activists, politicians and those questioning power) are at higher risk of being targets of promulgation of deepfake pornography.[171] Social media [edit]Deepfakes have begun to see use in popular social media platforms, notably through Zao, a Chinese deepfake app that allows users to substitute their own faces onto those of characters in scenes from films and television shows such as Romeo + Juliet and Game of Thrones.[172] The app originally faced scrutiny over its invasive user data and privacy policy, after which the company put out a statement claiming it would revise the policy.[19] In January 2020 Facebook announced that it was introducing new measures to counter this on its platforms.[173] The Congressional Research Service cited unspecified evidence as showing that foreign intelligence operatives used deepfakes to create social media accounts with the purposes of recruiting individuals with access to classified information.[92] In 2021, realistic deepfake videos of actor Tom Cruise were released on TikTok, which went viral and garnered more than tens of millions of views. The deepfake videos featured an \"artificial intelligence-generated doppelganger\" of Cruise doing various activities such as teeing off at the golf course, showing off a coin trick, and biting into a lollipop. The creator of the clips, Belgian VFX Artist Chris Umé,[174] said he first got interested in deepfakes in 2018 and saw the \"creative potential\" of them.[175][176] Sockpuppets [edit]Deepfake photographs can be used to create sockpuppets, non-existent people, who are active both online and in traditional media. A deepfake photograph appears to have been generated together with a legend for an apparently non-existent person named Oliver Taylor, whose identity was described as a university student in the United Kingdom. The Oliver Taylor persona submitted opinion pieces in several newspapers and was active in online media attacking a British legal academic and his wife, as \"terrorist sympathizers.\" The academic had drawn international attention in 2018 when he commenced a lawsuit in Israel against NSO, a surveillance company, on behalf of people in Mexico who alleged they were victims of NSO's phone hacking technology. Reuters could find only scant records for Oliver Taylor and \"his\" university had no records for him. Many experts agreed that the profile photo is a deepfake. Several newspapers have not retracted articles attributed to him or removed them from their websites. It is feared that such techniques are a new battleground in disinformation.[177] Collections of deepfake photographs of non-existent people on social networks have also been deployed as part of Israeli partisan propaganda. The Facebook page \"Zionist Spring\" featured photos of non-existent persons along with their \"testimonies\" purporting to explain why they have abandoned their left-leaning politics to embrace right-wing politics, and the page also contained large numbers of posts from Prime Minister of Israel Benjamin Netanyahu and his son and from other Israeli right wing sources. The photographs appear to have been generated by \"human image synthesis\" technology, computer software that takes data from photos of real people to produce a realistic composite image of a non-existent person. In much of the \"testimonies,\" the reason given for embracing the political right was the shock of learning of alleged incitement to violence against the prime minister. Right wing Israeli television broadcasters then broadcast the \"testimonies\" of these non-existent people based on the fact that they were being \"shared\" online. The broadcasters aired these \"testimonies\" despite being unable to find such people, explaining \"Why does the origin matter?\" Other Facebook profiles of fictitious individuals posted material that allegedly contained material critical of the prime minister which the prime minister claimed was a plot to murder him.[178][179] Concerns and countermeasures [edit]Though fake photos have long been plentiful, faking motion pictures has been more difficult, and the presence of deepfakes increases the difficulty of classifying videos as genuine or not.[132] AI researcher Alex Champandard has said people should know how fast things can be corrupted with deepfake technology, and that the problem is not a technical one, but rather one to be solved by trust in information and journalism.[132] Computer science associate professor Hao Li of the University of Southern California states that deepfakes created for malicious use, such as fake news, will be even more harmful if nothing is done to spread awareness of deepfake technology.[180] Li predicted that genuine videos and deepfakes would become indistinguishable in as soon as six months, as of October 2019, due to rapid advancement[181] in artificial intelligence and computer graphics.[180] Former Google fraud czar Shuman Ghosemajumder has called deepfakes an area of \"societal concern\" and said that they will inevitably evolve to a point at which they can be generated automatically, and an individual could use that technology to produce millions of deepfake videos.[182] Credibility of information [edit]A primary pitfall is that humanity could fall into an age in which it can no longer be determined whether a medium's content corresponds to the truth.[132][183] Deepfakes are one of a number of tools for disinformation attack, creating doubt, and undermining trust. They have a potential to interfere with democratic functions in societies, such as identifying collective agendas, debating issues, informing decisions, and solving problems though the exercise of political will.[184] People may also start to dismiss real events as fake.[129] Defamation [edit]Deepfakes possess the ability to damage individual entities tremendously.[185] This is because deepfakes are often targeted at one individual, and/or their relations to others in hopes to create a narrative powerful enough to influence public opinion or beliefs. This can be done through deepfake voice phishing, which manipulates audio to create fake phone calls or conversations.[185] Another method of deepfake use is fabricated private remarks, which manipulate media to convey individuals voicing damaging comments.[185] The quality of a negative video or audio does not need to be that high. As long as someone's likeness and actions are recognizable, a deepfake can hurt their reputation.[129] In September 2020 Microsoft made public that they are developing a Deepfake detection software tool.[186] Detection [edit]Audio [edit]Detecting fake audio is a highly complex task that requires careful attention to the audio signal in order to achieve good performance. Using deep learning, preprocessing of feature design and masking augmentation have been proven effective in improving performance.[187] Video [edit]Most of the academic research surrounding deepfakes focuses on the detection of deepfake videos.[188] One approach to deepfake detection is to use algorithms to recognize patterns and pick up subtle inconsistencies that arise in deepfake videos.[188] For example, researchers have developed automatic systems that examine videos for errors such as irregular blinking patterns of lighting.[189][17] This approach has been criticized because deepfake detection is characterized by a \"moving goal post\" where the production of deepfakes continues to change and improve as algorithms to detect deepfakes improve.[188] In order to assess the most effective algorithms for detecting deepfakes, a coalition of leading technology companies hosted the Deepfake Detection Challenge to accelerate the technology for identifying manipulated content.[190] The winning model of the Deepfake Detection Challenge was 65% accurate on the holdout set of 4,000 videos.[191] A team at Massachusetts Institute of Technology published a paper in December 2021 demonstrating that ordinary humans are 69–72% accurate at identifying a random sample of 50 of these videos.[192] A team at the University of Buffalo published a paper in October 2020 outlining their technique of using reflections of light in the eyes of those depicted to spot deepfakes with a high rate of success, even without the use of an AI detection tool, at least for the time being.[193] In the case of well-documented individuals such as political leaders, algorithms have been developed to distinguish identity-based features such as patterns of facial, gestural, and vocal mannerisms and detect deep-fake impersonators.[194] Another team led by Wael AbdAlmageed with Visual Intelligence and Multimedia Analytics Laboratory (VIMAL) of the Information Sciences Institute at the University Of Southern California developed two generations[195][196] of deepfake detectors based on convolutional neural networks. The first generation[195] used recurrent neural networks to spot spatio-temporal inconsistencies to identify visual artifacts left by the deepfake generation process. The algorithm achieved 96% accuracy on FaceForensics++, the only large-scale deepfake benchmark available at that time. The second generation[196] used end-to-end deep networks to differentiate between artifacts and high-level semantic facial information using two-branch networks. The first branch propagates color information while the other branch suppresses facial content and amplifies low-level frequencies using Laplacian of Gaussian (LoG). Further, they included a new loss function that learns a compact representation of bona fide faces, while dispersing the representations (i.e. features) of deepfakes. VIMAL's approach showed state-of-the-art performance on FaceForensics++ and Celeb-DF benchmarks, and on 16 March 2022 (the same day of the release), was used to identify the deepfake of Volodymyr Zelensky out-of-the-box without any retraining or knowledge of the algorithm with which the deepfake was created. [citation needed] Other techniques suggest that blockchain could be used to verify the source of the media.[197] For instance, a video might have to be verified through the ledger before it is shown on social media platforms.[197] With this technology, only videos from trusted sources would be approved, decreasing the spread of possibly harmful deepfake media.[197] Digitally signing of all video and imagery by cameras and video cameras, including smartphone cameras, was suggested to fight deepfakes.[198] That allows tracing every photograph or video back to its original owner that can be used to pursue dissidents.[198] One easy way to uncover deepfake video calls consists in asking the caller to turn sideways.[199] Deepfake detection and regulation [edit]Legal experts are actively questioning whether current and emerging regulatory frameworks adequately balance the advancements in deepfake detection with the protection of individual rights. Relevant legislation being scrutinized includes the EU AI Act, the General Data Protection Regulation (GDPR), the Digital Services Act in the European Union, as well as the fragmented state and federal laws in the United States, the Online Safety Act 2023 in the United Kingdom, and China's Administrative Provisions on Deep Synthesis in Internet-Based Information Services (commonly known as the Deep Synthesis Provisions).[200] Scholars are evaluating if these frameworks effectively address the complex interplay between technology, rights, and responsibilities in the context of deepfakes.[201] Prevention [edit]Henry Ajder who works for Deeptrace, a company that detects deepfakes, says there are several ways to protect against deepfakes in the workplace. Semantic passwords or secret questions can be used when holding important conversations. Voice authentication and other biometric security features should be up to date. Educate employees about deepfakes.[129] Media Literacy and deepfakes [edit]Due to the capability of deepfakes to fool viewers and believably mimic a person, research has indicated that the concept of truth through observation cannot be fully relied on.[202] Additionally, literacy of the technology among populations could be called into question due to the relatively new success of convincing deepfakes.[202] When combined with increasing ease of access to the technology, this has led to the concern amongst some experts that some societies are not prepared to interact with deepfakes organically without potential consequences from sharing misinformation and disinformation.[202] Media literacy has been considered as a potential counter to \"prime\" a viewer to identify a deepfake when they encounter one organically by engendering critical thinking.[202] While media literacy education can have conflicting results in the overall success in detecting deepfakes,[203] research has indicated that critical thinking and a skeptical outlook toward a presented piece of media are effective at assisting an individual in determining a deepfake.[203][204] Media literacy frameworks promote critical analysis of media and the motivations behind the presentation of the associated content. Media literacy shows promise as a potential cognitive countermeasure when interacting with malicious deepfakes.[203] Controversies [edit]In March 2024, a video clip was released by Buckingham Palace announcing that Kate Middleton had cancer and was undergoing chemotherapy. The appearance of a ring worn by Middleton in the clip fueled rumors that the clip was a deepfake.[205] Johnathan Perkins, UCLA's Director of Race and Equity, doubted Middleton had cancer, and further speculated that she could be in critical condition or dead.[206] Politics [edit]Recently, the use of deepfakes has inspired research on deepfake's capability and effects when used in disinformation campaigns. This capability has raised concerns, partly due to the potential of deepfakes to circumvent a person's skepticism and influence their views on an issue.[207][183] Unlike crude misinformation, political propaganda via generative AI often co-opts cultural tropes, visual media, and satire to craft emotionally resonant messages that are difficult to fact-check without losing nuance.[208] Due to the continued advancement in technology that improves deceptive capabilities of deepfakes, some scholars believe that deepfakes could pose a significant threat to democratic societies.[209] Studies have investigated the effects of political deepfakes.[207][209][183] In two separate studies focusing on Dutch participants, it was found that deepfakes have varying effects on an audience. As a tool of disinformation, deepfakes did not necessarily produce stronger reactions or shifts in viewpoints than traditional textual disinformation.[207] However, deepfakes did produce a reassuring effect on individuals who held preconceived notions that aligned with the viewpoint promoted by the deepfake disinformation in the study.[207] Additionally, deepfakes are effective when designed to target a specific demographic segment related to a particular issue.[209] \"Microtargeting\" involves understanding nuanced political issues of a specific demographic to create a targeted deepfake. The targeted deepfake is then used to connect with and influence the viewpoint of that demographic. Targeted deepfakes were found to be notably effective by the researchers.[209] Research has also found that the political effects of deepfakes are not necessarily as straightforward or assured. Researchers in the United Kingdom uncovered that deepfake political disinformation does not have a guaranteed effect on populations beyond indications that it may sow distrust or uncertainty in a source that provides the deepfake.[183] The implications of distrust in sources led researchers to conclude that deepfakes may have outsized effect in a \"low-trust\" information environment where public institutions are not trusted by the public.[183] Across the world, there are key instances where deepfakes have been used to misrepresent well-known politicians and other public figures.[210] Liar's dividend [edit]The liar's dividend is a political and social phenomenon in which, when faced with incriminating or embarrassing authentic video or audio recordings of themselves, individuals will claim that the recordings are AI in order to dismiss the claims and gain sympathy.[211] Example events [edit]- Barack Obama - On 17 April 2018, American actor Jordan Peele, BuzzFeed, and Monkeypaw Productions posted a deepfake of Barack Obama to YouTube, which depicted Barack Obama cursing and calling Donald Trump names.[213] In this deepfake, Peele's voice and face were transformed and manipulated into those of Obama. The intent of this video was to portray the dangerous consequences and power of deepfakes, and how deepfakes can make anyone say anything. - Donald Trump - On 5 May 2019, Derpfakes posted a deepfake of Donald Trump to YouTube, based on a skit Jimmy Fallon performed on The Tonight Show.[214] In the original skit (aired 4 May 2016), Jimmy Fallon dressed as Donald Trump and pretended to participate in a phone call with Barack Obama, conversing in a manner that presented him to be bragging about his primary win in Indiana.[214] In the deepfake, Jimmy Fallon's face was transformed into Donald Trump's face, with the audio remaining the same. This deepfake video was produced by Derpfakes with a comedic intent. In March 2023, a series of images appeared to show New York Police Department officers restraining Trump.[215] The images, created using Midjourney, were initially posted on Twitter by Eliot Higgins but were later re-shared without context, leading some viewers to believe they were real photographs.[212] - Nancy Pelosi - In 2019, a clip from Nancy Pelosi's speech at the Center for American Progress (given on 22 May 2019) in which the video was slowed down, in addition to the pitch of the audio being altered, to make it seem as if she were drunk, was widely distributed on social media. Critics argue that this was not a deepfake, but a shallowfakea less sophisticated form of video manipulation. —[216][217] - Mark Zuckerberg - In May 2019, two artists collaborating with the company CannyAI created a deepfake video of Facebook founder Mark Zuckerberg talking about harvesting and controlling data from billions of people. The video was part of an exhibit to educate the public about the dangers of artificial intelligence.[218][219] - Kim Jong-un and Vladimir Putin - On 29 September 2020, deepfakes of North Korean leader Kim Jong-un and Russian President Vladimir Putin were uploaded to YouTube, created by a nonpartisan advocacy group RepresentUs.[220] The deepfakes of Kim and Putin were meant to air publicly as commercials to relay the notion that interference by these leaders in US elections would be detrimental to the United States' democracy. The commercials also aimed to shock Americans to realize how fragile democracy is, and how media and news can significantly influence the country's path regardless of credibility.[220] However, while the commercials included an ending comment detailing that the footage was not real, they ultimately did not air due to fears and sensitivity regarding how Americans may react.[220] On 5 June 2023, an unknown source broadcast a reported deepfake of Vladimir Putin on multiple radio and television networks. In the clip, Putin appears to deliver a speech announcing the invasion of Russia and calling for a general mobilization of the army.[221] - Volodymyr Zelenskyy - On 16 March 2022, a one-minute long deepfake video depicting Ukraine's president Volodymyr Zelenskyy seemingly telling his soldiers to lay down their arms and surrender during the 2022 Russian invasion of Ukraine was circulated on social media.[184] Russian social media boosted it, but after it was debunked, Facebook and YouTube removed it. Twitter allowed the video in tweets where it was exposed as a fake, but said it would be taken down if posted to deceive people. Hackers inserted the disinformation into a live scrolling-text news crawl on TV station Ukraine 24, and the video appeared briefly on the station's website in addition to false claims that Zelenskyy had fled his country's capital, Kyiv. It was not immediately clear who created the deepfake, to which Zelenskyy responded with his own video, saying, \"We don't plan to lay down any arms. Until our victory.\"[222] - Wolf News - In late 2022, pro-China propagandists started spreading deepfake videos purporting to be from \"Wolf News\" that used synthetic actors. The technology was developed by a London company called Synthesia, which markets it as a cheap alternative to live actors for training and HR videos.[223] - Pope Francis - In March 2023, an anonymous construction worker from Chicago used Midjourney to create a fake image of Pope Francis in a white Balenciaga puffer jacket. The image went viral, receiving over twenty million views.[224] Writer Ryan Broderick dubbed it \"the first real mass-level AI misinformation case\".[225] Experts consulted by Slate characterized the image as unsophisticated: \"you could have made it on Photoshop five years ago\".[226] - Keir Starmer - In October 2023, a deepfake audio clip of the UK Labour Party leader Keir Starmer abusing staffers was released on the first day of a Labour Party conference. The clip purported to be an audio tape of Starmer abusing his staffers.[227] - Rashmika Mandanna - In early November 2023, a famous South Indian actor, Rashmika Mandanna fell prey to DeepFake when a morphed video of a famous British-Indian influencer, Zara Patel, with Rashmika's face started to float on social media. Zara Patel claims to not be involved in its creation.[228] - Bongbong Marcos - In April 2024, a deepfake video misrepresenting Philippine President Bongbong Marcos was released. It is a slideshow accompanied by a deepfake audio of Marcos purportedly ordering the Armed Forces of the Philippines and special task force to act \"however appropriate\" should China attack the Philippines. The video was released amidst tensions related to the South China Sea dispute.[229] The Presidential Communications Office has said that there is no such directive from the president and said a foreign actor might be behind the fabricated media.[230] Criminal charges has been filed by the Kapisanan ng mga Brodkaster ng Pilipinas in relation to the deepfake media.[231] On 22 July 2024, a video of Marcos purportedly snorting illegal drugs was released by Claire Contreras, a former supporter of Marcos. Dubbed as the polvoron video, the media noted its consistency with the insinuation of Marcos' predecessor—Rodrigo Duterte—that Marcos is a drug addict; the video was also shown at a Hakbang ng Maisug rally organized by people aligned with Duterte.[232] Two days later, the Philippine National Police and the National Bureau of Investigation, based on their own findings, concluded that the video was created using AI; they further pointed out inconsistencies with the person on the video with Marcos, such as details on the two people's ears.[233] - Joe Biden - Prior to the 2024 United States presidential election, phone calls imitating the voice of the incumbent Joe Biden were made to dissuade people from voting for him. The person responsible for the calls was charged with voter suppression and impersonating a candidate. The FCC proposed to fine him US$6 million and Lingo Telecom, the company that allegedly relayed the calls, $2 million.[234][235] - Arup Group - The firm Arup Group lost $25 million in 2024 from a deepfake scam.[236] - Sara Duterte - Philippine Senator Ronald dela Rosa on 14 June 2025 shared a 40-second Deepfake video created via Veo where two students on the street testified on why the impeachment proceedings against Vice President Sara Duterte is selective and politically motivated.[237] Dela Rosa lauded the supposed youth for their opinions. When informed it was an AI video, he says that if that was the case the video creator had a point.[238] Duterte herself defended Dela Rosa, insisting that sharing an AI video is not wrong as long as its \"not for profit\".[239] Responses [edit]Social media platforms [edit]Chat site Discord has taken action against deepfakes in the past,[240] and has taken a general stance against deepfakes.[241][242] Gfycat began removing all deepfakes from its site on 31 January 2018.[243][241] Reddit banned the r/deepfakes subreddit on 7 February 2018, due to the policy violation of \"involuntary pornography\".[244][245][246][247][248][excessive citations] That same month, representatives from Twitter stated that they would suspend accounts suspected of posting non-consensual deepfake content.[249] In February 2018, Pornhub said that it would ban deepfake videos on its website because it is considered \"non consensual content\" which violates their terms of service.[250] They also stated previously to Mashable that they will take down content flagged as deepfakes.[251] Writers from Motherboard reported that searching \"deepfakes\" on Pornhub still returned multiple recent deepfake videos.[250] Google added \"involuntary synthetic pornographic imagery\" to its ban list in September 2018, allowing anyone to request the block of results showing their fake nudes.[252][check quotation syntax] In May 2022, Google officially changed the terms of service for their Jupyter Notebook colabs, banning the use of their colab service for the purpose of creating deepfakes.[253] This came a few days after the publication of a VICE article in which its author, Emanuel Maiberg, reported \"Most deepfakes are non-consensual porn\", and that the main use of popular deepfake software DeepFaceLab (DFL), \"the most important technology powering the vast majority of this generation of deepfakes\", which often was used in combination with Google colabs, was to create non-consensual pornography. Maiberg pointed to the fact that among many other well-known examples of third-party DFL implementations, such as deepfakes commissioned by The Walt Disney Company, official music videos, and web series Sassy Justice by the creators of South Park, DFL's GitHub page, also linked to deepfake porn website Mr. and participants of the DFL Discord server also participate on DeepfakesMr.. Deepfakes[254] Facebook has previously stated that they would not remove deepfakes from their platforms.[255] The videos will instead be flagged as fake by third-parties and then have a lessened priority in user's feeds.[256] This response was prompted in June 2019 after a deepfake featuring a 2016 video of Mark Zuckerberg circulated on Facebook and Instagram.[255] Subsequently, Facebook has taken efforts towards encouraging the creation of deepfakes in order to develop state of the art deepfake detection software. Facebook was the prominent partner in hosting the Deepfake Detection Challenge (DFDC), held December 2019, to 2114 participants who generated more than 35,000 models.[257] The top performing models with the highest detection accuracy were analyzed for similarities and differences; these findings are areas of interest in further research to improve and refine deepfake detection models.[257] Facebook has also detailed that the platform will be taking down media generated with artificial intelligence used to alter an individual's speech.[258] However, media that has been edited to alter the order or context of words in one's message would remain on the site but be labeled as false, since it was not generated by artificial intelligence.[258] Twitter (now known as X) is taking active measures to handle synthetic and manipulated media on their platform. In order to prevent disinformation from spreading, Twitter is placing a notice on tweets that contain manipulated media and/or deepfakes that signal to viewers that the media is manipulated.[259] There will also be a warning that appears to users who plan on retweeting, liking, or engaging with the tweet.[259] Twitter will also work to provide users a link next to the tweet containing manipulated or synthetic media that links to a Twitter Moment or credible news article on the related topic—as a debunking action.[259] Twitter also has the ability to remove any tweets containing deepfakes or manipulated media that may pose a harm to users' safety.[259] In order to better improve Twitter's detection of deepfakes and manipulated media, Twitter asked users who are interested in partnering with them to work on deepfake detection solutions to fill out a form.[260] In August 2024, the secretaries of state of Minnesota, Pennsylvania, Washington, Michigan and New Mexico penned an open letter to X owner Elon Musk urging modifications to its AI chatbot Grok's new text-to-video generator, added in August 2024, stating that it had disseminated election misinformation.[261][262][263] Legislation [edit]In the United States, there have been some responses to the problems posed by deepfakes. In 2018, the Malicious Deep Fake Prohibition Act was introduced to the US Senate;[264] in 2019, the Deepfakes Accountability Act was introduced in the 116th United States Congress by U.S. representative for New York's 9th congressional district Yvette Clarke.[265] In 2024, over half of documented identity fraud involved AI-created forgeries,[266] leading several states to introduce legislation regarding deepfakes, including Virginia,[267] Texas, California, and New York;[268] charges as varied as identity theft, cyberstalking, and revenge porn have been pursued, while more comprehensive statutes are urged.[252] Among U.S. legislative efforts, on 3 October 2019, California governor Gavin Newsom signed into law Assembly Bills No. 602 and No. 730.[269][270] Assembly Bill No. 602 provides individuals targeted by sexually explicit deepfake content made without their consent with a cause of action against the content's creator.[269] Assembly Bill No. 730 prohibits the distribution of malicious deepfake audio or visual media targeting a candidate running for public office within 60 days of their election.[270] U.S. representative Yvette Clarke introduced H.R. 5586: Deepfakes Accountability Act into the 118th United States Congress on 20 September 2023 in an effort to protect national security from threats posed by deepfake technology.[271] U.S. representative María Salazar introduced H.R. 6943: No AI Fraud Act into the 118th United States Congress on 10 January 2024, to establish specific property rights of individual physicality, including voice.[272] In November 2019, China announced that deepfakes and other synthetically faked footage should bear a clear notice about their fakeness starting in 2020. Failure to comply could be considered a crime the Cyberspace Administration of China stated on its website.[273] The Chinese government seems to be reserving the right to prosecute both users and online video platforms failing to abide by the rules.[274] The Cyberspace Administration of China, the Ministry of Industry and Information Technology, and the Ministry of Public Security jointly issued the Provision on the Administration of Deep Synthesis Internet Information Service in November 2022.[275] China's updated Deep Synthesis Provisions (Administrative Provisions on Deep Synthesis in Internet-Based Information Services) went into effect in January 2023.[276] In the United Kingdom, producers of deepfake material could be prosecuted for harassment, but deepfake production was not a specific crime[277] until 2023, when the Online Safety Act was passed, which made deepfakes illegal; the UK plans to expand the Act's scope to criminalize deepfakes created with \"intention to cause distress\" in 2024.[278][279] In Canada, in 2019, the Communications Security Establishment released a report which said that deepfakes could be used to interfere in Canadian politics, particularly to discredit politicians and influence voters.[280][281] As a result, there are multiple ways for citizens in Canada to deal with deepfakes if they are targeted by them.[282] In February 2024, bill C-63 was tabled in the 44th Canadian Parliament in order to enact the Online Harms Act, which would amend Criminal Code, and other Acts. An earlier version of the Bill, C-36, was ended by the dissolution of the 43rd Canadian Parliament in September 2021.[283][284] In India, there are no direct laws or regulation on AI or deepfakes, but there are provisions under the Indian Penal Code and Information Technology Act 2000/2008, which can be looked at for legal remedies, and the new proposed Digital India Act will have a chapter on AI and deepfakes in particular, as per the MoS Rajeev Chandrasekhar.[285] In Europe, the European Union's 2024 Artificial Intelligence Act (AI Act) takes a risk-based approach to regulating AI systems, including deepfakes. It establishes categories of \"unacceptable risk,\" \"high risk,\" \"specific/limited or transparency risk\", and \"minimal risk\" to determine the level of regulatory obligations for AI providers and users. However, the lack of clear definitions for these risk categories in the context of deepfakes creates potential challenges for effective implementation. Legal scholars have raised concerns about the classification of deepfakes intended for political misinformation or the creation of non-consensual intimate imagery. Debate exists over whether such uses should always be considered \"high-risk\" AI systems, which would lead to stricter regulatory requirements.[286] In August 2024, the Irish Data Protection Commission (DPC) launched court proceedings against X for its unlawful use of the personal data of over 60 million EU/EEA users, in order to train its AI technologies, such as its chatbot Grok.[287] Response from DARPA [edit]In 2016, the Defense Advanced Research Projects Agency (DARPA) launched the Media Forensics (MediFor) program which was funded through 2020.[288] MediFor aimed at automatically spotting digital manipulation in images and videos, including Deepfakes.[289][290] In the summer of 2018, MediFor held an event where individuals competed to create AI-generated videos, audio, and images as well as automated tools to detect these deepfakes.[291] According to the MediFor program, it established a framework of three tiers of information—digital integrity, physical integrity and semantic integrity—to generate one integrity score in an effort to enable accurate detection of manipulated media.[292] In 2019, DARPA hosted a \"proposers day\" for the Semantic Forensics (SemaFor) program where researchers were driven to prevent viral spread of AI-manipulated media.[293] DARPA and the Semantic Forensics Program were also working together to detect AI-manipulated media through efforts in training computers to utilize common sense, logical reasoning.[293] Built on the MediFor's technologies, SemaFor's attribution algorithms infer if digital media originates from a particular organization or individual, while characterization algorithms determine whether media was generated or manipulated for malicious purposes.[294] In March 2024, SemaFor published an analytic catalog that offers the public access to open-source resources developed under SemaFor.[295][296] International Panel on the Information Environment [edit]The International Panel on the Information Environment was launched in 2023 as a consortium of over 250 scientists working to develop effective countermeasures to deepfakes and other problems created by perverse incentives in organizations disseminating information via the Internet.[297] In popular culture [edit]- The 1986 mid-December issue of Analog magazine published the novelette \"Picaper\" by Jack Wodhams.[298] Its plot revolves around digitally enhanced or digitally generated videos produced by skilled hackers serving unscrupulous lawyers and political figures.[299] - The 1987 film The Running Man starring Arnold Schwarzenegger depicts an autocratic government using computers to digitally replace the faces of actors with those of wanted fugitives to make it appear the fugitives had been neutralized. - In the 1992 techno-thriller A Philosophical Investigation by Philip Kerr, \"Wittgenstein\", the main character and a serial killer, makes use of both a software similar to deepfake and a virtual reality suit for having sex with an avatar of Isadora \"Jake\" Jakowicz, the female police lieutenant assigned to catch him.[300] - The 1993 film Rising Sun starring Sean Connery and Wesley Snipes depicts another character, Jingo Asakuma, who reveals that a computer disc has digitally altered personal identities to implicate a competitor. - Deepfake technology is part of the plot of the 2019 BBC One TV series The Capture. The first series follows former British Army sergeant Shaun Emery, who is accused of assaulting and abducting his barrister. Expertly doctored CCTV footage is revealed to have framed him and mislead the police investigating the case.[301][302] The second series follows politician Isaac Turner who discovers that another deepfake is tarnishing his reputation until the \"correction\" is eventually exposed to the public. - Al Davis vs. the NFL: The narrative structure of this 2021 documentary, part of ESPN's 30 for 30 documentary series, uses deepfake versions of the film's two central characters, both deceased—Al Davis, who owned the Las Vegas Raiders during the team's tenure in Oakland and Los Angeles, and Pete Rozelle, the NFL commissioner who frequently clashed with Davis.[303][304] - Deepfake technology is featured in \"Impawster Syndrome\", the 57th episode of the Canadian police series Hudson & Rex, first broadcast on 6 January 2022, in which a member of the St. John's police team is investigated on suspicion of robbery and assault due to doctored CCTV footage using his likeness.[305] - Using deepfake technology in his music video for his 2022 single, \"The Heart Part 5\", musician Kendrick Lamar transformed into figures resembling Nipsey Hussle, O.J. Simpson, and Kanye West, among others.[306] The deepfake technology in the video was created by Deep Voodoo, a studio led by Trey Parker and Matt Stone, who created South Park.[306] - Aloe Blacc honored his long-time collaborator Avicii four years after his death by performing their song \"Wake Me Up\"[307] in English, Spanish, and Mandarin, using deepfake technologies.[308] - In January 2023, ITVX released the series Deep Fake Neighbour Wars, in which various celebrities were played by actors experiencing inane conflicts, the celebrity's face deepfaked onto them.[309] - In October 2023, Tom Hanks shared a photo of an apparent deepfake likeness depicting him promoting \"some dental plan\" to his Instagram page. Hanks warned his fans, \"BEWARE . . . I have nothing to do with it.\"[110] See also [edit]- Artificial intelligence and elections - Artificial intelligence art - Computer facial animation - Dead Internet theory - Digital cloning - Digital face replacement - Facial motion capture - Fake nude photography - Fifth-generation warfare - Generative artificial intelligence - Hyperreality - Identity replacement technology - Interactive online characters - Regulation of artificial intelligence - StyleGAN - Synthetic media - Uncanny valley - Virtual actor References [edit]- ^ a b c Wahab, Abdul (1 October 2025). \"Futures of Deepfake and society: Myths, metaphors, and future implications for a trustworthy digital future\". Futures. 173 103672. doi:10.1016/j.futures.2025.103672. ISSN 0016-3287. - ^ Kalpokas, Ignas; Kalpokiene, Julija (2022). Deepfakes. Springer Cham. pp. 1–2. doi:10.1007/978-3-030-93802-4. ISBN 978-3-030-93801-7. - ^ Berry, David M. (19 March 2025). \"Synthetic media and computational capitalism: towards a critical theory of artificial intelligence\". AI & Society. arXiv:2503.18976. doi:10.1007/s00146-025-02265-2. ISSN 1435-5655. - ^ Juefei-Xu, Felix; Wang, Run; Huang, Yihao; Guo, Qing; Ma, Lei; Liu, Yang (1 July 2022). \"Countering Malicious DeepFakes: Survey, Battleground, and Horizon\". International Journal of Computer Vision. 130 (7): 1678–1734. doi:10.1007/s11263-022-01606-8. ISSN 1573-1405. PMC 9066404. PMID 35528632. - ^ a b Kietzmann, J.; Lee, L. W.; McCarthy, I. P.; Kietzmann, T. C. (2020). \"Deepfakes: Trick or treat?\" (PDF). Business Horizons. 63 (2): 135–146. doi:10.1016/j.bushor.2019.11.006. S2CID 213818098. Archived (PDF) from the original on 29 December 2022. Retrieved 30 December 2022. - ^ Waldrop, M. Mitchell (16 March 2020). \"Synthetic media: The real trouble with deepfakes\". Knowable Magazine. Annual Reviews. doi:10.1146/knowable-031320-1. Archived from the original on 19 November 2022. Retrieved 19 December 2022. - ^ Schwartz, Oscar (12 November 2018). \"You thought fake news was bad? Deep fakes are where truth goes to die\". The Guardian. Archived from the original on 16 June 2019. Retrieved 14 November 2018. - ^ Farid, Hany (15 September 2019). \"Image Forensics\". Annual Review of Vision Science. 5 (1): 549–573. doi:10.1146/annurev-vision-091718-014827. ISSN 2374-4642. PMID 31525144. S2CID 263558880. Archived from the original on 10 June 2024. Retrieved 20 September 2023. - ^ Banks, Alec (20 February 2018). \"What Are Deepfakes & Why the Future of Porn is Terrifying\". Highsnobiety. Archived from the original on 14 July 2021. Retrieved 20 February 2018. - ^ Christian, Jon. \"Experts fear face swapping tech could start an international showdown\". The Outline. Archived from the original on 16 January 2020. Retrieved 28 February 2018. - ^ Roose, Kevin (4 March 2018). \"Here Come the Fake Videos, Too\". The New York Times. ISSN 0362-4331. Archived from the original on 18 June 2019. Retrieved 24 March 2018. - ^ Schreyer, Marco; Sattarov, Timur; Reimer, Bernd; Borth, Damian (October 2019). \"Adversarial Learning of Deepfakes in Accounting\". arXiv:1910.03810 [cs.LG]. - ^ \"Dangers of Deepfake: What to Watch For | University IT\". uit.stanford.edu. Retrieved 11 August 2025. - ^ Savat, Sara (19 August 2024). \"Political deepfake videos no more deceptive than other fake news, research finds\". The Source. Retrieved 11 August 2025. - ^ Caramancion, Kevin Matthe (21 April 2021). \"The Demographic Profile Most at Risk of being Disinformed\". 2021 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS). IEEE. pp. 1–7. doi:10.1109/iemtronics52119.2021.9422597. ISBN 978-1-6654-4067-7. S2CID 234499888. Archived from the original on 10 June 2024. Retrieved 9 June 2023. - ^ Lalla, Vejay; Mitrani, Adine; Harned, Zach. \"Artificial Intelligence: Deepfakes in the Entertainment Industry\". World Intellectual Property Organization. Archived from the original on 8 November 2022. Retrieved 8 November 2022. - ^ a b c Harwell, Drew (12 June 2019). \"Top AI researchers race to detect 'deepfake' videos: 'We are outgunned'\". The Washington Post. Archived from the original on 31 October 2019. Retrieved 8 November 2019. - ^ Sanchez, Julian (8 February 2018). \"Thanks to AI, the future of 'fake news' is being pioneered in homemade porn\". NBC News. Archived from the original on 9 November 2019. Retrieved 8 November 2019. - ^ a b c d Porter, Jon (2 September 2019). \"Another convincing deepfake app goes viral prompting immediate privacy backlash\". The Verge. Archived from the original on 3 September 2019. Retrieved 8 November 2019. - ^ a b Vatreš, Amina (2021). \"Deepfake Phenomenon: An advanced form of fake news and its implications on reliable journalism\". Društvene i humanističke studije. 16 (3): 561–576. doi:10.51558/2490-3647.2021.6.3.561. - ^ a b Rana, Md Shohel; Nobi, Mohammad Nur; Murali, Beddhu; Sung, Andrew H. (2022). \"Deepfake Detection: A Systematic Literature Review\". IEEE Access. 10: 25494–25513. Bibcode:2022IEEEA..1025494R. doi:10.1109/ACCESS.2022.3154404. ISSN 2169-3536. - ^ Sudarsan, Ananya; Chua, Hui Na; Jasser, Muhammed Basheer; Wong, Richard T.K. (1 March 2024). \"Deepfake Characterization, Propagation, and Detection in Social Media - A Synthesis Review\". 2024 20th IEEE International Colloquium on Signal Processing & Its Applications (CSPA). IEEE. pp. 219–224. doi:10.1109/CSPA60979.2024.10525373. ISBN 979-8-3503-8231-0. - ^ Sudarsan, Ananya; Chua, Hui Na; Jasser, Muhammed Basheer; Wong, Richard T.K. (1 March 2024). \"Deepfake Characterization, Propagation, and Detection in Social Media - A Synthesis Review\". 2024 20th IEEE International Colloquium on Signal Processing & Its Applications (CSPA). IEEE. pp. 219–224. doi:10.1109/CSPA60979.2024.10525373. ISBN 979-8-3503-8231-0. - ^ Sudarsan, Ananya; Chua, Hui Na; Jasser, Muhammed Basheer; Wong, Richard T.K. (1 March 2024). \"Deepfake Characterization, Propagation, and Detection in Social Media - A Synthesis Review\". 2024 20th IEEE International Colloquium on Signal Processing & Its Applications (CSPA). IEEE. pp. 219–224. doi:10.1109/CSPA60979.2024.10525373. ISBN 979-8-3503-8231-0. - ^ Sudarsan, Ananya; Chua, Hui Na; Jasser, Muhammed Basheer; Wong, Richard T.K. (1 March 2024). \"Deepfake Characterization, Propagation, and Detection in Social Media - A Synthesis Review\". 2024 20th IEEE International Colloquium on Signal Processing & Its Applications (CSPA). IEEE. pp. 219–224. doi:10.1109/CSPA60979.2024.10525373. ISBN 979-8-3503-8231-0. - ^ Sudarsan, Ananya; Chua, Hui Na; Jasser, Muhammed Basheer; Wong, Richard T.K. (1 March 2024). \"Deepfake Characterization, Propagation, and Detection in Social Media - A Synthesis Review\". 2024 20th IEEE International Colloquium on Signal Processing & Its Applications (CSPA). IEEE. pp. 219–224. doi:10.1109/CSPA60979.2024.10525373. ISBN 979-8-3503-8231-0. - ^ a b c Alanazi, Sami; Asif, Seemal; Caird-daley, Antoinette; Moulitsas, Irene (20 February 2025). \"Unmasking deepfakes: a multidisciplinary examination of social impacts and regulatory responses\". Human-Intelligent Systems Integration. doi:10.1007/s42454-025-00060-4. ISSN 2524-4876. - ^ Bode, Lisa; Lees, Dominic; Golding, Dan (29 July 2021). \"The Digital Face and Deepfakes on Screen\". Convergence: The International Journal of Research into New Media Technologies. 27 (4): 849–854. doi:10.1177/13548565211034044. ISSN 1354-8565. S2CID 237402465. - ^ a b Holliday, Christopher (26 July 2021). \"Rewriting the stars: Surface tensions and gender troubles in the online media production of digital deepfakes\". Convergence: The International Journal of Research into New Media Technologies. 27 (4): 899–918. doi:10.1177/13548565211029412. ISSN 1354-8565. S2CID 237402548. - ^ Gingrich, Oliver M. (5 July 2021). \"GENDER*UCK: Reframing gender & media art\". Proceedings of EVA London 2021 (EVA 2021). Electronic Workshops in Computing. doi:10.14236/ewic/EVA2021.25. S2CID 236918199. - ^ Fletcher, John (2018). \"Deepfakes, Artificial Intelligence, and Some Kind of Dystopia: The New Faces of Online Post-Fact Performance\". Theatre Journal. 70 (4): 455–471. doi:10.1353/tj.2018.0097. ISSN 1086-332X. S2CID 191988083. - ^ Öhman, Carl (1 June 2020). \"Introducing the pervert's dilemma: a contribution to the critique of Deepfake Pornography\". Ethics and Information Technology. 22 (2): 133–140. doi:10.1007/s10676-019-09522-1. ISSN 1572-8439. S2CID 208145457. - ^ Fallis, Don (1 December 2021). \"The Epistemic Threat of Deepfakes\". Philosophy & Technology. 34 (4): 623–643. doi:10.1007/s13347-020-00419-2. ISSN 2210-5433. PMC 7406872. PMID 32837868. - ^ Chesney, Robert; Citron, Danielle Keats (2018). \"Deep Fakes: A Looming Challenge for Privacy, Democracy, and National Security\". SSRN Electronic Journal. doi:10.2139/ssrn.3213954. ISSN 1556-5068. Archived from the original on 21 December 2019. Retrieved 9 February 2022. - ^ Yadlin-Segal, Aya; Oppenheim, Yael (February 2021). \"Whose dystopia is it anyway? Deepfakes and social media regulation\". Convergence: The International Journal of Research into New Media Technologies. 27 (1): 36–51. doi:10.1177/1354856520923963. ISSN 1354-8565. S2CID 219438536. Archived from the original on 9 February 2022. Retrieved 9 February 2022. - ^ Hwang, Yoori; Ryu, Ji Youn; Jeong, Se-Hoon (1 March 2021). \"Effects of Disinformation Using Deepfake: The Protective Effect of Media Literacy Education\". Cyberpsychology, Behavior, and Social Networking. 24 (3): 188–193. doi:10.1089/cyber.2020.0174. ISSN 2152-2715. PMID 33646021. S2CID 232078561. Archived from the original on 10 June 2024. Retrieved 9 February 2022. - ^ Hight, Craig (12 November 2021). \"Deepfakes and documentary practice in an age of misinformation\". Continuum. 36 (3): 393–410. doi:10.1080/10304312.2021.2003756. ISSN 1030-4312. S2CID 244092288. Archived from the original on 9 February 2022. Retrieved 9 February 2022. - ^ Hancock, Jeffrey T.; Bailenson, Jeremy N. (1 March 2021). \"The Social Impact of Deepfakes\". Cyberpsychology, Behavior, and Social Networking. 24 (3): 149–152. doi:10.1089/cyber.2021.29208.jth. ISSN 2152-2715. PMID 33760669. S2CID 232356146. Archived from the original on 10 June 2024. Retrieved 9 February 2022. - ^ de Seta, Gabriele (30 July 2021). \"Huanlian, or changing faces: Deepfakes on Chinese digital media platforms\". Convergence: The International Journal of Research into New Media Technologies. 27 (4): 935–953. doi:10.1177/13548565211030185. hdl:11250/2833613. ISSN 1354-8565. S2CID 237402447. Archived from the original on 10 June 2024. Retrieved 9 February 2022. - ^ a b Bregler, Christoph; Covell, Michele; Slaney, Malcolm (1997). \"Video Rewrite: Driving visual speech with audio\". Proceedings of the 24th annual conference on Computer graphics and interactive techniques – SIGGRAPH '97. Vol. 24. pp. 353–360. doi:10.1145/258734.258880. ISBN 0-89791-896-7. S2CID 2341707. Archived from the original on 10 June 2024. Retrieved 10 July 2023. - ^ a b c Suwajanakorn, Supasorn; Seitz, Steven M.; Kemelmacher-Shlizerman, Ira (July 2017). \"Synthesizing Obama: Learning Lip Sync from Audio\". ACM Trans. Graph. 36 (4): 95:1–95:13. doi:10.1145/3072959.3073640. S2CID 207586187. Archived from the original on 19 May 2020. Retrieved 10 July 2023. - ^ a b Thies, Justus; Zollhöfer, Michael; Stamminger, Marc; Theobalt, Christian; Nießner, Matthias (June 2016). \"Face2Face: Real-Time Face Capture and Reenactment of RGB Videos\". 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE. pp. 2387–2395. arXiv:2007.14808. doi:10.1109/CVPR.2016.262. ISBN 978-1-4673-8851-1. S2CID 206593693. - ^ \"Deepfakes for dancing: you can now use AI to fake those dance moves you always wanted\". The Verge. Archived from the original on 17 May 2019. Retrieved 27 August 2018. - ^ Farquhar, Peter (27 August 2018). \"An AI program will soon be here to help your deepface dancing – just don't call it deepfake\". Business Insider Australia. Archived from the original on 10 April 2019. Retrieved 27 August 2018. - ^ Mirsky, Yisroel; Mahler, Tom; Shelef, Ilan; Elovici, Yuval (2019). CT-GAN: Malicious Tampering of 3D Medical Imagery using Deep Learning. pp. 461–478. arXiv:1901.03597. ISBN 978-1-939133-06-9. Archived from the original on 20 June 2020. Retrieved 18 June 2020. - ^ O'Neill, Patrick Howell (3 April 2019). \"Researchers Demonstrate Malware That Can Trick Doctors Into Misdiagnosing Cancer\". Gizmodo. Archived from the original on 10 June 2024. Retrieved 3 June 2022. - ^ Mirsky, Yisroel; Lee, Wenke (12 May 2020). \"The Creation and Detection of Deepfakes: A Survey\". ACM Computing Surveys. arXiv:2004.11138. doi:10.1145/3425780. S2CID 216080410. - ^ Karnouskos, Stamatis (2020). \"Artificial Intelligence in Digital Media: The Era of Deepfakes\" (PDF). IEEE Transactions on Technology and Society. 1 (3): 138. Bibcode:2020ITTS....1..138K. doi:10.1109/TTS.2020.3001312. S2CID 221716206. Archived (PDF) from the original on 14 July 2021. Retrieved 9 July 2020. - ^ a b Cole, Samantha (24 January 2018). \"We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now\". Vice. Archived from the original on 7 September 2019. Retrieved 4 May 2019. - ^ Haysom, Sam (31 January 2018). \"People Are Using Face-Swapping Tech to Add Nicolas Cage to Random Movies and What Is 2018\". Mashable. Archived from the original on 24 July 2019. Retrieved 4 April 2019. - ^ Hathaway, Jay (8 February 2018). \"Here's where 'deepfakes,' the new fake celebrity porn, went after the Reddit ban\". The Daily Dot. Archived from the original on 6 July 2019. Retrieved 22 December 2018. - ^ \"What is a Deepfake and How Are They Made?\". Online Tech Tips. 23 May 2019. Archived from the original on 8 November 2019. Retrieved 20 December 2025. - ^ Robertson, Adi (11 February 2018). \"I'm using AI to face-swap Elon Musk and Jeff Bezos, and I'm really bad at it\". The Verge. Archived from the original on 24 March 2018. Retrieved 8 November 2019. - ^ \"Deepfakes web | The best online faceswap app\". Deepfakes web. Archived from the original on 14 July 2021. Retrieved 21 February 2021. - ^ \"Faceswap is the leading free and Open Source multi-platform Deepfakes software\". 15 October 2019. Archived from the original on 31 May 2021. Retrieved 14 July 2021 – via WordPress. - ^ \"DeepFaceLab is a tool that utilizes machine learning to replace faces in videos. Includes prebuilt ready to work standalone Windows 7,8,10 binary (look readme.md).: iperov/DeepFaceLab\". 19 June 2019. Archived from the original on 9 May 2019. Retrieved 6 March 2019 – via GitHub. - ^ Chandler, Simon. \"Why Deepfakes Are A Net Positive For Humanity\". Forbes. Archived from the original on 16 November 2020. Retrieved 3 November 2020. - ^ Pangburn, D. J. (21 September 2019). \"You've been warned: Full body deepfakes are the next step in AI-based human mimicry\". Fast Company. Archived from the original on 8 November 2019. Retrieved 8 November 2019. - ^ Lyons, Kim (29 January 2020). \"FTC says the tech behind audio deepfakes is getting better\". The Verge. Archived from the original on 30 January 2020. Retrieved 8 February 2020. - ^ \"Audio samples from \"Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis\"\". google.github.io. Archived from the original on 14 November 2019. Retrieved 8 February 2020. - ^ Jia, Ye; Zhang, Yu; Weiss, Ron J.; Wang, Quan; Shen, Jonathan; Ren, Fei; Chen, Zhifeng; Nguyen, Patrick; Pang, Ruoming; Moreno, Ignacio Lopez; Wu, Yonghui (2 January 2019). \"Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis\". arXiv:1806.04558 [cs.CL]. - ^ \"TUM Visual Computing: Prof. Matthias Nießner\". www.niessnerlab.org. Archived from the original on 21 February 2020. Retrieved 8 February 2020. - ^ \"Full Page Reload\". IEEE Spectrum: Technology, Engineering, and Science News. 11 December 2019. Archived from the original on 26 June 2020. Retrieved 8 February 2020. - ^ \"Contributing Data to Deepfake Detection Research\". 24 September 2019. Archived from the original on 5 February 2020. Retrieved 8 February 2020. - ^ Thalen, Mikael. \"You can now deepfake yourself into a celebrity with just a few clicks\". daily dot. Archived from the original on 6 April 2020. Retrieved 3 April 2020. - ^ Matthews, Zane (6 March 2020). \"Fun or Fear: Deepfake App Puts Celebrity Faces In Your Selfies\". Kool1079. Archived from the original on 24 March 2020. Retrieved 6 March 2020. - ^ van der Sloot, Bart (2024). Regulating the Synthetic Society : Generative AI, Legal Questions, and Societal Challenges. Bloomsbury Academic. ISBN 978-1-5099-7495-5. Retrieved 21 November 2025. - ^ \"Kanye West, Kim Kardashian and her dad: Should we make holograms of the dead?\". BBC News. 31 October 2020. Archived from the original on 15 November 2020. Retrieved 11 November 2020. - ^ \"Kanye West Gave Kim Kardashian a Hologram of Her Father for Her Birthday\". themodems. 30 October 2020. Archived from the original on 11 November 2020. Retrieved 11 November 2020. - ^ \"Parkland victim Joaquin Oliver comes back to life in heartbreaking plea to voters\". adage.com. 2 October 2020. Archived from the original on 11 November 2020. Retrieved 11 November 2020. - ^ Bowenbank, Starr (14 September 2022). \"Simon Cowell Duets With Elvis in Metaphysic's Latest Deepfake 'AGT' Performance: Watch\". Billboard. Archived from the original on 15 September 2022. Retrieved 8 November 2022. - ^ Zucconi, Alan (14 March 2018). \"Understanding the Technology Behind DeepFakes\". Alan Zucconi. Archived from the original on 1 November 2019. Retrieved 8 November 2019. - ^ \"What is a Deepfake?\". Blog - Synthesys. 3 May 2022. Archived from the original on 26 June 2022. Retrieved 17 May 2022. - ^ a b \"These New Tricks Can Outsmart Deepfake Videos—for Now\". Wired. ISSN 1059-1028. Archived from the original on 3 October 2019. Retrieved 9 November 2019. - ^ Kemp, Luke (8 July 2019). \"In the age of deepfakes, could virtual actors put humans out of business?\". The Guardian. ISSN 0261-3077. Archived from the original on 20 October 2019. Retrieved 20 October 2019. - ^ Verma, Pranshu (21 July 2023). \"Digital clones made by AI tech could make Hollywood extras obsolete\". Washington Post. Archived from the original on 20 July 2023. Retrieved 4 January 2024. - ^ a b \"High-Resolution Neural Face Swapping for Visual Effects | Disney Research Studios\". Archived from the original on 27 November 2020. Retrieved 7 October 2020. - ^ a b \"Disney's deepfake technology could be used in film and TV\". Blooloop. 21 July 2020. Archived from the original on 12 November 2020. Retrieved 7 October 2020. - ^ Lindley, Jon A. (2 July 2020). \"Disney Ventures Into Bringing Back 'Dead Actors' Through Facial Recognition\". Tech Times. Archived from the original on 14 July 2021. Retrieved 7 October 2020. - ^ Radulovic, Petrana (17 October 2018). \"Harrison Ford is the star of Solo: A Star Wars Story thanks to deepfake technology\". Polygon. Archived from the original on 20 October 2019. Retrieved 20 October 2019. - ^ Winick, Erin. \"How acting as Carrie Fisher's puppet made a career for Rogue One's Princess Leia\". MIT Technology Review. Archived from the original on 23 October 2019. Retrieved 20 October 2019. - ^ \"Deepfake Luke Skywalker is another step down a ghoulish CGI path\". British GQ. 10 February 2022. Archived from the original on 22 May 2022. Retrieved 3 June 2022. - ^ Dazed (10 February 2022). \"Will deepfakes rewrite history as we know it?\". Dazed. Archived from the original on 8 June 2022. Retrieved 3 June 2022. - ^ Schwartzel, Erich (21 December 2023). \"Behind the Making of My AI Digital Double\". Wall Street Journal. Archived from the original on 6 January 2024. Retrieved 4 January 2024. - ^ Coffee, Patrick (18 June 2023). \"Celebrities Use AI to Take Control of Their Own Images\". Wall Street Journal. Archived from the original on 10 June 2024. Retrieved 4 January 2024. - ^ Prescott, Katie Prescott (23 August 2024). \"The man who creates fake people – like David Beckham speaking nine languages\". The Times. Retrieved 22 October 2024. - ^ \"Not Vijay, Here's Who Played the Younger Version of Him in The GOAT\". english.tupaki.com/. 8 September 2024. Retrieved 8 November 2024. - ^ Constantine, Megan; Lim, Audrey; Glass, Lia; Webb, Melanie; Simpson, Kyle; Carrion, Joey; DeMoraes, Isa; Olatunde, Timi; Westerman, Reagan; Rybachek, Anna; Gunn, Nicholas (24 October 2025). \"The Student Movement Volume 110 Issue 5: At the Market for Cuisine and K-Pop\". The Student Movement V. 110 (2025-2026). - ^ Katerina Cizek, William Uricchio, and Sarah Wolozin: Collective Wisdom | Massachusetts Institute of Technology [1] Archived 4 March 2020 at the Wayback Machine - ^ \"ANSA | Ornella Muti in cortometraggio a Firenze\". 3 November 2017. Archived from the original on 27 February 2020. Retrieved 27 February 2020. - ^ \"'South Park' creators launch new deepfake satire series 'Sassy Justice'\". NME. 27 October 2020. Archived from the original on 10 June 2024. Retrieved 7 June 2022. - ^ a b Tayler, Kelley M.; Harris, Laurie A. (8 June 2021). Deep Fakes and National Security (Report). Congressional Research Service. p. 1. Archived from the original on 14 June 2022. Retrieved 19 July 2021. - ^ Limberg, Peter (24 May 2020). \"Blackmail Inflation\". CultState. Archived from the original on 24 January 2021. Retrieved 18 January 2021. - ^ \"For Kappy\". Telegraph. 24 May 2020. Archived from the original on 24 January 2021. Retrieved 18 January 2021. - ^ Harwell, Drew (8 February 2023). \"How deepfake videos are used to spread disinformation and harass people\". The Washington Post. Retrieved 13 August 2025. - ^ \"The AGT Judges Had Priceless Reactions to That Simon Cowell Singing Audition\". NBC Insider Official Site. 8 June 2022. Archived from the original on 29 August 2022. Retrieved 29 August 2022. - ^ Marr, Bernard. \"Can A Metaverse AI Win America's Got Talent? (And What That Means For The Industry)\". Forbes. Archived from the original on 30 August 2022. Retrieved 30 August 2022. - ^ Morales, Jowi (10 June 2022). \"Deepfakes Go Mainstream: How Metaphysic's AGT Entry Will Impact Entertainment\". MUO. Archived from the original on 10 June 2024. Retrieved 29 August 2022. - ^ Carter, Rebecca (1 June 2019). \"BGT viewers slam Simon Cowell for 'rude' and 'nasty' remark to contestant\". Entertainment Daily. Archived from the original on 31 August 2022. Retrieved 31 August 2022. - ^ Simon Cowell Sings on Stage?! Metaphysic Will Leave You Speechless | AGT 2022, archived from the original on 29 August 2022, retrieved 29 August 2022 - ^ Segarra, Edward. \"'AGT' judges Simon Cowell, Howie Mandel get 'deepfake' treatment by AI act Metaphysic: Watch here\". USA TODAY. Archived from the original on 31 August 2022. Retrieved 31 August 2022. - ^ Bowenbank, Starr (14 September 2022). \"Simon Cowell Duets With Elvis in Metaphysic's Latest Deepfake 'AGT' Performance: Watch\". Billboard. Archived from the original on 10 June 2024. Retrieved 15 September 2022. - ^ Zwiezen, Zack (18 January 2021). \"Website Lets You Make GLaDOS Say Whatever You Want\". Kotaku. Archived from the original on 17 January 2021. Retrieved 18 January 2021. - ^ Ruppert, Liana (18 January 2021). \"Make Portal's GLaDOS And Other Beloved Characters Say The Weirdest Things With This App\". Game Informer. Archived from the original on 18 January 2021. Retrieved 18 January 2021. - ^ Clayton, Natalie (19 January 2021). \"Make the cast of TF2 recite old memes with this AI text-to-speech tool\". PC Gamer. Archived from the original on 19 January 2021. Retrieved 19 January 2021. - ^ Sherman, Maria (3 December 2023). \"Kiss say farewell to live touring, become first US band to go virtual and become digital avatars\". AP News. Associated Press. Archived from the original on 1 January 2024. Retrieved 4 January 2024. - ^ a b c Cerullo, Megan (9 January 2024). \"AI-generated ads using Taylor Swift's likeness dupe fans with fake Le Creuset giveaway\". CBS News. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ a b Westfall, Chris. \"AI Deepfakes On The Rise Causing Billions In Fraud Losses\". Forbes. Retrieved 1 December 2024. - ^ a b c d e Hsu, Tiffany; Lu, Yiwen (9 January 2024). \"No, That's Not Taylor Swift Peddling Le Creuset Cookware\". The New York Times. p. B1. Retrieved 10 January 2024. - ^ a b c Taylor, Derrick Bryson (2 October 2023). \"Tom Hanks Warns of Dental Ad Using A.I. Version of Him\". The New York Times. ISSN 0362-4331. Archived from the original on 10 June 2024. Retrieved 12 October 2023. - ^ a b c Johnson, Kirsten (11 December 2023). \"Arizona woman falls victim to deepfake scam using celebrities on social media\". ABC 15 Arizona. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ a b Kulundu, Mary (4 January 2024). \"Deepfake videos of Elon Musk used in get-rich-quick scam\". Agence France-Presse. Archived from the original on 10 June 2024. Retrieved 10 January 2024. - ^ Esmael, Lisbet (3 January 2024). \"PH needs multifaceted approach vs 'deepfake' videos used to scam Pinoys\". CNN Philippines. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ Gerken, Tom (4 October 2023). \"MrBeast and BBC stars used in deepfake scam videos\". BBC News. Archived from the original on 10 June 2024. Retrieved 10 January 2024. - ^ a b Lim, Kimberly (29 December 2023). \"Singapore PM Lee warns of 'very convincing' deepfakes 'spreading disinformation' after fake video of him emerges\". South China Morning Post. Archived from the original on 9 January 2024. Retrieved 10 January 2024. - ^ Taylor, Josh (30 November 2023). \"Scammer paid Facebook 7c per view to circulate video of deepfake Jim Chalmers and Gina Rinehart\". The Guardian. Archived from the original on 10 June 2024. Retrieved 10 January 2024. - ^ Palmer, Joseph Olbrycht (14 December 2023). \"Deepfake of Australian treasury, central bank officials used to promote investment scam\". Agence France-Presse. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ a b c Koebler, Jason (9 January 2024). \"Deepfaked Celebrity Ads Promoting Medicare Scams Run Rampant on YouTube\". 404 Media. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ a b c Rosenblatt, Kalhan (3 October 2023). \"MrBeast calls TikTok ad showing an AI version of him a 'scam'\". NBC News. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ Koebler, Jason (25 January 2024). \"YouTube Deletes 1,000 Videos of Celebrity AI Scam Ads\". 404 Media. Archived from the original on 10 June 2024. Retrieved 2 February 2024. - ^ Bucci, Nino (27 November 2023). \"Dick Smith criticises Facebook after scammers circulate deepfake video ad\". The Guardian. Archived from the original on 10 June 2024. Retrieved 10 January 2024. - ^ Lomas, Natasha (7 July 2023). \"Martin Lewis warns over 'first' deepfake video scam ad circulating on Facebook\". TechCrunch. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ Lopatto, Elizabeth (3 January 2024). \"Fun new deepfake consequence: more convincing crypto scams\". The Verge. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ Spoto, Maia; Poritz, Isaiah (11 October 2023). \"MrBeast, Tom Hanks Stung by AI Scams as Law Rushes to Keep Pace\". Bloomberg Law. Archived from the original on 10 January 2024. Retrieved 10 January 2024. - ^ Statt, Nick (5 September 2019). \"Thieves are now using AI deepfakes to trick companies into sending them money\". Archived from the original on 15 September 2019. Retrieved 13 September 2019. - ^ Damiani, Jesse. \"A Voice Deepfake Was Used To Scam A CEO Out Of $243,000\". Forbes. Archived from the original on 14 September 2019. Retrieved 9 November 2019. - ^ \"Deepfakes, explained\". MIT Sloan. 5 March 2024. Archived from the original on 5 March 2024. Retrieved 6 March 2024. - ^ Schwartz, Christopher; Wright, Matthew (17 March 2023). \"Voice deepfakes are calling – here's what they are and how to avoid getting scammed\". The Conversation. Archived from the original on 4 January 2024. Retrieved 4 January 2024. - ^ a b c d Somers, Meredith (21 July 2020). \"Deepfakes, explained\". MIT Sloan. Archived from the original on 5 March 2024. Retrieved 6 March 2024. - ^ C, Kim (22 August 2020). \"Coffin Dance and More: The Music Memes of 2020 So Far\". Music Times. Archived from the original on 26 June 2021. Retrieved 26 August 2020. - ^ Sholihyn, Ilyas (7 August 2020). \"Someone deepfaked Singapore's politicians to lip-sync that Japanese meme song\". AsiaOne. Archived from the original on 3 September 2020. Retrieved 26 August 2020. - ^ a b c d \"Wenn Merkel plötzlich Trumps Gesicht trägt: die gefährliche Manipulation von Bildern und Videos\". Aargauer Zeitung. az Aargauer Zeitung. 3 February 2018. Archived from the original on 13 April 2019. Retrieved 9 April 2018. - ^ Gensing, Patrick. \"Deepfakes: Auf dem Weg in eine alternative Realität?\". Archived from the original on 11 October 2018. Retrieved 9 April 2018. - ^ Romano, Aja (18 April 2018). \"Jordan Peele's simulated Obama PSA is a double-edged warning against fake news\". Vox. Archived from the original on 11 June 2019. Retrieved 10 September 2018. - ^ Swenson, Kyle (11 January 2019). \"A Seattle TV station aired doctored footage of Trump's Oval Office speech. The employee has been fired\". The Washington Post. Archived from the original on 15 April 2019. Retrieved 11 January 2019. - ^ O'Sullivan, Donie (4 June 2019). \"Congress to investigate deepfakes as doctored Pelosi video causes stir\". CNN. Archived from the original on 29 June 2019. Retrieved 9 November 2019. - ^ \"#TellTheTruthBelgium\". Extinction Rebellion Belgium. Archived from the original on 25 April 2020. Retrieved 21 April 2020. - ^ Holubowicz, Gerald (15 April 2020). \"Extinction Rebellion s'empare des deepfakes\". Journalism.design (in French). Archived from the original on 29 July 2020. Retrieved 21 April 2020. - ^ Carnahan, Dustin (16 September 2020). \"Faked videos shore up false beliefs about Biden's mental health\". The Conversation. Archived from the original on 9 April 2022. Retrieved 9 April 2022. - ^ Parker, Ashley (7 September 2020). \"Trump and allies ramp up efforts to spread disinformation and fake news\". The Independent. Retrieved 9 April 2022. - ^ Christopher, Nilesh (18 February 2020). \"We've Just Seen the First Use of Deepfakes in an Indian Election Campaign\". Vice. Archived from the original on 19 February 2020. Retrieved 19 February 2020. - ^ \"Amabie: the mythical creature making a coronavirus comeback\". The Economist. 28 April 2020. ISSN 0013-0613. Archived from the original on 20 May 2021. Retrieved 3 June 2021. - ^ Roth, Andrew (22 April 2021). \"European MPs targeted by deepfake video calls imitating Russian opposition\". The Guardian. Archived from the original on 29 March 2022. Retrieved 29 March 2022. - ^ Ivanov, Maxim; Rothrock, Kevin (22 April 2021). \"Hello, this is Leonid Volkov* Using deepfake video and posing as Navalny's right-hand man, Russian pranksters fool Latvian politicians and journalists into invitation and TV interview\". Meduza. Archived from the original on 29 March 2022. Retrieved 29 March 2022. - ^ \"Dutch MPs in video conference with deep fake imitation of Navalny's Chief of Staff\". nltimes.nl. 24 April 2021. Archived from the original on 10 June 2024. Retrieved 29 March 2022. - ^ \"'Deepfake' Navalny Aide Targets European Lawmakers\". The Moscow Times. 23 April 2021. Archived from the original on 29 March 2022. Retrieved 29 March 2022. - ^ Vincent, James (30 April 2021). \"'Deepfake' that supposedly fooled European politicians was just a look-alike, say pranksters\". The Verge. Archived from the original on 29 March 2022. Retrieved 29 March 2022. - ^ Novak, Matt (8 May 2023). \"Viral Video Of Kamala Harris Speaking Gibberish Is Actually A Deepfake\". Forbes. Archived from the original on 18 July 2023. Retrieved 18 July 2023. - ^ \"PolitiFact - Kamala Harris wasn't slurring about today, yesterday or tomorrow. This video is altered\". Politifact. Archived from the original on 10 June 2024. Retrieved 18 July 2023. - ^ Shuham, Matt (8 June 2023). \"DeSantis Campaign Ad Shows Fake AI Images Of Trump Hugging Fauci\". HuffPost. Archived from the original on 10 June 2024. Retrieved 8 June 2023. - ^ GÖRGEN, Ahmet; SAYGINER, Can (1 August 2025). \"Deepfake Technology, Media, and National Security: The Case of the German Chancellor's Deepfake Video\". Security Strategies Journal / Güvenlik Stratejileri Dergisi. 21 (51): 279–297. doi:10.17752/guvenlikstrtj.1706990. ISSN 1305-4740. Retrieved 3 December 2025. - ^ \"AI Deepfakes Pose Major Threat to Elections in US and India\". The Washington Post. ISSN 0190-8286. Archived from the original on 20 May 2024. Retrieved 22 October 2024. - ^ Christopher, Nilesh (March 2024). \"Indian Voters Are Being Bombarded With Millions of Deepfakes. Political Candidates Approve\". Wired. Archived from the original on 12 March 2024. Retrieved 20 October 2024. - ^ \"What an Indian Deepfaker Tells Us About Global Election Security\". Bloomberg. Archived from the original on 1 April 2024. Retrieved 20 October 2024. - ^ Politi, Daniel; Alcoba, Natalie (2 July 2025). \"Argentina's President Joins A.I.-Fueled Smear Campaign Against Journalist\". New York Times. Retrieved 3 July 2025. - ^ \"Julia Mengolini se quebró por una violenta campaña de libertarios a la que se sumó Milei\". La Nación (in Spanish). Retrieved 28 June 2025. - ^ Smith, Colby (21 July 2025). \"Trump Live Updates: Epstein Fallout Continues as President Urges Base to Move on\". The New York Times. ISSN 0362-4331. Retrieved 21 July 2025. - ^ Margolis, Andrea (20 July 2025). \"Trump posts AI-generated video showing Obama getting arrested to 'YMCA'\". Fox News. Retrieved 21 July 2025. - ^ a b Roettgers, Janko (21 February 2018). \"Porn Producers Offer to Help Hollywood Take Down Deepfake Videos\". Variety. Archived from the original on 10 June 2019. Retrieved 28 February 2018. - ^ a b c Dickson, E. J. (7 October 2019). \"Deepfake Porn Is Still a Threat, Particularly for K-Pop Stars\". Rolling Stone. Archived from the original on 30 October 2019. Retrieved 9 November 2019. - ^ \"The State of Deepfake - Landscape, Threats, and Impact\" (PDF). Deeptrace. 1 October 2019. Archived (PDF) from the original on 9 August 2020. Retrieved 7 July 2020. - ^ Goggin, Benjamin (7 June 2019). \"From porn to 'Game of Thrones': How deepfakes and realistic-looking fake videos hit it big\". Business Insider. Archived from the original on 8 November 2019. Retrieved 9 November 2019. - ^ Lee, Dave (3 February 2018). \"'Fake porn' has serious consequences\". Archived from the original on 1 December 2019. Retrieved 9 November 2019. - ^ Cole, Samantha (19 June 2018). \"Gfycat's AI Solution for Fighting Deepfakes Isn't Working\". Vice. Archived from the original on 8 November 2019. Retrieved 9 November 2019. - ^ Zoe, Freni (24 November 2019). \"Deepfake Porn Is Here To Stay\". Medium. Archived from the original on 10 December 2019. Retrieved 10 December 2019. - ^ Cole, Samantha; Maiberg, Emanuel; Koebler, Jason (26 June 2019). \"This Horrifying App Undresses a Photo of Any Woman with a Single Click\". Vice. Archived from the original on 2 July 2019. Retrieved 2 July 2019. - ^ Cox, Joseph (9 July 2019). \"GitHub Removed Open Source Versions of DeepNude\". Vice Media. Archived from the original on 24 September 2020. Retrieved 14 July 2019. - ^ \"pic.twitter.com/8uJKBQTZ0o\". 27 June 2019. Archived from the original on 6 April 2021. Retrieved 3 August 2019. - ^ \"Hundreds of sexual deepfake ads using Emma Watson's face ran on Facebook and Instagram in the last two days\". NBC News. 7 March 2023. Archived from the original on 29 February 2024. Retrieved 8 March 2024. - ^ Filipovic, Jill (31 January 2024). \"Anyone could be a victim of 'deepfakes'. But there's a reason Taylor Swift is a target\". The Guardian. ISSN 0261-3077. Archived from the original on 10 June 2024. Retrieved 8 March 2024. - ^ Paris, Britt (October 2021). \"Configuring Fakes: Digitized Bodies, the Politics of Evidence, and Agency\". Social Media + Society. 7 (4) 20563051211062919. doi:10.1177/20563051211062919. ISSN 2056-3051. - ^ Damiani, Jesse. \"Chinese Deepfake App Zao Goes Viral, Faces Immediate Criticism Over User Data And Security Policy\". Forbes. Archived from the original on 14 September 2019. Retrieved 18 November 2019. - ^ \"Ahead of Irish and US elections, Facebook announces new measures against 'deepfake' videos\". Independent.ie. 7 January 2020. Archived from the original on 8 January 2020. Retrieved 7 January 2020. - ^ \"How Belgian visual expert Chris Ume masterminded Tom Cruise's deepfakes\". The Statesman. 6 March 2021. Archived from the original on 24 August 2022. Retrieved 24 August 2022. - ^ Metz, Rachel. \"How a deepfake Tom Cruise on TikTok turned into a very real AI company\". CNN. Archived from the original on 10 June 2024. Retrieved 17 March 2022. - ^ Corcoran, Mark; Henry, Matt (23 June 2021). \"This is not Tom Cruise. That's what has security experts so worried\". ABC News. Archived from the original on 28 March 2022. Retrieved 28 March 2022. - ^ Reuters, 15 July 2020, Deepfake Used to Attack Activist Couple Shows New Disinformation Frontier Archived 26 September 2020 at the Wayback Machine - ^ 972 Magazine, 12 August 2020, \"'Leftists for Bibi'? Deepfake Pro-Netanyahu Propaganda Exposed: According to a Series of Facebook Posts, the Israeli Prime Minister is Winning over Left-Wing Followers--Except that None of the People in Question Exist\" Archived 14 August 2020 at the Wayback Machine - ^ The Seventh Eye, 9 June 2020, הפורנוגרפיה של ההסתהתומכי נתניהו ממשיכים להפיץ פוסטים מזויפים בקבוצות במדיה החברתית • לצד הטרלות מעלות גיחוך מופצות תמונות שקריות על מנת להגביר את השנאה והפילוג בחברה הישראלית Archived 18 August 2020 at the Wayback Machine - ^ a b \"Perfect Deepfake Tech Could Arrive Sooner Than Expected\". www.wbur.org. 2 October 2019. Archived from the original on 30 October 2019. Retrieved 9 November 2019. - ^ Vincent, James. \"Deepfakes are becoming more realistic — and harder to detect\". The Verge. Retrieved 13 August 2025. - ^ Sonnemaker, Tyler. \"As social media platforms brace for the incoming wave of deepfakes, Google's former 'fraud czar' predicts the biggest danger is that deepfakes will eventually become boring\". Business Insider. Archived from the original on 14 April 2021. Retrieved 14 April 2021. - ^ a b c d e Vaccari, Cristian; Chadwick, Andrew (January 2020). \"Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News\". Social Media + Society. 6 (1): 205630512090340. doi:10.1177/2056305120903408. ISSN 2056-3051. S2CID 214265502. - ^ a b Pawelec, M (2022). \"Deepfakes and Democracy (Theory): How Synthetic Audio-Visual Media for Disinformation and Hate Speech Threaten Core Democratic Functions\". Digital Society: Ethics, Socio-legal and Governance of Digital Technology. 1 (2) 19. doi:10.1007/s44206-022-00010-6. PMC 9453721. PMID 36097613. - ^ a b c Bateman, Jon (2020). \"Summary\". Deepfakes and Synthetic Media in the Financial System: 1–2. Archived from the original on 20 April 2021. Retrieved 28 October 2020. - ^ Kelion, Leo (September 2020). \"Deepfake detection tool unveiled by Microsoft\". BBC News. Archived from the original on 14 April 2021. Retrieved 15 April 2021. - ^ Cohen, Ariel; Rimon, Inbal; Aflalo, Eran; Permuter, Haim H. (June 2022). \"A study on data augmentation in voice anti-spoofing\". Speech Communication. 141: 56–67. arXiv:2110.10491. doi:10.1016/j.specom.2022.04.005. S2CID 239050551. - ^ a b c Manke, Kara (18 June 2019). \"Researchers use facial quirks to unmask 'deepfakes'\". Berkeley News. Archived from the original on 9 November 2019. Retrieved 9 November 2019. - ^ Farid, Hany (1 December 2006). \"Digital Doctoring: How to Tell the Real from the Fake\". Significance. 3 (4): 162–166. doi:10.1111/j.1740-9713.2006.00197.x. S2CID 13861938. - ^ \"Join the Deepfake Detection Challenge (DFDC)\". deepfakedetectionchallenge.ai. Archived from the original on 12 January 2020. Retrieved 8 November 2019. - ^ \"Deepfake Detection Challenge Results: An open initiative to advance AI\". ai.facebook.com. Archived from the original on 29 October 2020. Retrieved 30 September 2022. - ^ Groh, Matthew; Epstein, Ziv; Firestone, Chaz; Picard, Rosalind (2022). \"Deepfake detection by human crowds, machines, and machine-informed crowds\". Proceedings of the National Academy of Sciences. 119 (1) e2110013119. arXiv:2105.06496. Bibcode:2022PNAS..11910013G. doi:10.1073/pnas.2110013119. PMC 8740705. PMID 34969837. - ^ Hu, Shu; Li, Yuezun; Lyu, Siwei (12 October 2020). \"Exposing GAN-Generated Faces Using Inconsistent Corneal Specular Highlights\". arXiv:2009.11924 [cs.CV]. - ^ Boháček, M; Farid, H (29 November 2022). \"Protecting world leaders against deep fakes using facial, gestural, and vocal mannerisms\". Proceedings of the National Academy of Sciences of the United States of America. 119 (48) e2216035119. Bibcode:2022PNAS..11916035B. doi:10.1073/pnas.2216035119. PMC 9860138. PMID 36417442. - ^ a b \"Google Scholar\". scholar.google.com. Retrieved 30 April 2022. - ^ a b Masi, Iacopo; Killekar, Aditya; Mascarenhas, Royston Marian; Gurudatt, Shenoy Pratik; Abdalmageed, Wael (2020). Two-branch recurrent network for isolating deepfakes in videos. Lecture Notes in Computer Science. Vol. 12352. pp. 667–684. arXiv:2008.03412. doi:10.1007/978-3-030-58571-6_39. ISBN 978-3-030-58570-9. Archived from the original on 10 June 2024. Retrieved 30 April 2022. - ^ a b c \"The Blockchain Solution to Our Deepfake Problems\". Wired. ISSN 1059-1028. Archived from the original on 7 November 2019. Retrieved 9 November 2019. - ^ a b Leetaru, Kalev. \"Why Digital Signatures Won't Prevent Deep Fakes But Will Help Repressive Governments\". Forbes. Archived from the original on 14 April 2021. Retrieved 17 February 2021. - ^ \"To Uncover a Deepfake Video Call, Ask the Caller to Turn Sideways\". Metaphysic. 8 August 2022. Archived from the original on 26 August 2022. Retrieved 24 August 2022. - ^ Helmus, Todd (2022). \"A Primer\". Artificial Intelligence, Deepfakes, and Disinformation: A Primer. RAND Corporation. Retrieved 13 August 2025. - ^ Romero-Moreno, Felipe (23 June 2025). \"Deepfake detection in generative AI: A legal framework proposal to protect human rights\". Computer Law & Security Review. 58 106162. doi:10.1016/j.clsr.2025.106162. - ^ a b c d Karnouskos, Stamatis (September 2020). \"Artificial Intelligence in Digital Media: The Era of Deepfakes\". IEEE Transactions on Technology and Society. 1 (3): 138–147. Bibcode:2020ITTS....1..138K. doi:10.1109/TTS.2020.3001312. ISSN 2637-6415. - ^ a b c Turós, Mátyás; Kenyeres, Attila Zoltán; Szűts, Zoltán (September 2024). \"Fake video detection among secondary school students: The impact of sociocultural, media literacy and media use factors\". Telematics and Informatics Reports. 15 100160. doi:10.1016/j.teler.2024.100160. - ^ Ahmed, Saifuddin (May 2023). \"Navigating the maze: Deepfakes, cognitive ability, and social media news skepticism\". New Media & Society. 25 (5): 1108–1129. doi:10.1177/14614448211019198. ISSN 1461-4448. - ^ \"Kate Middleton's ring mysteriously vanishes, raises more AI concerns\". MSN. 25 March 2024. Archived from the original on 10 June 2024. Retrieved 19 May 2024. - ^ Hindustan Times (5 April 2024). \"'Kate's cancer admission is fake', Meghan Markle's fan and UCLA director, Johnathan Perkins, floats conspiracy theory\". The Hindustan Times. Archived from the original on 10 June 2024. Retrieved 19 May 2024. - ^ a b c d Hameleers, Michael; van der Meer, Toni G. L. A.; Dobber, Tom (February 2024). \"They Would Never Say Anything Like This! Reasons To Doubt Political Deepfakes\". European Journal of Communication. 39 (1): 56–70. doi:10.1177/02673231231184703. ISSN 0267-3231. - ^ Salubi, Oghenere (16 October 2025). \"Artificial Intelligence, Misinformation, and Libraries: A New Frontier for Information Professionals\". 88th Annual Meeting of the Association for Information Science & Technology. doi:10.1002/pra2.1279. Retrieved 4 November 2025. - ^ a b c d Dobber, Tom; Metoui, Nadia; Trilling, Damian; Helberger, Natali; de Vreese, Claes (January 2021). \"Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes?\". The International Journal of Press/Politics. 26 (1): 69–91. doi:10.1177/1940161220944364. ISSN 1940-1612. - ^ Salvi, Alessandro; Filipova, Raina; Hogeveen, Bryan; Karásková, Ivana; Pawlak, Patryk; Salvi, Andrea (2024). THE ATTACK OF THE CLONES: Deepfakes and the evolving landscape of disinformation. European Union Institute for Security Studies (EUISS). pp. 32–40. Retrieved 13 August 2025. - ^ \"Deepfakes, Elections, and Shrinking the Liar's Dividend | Brennan Center for Justice\". www.brennancenter.org. 8 February 2024. Retrieved 10 December 2025. - ^ a b \"AI-generated images of Trump being arrested circulate on social media\". AP News. 21 March 2023. Archived from the original on 10 June 2024. Retrieved 10 October 2023. - ^ Fagan, Kaylee. \"A viral video that appeared to show Obama calling Trump a 'dips---' shows a disturbing new trend called 'deepfakes'\". Business Insider. Archived from the original on 22 September 2020. Retrieved 3 November 2020. - ^ a b \"The rise of the deepfake and the threat to democracy\". The Guardian. Archived from the original on 1 November 2020. Retrieved 3 November 2020. - ^ \"Trump shares deepfake photo of himself praying as AI images of arrest spread online\". The Independent. 24 March 2023. Archived from the original on 28 May 2023. Retrieved 16 June 2023. - ^ Towers-Clark, Charles. \"Mona Lisa And Nancy Pelosi: The Implications Of Deepfakes\". Forbes. Archived from the original on 23 November 2020. Retrieved 7 October 2020. - ^ \"What Is The Difference Between A Deepfake And Shallowfake?\". 21 April 2020. Archived from the original on 26 June 2022. Retrieved 5 December 2021. - ^ \"Gallery: 'Spectre' Launches ( Press Release)\". Bill Posters. 29 May 2019. Archived from the original on 10 June 2024. Retrieved 15 May 2024. - ^ Cole, Samantha (11 June 2019). \"This Deepfake of Mark Zuckerberg Tests Facebook's Fake Video Policies\". Vice. Archived from the original on 10 June 2024. Retrieved 15 May 2024. - ^ a b c \"Deepfake Putin is here to warn Americans about their self-inflicted doom\". MIT Technology Review. Archived from the original on 30 October 2020. Retrieved 7 October 2020. - ^ Sonne, Paul (5 June 2023). \"Fake Putin Speech Calling for Martial Law Aired in Russia\". The New York Times. Archived from the original on 10 June 2024. Retrieved 6 June 2023. - ^ Allyn, Bobby (16 March 2022). \"Deepfake video of Zelenskyy could be 'tip of the iceberg' in info war, experts warn\". NPR. Archived from the original on 29 March 2022. Retrieved 17 March 2022. - ^ Satariano, Adam; Mozur, Paul (7 February 2023). \"The People Onscreen Are Fake. The Disinformation Is Real\". The New York Times. Archived from the original on 10 June 2024. Retrieved 10 February 2023. - ^ \"Pope Francis in Balenciaga deepfake fools millions: 'Definitely scary'\". New York Post. 28 March 2023. Archived from the original on 10 June 2024. Retrieved 16 June 2023. - ^ Lu, Donna (31 March 2023). \"Misinformation, mistakes and the Pope in a puffer: what rapidly evolving AI can – and can't – do\". The Guardian. Archived from the original on 10 June 2024. Retrieved 16 June 2023. - ^ Murphy, Heather Tal (29 March 2023). \"The Pope in a Coat Is Not From a Holy Place\". Slate. Archived from the original on 10 June 2024. Retrieved 16 June 2023. - ^ \"Deepfake audio of Sir Keir Starmer released on first day of Labour conference\". Sky News. Retrieved 29 May 2024. - ^ \"Woman in deepfake video with Rashmika Mandanna's face breaks silence: I'm deeply disturbed and upset by what is happening\". The Times of India. 9 November 2023. ISSN 0971-8257. Archived from the original on 23",
    "text_length": 120000,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:19.226106"
  },
  {
    "id": "page_19",
    "url": "https://en.wikipedia.org/wiki/Machine_learning_in_earth_sciences",
    "domain": "en.wikipedia.org",
    "title": "Machine learning in earth sciences - Wikipedia",
    "text": "Machine learning in earth sciences | Part of a series on | | Artificial intelligence (AI) | |---| Applications of machine learning (ML) in earth sciences include geological mapping, gas leakage detection and geological feature identification. Machine learning is a subdiscipline of artificial intelligence aimed at developing programs that are able to classify, cluster, identify, and analyze vast and complex data sets without the need for explicit programming to do so.[1] Earth science is the study of the origin, evolution, and future[2] of the Earth. The earth's system can be subdivided into four major components including the solid earth, atmosphere, hydrosphere, and biosphere.[3] A variety of algorithms may be applied depending on the nature of the task. Some algorithms may perform significantly better than others for particular objectives. For example, convolutional neural networks (CNNs) are good at interpreting images, whilst more general neural networks may be used for soil classification,[4] but can be more computationally expensive to train than alternatives such as support vector machines. The range of tasks to which ML (including deep learning) is applied has been ever-growing in recent decades, as has the development of other technologies such as unmanned aerial vehicles (UAVs),[5] ultra-high resolution remote sensing technology, and high-performance computing.[6] This has led to the availability of large high-quality datasets and more advanced algorithms. Significance [edit]Complexity of earth science [edit]Problems in earth science are often complex.[7] It is difficult to apply well-known and described mathematical models to the natural environment, therefore machine learning is commonly a better alternative for such non-linear problems.[8] Ecological data are commonly non-linear and consist of higher-order interactions, and together with missing data, traditional statistics may underperform as unrealistic assumptions such as linearity are applied to the model.[9][10] A number of researchers found that machine learning outperforms traditional statistical models in earth science, such as in characterizing forest canopy structure,[11] predicting climate-induced range shifts,[12] and delineating geologic facies.[13] Characterizing forest canopy structure enables scientists to study vegetation response to climate change.[14] Predicting climate-induced range shifts enable policy makers to adopt suitable conversation method to overcome the consequences of climate change.[12] Delineating geologic facies helps geologists to understand the geology of an area, which is essential for the development and management of an area.[15] Inaccessible data [edit]In Earth Sciences, some data are often difficult to access or collect, therefore inferring data from data that are easily available by machine learning method is desirable.[10] For example, geological mapping in tropical rainforests is challenging because the thick vegetation cover and rock outcrops are poorly exposed.[16] Applying remote sensing with machine learning approaches provides an alternative way for rapid mapping without the need of manually mapping in the unreachable areas.[16] Reduce time costs [edit]Machine learning can also reduce the efforts done by experts, as manual tasks of classification and annotation etc. are the bottlenecks in the workflow of the research of earth science.[10] Geological mapping, especially in a vast, remote area is labour, cost and time-intensive with traditional methods.[17] Incorporation of remote sensing and machine learning approaches can provide an alternative solution to eliminate some field mapping needs.[17] Consistent and bias-free [edit]Consistency and bias-free is also an advantage of machine learning compared to manual works by humans. In research comparing the performance of human and machine learning in the identification of dinoflagellates, machine learning is found to be not as prone to systematic bias as humans.[18] A recency effect that is present in humans is that the classification often biases towards the most recently recalled classes.[18] In a labelling task of the research, if one kind of dinoflagellates occurs rarely in the samples, then expert ecologists commonly will not classify it correctly.[18] The systematic bias strongly deteriorate the classification accuracies of humans.[18] Optimal machine learning algorithm [edit]The extensive usage of machine learning in various fields has led to a wide range of algorithms of learning methods being applied. Choosing the optimal algorithm for a specific purpose can lead to a significant boost in accuracy:[19] for example, the lithological mapping of gold-bearing granite-greenstone rocks in Hutti, India with AVIRIS-NG hyperspectral data, shows more than 10% difference in overall accuracy between using support vector machines (SVMs) and random forest.[20] Some algorithms can also reveal hidden important information: white box models are transparent models, the outputs of which can be easily explained, while black box models are the opposite.[19] For example, although an SVM yielded the best result in landslide susceptibility assessment accuracy, the result cannot be rewritten in the form of expert rules that explain how and why an area was classified as that specific class.[7] In contrast, decision trees are transparent and easily understood, and the user can observe and fix the bias if any is present in such models.[7] If computational resource is a concern, more computationally demanding learning methods such as deep neural networks are less preferred, despite the fact that they may outperform other algorithms, such as in soil classification.[4] Usage [edit]Mapping [edit]Geological or lithological mapping and mineral prospectivity mapping [edit]Geological or lithological mapping produces maps showing geological features and geological units. Mineral prospectivity mapping utilizes a variety of datasets such as geological maps and aeromagnetic imagery to produce maps that are specialized for mineral exploration.[21] Geological, lithological, and mineral prospectivity mapping can be carried out by processing data with ML techniques, with the input of spectral imagery obtained from remote sensing and geophysical data.[22] Spectral imaging is also used – the imaging of wavelength bands in the electromagnetic spectrum, while conventional imaging captures three wavelength bands (red, green, blue) in the electromagnetic spectrum.[23] Random forests and SVMs are some algorithms commonly used with remotely-sensed geophysical data, while Simple Linear Iterative Clustering-Convolutional Neural Network (SLIC-CNN)[5] and Convolutional Neural Networks (CNNs)[17] are commonly applied to aerial imagery. Large scale mapping can be carried out with geophysical data from airborne and satellite remote sensing geophysical data,[20] and smaller-scale mapping can be carried out with images from Unmanned Aerial Vehicles (UAVs) for higher resolution.[5] Vegetation cover is one of the major obstacles for geological mapping with remote sensing, as reported in various research, both in large-scale and small-scale mapping. Vegetation affects the quality of spectral images,[22] or obscures the rock information in aerial images.[5] | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Lithological Mapping of Gold-bearing granite-greenstone rocks[20] | AVIRIS-NG hyperspectral data | Hutti, India | Linear Discriminant Analysis (LDA), | Support Vector Machine (SVM) outperforms the other Machine Learning Algorithms (MLAs) | | Lithological Mapping in the Tropical Rainforest[16] | Magnetic Vector Inversion, Ternary RGB map, Shuttle Radar Topography Mission (SRTM), false color (RGB) of Landsat 8 combining bands 4, 3 and 2 | Cinzento Lineament, Brazil | Random Forest | Two predictive maps were generated: (1) Map generated with remote sensing data only has a 52.7% accuracy when compared to the geological map, but several new possible lithological units are identified (2) Map generated with remote sensing data and spatial constraints has a 78.7% accuracy but no new possible lithological units are identified | | Geological Mapping for mineral exploration[24] | Airborne polarimetric Terrain Observation with Progressive Scans SAR (TopSAR), geophysical data | Western Tasmania | Random Forest | Low reliability of TopSAR for geological mapping, but accurate with geophysical data. | | Geological and Mineralogical mapping[citation needed] | Multispectral and hyperspectral satellite data | Central Jebilet, Morocco | Support Vector Machine (SVM) | The accuracy of using hyperspectral data for classifying is slightly higher than that using multispectral data, obtaining 93.05% and 89.24% respectively, showing that machine learning is a reliable tool for mineral exploration. | | Integrating Multigeophysical Data into a Cluster Map[25] | Airborne magnetic, frequency electromagnetic, radiometric measurements, ground gravity measurements | Trøndelag, Mid-Norway | Random Forest | The cluster map produced has a satisfactory relationship with the existing geological map but with minor misfits. | | High-Resolution Geological Mapping with Unmanned Aerial Vehicle (UAV)[5] | Ultra-resolution RGB images | Taili waterfront, Liaoning Province, China | Simple Linear Iterative Clustering-Convolutional Neural Network (SLIC-CNN) | The result is satisfactory in mapping major geological units but showed poor performance in mapping pegmatites, fine-grained rocks and dykes. UAVs were unable to collect rock information where the rocks were not exposed. | | Surficial Geology Mapping[17] Remote Predictive Mapping (RPM) | Aerial Photos, Landsat Reflectance, High-Resolution Digital Elevation Data | South Rae Geological Region, Northwest Territories, Canada | Convolutional Neural Networks (CNN), Random Forest | The resulting accuracy of CNN was 76% in the locally trained area, while 68% for an independent test area. The CNN achieved a slightly higher accuracy of 4% than the Random Forest. | Landslide susceptibility and hazard mapping [edit]Landslide susceptibility refers to the probability of landslide of a certain geographical location, which is dependent on local terrain conditions.[26] Landslide susceptibility mapping can highlight areas prone to landslide risks, which is useful for urban planning and disaster management.[7] Such datasets for ML algorithms usually include topographic information, lithological information, satellite images, etc., and some may include land use, land cover, drainage information, and vegetation cover[7][27][28][29] according to the study requirements. As usual, for training an ML model for landslide susceptibility mapping, training and testing datasets are required.[7] There are two methods of allocating datasets for training and testing: one is to randomly split the study area for the datasets; another is to split the whole study into two adjacent parts for the two datasets. To test classification models, the common practice is to split the study area randomly;[7][30] however, it is more useful if the study area can be split into two adjacent parts so that an automation algorithm can carry out mapping of a new area with the input of expert-processed data of adjacent land.[7] | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Landslide Susceptibility Assessment[7] | Digital Elevation Model (DEM), Geological Map, 30m Landsat Imagery | Fruška Gora Mountain, Serbia | Support Vector Machine (SVM), | Support Vector Machine (SVM) outperforms others | | Landslide Susceptibility Mapping[30] | ASTER satellite-based geomorphic data, geological maps | Honshu Island, Japan | Artificial Neural Network (ANN) | Accuracy greater than 90% for determining the probability of landslide. | | Landslide Susceptibility Zonation through ratings[27] | Spatial data layers with slope, aspect, relative relief, lithology, structural features, land use, land cover, drainage density | Parts of Chamoli and Rudraprayag districts of the State of Uttarakhand, India | Artificial Neural Network (ANN) | The AUC of this approach reaches 0.88. This approach generated an accurate assessment of landslide risks. | | Regional Landslide Hazard Analysis[28] | Topographic slope, aspect, and curvature; distance from drainage, lithology, distance from lineament, land cover from TM satellite images, vegetation index (NDVI), precipitation data | Eastern Selangor state, Malaysia | Artificial Neural Network (ANN) | The approach achieved 82.92% accuracy of prediction. | Feature identification and detection [edit]Discontinuity analyses [edit]Discontinuities such as fault planes and bedding planes have important implications in civil engineering.[31] Rock fractures can be recognized automatically by machine learning through photogrammetric analysis, even with the presence of interfering objects such as vegetation.[32] In ML training for classifying images, data augmentation is a common practice to avoid overfitting and increase the training dataset size and variability.[32] For example, in a study of rock fracture recognition, 68 images for training and 23 images for testing were prepared via random splitting.[32] Data augmentation was performed, increasing the training dataset size to 8704 images by flipping and random cropping.[32] The approach was able to recognize rock fractures accurately in most cases.[32] Both the negative prediction value (NPV) and the specificity were over 0.99.[32] This demonstrated the robustness of discontinuity analyses with machine learning. | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Recognition of Rock Fractures[32] | Rock images collected in field survey | Gwanak Mountain and Bukhan Mountain, Seoul, Korea and Jeongseon-gun, Gangwon-do, Korea | Convolutional Neural Network (CNN) | The approach was able to recognize the rock fractures accurately in most cases. The NPV and the specificity were over 0.99. | Carbon dioxide leakage detection [edit]Quantifying carbon dioxide leakage from a geological sequestration site has gained increased attention as the public is interested in whether carbon dioxide is stored underground safely and effectively.[33] Carbon dioxide leakage from a geological sequestration site can be detected indirectly with the aid of remote sensing and an unsupervised clustering algorithm such as Iterative Self-Organizing Data Analysis Technique (ISODATA).[34] The increase in soil CO2 concentration causes a stress response for plants by inhibiting plant respiration, as oxygen is displaced by carbon dioxide.[35] The vegetation stress signal can be detected with the Normalized Difference Red Edge Index (NDRE).[35] The hyperspectral images are processed by the unsupervised algorithm, clustering pixels with similar plant responses.[35] The hyperspectral information in areas with known CO2 leakage is extracted so that areas with leakage can be matched with the clustered pixels with spectral anomalies.[35] Although the approach can identify CO2 leakage efficiently, there are some limitations that require further study.[35] The NDRE may not be accurate due to reasons like higher chlorophyll absorption, variation in vegetation, and shadowing effects; therefore, some stressed pixels can be incorrectly classed as healthy.[35] Seasonality, groundwater table height may also affect the stress response to CO2 of the vegetation.[35] | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Detection of CO2 leak from a geologic sequestration site[34] | Aerial hyperspectral imagery | The Zero Emissions Research and Technology (ZERT), US | Iterative Self-Organizing Data Analysis Technique (ISODATA) method | The approach was able to detect areas with CO2 leaks however other factors like the growing seasons of the vegetation also interfere with the results. | Quantification of water inflow [edit]The rock mass rating (RMR)[36] system is a widely adopted rock mass classification system by geomechanical means with the input of six parameters. The amount of water inflow is one of the inputs of the classification scheme, representing the groundwater condition. Quantification of the water inflow in the faces of a rock tunnel was traditionally carried out by visual observation in the field, which is labour and time-consuming, and fraught with safety concerns.[37] Machine learning can determine water inflow by analyzing images taken on the construction site.[37] The classification of the approach mostly follows the RMR system, but combining damp and wet states, as it is difficult to distinguish only by visual inspection.[37][36] The images were classified into the non-damaged state, wet state, dripping state, flowing state, and gushing state.[37] The accuracy of classifying the images was approximately 90%.[37] | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Quantification of water inflow in rock tunnel faces[37] | Images of water inflow | - | Convolutional Neural Network (CNN) | The approach achieved a mean accuracy of 93.01%. | Classification [edit]Soil classification [edit]The most popular cost-effective method od soil investigation method is cone penetration testing (CPT).[38] The test is carried out by pushing a metallic cone through the soil: the force required to push at a constant rate is recorded as a quasi-continuous log.[4] Machine learning can classify soil with the input of CPT data.[4] In an attempt to classify with ML, there are two tasks required to analyze the data, namely segmentation and classification.[4] Segmentation can be carried out with the Constraint Clustering and Classification (CONCC) algorithm to split a single series data into segments.[4] Classification can then be carried out by algorithms such as decision trees, SVMs, or neural networks.[4] | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Soil classification[4] | Cone Penetration Test (CPT) logs | - | Decision Trees, Artificial Neural Network (ANN), Support Vector Machine | The Artificial Neural Network (ANN) outperformed the others in classifying humus clay and peat, while decision trees outperformed the others in classifying clayey peat. SVMs gave the poorest performance among the three. | Geological structure classification [edit]Exposed geological structures such as anticlines, ripple marks, and xenoliths can be identified automatically with deep learning models.[39] Research has demonstrated that three-layer CNNs and transfer learning have strong accuracy (about 80% and 90% respectively), while others like k-nearest neighbors (k-NN), regular neural nets, and extreme gradient boosting (XGBoost) have low accuracies (ranging from 10% - 30%).[39] The grayscale images and colour images were both tested, with the accuracy difference being little, implying that colour is not very important in identifying geological structures.[39] | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Geological structures classification[39] | Images of geological structures | - | k-nearest neighbors (k-NN), Artificial Neural Network (ANN), Extreme Gradient Boosting (XGBoost), three-layer Convolutional Neural Network (CNN), transfer learning | Three-layer Convolutional Neural Network (CNN) and Transfer Learning reached accuracies of about 80% and 90% respectively, while others were low (10% to 30%). | Forecast and predictions [edit]Earthquake early warning systems and forecasting [edit]Earthquake warning systems are often vulnerable to local impulsive noise, therefore giving out false alerts.[40] False alerts can be eliminated by discriminating the earthquake waveforms from noise signals with the aid of ML methods. The method consists of two parts, the first being unsupervised learning with a generative adversarial network (GAN) to learn and extract features of first-arrival P-waves, and the second being use of a random forest to discriminate P-waves. This approach achieved 99.2% in recognizing P-waves, and can avoid false triggers by noise signals with 98.4% accuracy.[40] Earthquakes can be produced in a laboratory settings to mimic real-world ones. With the help of machine learning, the patterns of acoustic signals as precursors for earthquakes can be identified. Predicting the time remaining before failure was demonstrated in a study with continuous acoustic time series data recorded from a fault. The algorithm applied was a random forest, trained with a set of slip events, performing strongly in predicting the time to failure. It identified acoustic signals to predict failures, with one of them being previously unidentified. Although this laboratory earthquake is not as complex as a natural one, progress was made that guides future earthquake prediction work.[41] | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Discriminating earthquake waveforms[40] | Earthquake dataset | Southern California and Japan | Generative adversarial network (GAN), random forest | This approach can recognise P waves with 99.2% accuracy and avoid false triggers by noise signals with 98.4% accuracy. | | Predicting time remaining for next earthquake[41] | Continuous acoustic time series data | - | Random Forest | The R2 value of the prediction reached 0.89, which demonstrated excellent performance. | Streamflow discharge prediction [edit]Real-time streamflow data is integral for decision making (e.g., evacuations, or regulation of reservoir water levels during flooding).[42] Streamflow data can be estimated by data provided by stream gauges, which measure the water level of a river. However, water and debris from flooding may damage stream gauges, resulting in lack of essential real-time data. The ability of machine learning to infer missing data[10] enables it to predict streamflow with both historical stream gauge data and real-time data. Streamflow Hydrology Estimate using Machine Learning (SHEM) is a model that can serve this purpose. To verify its accuracies, the prediction result was compared with the actual recorded data, and the accuracies were found to be between 0.78 and 0.99. | Objective | Input dataset | Location | Machine Learning Algorithms (MLAs) | Performance | |---|---|---|---|---| | Streamflow Estimate with data missing[43] | Streamgage data from NWIS-Web | Four diverse watersheds in Idaho, US and Washington, US | Random Forests | The estimates correlated well to the historical data of the discharges. The accuracy ranges from 0.78 to 0.99. | Challenge [edit]Inadequate training data [edit]An adequate amount of training and validation data is required for machine learning.[10] However, some very useful products like satellite remote sensing data only have decades of data since the 1970s. If one is interested in the yearly data, then only less than 50 samples are available.[44] Such amount of data may not be adequate. In a study of automatic classification of geological structures, the weakness of the model is the small training dataset, even though with the help of data augmentation to increase the size of the dataset.[39] Another study of predicting streamflow found that the accuracies depend on the availability of sufficient historical data, therefore sufficient training data determine the performance of machine learning.[43] Inadequate training data may lead to a problem called overfitting. Overfitting causes inaccuracies in machine learning[45] as the model learns about the noise and undesired details. Limited by data input [edit]Machine learning cannot carry out some of the tasks as a human does easily. For example, in the quantification of water inflow in rock tunnel faces by images for Rock Mass Rating system (RMR),[37] the damp and the wet state was not classified by machine learning because discriminating the two only by visual inspection is not possible. In some tasks, machine learning may not able to fully substitute manual work by a human. Black-box operation [edit]In many machine learning algorithms, for example, Artificial Neural Network (ANN), it is considered as 'black box' approach as clear relationships and descriptions of how the results are generated in the hidden layers are unknown.[46] 'White-box' approach such as decision tree can reveal the algorithm details to the users.[47] If one wants to investigate the relationships, such 'black-box' approaches are not suitable.[48] However, the performances of 'black-box' algorithms are usually better.[49] References [edit]- ^ Mueller, J. P., & Massaron, L. (2021). Machine learning for dummies. John Wiley & Sons. - ^ Resources., National Academies Press (U.S.) National Research Council (U.S.). Commission on Geosciences, Environment, and (2001). Basic research opportunities in earth science. National Academies Press. OCLC 439353646. {{cite book}} : CS1 maint: multiple names: authors list (link) - ^ Miall, A.D. (December 1995). \"The blue planet: An introduction to earth system science\". Earth-Science Reviews. 39 (3–4): 269–271. doi:10.1016/0012-8252(95)90023-3. ISSN 0012-8252. - ^ a b c d e f g h Bhattacharya, B.; Solomatine, D.P. (March 2006). \"Machine learning in soil classification\". Neural Networks. 19 (2): 186–195. doi:10.1016/j.neunet.2006.01.005. ISSN 0893-6080. PMID 16530382. S2CID 14421859. - ^ a b c d e Sang, Xuejia; Xue, Linfu; Ran, Xiangjin; Li, Xiaoshun; Liu, Jiwen; Liu, Zeyu (2020-02-05). \"Intelligent High-Resolution Geological Mapping Based on SLIC-CNN\". ISPRS International Journal of Geo-Information. 9 (2): 99. Bibcode:2020IJGI....9...99S. doi:10.3390/ijgi9020099. ISSN 2220-9964. - ^ Si, Lei; Xiong, Xiangxiang; Wang, Zhongbin; Tan, Chao (2020-03-14). \"A Deep Convolutional Neural Network Model for Intelligent Discrimination between Coal and Rocks in Coal Mining Face\". Mathematical Problems in Engineering. 2020: 1–12. doi:10.1155/2020/2616510. ISSN 1024-123X. - ^ a b c d e f g h i Marjanović, Miloš; Kovačević, Miloš; Bajat, Branislav; Voženílek, Vít (November 2011). \"Landslide susceptibility assessment using SVM machine learning algorithm\". Engineering Geology. 123 (3): 225–234. Bibcode:2011EngGe.123..225M. doi:10.1016/j.enggeo.2011.09.006. ISSN 0013-7952. - ^ Merembayev, Timur; Yunussov, Rassul; Yedilkhan, Amirgaliyev (November 2018). \"Machine Learning Algorithms for Classification Geology Data from Well Logging\". 2018 14th International Conference on Electronics Computer and Computation (ICECCO). IEEE. pp. 206–212. doi:10.1109/icecco.2018.8634775. ISBN 978-1-7281-0132-3. S2CID 59620103. - ^ De'ath, Glenn; Fabricius, Katharina E. (November 2000). \"Classification and Regression Trees: A Powerful Yet Simple Technique for Ecological Data Analysis\". Ecology. 81 (11): 3178–3192. doi:10.1890/0012-9658(2000)081[3178:cartap]2.0.co;2. ISSN 0012-9658. - ^ a b c d e Thessen, Anne (2016-06-27). \"Adoption of Machine Learning Techniques in Ecology and Earth Science\". One Ecosystem. 1 e8621. Bibcode:2016OneEc...1E8621T. doi:10.3897/oneeco.1.e8621. ISSN 2367-8194. - ^ Zhao, Kaiguang; Popescu, Sorin; Meng, Xuelian; Pang, Yong; Agca, Muge (August 2011). \"Characterizing forest canopy structure with lidar composite metrics and machine learning\". Remote Sensing of Environment. 115 (8): 1978–1996. Bibcode:2011RSEnv.115.1978Z. doi:10.1016/j.rse.2011.04.001. ISSN 0034-4257. - ^ a b Lawler, Joshua J.; White, Denis; Neilson, Ronald P.; Blaustein, Andrew R. (2006-06-26). \"Predicting climate-induced range shifts: model differences and model reliability\". Global Change Biology. 12 (8): 1568–1584. Bibcode:2006GCBio..12.1568L. CiteSeerX 10.1.1.582.9206. doi:10.1111/j.1365-2486.2006.01191.x. ISSN 1354-1013. S2CID 37416127. - ^ Tartakovsky, Daniel M. (2004). \"Delineation of geologic facies with statistical learning theory\". Geophysical Research Letters. 31 (18). Bibcode:2004GeoRL..3118502T. CiteSeerX 10.1.1.146.5147. doi:10.1029/2004gl020864. ISSN 0094-8276. S2CID 16256805. - ^ Hurtt, George C.; Dubayah, Ralph; Drake, Jason; Moorcroft, Paul R.; Pacala, Stephen W.; Blair, J. Bryan; Fearon, Matthew G. (June 2004). \"Beyond Potential Vegetation: Combining Lidar Data and a Height-Structured Model for Carbon Studies\". Ecological Applications. 14 (3): 873–883. Bibcode:2004EcoAp..14..873H. doi:10.1890/02-5317. ISSN 1051-0761. - ^ Akpokodje, E. G. (June 1979). \"The importance of engineering geological mapping in the development of the Niger delta basin\". Bulletin of the International Association of Engineering Geology. 19 (1): 101–108. doi:10.1007/bf02600459. ISSN 1435-9529. S2CID 129112606. - ^ a b c Costa, Iago; Tavares, Felipe; Oliveira, Junny (April 2019). \"Predictive lithological mapping through machine learning methods: a case study in the Cinzento Lineament, Carajás Province, Brazil\". Journal of the Geological Survey of Brazil. 2 (1): 26–36. doi:10.29396/jgsb.2019.v2.n1.3. ISSN 2595-1939. S2CID 134822423. - ^ a b c d Latifovic, Rasim; Pouliot, Darren; Campbell, Janet (2018-02-16). \"Assessment of Convolution Neural Networks for Surficial Geology Mapping in the South Rae Geological Region, Northwest Territories, Canada\". Remote Sensing. 10 (2): 307. Bibcode:2018RemS...10..307L. doi:10.3390/rs10020307. ISSN 2072-4292. - ^ a b c d Culverhouse, PF; Williams, R; Reguera, B; Herry, V; González-Gil, S (2003). \"Do experts make mistakes? A comparison of human and machine identification of dinoflagellates\". Marine Ecology Progress Series. 247: 17–25. Bibcode:2003MEPS..247...17C. doi:10.3354/meps247017. hdl:10261/321441. ISSN 0171-8630. - ^ a b Loyola-Gonzalez, Octavio (2019). \"Black-Box vs. White-Box: Understanding Their Advantages and Weaknesses From a Practical Point of View\". IEEE Access. 7: 154096–154113. Bibcode:2019IEEEA...7o4096L. doi:10.1109/ACCESS.2019.2949286. ISSN 2169-3536. S2CID 207831043. - ^ a b c Kumar, Chandan; Chatterjee, Snehamoy; Oommen, Thomas; Guha, Arindam (April 2020). \"Automated lithological mapping by integrating spectral enhancement techniques and machine learning algorithms using AVIRIS-NG hyperspectral data in Gold-bearing granite-greenstone rocks in Hutti, India\". International Journal of Applied Earth Observation and Geoinformation. 86 102006. Bibcode:2020IJAEO..8602006K. doi:10.1016/j.jag.2019.102006. ISSN 0303-2434. S2CID 210040191. - ^ \"Geologic mapping (UB) - AAPG Wiki\". wiki.aapg.org. Retrieved 2024-06-27. - ^ a b Harvey, A. S.; Fotopoulos, G. (2016-06-23). \"Geological Mapping Using Machine Learning Algorithms\". ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. XLI-B8: 423–430. doi:10.5194/isprsarchives-xli-b8-423-2016. ISSN 2194-9034. - ^ Mattikalli, N (January 1997). \"Soil color modeling for the visible and near-infrared bands of Landsat sensors using laboratory spectral measurements\". Remote Sensing of Environment. 59 (1): 14–28. Bibcode:1997RSEnv..59...14M. doi:10.1016/s0034-4257(96)00075-2. ISSN 0034-4257. - ^ Radford, D. D., Cracknell, M. J., Roach, M. J., & Cumming, G. V. (2018). Geological mapping in western Tasmania using radar and random forests. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 11(9), 3075-3087. - ^ Wang, Y., Ksienzyk, A. K., Liu, M., & Brönner, M. (2021). Multigeophysical data integration using cluster analysis: assisting geological mapping in Trøndelag, Mid-Norway. Geophysical Journal International, 225(2), 1142-1157. - ^ \"Phillips River landslide hazard mapping project\", Landslide Risk Management, CRC Press, pp. 457–466, 2005-06-30, doi:10.1201/9781439833711-28, ISBN 978-0-429-15135-4 - ^ a b Chauhan, S., Sharma, M., Arora, M. K., & Gupta, N. K. (2010). Landslide susceptibility zonation through ratings derived from artificial neural network. International Journal of Applied Earth Observation and Geoinformation, 12(5), 340-350. - ^ a b Biswajeet, Pradhan; Saro, Lee (November 2007). \"Utilization of Optical Remote Sensing Data and GIS Tools for Regional Landslide Hazard Analysis Using an Artificial Neural Network Model\". Earth Science Frontiers. 14 (6): 143–151. Bibcode:2007ESF....14..143B. doi:10.1016/s1872-5791(08)60008-1. ISSN 1872-5791. - ^ Dou, Jie; Yamagishi, Hiromitsu; Pourghasemi, Hamid Reza; Yunus, Ali P.; Song, Xuan; Xu, Yueren; Zhu, Zhongfan (2015-05-19). \"An integrated artificial neural network model for the landslide susceptibility assessment of Osado Island, Japan\". Natural Hazards. 78 (3): 1749–1776. Bibcode:2015NatHa..78.1749D. doi:10.1007/s11069-015-1799-2. ISSN 0921-030X. S2CID 51960414. - ^ a b Kawabata, Daisaku; Bandibas, Joel (December 2009). \"Landslide susceptibility mapping using geological data, a DEM from ASTER images and an Artificial Neural Network (ANN)\". Geomorphology. 113 (1–2): 97–109. Bibcode:2009Geomo.113...97K. doi:10.1016/j.geomorph.2009.06.006. ISSN 0169-555X. - ^ \"International society for rock mechanics commission on standardization of laboratory and field tests\". International Journal of Rock Mechanics and Mining Sciences & Geomechanics Abstracts. 15 (6): 319–368. December 1978. doi:10.1016/0148-9062(78)91472-9. ISSN 0148-9062. - ^ a b c d e f g Byun, Hoon; Kim, Jineon; Yoon, Dongyoung; Kang, Il-Seok; Song, Jae-Joon (2021-07-08). \"A deep convolutional neural network for rock fracture image segmentation\". Earth Science Informatics. 14 (4): 1937–1951. Bibcode:2021EScIn..14.1937B. doi:10.1007/s12145-021-00650-1. ISSN 1865-0473. S2CID 235762914. - ^ Repasky, Kevin (2014-03-31). Development and Deployment of a Compact Eye-Safe Scanning Differential absorption Lidar (DIAL) for Spatial Mapping of Carbon Dioxide for Monitoring/Verification/Accounting at Geologic Sequestration Sites (Report). doi:10.2172/1155030. OSTI 1155030. - ^ a b Bellante, G.J.; Powell, S.L.; Lawrence, R.L.; Repasky, K.S.; Dougher, T.A.O. (March 2013). \"Aerial detection of a simulated CO2 leak from a geologic sequestration site using hyperspectral imagery\". International Journal of Greenhouse Gas Control. 13: 124–137. Bibcode:2013IJGGC..13..124B. doi:10.1016/j.ijggc.2012.11.034. ISSN 1750-5836. - ^ a b c d e f g Bateson, L.; Vellico, M.; Beaubien, S.; Pearce, J.; Annunziatellis, A.; Ciotoli, G.; Coren, F.; Lombardi, S.; Marsh, S. (July 2008). \"The application of remote-sensing techniques to monitor CO2-storage sites for surface leakage: Method development and testing at Latera (Italy) where naturally produced CO2 is leaking to the atmosphere\". International Journal of Greenhouse Gas Control. 2 (3): 388–400. Bibcode:2008IJGGC...2..388B. doi:10.1016/j.ijggc.2007.12.005. ISSN 1750-5836. - ^ a b Bieniawski, Z. T. (1988), \"The Rock Mass Rating (RMR) System (Geomechanics Classification) in Engineering Practice\", Rock Classification Systems for Engineering Purposes, West Conshohocken, PA: ASTM International, pp. 17–17–18, doi:10.1520/stp48461s, ISBN 978-0-8031-6663-9 - ^ a b c d e f g Chen, Jiayao; Zhou, Mingliang; Zhang, Dongming; Huang, Hongwei; Zhang, Fengshou (March 2021). \"Quantification of water inflow in rock tunnel faces via convolutional neural network approach\". Automation in Construction. 123 103526. doi:10.1016/j.autcon.2020.103526. ISSN 0926-5805. S2CID 233849934. - ^ Coerts, Alfred (1996). Analysis of static cone penetration test data for subsurface modelling: a methodology. Koninklijk Nederlands Aardrijkskundig Genootschap/Faculteit Ruimtelijke Wetenschappen Universiteit Utrecht. ISBN 90-6809-230-8. OCLC 37725852. - ^ a b c d e Zhang, Ye; Wang, Gang; Li, Mingchao; Han, Shuai (2018-12-04). \"Automated Classification Analysis of Geological Structures Based on Images Data and Deep Learning Model\". Applied Sciences. 8 (12): 2493. doi:10.3390/app8122493. ISSN 2076-3417. - ^ a b c Li, Zefeng; Meier, Men-Andrin; Hauksson, Egill; Zhan, Zhongwen; Andrews, Jennifer (2018-05-28). \"Machine Learning Seismic Wave Discrimination: Application to Earthquake Early Warning\". Geophysical Research Letters. 45 (10): 4773–4779. Bibcode:2018GeoRL..45.4773L. doi:10.1029/2018gl077870. ISSN 0094-8276. S2CID 54926314. - ^ a b Rouet-Leduc, Bertrand; Hulbert, Claudia; Lubbers, Nicholas; Barros, Kipton; Humphreys, Colin J.; Johnson, Paul A. (2017-09-22). \"Machine Learning Predicts Laboratory Earthquakes\". Geophysical Research Letters. 44 (18): 9276–9282. arXiv:1702.05774. Bibcode:2017GeoRL..44.9276R. doi:10.1002/2017gl074677. ISSN 0094-8276. S2CID 118842086. - ^ Kirchner, James W. (March 2006). \"Getting the right answers for the right reasons: Linking measurements, analyses, and models to advance the science of hydrology\". Water Resources Research. 42 (3). Bibcode:2006WRR....42.3S04K. doi:10.1029/2005wr004362. ISSN 0043-1397. S2CID 2089939. - ^ a b Petty, T.R.; Dhingra, P. (2017-08-08). \"Streamflow Hydrology Estimate Using Machine Learning (SHEM)\". JAWRA Journal of the American Water Resources Association. 54 (1): 55–68. doi:10.1111/1752-1688.12555. ISSN 1093-474X. S2CID 135100027. - ^ Karpatne, Anuj; Ebert-Uphoff, Imme; Ravela, Sai; Babaie, Hassan Ali; Kumar, Vipin (2019-08-01). \"Machine Learning for the Geosciences: Challenges and Opportunities\". IEEE Transactions on Knowledge and Data Engineering. 31 (8): 1544–1554. arXiv:1711.04708. doi:10.1109/tkde.2018.2861006. ISSN 1041-4347. S2CID 42476116. - ^ Farrar, Donald E.; Glauber, Robert R. (February 1967). \"Multicollinearity in Regression Analysis: The Problem Revisited\". The Review of Economics and Statistics. 49 (1): 92. doi:10.2307/1937887. hdl:1721.1/48530. ISSN 0034-6535. JSTOR 1937887. - ^ Taghizadeh-Mehrjardi, R.; Nabiollahi, K.; Kerry, R. (March 2016). \"Digital mapping of soil organic carbon at multiple depths using different data mining techniques in Baneh region, Iran\". Geoderma. 266: 98–110. Bibcode:2016Geode.266...98T. doi:10.1016/j.geoderma.2015.12.003. ISSN 0016-7061. - ^ Delibasic, Boris; Vukicevic, Milan; Jovanovic, Milos; Suknovic, Milija (August 2013). \"White-Box or Black-Box Decision Tree Algorithms: Which to Use in Education?\". IEEE Transactions on Education. 56 (3): 287–291. Bibcode:2013ITEdu..56..287D. doi:10.1109/te.2012.2217342. ISSN 0018-9359. S2CID 11792899. - ^ Hu, Tongxi; Zhang, Xuesong; Bohrer, Gil; Liu, Yanlan; Zhou, Yuyu; Martin, Jay; Li, Yang; Zhao, Kaiguang (2023-05-06). \"Crop yield prediction via explainable AI and interpretable machine learning: Dangers of black box models for evaluating climate change impacts on crop yield\" (PDF). Agricultural and Forest Meteorology. 336 (109458776). - ^ Merghadi, Abdelaziz; Yunus, Ali P.; Dou, Jie; Whiteley, Jim; ThaiPham, Binh; Bui, Dieu Tien; Avtar, Ram; Abderrahmane, Boumezbeur (August 2020). \"Machine learning methods for landslide susceptibility studies: A comparative overview of algorithm performance\". Earth-Science Reviews. 207 103225. Bibcode:2020ESRv..20703225M. doi:10.1016/j.earscirev.2020.103225. ISSN 0012-8252. S2CID 225816933.",
    "text_length": 39113,
    "depth": 1,
    "crawled_at": "2026-01-11T13:23:21.802958"
  }
]